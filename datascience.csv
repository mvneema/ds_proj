Title,Location,Company,Salary,Sponsored,Description
Data Science Accelerator,"Pune, Maharashtra",bp,None,Organic,"Share

India - Maharashtra - Pune

Data Science Accelerator

120684BR

Job advert

We’re equipping our new GBS centre with innovative minds who are excited to lead the transformation of processes with a digital-first approach. Is thinking big – and delivering successful outcomes – in the space of digital solutions and customer experiences your forte? Do you have a passion for encouraging a culture of curiosity, creativity and collaboration? Here’s where you will have every opportunity to challenge conventions and break new ground. Let’s hear from you.

We require an individual that embraces innovation and technology to enable the right business intelligence and analytics strategies. This role is highly collaborative which will involve facilitating brainstorming sessions and working closely with the team to form the correct solutions that will meet the business needs. The candidate is expected to manage the processes and will be responsible for accurate data collection, processing, modelling and analysis.
Partner with stakeholders to collect demand by understanding problem statements, refining requirements & provide insights & analytics solutions on core procurement metrics
Develop business intelligence strategies and analytics solutions to improve business performance, i.e. drive efficiency through standardization, simplification and automation
Use advanced data modelling, predictive modelling and analytical techniques to interpret key findings and leverage these insights into initiatives that will support business outcomes
Collaborate with the business, its applications, solutions and with technical architects to understand the implications of data architecture and to maximize the value of information across the organization
Build, develop and maintain data models, data automation systems, dashboards and performance metrics support that enable key business decisions
Develop processes, techniques and tools to analyze model performance while ensuring data accuracy
Understanding of machine learning approach to define, design and create algorithms
Lead & recommend continuous improvement of processes and adopting latest technologies and methodologies
Working hours (ANZ/ASPAC/UK/Europe/US shift) to support Business Partners
Essential Education & Experience
Bachelor’s Degree in Computer Science, Mathematics, Statistics or a related field
Minimum 7 years of experience managing a client-service oriented function with experience in management of large corporate projects, strategic thinking, relationship management and processes
Minimum 5 years of experience working with multiple source datasets – data mining, data processing, database programming and data analytics
Some understanding of PSCM applications and procurement and general accounting practices
Must have experience with MS Office including advanced Excel skills with the ability to create and manage pivot tables, design and manipulate complex graphs, use of macros to drive automation, use of Query to connect data across several sources
Must have experience in the area of modernized data Visualization Tools (Tableau, Power BI, etc.)
Proficient in programming languages (Python, SQL, SAS, etc.); ability to perform effective querying involving multiple tables and subqueries
Understanding of advanced statistical techniques and concepts (linear algebra, regression models, probabilities, distribution, descriptive and inferential, etc.)
Experience with Machine Learning and/or Predictive Analytics will be an added advantage
Experience using and developing data architectures will be an added advantage
Direct process management experience including best practices, driving innovation, continuous improvement, technologies, procedures and tools
Shared service centre experience is essential
Experience of working cross culturally and in an international environment
Resilient and experienced in working in multi-faceted environment

Segment

Corporate & Functions

Job Family Group

Procurement & Supply Chain Management Group

Relocation available

No

Travel required

Yes - up to 10%

Country

India

About BP

At BP, we’re involved in every aspect of the energy system. With over 73,000 employees in 78 countries, we’re constantly working towards delivering light, heat and mobility to millions, every day. Everyone here has a real contribution to make to the world's ambition of a low carbon future, whether they work in business support, legal, technology, HR, communications, audit or more. They keep our business performing brilliantly and driving the transition to a low carbon future. Join BP and help us change the way we power up the world.

Experience Level

Entry"
Data Engineer,"Bengaluru, Karnataka",Levi Strauss & Co.,None,Organic,"JOB DESCRIPTION
At Levi Strauss & Co, we are revolutionizing the apparel business and redefining the way denim is made.
We are taking one of the world’s most iconic brands into the next century:
from creating machine learning-powered denim finishes to using block-chain for our factory workers’ wellbeing, to building algorithms to better meet the needs of our consumers and optimize our supply chain.
Be a pioneer in the fashion industry by joining our global Data, Analytics & AI “startup with assets,” where you will have the chance to build exciting solutions that will impact our business and at the same time be part of a bigger, across-continents, data community.
As a data engineer, you will build a solid data foundation that powers the entire spectrum from Business Intelligence to Artificial Intelligence. You’ll be critical to helping us in our transition from batch to real-time, one-to-one to many-to-many connections, centrally-managed infrastructure to self-service tools that allow easy experimentation, and from manual to automated processes.
This role will work closely with the Data Science and AI team and will focus on enablement and acceleration of new and existing workflows. We need someone who will bring thoughtful perspective, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend software engineering skills into the field of Machine Learning and Artificial Intelligence.
Duties and responsibilities
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation
Work closely with data scientists and analysts to create and deploy new features
Write efficient and well-organized software to ship products in an iterative, continual-release environment
Monitor and plan out core infrastructure enhancements
Contribute to and promote good software engineering practices across the team
Mentor and educate team members to adopt best practices in writing and maintaining production code
Communicate clearly and effectively to technical and non-technical audiences
Actively contribute to and re-use community best practices
Embody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds
Qualifications
University or advanced degree in engineering, computer science, mathematics, or a related field
Strong experience working with a variety of relational SQL and NoSQL databases
Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Ability to work in Linux environment
Experience working with APIs
Strong knowledge of data pipeline and workflow management tools
Expertise in standard software engineering methodology, e.g. unit testing, code reviews, design documentation
Experience creating ETL processes that prepare data for consumption appropriately
Experience in setting up, maintaining and optimizing databases for production usage in reporting, analysis and ML applications
Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well
Relevant working experience with Docker and Kubernetes preferred
Ability to work with ML frameworks preferred
LOCATION
India, Bangalore - Office
FULL TIME/PART TIME
Full time"
Data Scientist,"Bengaluru, Karnataka",Adecco Group Internal,None,Organic,"SUMMARY:
The Data Scientist works as a part of the Business Intelligence Team and is responsible for discovering insights from data using advanced analytics to help meet business needs. This role is responsible for mining and analyzing complex talent data, building predictive models using statistical and machine learning as well as unsupervised methods in order to provide talent analytics for internal and external customers.

GENERAL RESPONSIBILITIES:

Work with stakeholders throughout the organization to identify opportunities for leveraging analytics to drive business solutions
Mine and analyze data to support and drive business strategies.
Use predictive modeling to improve customer experiences and other business outcomes.
Design and build new data sets for data modeling
Determine new ways to improve data and predictive capabilities
Evaluate and deploy predictive models in Power BI or via other avenues
Coordinate with different functional teams to implement models and monitor outcomes.
Participate in special projects and perform other duties as assigned.

EDUCATION & JOB REQUIREMENTS:

Bachelor’s/Master’s in Statistics, Mathematics, Computer Science or another quantitative field or equivalent experience desired
Use statistical computer languages (R, Python, SLQ, etc.) to mine data
Statistical and Machine Learning
Deploy models in Power BI or potentially via other avenues
KNOWLEDGE, SKILLS & ABILITIES:
Strong problem-solving skills
Experience building models using advanced statistical and machine learning techniques
Experience visualizing/presenting data for stakeholders using PowerBI, ggplot, or similar tools
Skilled in communicating effectively
Attention to detail
Ability to establish and maintain effective working relationships.
Ability to maintain and meet deadlines
Experience with business intelligence tools such as Power BI, Spotfire, Tableau, etc
Experience with VMS and/or ATS tools such as Fieldglass, Beeline, Avature, Taleo, or SuccessFactors, strongly desired but not required"
Data Analytics part time job/internship at Multiple location...,"Chennai, Tamil Nadu",Enerjazz,"₹5,000 - ₹10,000 a month",Organic,"About the company:
We are a green energy startup based in Amsterdam funded by the EU. Our founder is from IIT and we operate from Delhi NCR in India.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Build and optimize databases for our battery testing system 2. Analyze and correlate the test data 3. Work on coding IoT for our product
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 11th Aug'20 and 15th Sep'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Must be a graduate student pursuing engineering Must have a background in maths, physics or a related field Must have excellent quantitative and analytical skills Must have advanced Excel skills Must be proficient with other Microsoft Office applications
Number of internships/jobs available: 1
Categories: Analytics,Data Science"
Jr. Data scientist,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"About the job :
Responsibilities :
Responsibilities include Identify, develop and implement the appropriate statistical
techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that
address business challenges across industry domains.
Define and develop, maintain and evolve data models, tools and capabilities.
Communicate your findings to the appropriate teams through visualisations.
Collaborate and communicate findings to diverse stakeholders.
Provide solutions but not limited to: Object detection/Image recognition, natural language
processing, Sentiment Analysis, Topic Modeling, Concept Extraction, Recommender
Systems, Text Classification, Clustering, Customer Segmentation & Targeting, Propensity
Modelling, Churn Modeling, Lifetime Value Estimation, Forecasting, Modeling Response to
Incentives, Marketing Mix Optimization, Price Optimization.
Qualifications and Experience :
Bachelors Computer Science, Information Systems, Machine Learning, Statistics,
Econometrics, Applied Mathematics, Operations Research or related technical degree with
ability to break complex business problems.
Minimum of 1 to 3 years of experience in a related position, as a data scientist or business
analyst building predictive analytics solutions for various types of business problems.
Knowledge of statistical techniques, machine learning algorithms and deep learning
frameworks like Tensorflow, Theano, Keras, Pytorch.
Minimum 1 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.
Company Profile:
Conceptualized as far back as 2015, and commencing full-time operations in 2018, Blackstraw LLc. is a software products and services company specializing in Artificial Intelligence (AI) and Machine Learning solutions for various industries. We support businesses around the world, including North America, Europe and Asia, working to simplify AI implementation through our platform that expedites data labelling, AI model-training, and, cloud or on-premise deployments.
With more than 100 years of combined work-experience, the 100+-strong Blackstraw Team comprises various experts in the AI value chain. We are a fast-moving team that prides ourselves in rapidly identifying different use-cases and fine-tuning our products to suit specific business needs.
We are focused on providing solutions related to computer vision, natural language processing, Data annotation tool for deep learning models, etc. To stay competitive in business, it is key for organizations to adopt and implement smart AI solutions and service offerings. However, most companies are unable to implement AI rapidly due to the complexity of existing solutions, inadequate data and cost implications.
Our mission is to enable enterprises to adopt AI in an easier, cost-effective and time-efficient manner with a plug-and-play approach to their data.
Blackstraw operations are based out of Mumbai, Pune and Chennai in India."
"Data Science Analyst - R, Python",India,Larsen & Toubro Infotech Limited,None,Organic,"Key Responsibilities • Development of statistical models, (predictive and descriptive) using internal and external data to support customer contact activity and collections strategy decision. • Development of Modelling infrastructure; which includes modelling datasets, model scoring and model monitoring • Analyse data to produce, evaluate, interpret and analyse a range of statistical and written information in order to support recommendations that will have a positive impact on policy and strategy • Develop strong relationships with stakeholders to gather and build modelling requirements and to build confidence and trust in model solutions • Support the identification of value adding opportunities, through proactive analytics into any variances in performance and identify underlying causes. • Contribute to the continuous improvement of approaches to modelling techniques and data structures Experience, Knowledge & Technical Skills • Minimum 2 years’ experience in a Data Science Role. • Proficient in developing models using techniques such as Logistic Regression, Linear Regression, CHAID, Random Forests, Gradient Boosting, Cluster Analysis, Discriminant Analysis, Bayesian Algorithms, Neural Networks, SVM, MARS. • Experienced in the use of Business Intelligence, Analytical and Statistical packages (e.g. SQL, SAS, R-Studio, Python, Azure ML) • Excellent communication, interpersonal and listening skills. For analysts based outside of the UK, ability to communicate in English to a high standard is essential • Ability to present complex and detailed data in a simple to understand and innovative way • A high level of customer focus with a proven record of delivering high standards of customer/seller service and experience • Ability to work independently, pro-actively, multi-task (organised) and deliver. • Also able to work in teams, mediating between team members to diminish negative effects on team productivity and work environment • Basic understanding of key commercial aspects of debt management and understand contribution to business • Degree in a Mathematics/Statistics related subject"
Data Analyst,"New Delhi, Delhi",MedTourEasy,"₹7,00,000 a year",Organic,"We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements

Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
BS in Mathematics, Economics, Computer Science, Information Management or Statistics"
Fresher/Junior Data Science Developer,"Chennai, Tamil Nadu",HTC Global Services Limited,"₹20,000 a month",Organic,"HTC Global Services hiring freshers for Junior Data Science Developer
Job Description:
HTC Global Services hiring freshers (2018 and 2019 ) for the position Junior Data Science Developer.
Candidates those who are in Chennai and immediately available to attend interview with HTC Global Services (MEPZ, Tambaram) can apply.
About HTC Global Services:
HTC Global Services (HTC) is a leading global provider of Information Technology (IT) and Business Process Services (BPS), headquartered in Troy, Michigan, USA. Established in 1990, HTC is an Inc. 500 Hall of Fame company and one of the fastest growing Asian American companies in the USA. Our client base spans over 2000 organizations across the globe. HTC acquired CareTech Solutions in December 2014 and Ciber, Inc. (Currently Ciber Global LLC) in June 2017. These acquisitions enable us to expand our operational capabilities in Healthcare IT and Technology Transformation services.
HTC is an ISO 9001 and 27001 certified company with processes compliant to SEI CMM Level 5. With over 10 global delivery centers and operating presence in several countries, we serve global clients across multiple time zones. Our ‘Business Partner’ approach enables us to offer high business value for our clients. It also brings in the benefit of repeated business for HTC. Our strategic solutions enable clients to transform and thrive in the changing world.
Designation : Fresher/ Junior Data Science Developer.
Job Requirements:
Key Skills:
Should have good knowledge in basics OOPS concepts.
Must possess good communication skill(both oral and written).
Qualification :
· Bachelors or masters in Science majored in Math/Statistics/Econometrics.
· Bachelors in Engineering with Data science/AI/ML as part of the curriculum
· Management graduates with specialisation in Analytics/Data Science/AI/ML.
Eligiblity Citeria:
· First class throughout curriculum is mandatory(from 10th standard to degree).
Certificates/Diplomas:
Should have done certification in date science, Analytics, Python from leading institutions or through online courses from Coursera/datacamp/udemy/udacity
Must to have:
Have few practical projects experience for a maximum of 2 years, active in Kaggle or other forums.
Probation period : One Year
Salary Offered : CTC 3.00 L pa
Agreement Period:
3 Years from the date of joining and should be ready to submit original documents.
Rounds of Interview:
Round 1: Aptitude (Technical and English )
Round 2: Technical & HR at the company.
Job Type: Permanant, Full-time
Salary: ₹300,000.00 per annum from Training onwards.
Benefits:
Provident fund (PF)
Paid leaves / Leave encashment
Industry:
Software Development
Interested candidates can reach me at :
Pavithra.M
Senior HR @ HTC Global Services Limited
Official Mobile Number: 9840604551
Job Types: Full-time, Fresher
Pay: From ₹20,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Science Internship,"Chennai, Tamil Nadu",SIMPLIFAID PVT LTD,"₹15,000 a month",Organic,"About the company:
We are into building products using cutting edge technologies using AI/ ML for the development sector. A deep-tech startup for social good that harnesses the power of digital solutions to help cities graduate to inclusive and sustainable cities. ""Our solutions are driven for societies to flourish by adopting cutting edge technologies as an enabler for its comprehensive and inclusive development"". Our Motto: We help measure the quality of service delivery and co-create action plans with municipal officials based on our location intelligence. Why do yearly performance assessments? We engage with state and national governments for conducting concurrent performance assess. We support other social enterprises, NGOs, and foundations who are on a similar mission to transform Indian cities with our location intelligence. Why don't you speak with us before making an investment in a certain location? We are here to provide you unbiased review that is most critical for your investment decision!
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on Python, machine learning, deep learning, and IoT products 2. Implementing models as APIs for consumption of business 3. Building data products using cutting edge technologies
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 3rd Aug'20 and 7th Sep'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 2
Additional details:
The intern would get an incentive of up to Rs. 10000 based on the delivery of work.
Categories: Data Science,Engineering"
Machine Learning Internship,"Chennai, Tamil Nadu",E-con Systems India Private Limited,"₹20,000 a month",Organic,"About the company:
e-con Systems is a product company focused on OEM products with the sole motive to help customers to speed up the time to market. Founded in 2003, e-con Systems has been a pioneer in the OEM Cameras and computer on module products. Camera modules include standalone MIPI camera modules and USB cameras. e-con Systems notable contribution has been in the launch of the World's first UVC compatible USB 3.0 camera. e-con Systems was also the world's first standalone stereo camera supplier. System on modules include processors from NVIDIA, NXP(Freescale), and Texas Instruments. These computers on modules have support for android and Linux.
About the internship/job:
Selected interns day-to-day responsibilities include: 1. Work on object detection model pruning in Tensorflow 2. Work on improving the accuracy metric of the object detection model without reducing the performance 3. Work on implementing semantic segmentation model in Tflite
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 4
Categories: Machine Learning,Data Science"
Online Trainer-Data Science,"Jaipur, Rajasthan",Parshi Emerging Technologies Pvt Ltd,None,Organic,"Urgent Requirement for Full-Time and Part Time Trainers across all India module including: Python, R , Machine learning, Data Science
Location: Multiple location in India/ Online
Experience: 2-8+Years of relevant
Job Types: Full-time, Part-time, Contract
Salary: ₹15,000.00 - ₹100,000.00 per month
Experience:
work: 1 year (Required)
total work: 1 year (Required)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes"
Data Science Online Trainer,India,Prognoz,None,Organic,"Job Id : PTPL/HR/8
Anywhere in India
1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics."
Data Science Internship,"Bengaluru, Karnataka",OTO Capital,"₹12,000 a month",Organic,"About the company:
In the recent years - consumers have changed and love to upgrade faster. They shift from one city to another for better career options, value access over ownership and perceive ownership as an additional responsibility of care and maintenance. Hence, there is a big need of providing him/her a hassle-free option to own (cars, bikes, etc.) without much commitment. OTO envisions the concept of 'Own Together' enabling ownership (starting with cars) in a new way of financing with flexible usage terms. With OTO, consumers pay for a car with up to 25% low, all-in, month-to-month payment. We aim to redefine the $40 Billion+ market of Car Ownership in India at first. We have already partnered with 100+ showrooms & corporates to provide this offering to the car purchasers at a point of sales.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. â€¢ Work with the data science team and contribute to the ongoing project 2. â€¢ Research about different techniques that can be used to achieve the goal of the project 3. â€¢ Practically understand the problem statement and Implement the research done to develop custom data models and algorithms 4. â€¢ Extract, Harmonize, clean, and merge data from different data sources for further use 5. â€¢ Build machine learning solutions to drive optimization and improvement in product and business strategies 6. â€¢ Develop processes and tools to monitor and analyze model performance and data accuracy
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
â€¢ Some experience working with large data i.e. mining, cleaning, manipulating data sets, and building statistical models â€¢ Research-oriented mind-set â€¢ Strong problem-solving skills with a drive to learn and master new technologies and techniques â€¢ Knowledge about statistical computer languages (Python, R, SQL, etc.) to draw insights from large data sets â€¢ Knowledge of machine learning and statistical techniques (OCR, clustering, decision tree learning, artificial neural networks, regression, statistical tests, etc.) and their real-world advantages/drawbacks â€¢ Knowledge about automobile and finance industry will be an extra advantage
Number of internships/jobs available: 2
Categories: Data Science"
Data Scientist,"Bengaluru, Karnataka",Netradyne,None,Organic,"Role and Responsibilities
You will perform analyses, build models, and design/conduct experiments to improve road safety and reduce accidents. You will
Design, develop and evaluate statistical and predictive models to understand driving risk.
Build models and design product features to improve scores, compliance and other key metrics.
Conduct statistical experiments and data-driven metrics to guide product features.
Perform data wrangling tasks such as acquiring, cleaning, structuring and enriching data.
Communicate and present findings in a clear and intuitive manner.
Build story-telling dashboards.
Requirements:
B. Tech, M. Tech or PhD in computer science, electrical engineering, statistics, math or a related area.
Good hands-on experience of coding – Python (required), R, etc.
Experience working with databases – Postgres, MongoDB, etc.
Strong knowledge of statistics, probability, and estimation theory.
Experience with deriving useful insights from large and complex datasets.
Experience with data visualization and storytelling.
Strong ability to communicate highly technical results to a diverse audience.
Ability to develop quick proof of concept solutions in a fast-paced startup environment.
Flexible and can-do approach. Ability to adjust to changing priorities.
Desired Skills:
Experience with predictive analytics is a plus.
Experience with data visualization tools like Tableau, Plotly-Dash is a plus.
Experience with designing and conducing successful statistical experiments is a plus."
Data Science Developer,"Bengaluru, Karnataka",Mphasis,None,Organic,"Implement techniques for Predictive analysis to determine a good fit machine learning model
Review all available attributes that may contribute to data anomaly based on identified use case
Conduct Data profiling, Data mining, and Data cleaning
Write complex algorithms using available ML tools and editors
Conduct Data Visualization and Trend Analysis
Work location: Bangalore & Hyderabad
Additional requirement:
Enthusiastic female engineers preferred"
Python Developer for Product Based Edutech Company,"Bengaluru, Karnataka",Shaw Academy,None,Organic,"Job Description:
· Strong programming skills with Python(numpy, pandas)
· Proficient experience of back-end programming language - Python.
· Experience in projects which include ETLs for analysis and reporting with huge volumes of data
· Experience in RDBMS and SQL programming
· Data migration, transformation, and scripting.
· Excellent problem-solving skills.
· Outputting data in different formats.
· Independent analytical problem solving skills
· Reporting skills in Tableau
· Implementing automated testing platforms and unit tests.
Key Job Responsibilities:
· Should be responsible for end to end development and testing of solutions for analytics team
· Create data tools for analytics and data science team members that assist them in building and optimizing models & reporting.
· Create and maintain optimal data pipeline architecture
· Should be able to Independently develop reports in Tableau
· This report will include core technical skills along with building reports on key business metrics.
· Business processes automations
Job Type: Full-time
Salary: ₹100,000.00 - ₹1,000,000.00 per year
Experience:
Data Science : 1 year (Preferred)
Python Development: 1 year (Preferred)
Work Remotely:
Temporarily due to COVID-19"
Data Scientist,"Bengaluru, Karnataka",Netradyne,None,Organic,"Role and Responsibilities
You will perform analyses, build models, and design/conduct experiments to improve road safety and reduce accidents. You will
Design, develop and evaluate statistical and predictive models to understand driving risk.
Build models and design product features to improve scores, compliance and other key metrics.
Conduct statistical experiments and data-driven metrics to guide product features.
Perform data wrangling tasks such as acquiring, cleaning, structuring and enriching data.
Communicate and present findings in a clear and intuitive manner.
Build story-telling dashboards.
Requirements:
B. Tech, M. Tech or PhD in computer science, electrical engineering, statistics, math or a related area.
Good hands-on experience of coding – Python (required), R, etc.
Experience working with databases – Postgres, MongoDB, etc.
Strong knowledge of statistics, probability, and estimation theory.
Experience with deriving useful insights from large and complex datasets.
Experience with data visualization and storytelling.
Strong ability to communicate highly technical results to a diverse audience.
Ability to develop quick proof of concept solutions in a fast-paced startup environment.
Flexible and can-do approach. Ability to adjust to changing priorities.
Desired Skills:
Experience with predictive analytics is a plus.
Experience with data visualization tools like Tableau, Plotly-Dash is a plus.
Experience with designing and conducing successful statistical experiments is a plus."
Fresher/Junior Data Science Developer,"Chennai, Tamil Nadu",HTC Global Services Limited,"₹20,000 a month",Organic,"HTC Global Services hiring freshers for Junior Data Science Developer
Job Description:
HTC Global Services hiring freshers (2018 and 2019 ) for the position Junior Data Science Developer.
Candidates those who are in Chennai and immediately available to attend interview with HTC Global Services (MEPZ, Tambaram) can apply.
About HTC Global Services:
HTC Global Services (HTC) is a leading global provider of Information Technology (IT) and Business Process Services (BPS), headquartered in Troy, Michigan, USA. Established in 1990, HTC is an Inc. 500 Hall of Fame company and one of the fastest growing Asian American companies in the USA. Our client base spans over 2000 organizations across the globe. HTC acquired CareTech Solutions in December 2014 and Ciber, Inc. (Currently Ciber Global LLC) in June 2017. These acquisitions enable us to expand our operational capabilities in Healthcare IT and Technology Transformation services.
HTC is an ISO 9001 and 27001 certified company with processes compliant to SEI CMM Level 5. With over 10 global delivery centers and operating presence in several countries, we serve global clients across multiple time zones. Our ‘Business Partner’ approach enables us to offer high business value for our clients. It also brings in the benefit of repeated business for HTC. Our strategic solutions enable clients to transform and thrive in the changing world.
Designation : Fresher/ Junior Data Science Developer.
Job Requirements:
Key Skills:
Should have good knowledge in basics OOPS concepts.
Must possess good communication skill(both oral and written).
Qualification :
· Bachelors or masters in Science majored in Math/Statistics/Econometrics.
· Bachelors in Engineering with Data science/AI/ML as part of the curriculum
· Management graduates with specialisation in Analytics/Data Science/AI/ML.
Eligiblity Citeria:
· First class throughout curriculum is mandatory(from 10th standard to degree).
Certificates/Diplomas:
Should have done certification in date science, Analytics, Python from leading institutions or through online courses from Coursera/datacamp/udemy/udacity
Must to have:
Have few practical projects experience for a maximum of 2 years, active in Kaggle or other forums.
Probation period : One Year
Salary Offered : CTC 3.00 L pa
Agreement Period:
3 Years from the date of joining and should be ready to submit original documents.
Rounds of Interview:
Round 1: Aptitude (Technical and English )
Round 2: Technical & HR at the company.
Job Type: Permanant, Full-time
Salary: ₹300,000.00 per annum from Training onwards.
Benefits:
Provident fund (PF)
Paid leaves / Leave encashment
Industry:
Software Development
Interested candidates can reach me at :
Pavithra.M
Senior HR @ HTC Global Services Limited
Official Mobile Number: 9840604551
Job Types: Full-time, Fresher
Pay: From ₹20,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Pune, Maharashtra",Springer Nature,None,Organic,"-
Responsibilities –
Understanding business case and acquire a thorough understanding of the data pertaining to the case
Research, conceptualize and implement analytical approaches and predictive modeling to evaluate scenarios
Propose and implement the entire solution including scope definition, hypothesis formation, data cleaning and preparation, feature engineering, modeling, and validation
Design, develop and execute analytic techniques on large complex structured and unstructured (text) data sets
Understand and implement published research papers and build a business solution
Visualize the data and suggest better algorithms and approaches
Must have:
Should have a strong educational background in Computer Science (preferably premier institutes)
Should have an excellent understanding of Machine Learning, Deep Learning concepts, and algorithms
Should have experience in development and usage of NLP tools like POS tagger, Shallow parser, Dependency parser, etc
Should have experience in using Machine Learning toolkits like Tensorflow, Keras, NumPy, NLTK, Sklearn, Pandas, Matplotlib
Should have experience with using text embedding like Word2Vec, Glove, fastText.
OOPS, Core Java or Python, development and optimization skills
Nice to have:
Should have an understanding of parallel computing architectures like Spark, Hadoop for ML applications
Understanding of RDBMS, NoSQL databases
Knowledge on Agile Methodologies, code sharing platforms like Github
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities."
Machine Learning Engineer Intern (Image Recognition in Biome...,"Bengaluru, Karnataka","Kaleidoscope Business Solutions, Inc","₹25,000 - ₹45,000 a month",Organic,"Job Summary
The Machine Learning Engineer Intern is a hands-on individual contributor who loves to transform raw data into valuable insight. You are self-directed and love to take a problem from its early definition into a concrete plan and have your hands in all steps of the process, from data collection and preparation to model selection and training, all the way through deployment of proof of concept and ideally to production.
Responsibilities and Duties
- Create processes to clean and augment our existing data set of 50000+ images
- Select appropriate image recognition models for classification and object detection
- Train models, including hyper parameter tuning and local / cloud processing
- Report on model accuracy and utility
- Develop proof-of-concept applications that implement your models to demonstrate business value
- Deploy proof-of-concept applications to internal beta testers
- Work with our engineers to deploy your models into real-world applications that help us improve patients' lives while making our healthcare system more efficient
Build neural network architectures for the KBS platform.
Develop prototypes and execute experiments to help guide engineering efforts.
Explore new model families and machine learning algorithms.
Experience with Deep Learning and CNNs
Key Skills
machine learning, deep learning , computer vision, react, neural networks
Required Experience and Qualifications
Requirements:
- Min BS in Computer Science, Electrical Engineering, Applied Mathematics or Physics
- 1+ years experience in Computer Vision, Machine Learning, Image Analysis
- Strong background in Python and Linux
- Strong foundations in probability, linear algebra, and optimization.
- Background in statistical modeling and inference.
- Experience with 3rd party Vision/Math tools such as Keras, Pytorch, TensorFlow, OpenCV, AWS, etc
Pluses:
- Experience with TensorFlow Lite on mobile
- Experience working with MobileNet SSD architecture
- Experience with object detection and/or digit recognition
- Swift / Objective C / Java / C++ experience on mobile devices
- Experience building APIs or microservices in Python or Node.js
- Exposure to React Native
Preferred Qualifications
Experience with large-scale industrial applications of statistical modeling and inference.
Experience with statistical modeling across a diverse range of data sets and domains.
Masters in Computer Science (AI/ML specialization), Statistics, Mathematics (Probability), or equivalent.
Benefits
**We:
Give you the newest MacBook Pro with accessories and best equipment / work setup to make you feel productive and empowered to do your best work once you complete one full year with Kaleidoscope Business Solutions.
We care about your professional development and give you Personal Innovation Fund (education reimbursement) once you complete one full year with Kaleidoscope Business Solutions.
Offer you opportunities for international travel
Provide a modern office environment
Offer competitive salary and bonuses
Contribute to open source software
About Kaleidoscope Business SolutionsWe're a AI software consulting firm headquartered in San Francisco with offices in India. We are a growing 10+ team of engineers, designers and project managers working with a client roster of leading organizations from around the world. Our clients are a mix of venture-backed start-ups, Fortune 500 brands, and innovative NGOs.
View our website for more details. www.kb.solutions
Still not sure about applying to us?
If you're interested in applying for this job, we need three important things from you after you click the ""Apply for this job"" button below:
- a short cover letter (paragraph) describing why this seems like a good fit to you- a link to your GitHub profile (if any)- your LinkedIn profile (if any)
If the idea of working with smart people on cutting-edge technology to save lives is appealing... apply!
Also, if you put the words ""Can't wait for MACHINE LEARNING!"" in your cover letter, it will please us to know that you took the time to read this post and have good attention to detail.
We're looking forward to hearing from you!
Job Types: Full-time, Temporary, Internship, Contract
Salary: ₹25,000.00 - ₹45,000.00 per month
Experience:
machine learning: 1 year (Required)
Deep Learning: 1 year (Required)
Education:
Bachelor's (Required)
Location:
Bengaluru, Karnataka (Preferred)
Industry:
Software Development
Work Remotely:
Yes"
"Online Trainer - Python, ML, Data Science","Coimbatore, Tamil Nadu",Nowa Labs,"₹1,000 an hour",Organic,"We are looking for a trainer in Python, Data Science and Machine Learning Technologies.
You need to be extremely good in
- Python
- numpy
- pandas
- sci-kit-learn
- Maths concepts required for Data Science
- Machine Learning fundamentals
You will be giving online training to the students across the world.
We would want you to present webinars and do mentorship to AI aspirants.
Job Types: Part-time, Contract
Salary: From ₹1,000.00 per hour
Experience:
total work: 1 year (Preferred)"
AI and Deep Learning Trainer,"Bengaluru, Karnataka",Perceptrons,"₹20,000 - ₹40,000 a month",Organic,"Job Description:
1. Good domain knowledge on data science with min 3-4 yrs
2. Good knowledge on Hadoop, Statistics, SQL,Python,Machine Learning,Deep Learning,NLP, Tensor-flow etc
3. Able to take CLASSROOM or ONLINE Daily/weekend classes at Rajajinagar Branch, Bangalore.
4. Need to handle 2-3 Batches per month (Incl Online & Classroom)
Skills Required:
Artificial Neural Network (ANN), Deep Learning, Machine Learning (ML), NLP, Computer Vision, etc
We are Global AI training institute located in Bangalore and US. for more details visit us at perceptrons.ai
Job Types: Full-time, Part-time
Salary: ₹20,000.00 - ₹40,000.00 per month
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Bachelor's (Preferred)
Industry:
Education & Instruction
Work Remotely:
Yes"
Data Science Developer,"Bengaluru, Karnataka",Mphasis,None,Organic,"Implement techniques for Predictive analysis to determine a good fit machine learning model
Review all available attributes that may contribute to data anomaly based on identified use case
Conduct Data profiling, Data mining, and Data cleaning
Write complex algorithms using available ML tools and editors
Conduct Data Visualization and Trend Analysis
Work location: Bangalore & Hyderabad
Additional requirement:
Enthusiastic female engineers preferred"
Data Scientist,"Bengaluru, Karnataka",ABB,None,Organic,"Basic Info
Location
Bangalore, Karnataka, India
Job type
Full-Time
Contract
Regular/Permanent

Take the next step in your career at ABB, working in a team that is dedicated to creating a future where innovative digital technologies allow greater access to cleaner energy.
ABB Global Industries and Services Private Limited (GISPL) is a company which has 5 functions to support ABB projects globally. We have 2000 employees as a part of this company serving in the areas of Research, Development, Engineering center and Regional ERP support center which contributes to ABB's 5 divisions globally. In 2015 the company name was registered as ABB Global Industries and Services Private Limited (GISPL).

ABB India Corporate Research Center (INCRC), co-located with ABB’s largest global software development and engineering units. INCRC performs research and develops technologies and concepts for ABB’s global business divisions. We collaborate with various ABB corporate research centers, premier academic institutes in India and abroad.

Reporting to the Research Department Manager and you will be supporting strategic corporate technology direction by focusing on solving industrial problems through reliable research work.
Your responsibilities
Gathering requirements and identifying of value-adding use cases for data-driven solutions in cooperation with ABB’s business divisions and end customers.
Evaluating and developing of mathematical algorithms (including open source data analysis/ machine learning libraries) for identified use cases.
Analyzing the errors of the model and designing strategies to overcome them.
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
Developing of proof of concepts, prototypes, and support in pilot evaluation and productization of solutions.
Communicating of project results to technical experts and management.
Creating of Intellectual property (invention disclosures) and publications in scientific conferences and journals.
Living ABB’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.
Your background
Ph.D./Master’s degree in Data Science/Information Science/Computer Science/Chemical/ Electrical/Electronics/Mechatronics/Controls/Industrial Engineering with a strong publication record.
Required 0 to 5 years of experience in industrial research for data analytics and machine learning for monitoring, diagnosis and predictive maintenance and related data visualisation tools.
Good knowledge of basic statistics (Hypothesis Testing, Probability, Distributions, etc.). Required multivariate statistical analysis (such as PCA, PLS, etc.), machine learning (supervised learning techniques such as ANN, Decision Trees, SVM, Naïve Bayes etc.)
Unsupervised learning techniques such as k-means, hierarchical clustering, Deep Learning, Time-series analysis, Signal Processing and related areas.
Proficiency in Python programming language preferably interacting with industrial data.
More about us
Bring your very own sense of pride and purpose as you help us drive forward the Fourth Industrial Revolution – creating a sustainable future for our planet, and your career. Join ABB and harness the power of our diverse global network, as you collaborate with and learn from our world-class teams. Above all, challenge yourself every day. Let’s write the future, together.
Important, please include in your CV the following passage:
“I hereby agree for my personal data, included in my job application, to be processed in line with the needs of recruitment, in accordance with the Law on Personal Data Protection of 29th August 1997 (Law Gazette from 2002, No.101, heading 926, as amended).”
Reference Number
IN75590425_E1
Publication date
2020-08-12"
Junior Data Scientist/ta,India,WSD Consultant,"₹7,00,000 - ₹15,00,000 a year",Organic,"Junior Data Scientist/ta
Gurgaon, Bangalore, Mumbai, Pune, Chennai, Hyderabad


candidate should qualify checklist written below:

Ques: Does the candidate has strong knowledge in Data Science/ Machine Learning/ Artificial Intelligence ? Please mention

Ques: Is the candidate willing to work full time as a Data Science program Manager/ Academic and content delivery/ End to End Curriculam delivery and management ?

Ques: Does the candidate has Data Science/ Machine learning content development and academic delivery experience/ Faculty Development programs in any Teaching Institution or E - Learning Companies?


Job Specifications

Exp. 1.0 - 5.0 Year(s)
Annual Fixed CTC Min : 7.0 Lacs Max: 15.0 Lacs
Qualification B.Tech/B.E. , Any Post Graduation
No of openings 3
Additional Doc/Msg
Experience
1 - 5 Years

Salary
7 Lac To 15 Lac P.A.

Industry
IT Software - Application Programming / Maintenance

Qualification
Other Bachelor Degree, MD/Medicinae Doctor, Other Doctorate Degree

Key Skills
Data Scientist


About Company
Company Name
Great Learning


About Company
Great Learning is an online and hybrid learning company that offers high-quality, impactful, and industry-relevant learning programs to working professionals. These programs help them master data-driven decision-making regardless of the sector or function they work in and secure their career growth into the future. These programs are delivered through a convenient and robust technology-enabled experience with no disruption to their careers.

Contact Person
Pramod Kumar

Address
Gurgaon

Mobile
8506010400

Email ID
jobwsd@gmail.com"
Data Science Internship,"Bengaluru, Karnataka",OTO Capital,"₹12,000 a month",Organic,"About the company:
In the recent years - consumers have changed and love to upgrade faster. They shift from one city to another for better career options, value access over ownership and perceive ownership as an additional responsibility of care and maintenance. Hence, there is a big need of providing him/her a hassle-free option to own (cars, bikes, etc.) without much commitment. OTO envisions the concept of 'Own Together' enabling ownership (starting with cars) in a new way of financing with flexible usage terms. With OTO, consumers pay for a car with up to 25% low, all-in, month-to-month payment. We aim to redefine the $40 Billion+ market of Car Ownership in India at first. We have already partnered with 100+ showrooms & corporates to provide this offering to the car purchasers at a point of sales.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. â€¢ Work with the data science team and contribute to the ongoing project 2. â€¢ Research about different techniques that can be used to achieve the goal of the project 3. â€¢ Practically understand the problem statement and Implement the research done to develop custom data models and algorithms 4. â€¢ Extract, Harmonize, clean, and merge data from different data sources for further use 5. â€¢ Build machine learning solutions to drive optimization and improvement in product and business strategies 6. â€¢ Develop processes and tools to monitor and analyze model performance and data accuracy
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
â€¢ Some experience working with large data i.e. mining, cleaning, manipulating data sets, and building statistical models â€¢ Research-oriented mind-set â€¢ Strong problem-solving skills with a drive to learn and master new technologies and techniques â€¢ Knowledge about statistical computer languages (Python, R, SQL, etc.) to draw insights from large data sets â€¢ Knowledge of machine learning and statistical techniques (OCR, clustering, decision tree learning, artificial neural networks, regression, statistical tests, etc.) and their real-world advantages/drawbacks â€¢ Knowledge about automobile and finance industry will be an extra advantage
Number of internships/jobs available: 2
Categories: Data Science"
Looking for a machine learning /Data Science Trainer,"Delhi, Delhi",Elite Institute sector-4 Rohini,"₹50,000 - ₹1,00,000 a month",Organic,"Knowledge and working experience in one or more of the following areas: Natural Language Processing, Clustering, and Classifications of Text, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Knowledge Engineering, Search Rank and Recommendation.
Candidate with excellent communication skills and passion for teaching and technology only should apply. Needs to train in- house students, beginners, and professionals on Python and Machine Learning.
Designing training programmers based on the needs of the organization.
Must be presentable and smart and should have very good communication skills.
Job Types: Part-time, Commission
Salary: ₹50,000.00 - ₹100,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Master's (Preferred)"
Deep Learning Intern WFH,Remote,Clarion Analytics LLP,None,Organic,"CLARION ANALYTICS is looking for Deep Learning Interns for its IVA team to develop and commercialise Artificial Intelligence solutions for the markets.
Role
Construct ,curate and work on problem specific datasets.
Study and develop state of the art techniques in deep learning.
Analyze and improve performance of GPU implementations.
Your Background
You are pursuing a PhD or Masters or Bachelor or equivalent in Computer Science, Artificial Intelligence, or Applied Math.
Solid understanding for deep learning and a strong algorithmic background
Excellent programming, debugging, performance analysis and test design skills.
Excellent understanding of deploying data pipelines for Computer Vision projects.
Excellent understanding of NVIDIA Jetson series and deploying Deep learning models on the edge.
Good to Have
Deep Learning experience.
Experience with DL Frameworks (e.g. TensorFlow, PyTorch, NVIDIA DeepStream).
Excellent C/C++ and Python programming skills.
GPU programming (CUDA or OpenCL).
Experience doing performance analysis and tuning.
Job Types: Full-time, Internship
Experience:
Raspbery, NVIDIA Jetson: 1 year (Preferred)
Deep Machine Learning: 1 year (Preferred)
TensorFlow, PyTorch , Caffe or other DCNN Framework: 1 year (Preferred)
NVIDIA CUDA , C/C++: 1 year (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Associate Professional Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Assists in the application of data analysis and data modeling techniques to establish, modify, and maintain basic data structures and their entity descriptions, relationship descriptions, and attribute definitions according to client specifications.
Assists in the analysis and validation of basic database structures, models and processes to ensure definition according to business objectives and operations.
Communicates with clients about matters of significance and discrepancies related to data to ascertain correct information and correct errors.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science or related field preferred
Zero or more years of experience in programming or data analysis
Experience working with relevant programming languages and relational databases
Experience working with data modeling practices and procedures
Experience working with company software and hardware products
Other Qualifications
Basic research and data analysis skills
Communication skills to communicate with designers, management and customers
Personal computer and business solutions software skills
Ability to work in a team environment
Work Environment
Office environment"
Artificial Intelligence/Machine Learning,"Jaipur, Rajasthan",CAD DESK,"₹20,000 - ₹40,000 a month",Organic,"B.E/Masters in Computer science/Statistics or equivalent
At least 3years of experience in predictive modeling, strong knowledge of machine learning algorithms.
Strong in R,Python/ Strong knowledge of C/C++, software design, programming techniques, and AI algorithms.
Very strong SQL and data visualization/ programming, ideally CUDA C/C++.
Experience with parallel Strong communication and organization skills, with a logical approach to problem solving, good time management, and task prioritization skills.
Job Type: Contract
Salary: ₹20,000.00 - ₹40,000.00 per month
Experience:
AI/ML Training: 1 year (Required)
Online training: 1 year (Preferred)
Education:
Bachelor's (Required)"
Data Scientist,"Pune, Maharashtra",Springer Nature,None,Organic,"-
Responsibilities –
Understanding business case and acquire a thorough understanding of the data pertaining to the case
Research, conceptualize and implement analytical approaches and predictive modeling to evaluate scenarios
Propose and implement the entire solution including scope definition, hypothesis formation, data cleaning and preparation, feature engineering, modeling, and validation
Design, develop and execute analytic techniques on large complex structured and unstructured (text) data sets
Understand and implement published research papers and build a business solution
Visualize the data and suggest better algorithms and approaches
Must have:
Should have a strong educational background in Computer Science (preferably premier institutes)
Should have an excellent understanding of Machine Learning, Deep Learning concepts, and algorithms
Should have experience in development and usage of NLP tools like POS tagger, Shallow parser, Dependency parser, etc
Should have experience in using Machine Learning toolkits like Tensorflow, Keras, NumPy, NLTK, Sklearn, Pandas, Matplotlib
Should have experience with using text embedding like Word2Vec, Glove, fastText.
OOPS, Core Java or Python, development and optimization skills
Nice to have:
Should have an understanding of parallel computing architectures like Spark, Hadoop for ML applications
Understanding of RDBMS, NoSQL databases
Knowledge on Agile Methodologies, code sharing platforms like Github
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities."
Data Scientist,"Bengaluru, Karnataka",Netradyne,None,Organic,"Role and Responsibilities
You will perform analyses, build models, and design/conduct experiments to improve road safety and reduce accidents. You will
Design, develop and evaluate statistical and predictive models to understand driving risk.
Build models and design product features to improve scores, compliance and other key metrics.
Conduct statistical experiments and data-driven metrics to guide product features.
Perform data wrangling tasks such as acquiring, cleaning, structuring and enriching data.
Communicate and present findings in a clear and intuitive manner.
Build story-telling dashboards.
Requirements:
B. Tech, M. Tech or PhD in computer science, electrical engineering, statistics, math or a related area.
Good hands-on experience of coding – Python (required), R, etc.
Experience working with databases – Postgres, MongoDB, etc.
Strong knowledge of statistics, probability, and estimation theory.
Experience with deriving useful insights from large and complex datasets.
Experience with data visualization and storytelling.
Strong ability to communicate highly technical results to a diverse audience.
Ability to develop quick proof of concept solutions in a fast-paced startup environment.
Flexible and can-do approach. Ability to adjust to changing priorities.
Desired Skills:
Experience with predictive analytics is a plus.
Experience with data visualization tools like Tableau, Plotly-Dash is a plus.
Experience with designing and conducing successful statistical experiments is a plus."
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Research Associate Intern,"Kamakshipalya, Bengaluru, Karnataka","Forte Research Systems India Private ltd.,",None,Organic,"Essential Job Duties:
Understand and interpret clinical trial study protocols to design and develop calendars. Understand and interpret clinical trial agreements and sponsor budgets to develop site budgets for the protocol.
Design and develop case report forms for clinical trial study protocols
Develop a familiarity with Forte’s Clinical Trial Management Software (CTMS) and Electronic Data Capture (EDC) software to utilize related functionalities in the design and development of calendars, budgets, financials and case report forms.
Work closely with reporting manager to complete daily/ weekly calendars, budgets, financials and/or case report forms design to meet with pre-determined quality criteria.
Understand and utilize internal case management software and other reporting software to ensure that daily/weekly work assignments are appropriately tracked and completed.
Actively participate in team meetings and contribute meaningfully to discussions related to specific customer cases and/or protocols.
Position Requirements:
Minimum qualification: Degree in Life sciences/related fields.
Knowledge of clinical research methodology, industry regulations and Good Clinical Practice guidelines related to human research
Expected to work independently, as well as in a team environment
Good organizational and administrative abilities
Familiarity with MS Office and various business software
Preferred: 0-1 year work experience in job areas such as:
o Clinical trial coordinator at site
o Clinical data management
o Pharmacovigilance
o Records management
Key Personal Attributes:
Highly personable nature that fosters team work
Excellent communication skills – oral as well as written
High energy and positive attitude towards working in a culturally diverse environment
Self-motivated and proactive
Working Hours:
Monday-Friday 9:00 a.m. to 5:00 p.m."
Data Analyst / Data Scientist | Internship | Tech-Savvy|,"Indore, Madhya Pradesh",Anaxee Digital Runners Pvt Ltd,None,Organic,"Job role:
As a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.

Job Location: Indore | Full-Time Internship | Stipend - Performance-Based |

About the company:
Anaxee Digital Runners is building India's largest last-mile verification & data collection network of Digital Runners (shared feet-on-street, tech-enabled) to help Businesses & Consumers reach remotest parts of India, on-demand. KYC | Field Verification | Data Collection | eSign | Tier-2, 3 & 4
Sounds like a moonshot? It is. We want to make REACH across India (remotest places), as easy as ordering pizza, on-demand. Already serving 11000 pin codes (57% of India) | Website: www.anaxee.com
Important: Check out our company pitch (6 min video) to understand this goal - https://www.youtube.com/watch?v=7QnyJsKedz8

Responsibilities:
Ensure that data flows smoothly from source to destination so that it can be processed
Utilize strong database skills to work with large, complex data sets to extract insights
Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes
Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure
Build tools for automating repetitive tasks so that bandwidth can be freed for analytics
Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions
Work closely with top management to prioritize information and analytic needs

Requirements:
Bachelors or Masters (Pursuing or Graduated) in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science), preferably with work experience of over [X] years.
Ability to program in any high-level language is required. Familiarity with R and statistical packages are preferred.
Proven problem solving and debugging skills.
Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.
Experience with text analytics, data mining and social media analytics.
Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc."
Data Science Internship,"Chennai, Tamil Nadu",SIMPLIFAID PVT LTD,"₹15,000 a month",Organic,"About the company:
We are into building products using cutting edge technologies using AI/ ML for the development sector. A deep-tech startup for social good that harnesses the power of digital solutions to help cities graduate to inclusive and sustainable cities. ""Our solutions are driven for societies to flourish by adopting cutting edge technologies as an enabler for its comprehensive and inclusive development"". Our Motto: We help measure the quality of service delivery and co-create action plans with municipal officials based on our location intelligence. Why do yearly performance assessments? We engage with state and national governments for conducting concurrent performance assess. We support other social enterprises, NGOs, and foundations who are on a similar mission to transform Indian cities with our location intelligence. Why don't you speak with us before making an investment in a certain location? We are here to provide you unbiased review that is most critical for your investment decision!
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on Python, machine learning, deep learning, and IoT products 2. Implementing models as APIs for consumption of business 3. Building data products using cutting edge technologies
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 3rd Aug'20 and 7th Sep'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 2
Additional details:
The intern would get an incentive of up to Rs. 10000 based on the delivery of work.
Categories: Data Science,Engineering"
Data Engineer Intern,"Nashik, Maharashtra",TRIARQ Health,None,Organic,"JOB SUMMARY:
TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care.
TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice, care management platform and patient engagement services to help doctors focus on better outcomes.
LOCATIONS:
India: TRIARQ Health 5th floor, Rushiraj Tower, Jehan Circle, Gangapur Road Nashik -422013
US: TRIARQ Health, 1050 Wilshire Drive, Suite 300, Troy, Michigan 48084
REQUIREMENT:
We are looking for a Data Engineer Intern that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
RESPONSIBILITIES:
Defining and Modifying data base structure as per application requirements.
Creating stored procedures and function.
Creating data models by understating business logic.
Data processing, Data cleansing, Data wrangling and verifying the integrity of data used for analysis.
Managing and monitoring data redundancy.
Integrate data base connection in services (Java /Python).
SKILLS AND QUALIFICATIONS:
Experience with query languages, Data Modeling, Database Design, Dimensional and Relational Modeling, Database Schemas
Good database scripting and programming skills Python, SQL, BigQuery, PostgreSQL, MySQL
Basic understanding of machine learning techniques and algorithms, such as Linear Regression, Classification, SVM, Decision Forests, etc.
Data-oriented personality.
Data science certification should add an advantage.
BENEFITS:
TRIARQ Health is the people’s first company work within a great company culture.
Individuals can develop from technical to communication to leadership. Proactively build your career - with help from your manager, set the path you would like to take - and then do it!
Gain incredible experience working with numerous technologies.
Job Type: Full-time
Interested candidates can call at Mob Number: 9420869028.
Website: www.TRIARQhealth.com
Job Types: Full-time, Contract
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19"
Web Developer,"Rohini Sub City, Delhi, Delhi",Divine Web Solution,"₹18,000 - ₹35,000 a month",Organic,"POSITION: JAVA DEVELOPER
REQUIREMENT: FULL TIME DEVELOPER
The position may require additional duties/responsibilities that may not be outlined below, and specific functions are subject to change.
· Designing and developing a web-based educational platform tailored specifically for use with interactive modules with videos.
· Developing a front end website based one architectural design.
· Designing user interactions on web pages.
· Developing back end website applications.
· Creating servers and databases for functionality
· Ensuring responsiveness of applications.
· Designing and developing APIs.
· Troubleshooting, debugging, and upgrading software.
· Designing and developing security and data protection measures.
· Meeting both technical and consumer needs.
· Staying abreast of developments in web technology.
· Supporting the company’s future web development initiatives.
· Designing and developing unit tests.
· Participating in code reviews.
QUALIFICATIONS & REQUIREMENTS
The following qualifications are the minimum requirements necessary to successfully perform this role. However, any equivalent combination of experience, education and training, which provides the necessary knowledge, skills and abilities, would be acceptable, subject to any legal and/or regulatory requirements.
· Degree in Computer Engineering, Computer Science or equivalent disciplines.
· Proficiency with fundamental front-end languages such as HTML, CSS and JavaScript.
· Proficiency with JAVA and Spring framework.(most important)
· Good understanding of scripting languages such as Python, groovy, shell, powershell.
· Proficiency with MongoDB and familiarity with other database technologies such as MSSQL.
· Proficiency with Microsoft Visual Studio.
· Familiarity with WebServer like NGINX, application server like JBoss running on linux OS, and windows IIS etc.
· Experience with Git is preferred.
· Experience interfacing with both internal team members and external customers as part of a solution-based service process.
· Experience troubleshooting and responding to customer concerns.
· Proven record of being reliable and accountable for all aspects of their job.
· Excellent analytical, interpersonal and communication skills with the ability to communicate complex technical issues in an easy to understand manner.
· Ability to work in a fast-paced, self-directed, entrepreneurial environment.
· Strong time management skills.
· Ability to adapt to changing technologies.
· Ability to multi-task activities with shifting priorities. Able to work productively in a pressurized environment.
* Should have knowledge of android application.,
Experience:
Java: 1 year (Min)
Education:
Bachelor's (Required)
Job Type: Full-time
Salary: ₹18,000.00 - ₹35,000.00 per month
Experience:
Total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Programming Languages needed:
CSS (Preferred)
Java (Preferred)
JavaScript (Preferred)
Python (Preferred)
PHP (Preferred)
Benefits:
Travel allowance
Industry:
IT Operations & Helpdesk
Work Remotely:
No"
AI Developer,"Hyderabad, Telangana",GrayRipples.com,None,Organic,"Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
"Online Trainer - Python, ML, Data Science","Coimbatore, Tamil Nadu",Nowa Labs,"₹1,000 an hour",Organic,"We are looking for a trainer in Python, Data Science and Machine Learning Technologies.
You need to be extremely good in
- Python
- numpy
- pandas
- sci-kit-learn
- Maths concepts required for Data Science
- Machine Learning fundamentals
You will be giving online training to the students across the world.
We would want you to present webinars and do mentorship to AI aspirants.
Job Types: Part-time, Contract
Salary: From ₹1,000.00 per hour
Experience:
total work: 1 year (Preferred)"
Machine Learning Engineer,"Bengaluru, Karnataka",Involvio,None,Organic,"We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we'd like to meet you. Your ultimate goal will be to shape and build efficient self-learning applications.

Responsibilities:
Designing and developing machine learning and deep learning systems.
Running machine learning tests and experiments.
Implementing appropriate ML algorithms.
Study and transform data science prototypes.
Design machine learning systems.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications according to requirements.
Select appropriate datasets and data representation methods.
Run machine learning tests and experiments.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks.
Keep abreast of developments in the field.
Requirements:
Proven experience as a Machine Learning Engineer or similar role.
Understanding of data structures, data modeling and software architecture.
Deep knowledge of math, probability, statistics and algorithms.
Ability to write robust code in Python, Java and R.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).
Excellent communication skills.
Ability to work in a team.
Outstanding analytical and problem-solving skills.
BSc in Computer Science, Mathematics or similar field; Master's degree is a plus."
Hiring For FREELANCE DATA SCIENTIST - BANGALORE,"Bengaluru, Karnataka",Atyati Technologies,None,Organic,"Revonic (headquartered in Dubai) and Atyati (headquartered in Bangalore) are sister companies, both part of a private investment group, Metdist. The Group owns a portfolio of companies across various sectors in the Middle East, India and SE Asia with a core focus on capturing growth in these developing regions. Within the portfolio the Group looks for synergies between its investee companies by sharing resources, leveraging technology, local knowledge and best practice. The Group has been operating for over 70 years and is a long term business builder
OBJECTIVE :We are looking for a data scientist that would like to join us on a freelance basis to work on different projects from a various set of large companies & partners that we work with.

Clients that we work with range from many industries like automotive, hospitality, retail, oil & gas to travel. The project will require data engineers who have at least 4 years' experience and we prefer that our data science team has vast experience in utilizing Microsoft Azure.

These projects can range from 1 month work all the way to 6 months of work. There is an outlook of definitive employment, once the economic situation improves globally.

DATA SCIENTIST
2/4
Responsibilities

* Manage data science products for multiple clients. From Predictive modelling to driving Segmentation Analysis. * Feeling comfortable with developing new products in a wide array of tools within Data Science. * Having a genuine interest & experience in Machine Learning and understanding of how this could drive business. * Interface with developers, engineers, project managers and data scientists to understand data needs. * Build data expertise and own data quality for allocated areas of ownership. * Design, build and launch new data models in production. * Driving new techniques, tools and data science processes within the company. * Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation. * Support existing processes running in production. * Define and manage SLA for all data sets in allocated areas of ownership. * Expert in developing data science roadmaps for with clients. * Able to manage expectations while working on multiple clients at the same time. * A desire to work in a collaborative, international and intellectually curious environment. * Ability to complete projects timely, accurately and with strong attention to detail, with continuous communication of progress updates to stakeholders.

Required Qualification

* Industry experience as a Data Scientist with a track record of manipulating, processing, and extracting value from large datasets and visualizing data into business intelligence tools like Tableau, PowerBi and Google Data Studio. * Experience building data products incrementally and integrating and managing datasets from multiple sources. * Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations. * Excellent communication skills including the ability to identify and communicate data driven insights. * A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience. * 4+ years of industry experience in predictive modeling, data science and analysis. * Previous experience in a ML or data scientist role and a track record of building ML or DL models. * Experience using Python and/or R. * Experience using ML libraries, such as scikit-learn, caret, mlr, mllib. * Experience with SparkML & Azure datascience tools. * Experience working with GPUs to develop model. * Experience handling terabyte size dataset. * Experience using data visualization tools. * Ability to write efficient and advanced SQL statements. * Ability to analyze data to identify deliverables, gaps and inconsistencies. * Proficiency in Tableau & PowerBi is mandatory.

One of Revonic's services is to provide companies of all sizes with data analytics & data science services where a thorough understanding of their business and their data is required.

As a Data Scientist with REVONIC, you will be working in an international, complex, and dynamic data environment. We are looking for an experienced Data Scientist with an uncanny ability to integrate multiple heterogeneous data sources to build data-driven insights & capabilities. The ideal candidate has analyzed large big data sets and has the capabilities to work with structured and unstructured data for businesses.

You are enthusiastic about learning new technologies and implementing solutions using these technologies to empower internal customers and scale the platform. You demonstrate solid communication skills and the ability to partner with other colleagues across technical and non-technical teams to develop and define key business questions, then build the solutions that answer those questions.

In this role, you will serve as the expert in designing, implementing, and operating data science solutions to flow information in end-user facing reporting applications such as Tableau or Microsoft PowerBi. Above all, you will bring large datasets together to answer business questions and drive data-driven decision making.
Salary: Not Disclosed by Recruiter
Industry:IT-Software / Software Services
Functional Area:IT Software - Application Programming, Maintenance
Role Category:Programming & Design
Role:Software Developer
Keyskills
Data ScienceGasMicrosoft Azure
Desired Candidate Profile
Please refer to the Job description above
Education-
UG:B.Tech/B.E. - Any Specialization, Any Graduate - Any Specialization
Doctorate:Doctorate Not Required
Company Profile
Atyati Technologies Pvt. Ltd.
https://www.revonic.com/

Revonic (headquartered in Dubai) and Atyati (headquartered in Bangalore) are sister companies, both part of a private investment group, Metdist. The Group owns a portfolio of companies across various sectors in the Middle East, India and SE Asia with a core focus on capturing growth in these developing regions. Within the portfolio the Group looks for synergies between its investee companies by sharing resources, leveraging technology, local knowledge and best practice. The Group has been operating for over 70 years and is a long term business builder."
Data Science Internship,"Bengaluru, Karnataka",OTO Capital,"₹12,000 a month",Organic,"About the company:
In the recent years - consumers have changed and love to upgrade faster. They shift from one city to another for better career options, value access over ownership and perceive ownership as an additional responsibility of care and maintenance. Hence, there is a big need of providing him/her a hassle-free option to own (cars, bikes, etc.) without much commitment. OTO envisions the concept of 'Own Together' enabling ownership (starting with cars) in a new way of financing with flexible usage terms. With OTO, consumers pay for a car with up to 25% low, all-in, month-to-month payment. We aim to redefine the $40 Billion+ market of Car Ownership in India at first. We have already partnered with 100+ showrooms & corporates to provide this offering to the car purchasers at a point of sales.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. â€¢ Work with the data science team and contribute to the ongoing project 2. â€¢ Research about different techniques that can be used to achieve the goal of the project 3. â€¢ Practically understand the problem statement and Implement the research done to develop custom data models and algorithms 4. â€¢ Extract, Harmonize, clean, and merge data from different data sources for further use 5. â€¢ Build machine learning solutions to drive optimization and improvement in product and business strategies 6. â€¢ Develop processes and tools to monitor and analyze model performance and data accuracy
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
â€¢ Some experience working with large data i.e. mining, cleaning, manipulating data sets, and building statistical models â€¢ Research-oriented mind-set â€¢ Strong problem-solving skills with a drive to learn and master new technologies and techniques â€¢ Knowledge about statistical computer languages (Python, R, SQL, etc.) to draw insights from large data sets â€¢ Knowledge of machine learning and statistical techniques (OCR, clustering, decision tree learning, artificial neural networks, regression, statistical tests, etc.) and their real-world advantages/drawbacks â€¢ Knowledge about automobile and finance industry will be an extra advantage
Number of internships/jobs available: 2
Categories: Data Science"
Jr. Software Developer - Machine Learning / Artificial Intel...,"Navi Mumbai, Maharashtra",V2Solutions,None,Organic,"This particular job post is no longer active. The job listing may still be published on V2Solutions. You may also want to search Indeed's current listings for V2Solutions to see if a newer version of this job post exists.
Key Responsibilities
Complete implementation, testing, and documentation of development projects and tasks
Provide timely project deliverables based on implementation plan
Prepare reference, documentation, and testing methodologies for applications and related errors
Available to review code created by Software Engineers and Programmers
Tests Base-cases, and outliers
Requirements
Experience:1-3 years
Technologies and tools: Python, R, Google Big Query, TensorFlow
Bachelor’s Degree from an accredited university in Computer Engineering, Computer Science, or related field
Understanding of data structures, data modelling and software architecture
Great attention to detail, ability to organize/prioritize multiple tasks, and meet deadlines.
Ability to work in a fast-paced environment"
Computer vision engineer,"Chennai, Tamil Nadu",Deepquanty Artificial Intelligence labs,None,Organic,"Hi,
Greeting from DeepQuanty Artificial Intelligence Labs !!!
We would like to take an opportunity to introduce DeepQuanty Artificial Intelligence Labs. It is a Computer Vision Lab devoted to extracting and processing data from images using Deep Learning, Artificial Intelligence and Machine Learning. It is a start-up no more than 1 year old with four products: SnapChek, FormEasy, EasyKYC and Zapscore - all directed at the BFSI Sector. It is well funded and operational. Thus this is an opportunity to apply your cross-functional skill sets, creativity, machine learning, robotics and control systems to solve exciting product development changes.
Company Profile: -
DeepQuanty Artificial Intelligence Labs is a product startup in the space of Artificial Intelligence and Machine Learning. It has already several products in the Computer Vision space and is very well received in the BFSI industries. It has every intention to exploit all opportunities in this space by way of astute product development and taking them to several other industries as well.
DeepQuanty AI Labs has been set up by founders with over 75 man years of experience in the area of analytics and technological product developments. Specifically, the founders come from successful and ongoing ventures MarketsOf1 Analytical Marketing Services Pvt. Ltd. and Pranion Technology Ventures.
Job Description: -
We’re looking for experienced, detail-oriented individuals to join our team and work in a startup environment. This is an opportunity to apply your cross-functional skill-sets, creativity and experience in computer vision, machine learning, robotics and control systems to solve exciting product development challenges. This is a high-visibility position within our fast growing company and assumption of increased responsibilities over time is expected.
Skills and Qualification: -
Minimum 2 year of experience working in AI / Machine Learning.
Minimum 1 year of experience working in Deep Learning.
Bachelor's or Master's Degree in Computer Science or related field.
Machine Learning in Computer Vision.
Working experience in frameworks like OpenCV, Tensorflow/Keras/PyTorch, Scikit-Learn, Matplotlib, Pandas, Numpy.
Good Python knowledge.
Working experience in Flask/Django/Tornado.
Well versed with Development Environment on Linux.
Job Location: -
Chennai
Job Types: Full-time, Internship
Experience:
Python & Linux: 1 year (Preferred)
Deep learning: 1 year (Preferred)"
PYTHON DEVELOPER,"Dehra Dun, Uttarakhand",V3iT,None,Organic,"We are looking for a Python Developer to join our engineering team and help us develop and maintain various software products.
Python Developer's responsibilities include writing and testing code, debugging programs, and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.
Should be able to perform web scraping from a complex website using python and dump the data into the excel sheet.
Should know APIs and how to use a published API in order to capture the live data from a website.
Knowledge of HTML and CSS is an additional advantage. Ultimately, you’ll build highly responsive web applications that align with our business needs.
Assess and prioritize feature requests.
Required Skills:
Good knowledge in Python, Java, SQL, C++ Language.
Strong Core Java, Python, OOP.
Good hands-on experience in web scraping from a complex website using python and dump the data into the excel sheet.
Good hands-on experience in API's and how to use a published API in order to capture the live data from a website.
Knowledge of HTML and CSS is an additional advantage.
Writing an effective, scalable code. Developing back-end components to improve responsiveness and overall performance. Integrating user-facing elements into applications.
Coordinate with internal teams to understand user requirements and provide technical solutions.
Work experience as a Python Developer.
Expertise in at least one popular Python framework (like Django, Flask, or Pyramid).
Knowledge of object-relational mapping (ORM).
Familiarity with front-end technologies (like JavaScript and HTML5).
Implement security and data protection solutions.
Qualifications:
B.Tech 4 years in Computer Science, Information Technology, Electronics and Communication, Electrical and Electronics.
Job Type: Full time. Start date: ASAP. Experience: 1 to 2 years in Domain. Location: Dehradun, Uttarakhand. Salary: As per industry standards.(Depends on candidate interview performance) Email: careers@V3iT.com"
Mobile AI Engineer - NLP & Speech Tech,"Chandigarh, Chandigarh",DataToBiz,"₹6,00,000 - ₹10,00,000 a year",Organic,"DataToBiz is an AI and Data Analytics Services startup. We are a team of young and dynamic professionals looking for an exceptional Mobile AI Engineer to join our team in Chandigarh. We are trying to solve some very exciting business challenges by applying cutting-edge Machine Learning and Deep Learning Technology.
Being a consulting and services startup we are looking for quick learners who can work in a cross-functional team of Consultants, SMEs from various domains, UX architects, and Application development experts, to deliver compelling solutions through the application of Data Science and Machine Learning. The desired candidate will have a passion for finding patterns in large datasets, an ability to quickly understand the underlying domain and expertise to apply Machine Learning tools and techniques to create insights from the data.
Responsibilities:
* As a Mobile AI engineer on our team, you will be responsible for solving complex data problems for various clients using deep learning techniques.
* Work with the team to extract and transform natural language data from audio and text on the mobile native application.
* Develop and implement a framework for mobile processing of language syntax and semantics as well as contextualization of audio and textual data using python
* Develop strategies and implement methods to pass NLP techniques to classification algorithms.
* Execute project plan to meet requirements and timelines.
* Identify success metrics and monitor them to ensure high-quality output for the client.
* Deliver production-ready models that can be deployed in the production system.
* Understand and identify appropriate data sources required for solving the business problem at hand.
Requirements
* 2+ years of working with Python, Machine learning with exposure to one or more DL frameworks like Tensorflow, Keras, Caffe, MXNet etc
* Minimum 2 years experience in text representation techniques and NLP algorithms to succeed in this role along with hands on Speech Analytics
* Exposure to Deep Learning algrithm implementation in either speech analytics or NLP domain
* Exposure to ML/DL techniques and algorithms to work with different data formats including voice and text unstructured data
* Strong verbal and written communication skills with other developers and business client
* Android or iOS experience will be advantageous
* Exposure to DL Model optimization & transfer learning techniques
Job Type: Full-time
Salary: ₹600,000.00 - ₹1,000,000.00 per year
Experience:
Full time Work: 2 years (Required)
NLP or Speech Tech: 1 year (Required)
Deep Learning: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19"
Developer/Programmer Analyst,"Chennai, Tamil Nadu",Infomatics,None,Organic,"Developer/programmer analysts must have strong analytical and problem-solving abilities. They must understand and conceptualize applications from both a technical/programming perspective and a business point of view. Because they deal with both technical personnel and business managers/administrators, as well as participate on project teams, they need strong interpersonal and communication skills. Excellent programming abilities in common languages and frameworks, such as C#/C++, Java Enterprise Edition/ AJAX and Microsoft .NET are needed for the coding aspects of the position. Most employers look for at least a bachelor’s degree in computer science, information science or management information systems, as well as relevant job experience.
Typical duties include:
Analyzing business application requirements for functional areas such as finance, manufacturing, marketing or human resources
Writing code, testing and debugging software applications
Recommending system changes and enhancements
Documenting software specifications and training users
Should be very good with general ABAP concepts including OO ABAP, Reports, Data Dictionary, Module pool, etc
Experience with forms (Adobe experience is preferred, if not, should be very good with Smartforms)
Experience with EDI/IDocs
Experience with Enhancements (user-exits, BADIs, enhancement spots)
Experience with Netweaver gateway (oData services) Desired: ABAP 7.4 and above
Enterprise HANA (HANA sidecar) or very strong with any other SQL"
Data Scientist,"Bengaluru, Karnataka",Netradyne,None,Organic,"Role and Responsibilities
You will perform analyses, build models, and design/conduct experiments to improve road safety and reduce accidents. You will
Design, develop and evaluate statistical and predictive models to understand driving risk.
Build models and design product features to improve scores, compliance and other key metrics.
Conduct statistical experiments and data-driven metrics to guide product features.
Perform data wrangling tasks such as acquiring, cleaning, structuring and enriching data.
Communicate and present findings in a clear and intuitive manner.
Build story-telling dashboards.
Requirements:
B. Tech, M. Tech or PhD in computer science, electrical engineering, statistics, math or a related area.
Good hands-on experience of coding – Python (required), R, etc.
Experience working with databases – Postgres, MongoDB, etc.
Strong knowledge of statistics, probability, and estimation theory.
Experience with deriving useful insights from large and complex datasets.
Experience with data visualization and storytelling.
Strong ability to communicate highly technical results to a diverse audience.
Ability to develop quick proof of concept solutions in a fast-paced startup environment.
Flexible and can-do approach. Ability to adjust to changing priorities.
Desired Skills:
Experience with predictive analytics is a plus.
Experience with data visualization tools like Tableau, Plotly-Dash is a plus.
Experience with designing and conducing successful statistical experiments is a plus."
Python developer with AI & ML,"Mumbai, Maharashtra",Chrisel Technolab,None,Organic,"Design distributed applications, architectural trade-offs applying synchronous and asynchronous design patterns, write code, and deliver with speed and quality.
Develop multi-tier scalable, high-volume performing, and reliable user-centric web services based applications that operate 24x7.
Produce high quality software that is unit tested, code reviewed, and checked in regularly for continuous integration.
Develop software related to machine learning, artificial intelligence and data analytics. Write and implement software solutions that integrate different systems.
Strong knowledge of machine learning fundamentals and python. Familiarity with AI/ML frameworks.
Knowledge of cloud computing infrastructure The ideal candidate should have:
2+ years of experience implementing and deploying machine learning and deep learning frameworks (TensorFlow, Keras, Caffe, etc.) through distributions cluster and application programming in cloud platforms including AWS and GCP.
Good understanding and knowledge of tools/libraries such as TensorFlow, Apache Spark, Keras H2O.ai, Caffe etc.,
Experience working with computer vision (classification, segmentation, object detection), data pipelines, and distributed machine learning in both batch and stream process.
Experience in working in complex, multi-stakeholder environments.
Sound knowledge of software designing, development, and algorithm related solutions.
Working knowledge on programming language in Python.
Strong object-oriented skills and development expertise on web services - Knowledge of different frameworks.
Knowledge in developing ORM (Object Relational Mapper) libraries- Able to integrate multiple data sources and databases into one system - Expert knowledge of computer science, with strong competencies in data structures, algorithms, and software design. - Knowledge with object oriented design, coding, testing patterns, and programming languages (Python). - Understanding building web applications and services. Knowledge with relational databases (transactional and non-transactional), database architecture, and distributed transaction management."
Machine Learning Engineer (Contract),"Bengaluru, Karnataka",Research Grid Ltd,"₹50,000 a month",Organic,"Company:
R.grid is an early-stage start-up that streamlines administrative medical research processes by using deep learning.
Job Overview:
We are looking for a Machine Learning Engineer who has skills in Natural Language Processing.
The job responsibilities include working with a team of software engineers building an app that utilizes deep learning-based natural language processing and data science combined with a user-friendly UX.
You should have a strong problem-solving ability and a background in mathematical modeling and statistical analysis.
Responsibilities and Duties:
Build and expand NLP algorithms, analytic systems, and other predictive models
Plan and manage data projects
Collaborate with a team of software engineers and data scientists
Lead data mining and collection procedures
Ensure data quality and integrity
Interpret and analyze data problems
Conceive, plan and prioritize data projects
Test performance of data-driven products
Visualize data and create reports
Experiment with new models and techniques
Align data projects with organizational goals
Requirements:
Excellent spoken and written English and comprehension
Proven experience as an NLP Engineer, Data Scientist, Machine Learning Engineer
Solid understanding of machine learning and neural networks
Knowledge of data management and visualization techniques
Expertise in statistical analysis and predictive modeling
Good knowledge of Python, R, and MATLAB
Experience with AWS
Strong organizational and leadership skills
Excellent communication skills
A business mindset
Degree in Computer Science, Data Science, Mathematics, Statistics or similar field
Benefits:
*
Monthly pay
No Saturday work
Business casual dress
Small team
Start-up environment
Job Types: Full-time, Contract
Salary: ₹50,000.00 per month
Experience:
Data Science: 4 years (Required)
AWS: 2 years (Required)
Machine Learning: 4 years (Required)
statistical analysis and predictive modelling: 3 years (Required)
Python: 4 years (Required)
NLP: 3 years (Required)
Education:
Master's (Preferred)
Location:
Bengaluru, Karnataka (Preferred)
Language:
English (Required)
Work Remotely:
Yes"
Fresher/Junior Data Science Developer,"Chennai, Tamil Nadu",HTC Global Services Limited,"₹20,000 a month",Organic,"HTC Global Services hiring freshers for Junior Data Science Developer
Job Description:
HTC Global Services hiring freshers (2018 and 2019 ) for the position Junior Data Science Developer.
Candidates those who are in Chennai and immediately available to attend interview with HTC Global Services (MEPZ, Tambaram) can apply.
About HTC Global Services:
HTC Global Services (HTC) is a leading global provider of Information Technology (IT) and Business Process Services (BPS), headquartered in Troy, Michigan, USA. Established in 1990, HTC is an Inc. 500 Hall of Fame company and one of the fastest growing Asian American companies in the USA. Our client base spans over 2000 organizations across the globe. HTC acquired CareTech Solutions in December 2014 and Ciber, Inc. (Currently Ciber Global LLC) in June 2017. These acquisitions enable us to expand our operational capabilities in Healthcare IT and Technology Transformation services.
HTC is an ISO 9001 and 27001 certified company with processes compliant to SEI CMM Level 5. With over 10 global delivery centers and operating presence in several countries, we serve global clients across multiple time zones. Our ‘Business Partner’ approach enables us to offer high business value for our clients. It also brings in the benefit of repeated business for HTC. Our strategic solutions enable clients to transform and thrive in the changing world.
Designation : Fresher/ Junior Data Science Developer.
Job Requirements:
Key Skills:
Should have good knowledge in basics OOPS concepts.
Must possess good communication skill(both oral and written).
Qualification :
· Bachelors or masters in Science majored in Math/Statistics/Econometrics.
· Bachelors in Engineering with Data science/AI/ML as part of the curriculum
· Management graduates with specialisation in Analytics/Data Science/AI/ML.
Eligiblity Citeria:
· First class throughout curriculum is mandatory(from 10th standard to degree).
Certificates/Diplomas:
Should have done certification in date science, Analytics, Python from leading institutions or through online courses from Coursera/datacamp/udemy/udacity
Must to have:
Have few practical projects experience for a maximum of 2 years, active in Kaggle or other forums.
Probation period : One Year
Salary Offered : CTC 3.00 L pa
Agreement Period:
3 Years from the date of joining and should be ready to submit original documents.
Rounds of Interview:
Round 1: Aptitude (Technical and English )
Round 2: Technical & HR at the company.
Job Type: Permanant, Full-time
Salary: ₹300,000.00 per annum from Training onwards.
Benefits:
Provident fund (PF)
Paid leaves / Leave encashment
Industry:
Software Development
Interested candidates can reach me at :
Pavithra.M
Senior HR @ HTC Global Services Limited
Official Mobile Number: 9840604551
Job Types: Full-time, Fresher
Pay: From ₹20,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Pune, Maharashtra",Kone AB,None,Organic,"We are looking for data analytic specialist to join the KONE Services and Solutions R&D team. In this role you are responsible to participate in analyzing data from our solutions and developing our analytics methods and algorithms for KONE’s equipment like elevators, escalators and building doors. Part of the work includes also participation of related new products development and/or existing products improvement via for example adding sensors & utilizing edge computing analytics.
Responsibilities and key activities:
Data analytics for KONE equipment
Development of new algorithms and methods
Improving existing solutions where big data is used
Analysis equipment reliability and performance, provide recommendations actions
Failure investigation for root causes.
We expect you to have
Master Degree in Computer Science or Statistics or Applied mathematics or engineering background with demonstrated ability in data analysis and problem solving.
More than 2 years of working experience on utilizing data analysis skills to improve products or services in real projects. Machine diagnostics knowledge is a plus.
Skilled in at least one of data analysis tool, e,g,: SPSS, Python, Matlab, R or strong programming languages skills (C++, Visual Basic, Java, etc.) to develop engineering calculation tools.
Big data and data analytics methods experience. There is good understanding of numerical optimization theory (Linear and Non-linear).
IoT and cloud technologies knowledge and experience
Utilizing sensors for data gathering experience plus
Experience working in R&D organization preferred
Strong self-motivated and quick learning;
Team work spirit, good communication and coordination skills;
Excellent English writing and speaking skills.
At KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life."
Machine Learning/Deep Learning Experts,"Bengaluru, Karnataka",CrunchMetrics,None,Organic,"We at CrunchMetrics are looking for talented Machine Learning Scientist with a background in Machine Learning development who desires to work on building solutions to complex challenges and can create, innovate, and define the next generation of autonomous analytics solutions. This role requires an expert level of data science knowledge as well as experience with data science techniques, systems and processes.
The position will report to the Head of Strategy and Products at CrunchMetrics and will be based in Bangalore, India
Info
Category :AI
Job Code :CMA01
No. of openings :7
Skills
Qualifications
BRIEF
6-8 years proven experience in building Machine Learning/ Deep Learning based solutions/ products.
Strong hands on skill in Python using libraries like NLTK, SkLearn or Hands on in R and Java.
Proven background in at least one of the following – Reliability models, Markov Models, Stochastic models, Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Non-parametric Methods, Multivariate Statistics.
Experience working with large data sets and tools like Elastic Search, Spark and Hive.
Excellent communication skills including the ability to present technical concepts to a wide range of audiences, both internal and external.
Ability to work effectively across teams."
Data Scientist II,"Bengaluru, Karnataka","Zendrive, Inc.",None,Organic,"“A Data Scientist is that unique blend of skills that can both unlock the insights of data and tell a fantastic story via the data.” - D J Patil

Do you find immense joy in finding patterns in data through analytical experimentation? As a member of the core team of Data Scientists at Zendrive, will you be able to unlock insights hidden within the terabytes of data gathered from millions of connected devices, to give the world a safer driving experience?

What we need you to do:
You need to communicate, collaborate and use your keen intuition for data and aptitude for large scale data analysis to make a business impact. We expect you to stay updated with current trends and developments in the field of statistics and data science and in addition, you need to:

Create meaningful datasets and mine them
Understand characteristics of data through visualisations
Propose and validate hypotheses through theoretical and empirical approaches
Evaluate alternate modes and justify performance
Put performance models into production
Clearly articulate key results and ideas to decision makers.

What you need to have:

BS / MS in Computer Science / Statistics / Applied Math or related areas
2 to 4 years of relevant work experience
Fluency in analytical tools such as Python (Numpy, Pandas, Scikit-learn, Tensorflow)
Experience in visualisation of complex data (ggplot, Matplotlib)

What will score bonus points:

Special emphasis will be given for your expertise in analysing multivariate time series data. Experience in Finance or Insurance Industry (risk modelling) is also a plus.

What we offer you:

Working from a remote location of your choice, until such time as we figure that it is safe to move into a more conducive office space, which may not be anytime soon. Having said that, we provide a great collaborative environment even virtually with the best engineering talent to be found anywhere in the world. Along with a competitive salary, we will be providing you the opportunity to contribute to the development of products that make a real impact on the world.

If you are excited about the job description and see yourself excelling in this role, hit the APPLY FOR THIS JOB button at the end of this page. Our Talent Acquisition team will get in touch with you."
Business Intelligence Developer,"Bengaluru, Karnataka",Solutionec,None,Organic,"Bangalore, India | Full-Time
At Solutionec, we believe the Aha! moment is the engine that drives human progress. Our mission is to give our clients the power to overcome limits and face complexity head-on by designing customized solutions and tools that offer leading-edge capabilities
In healthcare and life sciences, these invaluable Aha! moments are the catalysts for potential life- changing, life-improving and life-saving innovations and achievements. Solutionec’s solutions support life by enabling more frequent, more rapid and more relevant Aha! moments.
About You
BS/MS in Computer Science or equivalent
Develop, implement and optimize stored procedures and functions using SQL
Reviewing query performance and optimizing code
Data modeling to visualize database structure
Background for writing business intelligence queries or dashboards
Strong knowledge in OLAP Systems, relationship data bases
Strong experience in writing SQL queries and using any of the commercial business intelligence tools
Creating database triggers for automation, e.g., automatic email notifications
Creating table indexes to improve database performance
Review and interpret ongoing business report requirements
Analyze existing SQL queries for performance improvements
Provide timely scheduled management reporting
Investigate job failure or issues and solve as when needed"
Data Engineer,"Bengaluru, Karnataka",IBM,None,Organic,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. To lead in this new era of technology and solve some of the world's most challenging problems.

Your Role and Responsibilities
As a Data Engineer, you play a vital role in building the right infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Expert in setting up effective pipelines to capture data from multiple sources into the enterprise centric storage.
Comfortable in building effective analytical tools that utilize the data pipeline to provide actionable insights into data synchronization, reporting, operational efficiency and related areas.
Work with stakeholders including the product owner, data and design teams to assist with data-related technical issues and support their data infrastructure needs.
Create and maintain optimal data pipeline architecture.
Identify, design, and implement process improvements aimed at automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Assemble large, complex data sets including legacy structured data warehouse that meet functional / non-functional business requirements.
Collaborate with DevOps team to develop Continuous Integration/Continuous Delivery pipelines using containerization technologies.
Solve Big Data and Distributed Data Streaming problems using latest technologies.
Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Manipulate, process and extract value from large disconnected datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Work on State-of-the-Art cloud technologies provided by IBM Public Cloud, RedHat, AWS & others.
Be part of open, transparent agile teams who always thrive for continuous learning and contribute towards continuous improvement.



Required Technical and Professional Expertise
Possess strong knowledge in designing database models to store structured & unstructured data efficiently and in creating effective data tools for analytics experts.
Knowledge in technologies like Hadoop, Spark, Kafka, Scala, Python, etc. Knowledge in relational model databases (like DB2, MySQL, Oracle, ...) and no-SQL databases (MongoDB, Elastic Search, ...)
Knowledge on enterprise data lakes, data analytics, reporting, in-memory data handling, enterprise integration tools, etc.
Good understanding of industry best practices for data governance and security.
Good communication skills and fluent in English.



Preferred Technical and Professional Expertise
None

About Business Unit
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we represent the Analytic Solutions area of the Sales & Marketing Systems. Our mission is to provide business insights to our partners in sales and marketing to win in the market place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud-based data.

Your Life @ IBM
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we do represent the Analytic Solutions area of the Sales & Marketing Systems. Our Mission is to provide business insights to our partners in sales and marketing to win in the market-place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud based data.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Data Scientist,"Chennai, Tamil Nadu",Xome,None,Organic,"Ready to be a Cooper too? This might just be right up your alley!
We’re here to keep the dream of home ownership alive. Oh, and while we’re at it, we’re determined to change the lending industry itself. It’s simple, but it won’t be easy. And we’ll need a great team behind us. (That’s where you come in.) We want to show the world that transparency, candor and collaboration aren’t just good values. They’re good business. Working here isn’t for people who want to punch a clock. It’s for people who want to punch a hole in the status quo. Come join us. And make a difference instead of just a living.
Role/Responsibilities:
Develop novel solutions to market-driven problems using knowledge of the latest ML techniques, statistical analysis, and practical experience on previous data science projects.
Collaborate with stakeholders, business unit product owners, development teams to understand business needs and technical requirements
Work actively in all aspects of model development, including design, model implementation, validation, calibration, documentation, monitoring, and reporting
Research complex business issues and recommend solutions, including input requirements, other required data sets, modeling approaches, and end products
Required Skills and Experience:
Masters in a quantitative / applied field (Statistics) or PhD preferred
8+ years of experience in data science roles
3+ years in handling teams
Strong statistical foundation with broad knowledge of supervised and unsupervised techniques
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.
Experience in model validation techniques, model testing and continuous monitoring of model performance
Strong knowledge of programming and modeling using R and SAS (the candidate would work in Python ecosystem)
Strong SQL skills and experience working with large data sets.
Experience working collaboratively, including building and maintaining relationships with stakeholders/clients.
Experience advising a team on innovative methodologies, data science tools, and environments.
Ability to articulate complex technical concepts/ideas to both technical and non-technical audience.
Experience applying modern machine learning techniques
Very strong in identifying hidden use cases from dataset/ business interactions and come up with new solutions
Nice to Have Skills & Qualities
Flexibility to learn and apply new methodologies
Mortgage Industry experience /knowledge
Mr. Cooper is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.
Job Requisition ID:
011698
Job Category:
Information Technology
Primary Location City:
Chennai
Primary Location Region:
Tamil Nadu
Primary Location Postal Code:
600089
Primary Location Country:
India
Posting Organization:
Xome
Line of Business:
Information Technology
Additional Posting Location(s):
Alternate Requisition:
No"
Data Analyst,"Bengaluru, Karnataka",Unusual Hire,None,Organic,"Data Analyst Job Description
ABOUT US
Unusual Hire: Helping Businesses, Building Dreams
Unusual Hire is an intriguing platform that allows companies to hire freelancers from a global network of top talent for all their dynamic recruitment needs. Unusual Hire gives entrepreneurs and freelancers an opportunity to break the norms and follow their dreams.
Why JOIN US:
OUR CULTURE
The life at Unusual revolves around our core values of trust and respect. We believe in collaboration and making mistakes. Unusual Hire gives you an opportunity to move fast and break the norms, no matter even if you commit mistakes, but you should always try. This place provides you the complete ownership; you are your boss here.We believe in equality, diversity, and maintaining a healthy relationship with our employees and clients. We have a diverse team of employees, who believe in showing the best results in our performance. If you have the right skills, you can work here, irrespective of your age or gender. We set our goals high and hire a team of quality professional freelancers to work with anywhere, anytime.
To know more visit our site @https://unusualhire.com/
Job Title: Data Analyst
Job Responsibilities
· Interpret data, analyze results using statistical techniques and provide ongoing reports
· Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
· Acquire data from primary or secondary data sources and maintain databases/data systems
· Identify, analyze, and interpret trends or patterns in complex data sets
· Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
· Work with management to prioritize business and information needs
· Locate and define new process improvement opportunities
Data Analyst Requirements:
· Bachelor’s degree from an accredited university or college in computer science.
· Work experience as a data analyst or in related field.
· Ability to work with stakeholders to assess potential risks.
· Ability to analyze existing tools and databases and provide software solution recommendations.
· Ability to translate business requirements into non-technical, lay terms.
· High-level experience in methodologies and processes for managing large scale databases.
· Demonstrated experience in handling large data sets and relational databases.
· Understanding of addressing and metadata standards.
· High-level written and verbal communication skills.
Compensation: Best in the industry.
Location: Bangalore
Job Type: Part-time
Work Remotely:
Temporarily due to COVID-19"
Data Scientist,"Chennai, Tamil Nadu",Xome,None,Organic,"Ready to be a Cooper too? This might just be right up your alley!
We’re here to keep the dream of home ownership alive. Oh, and while we’re at it, we’re determined to change the lending industry itself. It’s simple, but it won’t be easy. And we’ll need a great team behind us. (That’s where you come in.) We want to show the world that transparency, candor and collaboration aren’t just good values. They’re good business. Working here isn’t for people who want to punch a clock. It’s for people who want to punch a hole in the status quo. Come join us. And make a difference instead of just a living.
Role/Responsibilities:
Develop novel solutions to market-driven problems using knowledge of the latest ML techniques, statistical analysis, and practical experience on previous data science projects.
Collaborate with stakeholders, business unit product owners, development teams to understand business needs and technical requirements
Work actively in all aspects of model development, including design, model implementation, validation, calibration, documentation, monitoring, and reporting
Research complex business issues and recommend solutions, including input requirements, other required data sets, modeling approaches, and end products
Required Skills and Experience:
Masters in a quantitative / applied field (Statistics) or PhD preferred
8+ years of experience in data science roles
3+ years in handling teams
Strong statistical foundation with broad knowledge of supervised and unsupervised techniques
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.
Experience in model validation techniques, model testing and continuous monitoring of model performance
Strong knowledge of programming and modeling using R and SAS (the candidate would work in Python ecosystem)
Strong SQL skills and experience working with large data sets.
Experience working collaboratively, including building and maintaining relationships with stakeholders/clients.
Experience advising a team on innovative methodologies, data science tools, and environments.
Ability to articulate complex technical concepts/ideas to both technical and non-technical audience.
Experience applying modern machine learning techniques
Very strong in identifying hidden use cases from dataset/ business interactions and come up with new solutions
Nice to Have Skills & Qualities
Flexibility to learn and apply new methodologies
Mortgage Industry experience /knowledge
Mr. Cooper is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.
Job Requisition ID:
011698
Job Category:
Information Technology
Primary Location City:
Chennai
Primary Location Region:
Tamil Nadu
Primary Location Postal Code:
600089
Primary Location Country:
India
Posting Organization:
Xome
Line of Business:
Information Technology
Additional Posting Location(s):
Alternate Requisition:
No"
"Online Trainer - Python, ML, Data Science","Coimbatore, Tamil Nadu",Nowa Labs,"₹1,000 an hour",Organic,"We are looking for a trainer in Python, Data Science and Machine Learning Technologies.
You need to be extremely good in
- Python
- numpy
- pandas
- sci-kit-learn
- Maths concepts required for Data Science
- Machine Learning fundamentals
You will be giving online training to the students across the world.
We would want you to present webinars and do mentorship to AI aspirants.
Job Types: Part-time, Contract
Salary: From ₹1,000.00 per hour
Experience:
total work: 1 year (Preferred)"
DATA SCIENTIST,"Bavdhan, Pune, Maharashtra",Alpha ICT LLP,None,Organic,"Should have a Master’s degree in Statistics, Mathematics, Computer Science
Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes
Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques"
Data Analyst,"Bengaluru, Karnataka",Unusual Hire,None,Organic,"Data Analyst Job Description
ABOUT US
Unusual Hire: Helping Businesses, Building Dreams
Unusual Hire is an intriguing platform that allows companies to hire freelancers from a global network of top talent for all their dynamic recruitment needs. Unusual Hire gives entrepreneurs and freelancers an opportunity to break the norms and follow their dreams.
Why JOIN US:
OUR CULTURE
The life at Unusual revolves around our core values of trust and respect. We believe in collaboration and making mistakes. Unusual Hire gives you an opportunity to move fast and break the norms, no matter even if you commit mistakes, but you should always try. This place provides you the complete ownership; you are your boss here.We believe in equality, diversity, and maintaining a healthy relationship with our employees and clients. We have a diverse team of employees, who believe in showing the best results in our performance. If you have the right skills, you can work here, irrespective of your age or gender. We set our goals high and hire a team of quality professional freelancers to work with anywhere, anytime.
To know more visit our site @https://unusualhire.com/
Job Title: Data Analyst
Job Responsibilities
· Interpret data, analyze results using statistical techniques and provide ongoing reports
· Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
· Acquire data from primary or secondary data sources and maintain databases/data systems
· Identify, analyze, and interpret trends or patterns in complex data sets
· Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
· Work with management to prioritize business and information needs
· Locate and define new process improvement opportunities
Data Analyst Requirements:
· Bachelor’s degree from an accredited university or college in computer science.
· Work experience as a data analyst or in related field.
· Ability to work with stakeholders to assess potential risks.
· Ability to analyze existing tools and databases and provide software solution recommendations.
· Ability to translate business requirements into non-technical, lay terms.
· High-level experience in methodologies and processes for managing large scale databases.
· Demonstrated experience in handling large data sets and relational databases.
· Understanding of addressing and metadata standards.
· High-level written and verbal communication skills.
Compensation: Best in the industry.
Location: Bangalore
Job Type: Part-time
Work Remotely:
Temporarily due to COVID-19"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Python Developer/Selenium Testing,"Chennai, Tamil Nadu",Yours Efficiently,"₹96,000 - ₹1,56,000 a year",Organic,"Job Description:
1. Hands-on coding experience in Selenium with Python
2. Design, implement and maintain test scripts with good quality in a python based automated test framework (Atom IDE) for testing web based user interface
3. Able to work independently and with the team to deliver test plans and test cases successfully with best practices
4. Experience in building test scripts for test automation framework using Page Object Model
5. Good to have hands-on experience in PyTest, Unittest automation with Python
6. Proficient in Python as an Object Oriented programming language and community standards for Python programming and related concept
7. Execute and report on planned tests, report and manage defects, regress software fixes for new and existing products, assist development with replicating and debugging problems and develop new test automation solutions as needed
8. Develop test reports and metrics
9. Experience in Test Automation Frameworks like Data Driven, Keyword Driven and Hybrid
10. Deep understanding of Test Case Development with prior experience in Test Case Automation
Educational Qualification:
Graduate or Post Graduate in Engineering, Science, Technology, (Preferably BE or MCA graduate) with Related Experience.
Experience Required:
0-3 Years Experience in Python Development & Selenium Testing.
Job Type: Full-time
Pay: ₹96,000.00 - ₹156,000.00 per year
Work Remotely:
Temporarily due to COVID-19"
Data Scientist,India,Tookitaki,None,Organic,"Data Science @ Tookitaki
The data science team is responsible for solving business problems with complex data. Data complexity could be characterized in terms of volume, dimensionality and multiple touchpoints/sources. We understand the data, ask fundamental-first-principle questions, apply our analytical and machine learning skills to solve the problem in the best way possible. We also encourage to participate in competitions like Kaggle.
Our ideal candidate
We are looking for a junior data scientist who has a deep interest in theoretical and applied machine learning and loves working in a fast-paced environment.
He/she should have 3-5 years’ work experience in predictive analytics/forecasting space and have solved real-world problems. Candidates with experience in transactional anomaly prediction, operational risk modelling would be given preference.
The role would be a client-facing one, hence good communication skills are a must. The candidate should have the ability to communicate complex models and analysis in a clear and precise manner. The candidate would be responsible for:
Comprehending business problems properly – what to predict, how to build DV, what value addition he/she is bringing to the client, etc.
Understanding and analyzing large, complex, multi-dimensional datasets and build features relevant for business.
Understanding the math behind algorithms and choosing one over another
Understanding approaches like stacking, ensemble and applying them correctly to increase accuracy
Desired technical requirements
Proficiency with Python and the ability to write production-ready codes. Experience in Scala would be a plus
Big data experience, e.g. familiarity with Spark, Hadoop, is highly preferred
Familiarity with SQL or other databases.
Desired Non-technical Requirements
Very strong communication skills both written and verbal
Strong desire to work with start-ups
Job Perks
Attractive variable compensation package
Opportunity to work with an award-winning organization in the hottest space in tech — artificial intelligence and advanced machine learning"
Data Specialist Analyst,"Bengaluru, Karnataka",JLL,None,Organic,"JLL, an international real estate management company, is looking for a Data specialist to join our Centre of Expertise (CoE). We are seeking candidates that are self-starters who can work in a diverse team across different time zones and fast-paced environment that can join our team immediately.

About the Role:
#JLLTechAmbitions
JLL is looking for a Data Specialist to support a key Global Transformation/Migration Program. The person will work closely with Regional and Country data lead along with local business team. The role will have wide range of responsibilities in variety of areas including data cleansing, research on company/client data and interact with business to provide key information back to the system.

Responsibilities:
Develops technical understanding of how the data flows from various source systems and source types to a modelled database solution in the data warehouse after series of transformations and data manipulations.
Consults with the business to develop documentation and communication materials to ensure accurate usage and interpretation of JLL business requirements.
Able to perform data stewardship and enrichment/enhancements on internal JLL data from Property and Company information from proprietary/reliable sources on the web.
Carry out data validation and testing tasks for enterprise data.
Ensures proper escalation, prioritization and remediation of data quality issues.

Sound like you? To apply you need to be / have:
Experience & Education
Minimum 2-3 years of work experience in the fields of information science, data management and/or computer science.
Good command of written and spoken English.
Bachelor’s degree in Information Science, Computer Science, Mathematics, Statistics or a quantitative discipline in science, business, or social science.

Technical Skills & Competencies:Mandatory:
SQL
SQL Server
Python
Alteryx
Advanced MS Excel

Preferable:
Proficient working with any HR ERP or SaaS Data models, SQL, SQL Server, Python and Alteryx.
Proficient working with MS Excel and Excel macros (a plus but not a mandatory requirement)
Good technical writing, documentation, and communication skills.
Self-motivated, positive attitude and a team player.
Strong organizational skills and the ability to deal with large volumes of data.
Ability to multi-task, work successfully under pressure, and effectively prioritize and manage time and workload to meet client needs.

What we can do for you:
At JLL, we make sure that you become the best version of yourself by helping you realize your full potential in a fully entrepreneurial and inclusive work environment. If you harbour passion for learning and adapting new technologies, JLL will continuously provide you with platforms to enrich your technical domains. We will empower your ambitions through our dedicated Total Rewards Program, competitive pay and benefits package. It’s no surprise that JLL has been recognized by the Ethisphere Institute as one of the 2019 World’s Most Ethical Companies for the 12th consecutive year.

Apply today!"
Python & Data Analytics Engineer,"Chennai, Tamil Nadu",Stratmark consulting Pvt ltd,"₹3,00,000 - ₹7,00,000 a year",Organic,"We are looking for proficient Python Developers with knowledge in Analytics and scripting. Additional skills required are API, AI & ML. Candidates with the background of B.E / B.Tech / M.Sc. / M.E / M.Tech /MCA in Computer Science or Applications will be preferred
Required Skills:
Proficient in Core Python and its libraries and Modeling - regression, classification, linear etc.
Proficient in building highly scalable and optimized engines for Data Analytics.
Good knowledge in JavaScript, CSS, HTML5, XML and Object Relational Mappers (ORM).S
Strongexposure in RDBMS (MySQL, MongoDB, Document DB, MSSQL) and Servers (Apache, Ngnix)
Good in exposing and consuming APIs, RESTAPI, Web ServicesE
Experiencein Visualization tools such as Power BI, Tableaun
Knowledgein AI and ML, Deep Learning (Audio/Video/NLP, Neural Network) will be an added advantage.
Knowledgeof Multi-process architecture (MVC, MVT) and Multiple Delivery platforms.
Goodexposure in Azure DevOps and Version Controls including Git.
Verygood in Analytical, Design, Communication and presentation skills.
Job Type: Full-time
Salary: ₹300,000.00 - ₹700,000.00 per year
Experience:
Software Development: 3 years (Preferred)
Rest API: 2 years (Preferred)
Python: 2 years (Preferred)
Java Script: 2 years (Preferred)
AI & ML: 2 years (Preferred)"
Data Engineer 2,"Chennai, Tamil Nadu",PayPal,None,Organic,"In this role, the individual will be part of the engineering team in Enterprise Data Lake Organization and will be responsible for.
Participating and collaborating with Product Owner/ Cross functional team in the organization to understand the business requirements and to deliver solutions that can scale.
Creativity and out of the box thinking is required.
Proactively anticipating problems and keeping the team and management informed in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Produce quality deliverables
Ability to work in a fact paced environment
Ability to deliver from coarse grained requirements
Skills and Experience
3+ years of experience in the IT industry, experience in Data Technology space is preferred.
Shell/ Perl scripting experience
Spark streaming experience is a must
Proficiency in any programming language like C, C++ or CORE Java
Working experience in a RDBMS and big data stack; Should have strong SQL programming skills
Knowledge of data warehousing concepts
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Basic Qualifications
Bachelor/master’s in engineering/Science degree with Mathematics or equivalent experience
3+ years of experience in IT
Job_Description_Summary: Enterprise Data Lake is a newly formed team in PayPal’s product and engineering organization under Customer Experiences and Technology. Its vision is to “Provide Enterprise Product Data at lower cost and better quality”. To achieve this vision, we are looking for people with a passion and curiosity to solve customer problems with data. The internal stakeholders for the Program include but are not limited to PayPal Inc.’s Product Teams, Finance, Risk, Compliance and Strategy Teams. Our External stakeholders include Customers and Regulators amongst others. This position is focused on delivering Core Data solutions using modern technology to serve the various needs of the business. The scope of the organization is global, and its data platforms serve a wide array of functions including Merchant, Partner, Operations, and Compliance business operations. At EDL, we are committed to bringing innovation, passion and customer focus to the business of enterprise solutions. One of the charters of EDL is to deliver on data driven companywide transformational initiatives to integrate PayPal Inc. data seamlessly using Big Data platform for both operational and analytical needs. In this position you will also have the opportunity to work with stakeholders and users to understand their needs and partner with engineering to deliver the solution. This position requires an individual who is comfortable working in cross-functional teams with a very high degree of analytical and technical skills.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Developer/Programmer Analyst,"Chennai, Tamil Nadu",Infomatics,None,Organic,"Developer/programmer analysts must have strong analytical and problem-solving abilities. They must understand and conceptualize applications from both a technical/programming perspective and a business point of view. Because they deal with both technical personnel and business managers/administrators, as well as participate on project teams, they need strong interpersonal and communication skills. Excellent programming abilities in common languages and frameworks, such as C#/C++, Java Enterprise Edition/ AJAX and Microsoft .NET are needed for the coding aspects of the position. Most employers look for at least a bachelor’s degree in computer science, information science or management information systems, as well as relevant job experience.
Typical duties include:
Analyzing business application requirements for functional areas such as finance, manufacturing, marketing or human resources
Writing code, testing and debugging software applications
Recommending system changes and enhancements
Documenting software specifications and training users
Should be very good with general ABAP concepts including OO ABAP, Reports, Data Dictionary, Module pool, etc
Experience with forms (Adobe experience is preferred, if not, should be very good with Smartforms)
Experience with EDI/IDocs
Experience with Enhancements (user-exits, BADIs, enhancement spots)
Experience with Netweaver gateway (oData services) Desired: ABAP 7.4 and above
Enterprise HANA (HANA sidecar) or very strong with any other SQL"
Data Science Internship,"Bengaluru, Karnataka",OTO Capital,"₹12,000 a month",Organic,"About the company:
In the recent years - consumers have changed and love to upgrade faster. They shift from one city to another for better career options, value access over ownership and perceive ownership as an additional responsibility of care and maintenance. Hence, there is a big need of providing him/her a hassle-free option to own (cars, bikes, etc.) without much commitment. OTO envisions the concept of 'Own Together' enabling ownership (starting with cars) in a new way of financing with flexible usage terms. With OTO, consumers pay for a car with up to 25% low, all-in, month-to-month payment. We aim to redefine the $40 Billion+ market of Car Ownership in India at first. We have already partnered with 100+ showrooms & corporates to provide this offering to the car purchasers at a point of sales.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. â€¢ Work with the data science team and contribute to the ongoing project 2. â€¢ Research about different techniques that can be used to achieve the goal of the project 3. â€¢ Practically understand the problem statement and Implement the research done to develop custom data models and algorithms 4. â€¢ Extract, Harmonize, clean, and merge data from different data sources for further use 5. â€¢ Build machine learning solutions to drive optimization and improvement in product and business strategies 6. â€¢ Develop processes and tools to monitor and analyze model performance and data accuracy
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
â€¢ Some experience working with large data i.e. mining, cleaning, manipulating data sets, and building statistical models â€¢ Research-oriented mind-set â€¢ Strong problem-solving skills with a drive to learn and master new technologies and techniques â€¢ Knowledge about statistical computer languages (Python, R, SQL, etc.) to draw insights from large data sets â€¢ Knowledge of machine learning and statistical techniques (OCR, clustering, decision tree learning, artificial neural networks, regression, statistical tests, etc.) and their real-world advantages/drawbacks â€¢ Knowledge about automobile and finance industry will be an extra advantage
Number of internships/jobs available: 2
Categories: Data Science"
Junior Data Analyst,"Chennai, Tamil Nadu",Indium Software,None,Organic,"Experience
–
No.Of.Positions
–
Location
Chennai
(willing to relocate to Hyderabad down the line )
Notice Period
–

Profile:
Bachelors or Masters Degree in Computer Science or any relevant field
Passion for problem solving by gathering descriptive insights through data extraction, slicing and dicing the data
Experienced in writing complex SQL select queries
Strong in querying logic and data interpretation
Individual contributor
Skills required (Technical, Managerial, Others):
SQL, one of the Visualisation toolset like PowerBI, Tableau, Qlikview
Database concepts
Business understanding
Good Communication skills, should be able to hold a conversation with client on a solution for 30 minutes
Good to have knowledge in R, Python, PowerBI
Responsibilities
Understand the real-time business problem, create insightful reports and build story via insights
Look at the data from different databases in different dimensions and think out of the box to find solutions
Connect different datasets to find new information, that presents implementable tactics and actions"
Data Engineer Intern,"Nashik, Maharashtra",TRIARQ Health,None,Organic,"JOB SUMMARY:
TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care.
TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice, care management platform and patient engagement services to help doctors focus on better outcomes.
LOCATIONS:
India: TRIARQ Health 5th floor, Rushiraj Tower, Jehan Circle, Gangapur Road Nashik -422013
US: TRIARQ Health, 1050 Wilshire Drive, Suite 300, Troy, Michigan 48084
REQUIREMENT:
We are looking for a Data Engineer Intern that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
RESPONSIBILITIES:
Defining and Modifying data base structure as per application requirements.
Creating stored procedures and function.
Creating data models by understating business logic.
Data processing, Data cleansing, Data wrangling and verifying the integrity of data used for analysis.
Managing and monitoring data redundancy.
Integrate data base connection in services (Java /Python).
SKILLS AND QUALIFICATIONS:
Experience with query languages, Data Modeling, Database Design, Dimensional and Relational Modeling, Database Schemas
Good database scripting and programming skills Python, SQL, BigQuery, PostgreSQL, MySQL
Basic understanding of machine learning techniques and algorithms, such as Linear Regression, Classification, SVM, Decision Forests, etc.
Data-oriented personality.
Data science certification should add an advantage.
BENEFITS:
TRIARQ Health is the people’s first company work within a great company culture.
Individuals can develop from technical to communication to leadership. Proactively build your career - with help from your manager, set the path you would like to take - and then do it!
Gain incredible experience working with numerous technologies.
Job Type: Full-time
Interested candidates can call at Mob Number: 9420869028.
Website: www.TRIARQhealth.com
Job Types: Full-time, Contract
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19"
AI Developer,"Hyderabad, Telangana",GrayRipples.com,None,Organic,"Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Junior Data Analyst,"Chennai, Tamil Nadu",Indium Software,None,Organic,"Experience
–
No.Of.Positions
–
Location
Chennai
(willing to relocate to Hyderabad down the line )
Notice Period
–

Profile:
Bachelors or Masters Degree in Computer Science or any relevant field
Passion for problem solving by gathering descriptive insights through data extraction, slicing and dicing the data
Experienced in writing complex SQL select queries
Strong in querying logic and data interpretation
Individual contributor
Skills required (Technical, Managerial, Others):
SQL, one of the Visualisation toolset like PowerBI, Tableau, Qlikview
Database concepts
Business understanding
Good Communication skills, should be able to hold a conversation with client on a solution for 30 minutes
Good to have knowledge in R, Python, PowerBI
Responsibilities
Understand the real-time business problem, create insightful reports and build story via insights
Look at the data from different databases in different dimensions and think out of the box to find solutions
Connect different datasets to find new information, that presents implementable tactics and actions"
Data Engineer,"Bengaluru, Karnataka",IBM,None,Organic,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. To lead in this new era of technology and solve some of the world's most challenging problems.

Your Role and Responsibilities
As a Data Engineer, you play a vital role in building the right infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Expert in setting up effective pipelines to capture data from multiple sources into the enterprise centric storage.
Comfortable in building effective analytical tools that utilize the data pipeline to provide actionable insights into data synchronization, reporting, operational efficiency and related areas.
Work with stakeholders including the product owner, data and design teams to assist with data-related technical issues and support their data infrastructure needs.
Create and maintain optimal data pipeline architecture.
Identify, design, and implement process improvements aimed at automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Assemble large, complex data sets including legacy structured data warehouse that meet functional / non-functional business requirements.
Collaborate with DevOps team to develop Continuous Integration/Continuous Delivery pipelines using containerization technologies.
Solve Big Data and Distributed Data Streaming problems using latest technologies.
Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Manipulate, process and extract value from large disconnected datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Work on State-of-the-Art cloud technologies provided by IBM Public Cloud, RedHat, AWS & others.
Be part of open, transparent agile teams who always thrive for continuous learning and contribute towards continuous improvement.



Required Technical and Professional Expertise
Possess strong knowledge in designing database models to store structured & unstructured data efficiently and in creating effective data tools for analytics experts.
Knowledge in technologies like Hadoop, Spark, Kafka, Scala, Python, etc. Knowledge in relational model databases (like DB2, MySQL, Oracle, ...) and no-SQL databases (MongoDB, Elastic Search, ...)
Knowledge on enterprise data lakes, data analytics, reporting, in-memory data handling, enterprise integration tools, etc.
Good understanding of industry best practices for data governance and security.
Good communication skills and fluent in English.



Preferred Technical and Professional Expertise
None

About Business Unit
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we represent the Analytic Solutions area of the Sales & Marketing Systems. Our mission is to provide business insights to our partners in sales and marketing to win in the market place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud-based data.

Your Life @ IBM
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we do represent the Analytic Solutions area of the Sales & Marketing Systems. Our Mission is to provide business insights to our partners in sales and marketing to win in the market-place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud based data.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Analytics & Data Science,"Bengaluru, Karnataka",Kpro Solutions,None,Organic,"Experience & Qualification:

Minimum of 9 years- experience using data science and modelling tools such as SAS, SPSS, Python or R against large data sets, with demonstrable expert-level proficiency with at least one of these tools require

Proficiency in using SQL, Hadoop/Spark for data extraction and analysis


Practical experience using multivariate and/or ML methods for classification, clustering and estimation, such as Decision Trees, Random Forests, CART/CHAID, Extreme Gradient Boosting, Ridge Regression, PCA and SVM

Responsibilities:

The candidate should be good at writing, reviewing and publishing web content

Excellent writing skills & command over English language is a must. Knowledge of technology, SaaS and experience in creating content for the web is a huge plus.

Job Description:

The candidate should be good in python,sql and data structure

email your resume / updated CV to hr@kpro.co.in"
"Analyst, Analytics & Metrics","Gurgaon, Haryana",MasterCard,None,Organic,"Integrated Analytics has pioneered a transaction based revenue methodology to inform and guide Mastercard’s Strategy, Product Design and Innovation within the Products & Innovation business. We build internal analytic partnerships, strengthening their focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market strategies.
Are you excited about Data Assets and the value they brings to an organization?
Are you an evangelist for data driven decision making?
Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across 6 continents?
Do you want to be the go-to resource for data analytics in the company?
Role
Work closely with Products & Innovation Global Digital team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support analytics and reporting needs across products, markets and services.
Translate business requirements into tangible solution specifications and high quality on time deliverables
Create repeatable processes to support development of modeling and reporting
Effectively use tools to manipulate large-scale databases, synthesizing data insights. Provide 1st level insights/conclusions/assessments and present findings via Tableau/PowerBI dashboards, Excel and PowerPoint.
Apply quality control, data validation, and cleansing processes to new and existing data sources
All About You
Experience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis
Financial Institution or a Payments experience a plus
Experience presenting data findings in a readable and insight driven format. Experience building support decks.
Advanced SQL coding
Experience on Platforms/Environments: SQL Server, Microsoft BI Stack
Experience on SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS) and SQL Server Reporting Services (SSRS) will be an added advantage
Experience in building data models a plus
Experience with data visualization tools such as Tableau, Domo, PowerBI a plus
Experience with Hadoop environments, Python, R, WPS, a plus
Excellent problem solving, quantitative and analytical skills
In depth technical knowledge, drive and ability to learn new technologies
Strong attention to detail and quality
Team player, excellent communication skills
Must be able to interact with management, internal stakeholders and collect requirements
Must be able to perform in a team, use judgment and operate under ambiguity
Education
Bachelor’s or Master’s Degree in a Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred
Additional Competencies
Excellent English, quantitative, technical, and communication (oral/written) skills
Analytical/Problem Solving
Strong attention to detail and quality
Creativity/Innovation
Self-motivated, operates with a sense of urgency
Project Management/Risk Mitigation
Able to prioritize and perform multiple tasks simultaneously
Due to COVID-19, most of our employees are working from home. We’ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. We value the safety of each member of our community because we know we’re all in this together.
Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.
If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly."
Principal Data & Applied Scientist,"Bengaluru, Karnataka",Microsoft,None,Organic,"What if your job description were simply “make tomorrow better?” Every day at Microsoft, we bring an insatiable curiosity to the workplace, challenging ourselves to reimagine what it is and what it can be. We build on what’s come before to create what’s next. We help shape the future and we empower billions of people around the globe.

We are the computational advertising team in the AI & Research organization at Microsoft. We are looking for candidates with research and applied experience in machine learning related areas. Search advertising is a $100 billion market worldwide. Microsoft's Bing search engine supports over 30% of desktop search in the US, with similarly significant presence in many other countries.
Responsibilities
We are a team of applied scientists working on machine learning components in the whole sponsored search stack. Our team works on problems related to machine learning, deep learning, natural language processing, image understanding, optimization, information retrieval, auction theory, among others. Our work entails building large-scale machine learning systems for ad matching, filtration, ranking, and multiobjective optimization, and a number of other ML-driven business problems. You will design, implement, analyze, tune complex algorithms and ML systems and the supporting infrastructure for operating on large datasets.
You will collaborate with top machine learning scientists and engineers in delivering direct business impact. We're looking for sound understanding and insight into productionizing machine learning models in large-scale systems, an ability to pick up new technical areas, as well as a commitment to developing, delivering, and supporting algorithms in production.

Qualifications
MS/BS in CS/EE, mathematical or machine learning related disciplines, with 10 or more years of experience
Solid understanding of probability, statistics, machine learning, data science
A/B testing & analysis of ML models, and optimizing models for accuracy
Experience with Hadoop, Spark, or other distributed computing systems for large-scale training & prediction with ML models.
End-to-end system design: data analysis, feature engineering, technique selection & implementation, debugging, and maintenance in production.
Experience implementing machine learning algorithms or research papers from scratch
Experience with TensorFlow/PyTorch and deep learning models is a plus

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
Data Scientist - PS Forecasting,"Bengaluru, Karnataka",HP,None,Organic,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.
We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.
At HP, the future is yours to create!
If you are our Data Scientist- PS Forecasting in India, you will get an opportunity to work on below.
This is an opportunity to join PS Category Ops team responsible for Statistical Forecasting & analytics for Personal Systems (Worldwide: Americas, Europe & Asia).
Key metrics include, Improving Forecast Accuracy (MAPE, RMSE etc.) and bias.
Mines data using modern tools and programming languages.
Defines and implements models to uncover patterns and predictions creating business value and innovation.
Manages relationships with business partners to evaluate and foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.
Ties insights into effective visualizations communicating business value and innovation potential.
Leads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and accuracy and data compliance.
Provides guidance, training and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with-
Statistical Forecasting techniques (Time series, Holts Winter, Regression analysis, ARIMA, ARIMAX etc.)
R /Python, Machine Learning Techniques (Random Forest/Decision Trees, Deep Learning)
Visualization skills: Power BI/Tableau would be preferable. Effectively and creatively tell stories and create visualizations to describe and communicate data insights.
Database Mangement: MS SQL/Oracle SQL
Exposure to Cloud solutions like AWS/Microsoft Azure will be an added advantage
Ability to design analytics solutions, simulation, modelling to address business problems.
Ability to effectively communicate data insights and negotiate options at senior management levels.
Education & Experience
Bachelor's or Master's in Operations / Operations Research / Computer Science / Statistics / Mathematics /Data Science/ MBA
6 - 12 years of work experience with significant hands-on experience in multitasking/ cross functional environment."
Data Scientist – AI ML Team,"Bengaluru, Karnataka",CustomerXPs,None,Organic,"Come aboard our growing global team and work for a category leader with a market presence in 15 countries. You will work with some of the leading financial institutions worldwide who rely on our product innovation in helping them shield themselves against the global $4 trillion problem of financial fraud. We create ‘customer-centric predictable enterprises’ and we do this by directing intelligence to the heart of every customer interaction. In real-time.
We are seeking sharp, energetic Data Scientists to help us keep pace with our global expansion. You’ll be core member of a specialist team working on our Artificial Intelligence & Machine Learning stream. You bring your skills, experience and passion and we will give you the springboard for your ambitions.
The Role:
Work as part of Clari5.ai team in defining, prototyping and implementing data science models/algorithms as part of the product.
Take ownership of the data science model end-to-end from data collection to model building to monitoring the model in production.
Along with product managers and domain experts, own the business outcomes/metrics which the data science model/algorithm drives.
Work with the product managers and engineering to define best practices for the team.
Mentor junior colleagues and conduct internal workshops.
Help to make data science and data-driven decision making a part of the organisation’s DNA.

Your Skills:
Must have 3 – 8 years of experience working on model building.
Solid understanding of the mathematics related to data science – probability, statistics, linear algebra etc.
Ability to understand business concerns and formulate them as technical problems that can be solved using data and math / stats / ML.
Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.
Must have built 2-3 end to end ML projects in the past.
Knowledge of R or Python is a must.
Strong hands on experience in working with SQL databases.
Experience working with large data sets, coming from varied sources, is a plus
Conceptual understanding of big data technologies (Hadoop / HDFS / Spark) is a plus.
Prior experience in Natural Language Processing, Recommender Systems or Social Network Analysis is a huge plus.

Your Education / Qualification:
Bachelor’s degree or equivalent combination of education and 3 years or more of experience.
Bachelor’s degree in Computer Science, Masters in Mathematics / Statistics preferred.
About Us
Endorsed Category Leader in Financial Crime Risk Management Systems for Enterprise Fraud by Chartis Research, Winner of Best Fraud Detection Product by Risk.net and ranked consistently in Chartis’ RiskTech100 rankings, CustomerXPs redefines real-time, cross-channel banking Enterprise Fraud Management using AI like a central nervous system to fight financial crime. The company’s flagship product Clari5 harnesses the combined power of Automation, AI, Decision Sciences & Real-time Decisions. Clari5 currently processes over 10 billion transactions, manages over 450 million accounts and reliably secures 4% of the global population’s banking transactions. With 200 million accounts at a single site, Clari5 has the world’s largest implementation of a fraud management solution. Tier 1 banking customers across 15 countries who trust Clari5 for driving their fraud management strategy are recipients of global industry acclaim, including Banking Technology’s Best Use of IT in Risk Management/Regulation and Celent’s Model Bank of the Year."
Big Data Engineer,"Bengaluru, Karnataka",PayU,None,Organic,"Role: Big Data Engineer
Company: PayU Payments Pvt Ltd
Location: Gurgaon/Bengaluru

About Company:
PayU, the fintech-arm of Naspers, is a leading financial services provider in global growth markets. We use our expertise and heritage in cross border and local payments to extend the services we offer to merchants and consumers. Our innovative technology, developed in-house as well as through investments and strategic partnerships, empowers billions of people and millions of merchants to buy and sell online, extending the reach of financial services.
Our local operations span 18 growth markets across Asia, Central and Eastern Europe, Latin America, the Middle East and Africa. Here we deliver fast, simple and efficient financial services technology that unlocks access to more than 2.3 billion consumers in our regions.
Regulated under the Reserve Bank of India, PayU India has advanced solutions to meet every digital payment need. The company has an in-depth understanding of the vast and intricate details of the Indian market and its payment landscape. The company brings convenience and trust through continuous innovation leveraging technology.
PayU India forays into two business verticals - payment offerings under PayU Payments Services Ltd. and alternate lending under PayU Finance. Headquartered in Sohna Road, Gurgaon, the company has a presence in Mumbai, Pune and Bangalore and has a total strength of 700+ employees. Anirban Mukherjee is the CEO for PayU India working with the global CEO Laurent Le Moal.
Under the aegis of PayU Payments Services Ltd., PayU provides payment gateway solutions to online businesses through its cutting-edge and award-winning technology. In India, PayU covers nearly 60% of the airline business and 90% of the entire e-commerce business and processes over INR 120,000 crores worth of digital payments annually (at current run rates). The company offers more than 70 local payment methods and serves more than 350,000 merchants including leading e-commerce businesses in India. The company also empowers SMBs, enabling them to accept mobile and online payments with minimum development effort.
With credit being the key business priority, PayU has also developed LazyPay, an alternate lending platform to offer credit solutions such as Small Ticket Credit (Buy Now, Pay Later), App based personal loans and Point of Sale Credit (Merchant EMI). Since its launch in 2017, LazyPay has gained significant traction and has disbursed 20mn+ loans to a customer base of a million user.
PayU is bullish on investment opportunities in India. The company has been an aggressive investor, committed to the evolution of fintech in the country. PayU has spent about $250 million over the past three years in Asia's third-largest economy and is further scouting for more lucrative investment and acquisition opportunities to fuel growth.
PayU's acquisitions in India include that of Wibmo (April 2019 worth $70 mn) and Citrus Payment Solutions (September 2016 for $130 mn). PayU has also invested in PaySense (July 2018) and ZestMoney (December 2016) in India.

Role and Background Information:
Gather and process raw data at scale.
Design and develop data applications using selected tools and frameworks as required and requested.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.


What you'd need to bring to the table:

2 – 7 years of recent experience in data engineering.
Bachelor's Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in MapReduce is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems

So what do we offer?
A Competitive salary, including benefits
Modern offices with individual working spaces
Exceptional projects
Awesome teams that love finding ways of making things better, faster, stronger
Interesting growth prospects
ESOPs (SARs)

Education-
Bachelor of Engineering (IIT/NIT/Bits is Preferred)"
DATA SCIENTIST,"Bavdhan, Pune, Maharashtra",Alpha ICT LLP,None,Organic,"Should have a Master’s degree in Statistics, Mathematics, Computer Science
Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes
Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques"
"Data Science Lead – Python, AI/ML","New Delhi, Delhi",MNF – MyNextFilm,None,Organic,"Data Science Lead – Python, AI/ML
We’re looking for a Data Science Lead to build our product.
You must also be an effective communicator, possess a high degree of passion for product development, work well in a team environment, thrive in a fast-paced culture, and bring a proven background in building scalable data-driven solutions.
What is to be done?
Assess product needs and requirements to ensure your team is adopting the appropriate approach to solve the challenges
Design controlled experiments to measure changes to output quality
Design and implement high performance and robust analytical models in support of product deliverables
Research and bring innovations to develop next generation product.
Evolve the approach for the application of machine learning/deep learning to existing programs
Be responsible for solution and code quality including providing detailed and constructive design and code reviews
Must have skills
Demonstrable strength in programming in Python
Demonstrated Experience in at least in one of the following on Unstructured Data – NLP/Operations research/Sentiment analysis/Probabilistic models
Good understanding of applied statistics, such as probability distributions, measures of dispersion and central tendency, hypothesis testing and statistical inferences.
Knowledge of NoSQL DBs like MongoDB, Cassandra and HBase
Ability to drive a product from conception to completion with guidance
Proven ability to perform in-depth analysis, compile and interpret results
Ability to differentiate and apply models on the problem statement
Should Know what model to apply and in what situation to apply (know advantages and disadvantages of ML /DL techniques)
Excellent quantitative skills and the ability to tell a story using data
It will be good if you also have
Expertise in application of machine learning algorithms on large datasets
Experience with large datasets and distributed computing
Experience in deploying models in cloud platforms such as AWS/Google Cloud
Knowledge of Reinforcement Learning
Personal attributes:
Strong written and verbal communication skills
Articulation skills
Good team player
Self-starter who requires minimal oversight
Ability to prioritize and manage multiple tasks
Process orientation and the ability to define and set up processes
Required Candidate profile
Education:
B. Tech/M. Tech in Computer Science, Math, Physics, Engineering, Statistics or other quantitative or computational field.
Ph.D. in Computer Science, Math, Physics, Engineering, Statistics or other quantitative or computational field"
Data Scientist,"Pune, Maharashtra",PharmaACE,None,Organic,"Data Scientist
Positions in Pune, India.
PharmaACE is a growing Global Healthcare Consulting Firm, headquartered in Princeton, New Jersey. Our expert teams of Business Analysts, based across the US, Canada, Europe, and India, provide Analytics and Business Solutions using our worldwide delivery models for a wide range of clients. Our clients include established, multinational BioPharma leaders and innovators, as well as entrepreneurial firms on the cutting edge of science. We have deep expertise in Forecasting, Business Analytics, Competitive Intelligence, Sales Analytics, and the Analytics Center of Excellence Model. Our wealth of therapeutic area experience cuts across Oncology, Immuno-science, CNS, CV-Met, and Rare Diseases. We support our clients’ needs in Primary Care, Specialty Care, and Hospital business units, and we have managed portfolios in the Biologics space, Branded Pharmaceuticals, Generics, APIs, Diagnostics, and Packaging & Delivery Systems.
Brief introduction :
If you are keen to work on analytical database problem solving, then work in the area of advance data analytics to provide consulting to pharmaceutical clients
Designation name & Description :
As a Data Scientist, you are expected to develop and implement AI/ML techniques to help client business needs.
Advance data analytics team designs and implements analyses in SQL or Redshift or Python or excel based on patient level data or similar datasets to address business problems for our clients and engage with onshore team / client to help them understand the analysis and lead to data driven decision making.
Job Responsibilities:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Managing available resources such as hardware, data, and personnel so that deadlines are met
Analyzing the AI/ML algorithms that could be used to solve a given problem and ranking them by their success probability
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world
Verifying data quality, and/or ensuring it via data cleaning
Supervising the data acquisition process if more data is needed
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Analyzing the errors of the model and designing strategies to overcome them
Knowledge on Deep learning techniques is added advantage
Deploying models to production
Qualifications :
Bachelor’s/Masters Degree
1-2 years of functionally related professional experience in software development is required
Having work experience in Pharma/Life sciences background is advantage
Experience of Data Science, Business Analytics, Predictive Analytics, NLP, Machine Learning and Cognitive Computing is required
Proficiency with Python and basic libraries for AI/ML
Expertise in visualizing and manipulating big datasets
Experience of programming languages Like R, Python, MySQL, NodeJS is required
Experience developing new applications within an agile environment preferred
Connect with PharmaACE in India on social media:
Follow PharmaACE on LinkedIn and Twitter for more job opportunities
Read our blogs for latest news and information from the Pharma world
To know more about us visit our website
Associate Consultant / Consultant Advanced Analytics Statistician – Consultant / Sr. Consultant Data Scientist Consultant / Senior Consultant Consultant - Business Intelligence Associate Consultant/ Consultant - Forecasting Associate Consultant - Consultant Commercial Analytics Analyst - Chart Audit Associate Consultant /Consultant – Chart Audit Associate Consultant(Epidemiologist) Consultant/Senior Consultant- Forecasting Consultant Forecasting (WFH)"
Data Analyst,"Bengaluru, Karnataka",Unusual Hire,None,Organic,"Data Analyst Job Description
ABOUT US
Unusual Hire: Helping Businesses, Building Dreams
Unusual Hire is an intriguing platform that allows companies to hire freelancers from a global network of top talent for all their dynamic recruitment needs. Unusual Hire gives entrepreneurs and freelancers an opportunity to break the norms and follow their dreams.
Why JOIN US:
OUR CULTURE
The life at Unusual revolves around our core values of trust and respect. We believe in collaboration and making mistakes. Unusual Hire gives you an opportunity to move fast and break the norms, no matter even if you commit mistakes, but you should always try. This place provides you the complete ownership; you are your boss here.We believe in equality, diversity, and maintaining a healthy relationship with our employees and clients. We have a diverse team of employees, who believe in showing the best results in our performance. If you have the right skills, you can work here, irrespective of your age or gender. We set our goals high and hire a team of quality professional freelancers to work with anywhere, anytime.
To know more visit our site @https://unusualhire.com/
Job Title: Data Analyst
Job Responsibilities
· Interpret data, analyze results using statistical techniques and provide ongoing reports
· Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
· Acquire data from primary or secondary data sources and maintain databases/data systems
· Identify, analyze, and interpret trends or patterns in complex data sets
· Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
· Work with management to prioritize business and information needs
· Locate and define new process improvement opportunities
Data Analyst Requirements:
· Bachelor’s degree from an accredited university or college in computer science.
· Work experience as a data analyst or in related field.
· Ability to work with stakeholders to assess potential risks.
· Ability to analyze existing tools and databases and provide software solution recommendations.
· Ability to translate business requirements into non-technical, lay terms.
· High-level experience in methodologies and processes for managing large scale databases.
· Demonstrated experience in handling large data sets and relational databases.
· Understanding of addressing and metadata standards.
· High-level written and verbal communication skills.
Compensation: Best in the industry.
Location: Bangalore
Job Type: Part-time
Work Remotely:
Temporarily due to COVID-19"
Computer vision engineer,"Chennai, Tamil Nadu",Deepquanty Artificial Intelligence labs,None,Organic,"Hi,
Greeting from DeepQuanty Artificial Intelligence Labs !!!
We would like to take an opportunity to introduce DeepQuanty Artificial Intelligence Labs. It is a Computer Vision Lab devoted to extracting and processing data from images using Deep Learning, Artificial Intelligence and Machine Learning. It is a start-up no more than 1 year old with four products: SnapChek, FormEasy, EasyKYC and Zapscore - all directed at the BFSI Sector. It is well funded and operational. Thus this is an opportunity to apply your cross-functional skill sets, creativity, machine learning, robotics and control systems to solve exciting product development changes.
Company Profile: -
DeepQuanty Artificial Intelligence Labs is a product startup in the space of Artificial Intelligence and Machine Learning. It has already several products in the Computer Vision space and is very well received in the BFSI industries. It has every intention to exploit all opportunities in this space by way of astute product development and taking them to several other industries as well.
DeepQuanty AI Labs has been set up by founders with over 75 man years of experience in the area of analytics and technological product developments. Specifically, the founders come from successful and ongoing ventures MarketsOf1 Analytical Marketing Services Pvt. Ltd. and Pranion Technology Ventures.
Job Description: -
We’re looking for experienced, detail-oriented individuals to join our team and work in a startup environment. This is an opportunity to apply your cross-functional skill-sets, creativity and experience in computer vision, machine learning, robotics and control systems to solve exciting product development challenges. This is a high-visibility position within our fast growing company and assumption of increased responsibilities over time is expected.
Skills and Qualification: -
Minimum 2 year of experience working in AI / Machine Learning.
Minimum 1 year of experience working in Deep Learning.
Bachelor's or Master's Degree in Computer Science or related field.
Machine Learning in Computer Vision.
Working experience in frameworks like OpenCV, Tensorflow/Keras/PyTorch, Scikit-Learn, Matplotlib, Pandas, Numpy.
Good Python knowledge.
Working experience in Flask/Django/Tornado.
Well versed with Development Environment on Linux.
Job Location: -
Chennai
Job Types: Full-time, Internship
Experience:
Python & Linux: 1 year (Preferred)
Deep learning: 1 year (Preferred)"
Data Analyst,"Bengaluru, Karnataka",Netradyne,None,Organic,"Experience: 0 to 3 Years
Role and Responsibilities
Primary role will be to understand the daily challenging problems, perform analysis and help team make informed decisions with data and visualizations.
Responsible for monitoring IoT devices and finding patterns that can help identify anomaly and device failures.
Monitoring and analysing important metrics.
Scripting and automating the processes and reports.
Every day is a new challenge; hence you will always be learning new things and tools to help solve the problems.
Essential Skills
Good knowledge in Mathematics, Statistics and Computer Science.
Ability to communicated findings in a clear and intuitive way.
Strong hold on python and data analysis libraries – pandas, numpy (scikit-learn is an added advantage)
Good understanding of data bases and SQL.
Well versed with MS office tools mainly Excel.
Experience in delivering data analysis and visualization projects – experience in machine learning is a bonus.
Ability to understand, articulate the problem and come up with mathematical solutions.
Motivated and natural curiosity in solving problems.
Knowledge of these tools is an added advantage – Tableau, Python-Dash, any other Visualization tools.
Qualifications and Education Requirements
BE/ BTECH/MSc in a related field (M. Tech. preferred)
Preferred Skills
Participation in online projects or competitions on data analysis"
Data Science Engineer,"Bengaluru, Karnataka",AXA Business Services,None,Organic,"Overview:
Will be responsible for promoting data science topics through the local entities; helping entities in integrating data science in their organisation; industrialize data science projects focusing on production, maintenance, monitoring, availability, performance; and manage an innovative set of data science tools (Smart Data Studio), used by data scientists across the group.
Key responsibilities:
Follow and manage the engineering aspects of industrialised Data Science projects: platforms, production constraints, connections, factory compatibility
Advise and support Smart Data Studio users
Help users regarding level 2 and level 3 issues
Help users regarding industrialized data science good practices
Contribute to documentation creation and update (wikis, tutorials, …)
Contribute to tools upgrade
Support Data Science tools development and benchmarking
Help product owner and developers to define functionalities, and prioritise the Smart Data Studio roadmap
Contribute to data science tools benchmarking and evaluation
Contribute to data science tools enhancements and new functionalities
Key skills:
Must have knowledge of machine learning (scikit-learn, MLLib, vowpal wabbit), coding (Python, Scala, R), spark (Python and/or Scala), GNU/Linux, Hadoop (administration and/or development with PIG, HIVE)
Added advantage: Knowledge of H2O, Dato, Data Science challenges track record, Git, Jenkins
Passion for learning new tools, languages and frameworks
Ability to be creative and innovation-minded
Fast adaptation to changing requirements
To work with minimal direct guidance, self-motivated and proactive
Practical, hands on approach to get results
Willing and capacity to teach and transfer knowledge to the team
English - Fluent in speaking and writing
Ability to work in a multi-cultural environment
Strong oral and written communication skills
3-5 years of relevant experience
Experienced in working in an international environment and open to overseas travel"
Data Analyst,"Bengaluru, Karnataka",Stellapps Technologies,None,Organic,"Full Time
2 years
Bangalore

Data Analyst
Creatively explore new analytical solutions to develop products
Responsibilities
Develop prototypes, proof of concepts, algorithms, predictive models, and custom analysis
Determine new ways to improve data and search quality, and predictive capabilities
Use statistical methods to analyze data and generate useful business reports
Data manipulation to uncover trends and insights i.e. sub setting, pivoting, summarization, sorting
Creating data visualizations to effectively convey findings
Work with management team to create a prioritized list of needs for each business segment
Experience with common data science toolkits, such as Python, Excel, R, NumPy, Pandas etc. Excellence in at least one of these is highly desirable
Strong verbal and written communication skills
Experience with data visualization tools such Tableau, Superset, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience in data models and reporting packages
An analytical mind and inclination for problem-solving
Requirements
Strategic Team
Full Time
Data Analyst
2 years
Bangalore"
Mobile AI Engineer - NLP & Speech Tech,"Chandigarh, Chandigarh",DataToBiz,"₹6,00,000 - ₹10,00,000 a year",Organic,"DataToBiz is an AI and Data Analytics Services startup. We are a team of young and dynamic professionals looking for an exceptional Mobile AI Engineer to join our team in Chandigarh. We are trying to solve some very exciting business challenges by applying cutting-edge Machine Learning and Deep Learning Technology.
Being a consulting and services startup we are looking for quick learners who can work in a cross-functional team of Consultants, SMEs from various domains, UX architects, and Application development experts, to deliver compelling solutions through the application of Data Science and Machine Learning. The desired candidate will have a passion for finding patterns in large datasets, an ability to quickly understand the underlying domain and expertise to apply Machine Learning tools and techniques to create insights from the data.
Responsibilities:
* As a Mobile AI engineer on our team, you will be responsible for solving complex data problems for various clients using deep learning techniques.
* Work with the team to extract and transform natural language data from audio and text on the mobile native application.
* Develop and implement a framework for mobile processing of language syntax and semantics as well as contextualization of audio and textual data using python
* Develop strategies and implement methods to pass NLP techniques to classification algorithms.
* Execute project plan to meet requirements and timelines.
* Identify success metrics and monitor them to ensure high-quality output for the client.
* Deliver production-ready models that can be deployed in the production system.
* Understand and identify appropriate data sources required for solving the business problem at hand.
Requirements
* 2+ years of working with Python, Machine learning with exposure to one or more DL frameworks like Tensorflow, Keras, Caffe, MXNet etc
* Minimum 2 years experience in text representation techniques and NLP algorithms to succeed in this role along with hands on Speech Analytics
* Exposure to Deep Learning algrithm implementation in either speech analytics or NLP domain
* Exposure to ML/DL techniques and algorithms to work with different data formats including voice and text unstructured data
* Strong verbal and written communication skills with other developers and business client
* Android or iOS experience will be advantageous
* Exposure to DL Model optimization & transfer learning techniques
Job Type: Full-time
Salary: ₹600,000.00 - ₹1,000,000.00 per year
Experience:
Full time Work: 2 years (Required)
NLP or Speech Tech: 1 year (Required)
Deep Learning: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19"
Risk Analytics - Machine Learning Engineer,"Chennai, Tamil Nadu",DTCC,None,Organic,"About this Opportunity
The incumbent will be responsible for studying data, discovering the information hidden and help making smarter and better decisions for the Business. The primary focus of the role will be on applying text and data mining techniques, doing statistical analysis and building high quality and high-performance prediction systems integrated with the Risk applications. They will also have proven experience in data analysis, modeling and implementing solutions along with sound understanding of capital markets and financial risk domain to be able to recommend the best-fit model and solution approach.
Business Unit: Global Chief Risk Office
Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems.
What You'll Do
Collaborate with cross functional teams to collate data
Enhancing data collection procedures to include information that is relevant for building analytical solutions
Analyze, extract and understand meaningful patterns from the large volumes / dimensions of historical data by utilizing analytics techniques and SMEs’ inputs
Design, develop, evaluate and implement high quality innovative predictive/prescriptive models using open source tools such as R, Python, or similar scripting within Apache Spark/AWS cloud based big data environment
Support the team in creating/executing novel approaches to solve challenging problems by leveraging AI/ ML/NLP and Big Data/Cloud technologies
Collaborate closely with Business Partners/Analysts, Data Analysts, Application Development and other Data Scientists to integrate innovations and algorithms into useable data products
Doing ad-hoc analysis and presenting results in a clear manner
Aligns risk and control processes into day to day responsibilities to monitor and mitigate risk; escalates appropriately
Sound Like You?
Minimum of 6 years of related experience
Bachelor's degree preferred with Masters or equivalent experience
Additional Qualifications
Minimum of 3-5 years of related experience in Data analysis, Data Science, Modeling
Experience with SQL, Python, Big Data and Machine Learning Algorithms
Strong analytical and problem-solving skills
Great communication skills
Experience in Financial industry with focus on Risk Management is preferred
Experience in Data Visualization tools and AWS is a plus

About DTCC

DTCC safeguards the financial markets and helps them run efficiently, in times of prosperity and crisis. We are uniquely positioned at the center of global trading activity, processing over 100 million financial transactions every day, pioneering industry-wide, post-trade solutions and maintaining multiple data and operating centers worldwide. From where we stand, we can anticipate the industry’s needs and we’re working to continually improve the world’s most resilient, secure and efficient market infrastructure. Our employees are driven to deliver innovative technologies that improve efficiency, lower cost and bring stability and certainty to the post-trade lifecycle.

Our work environment favors openness and gives people freedom to do their jobs well, by encouraging diverse opinions and emphasizing teamwork. When you join our team, you’ll have an opportunity to make meaningful contributions at a company that is recognized as a thought leader in both the financial services and technology industries. A DTCC career is more than a good way to earn a living. It’s the chance to make a difference at a company that’s truly one of a kind.

Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems."
Data Science Engineer,"Bengaluru, Karnataka",AXA Business Services,None,Organic,"Overview:
Will be responsible for promoting data science topics through the local entities; helping entities in integrating data science in their organisation; industrialize data science projects focusing on production, maintenance, monitoring, availability, performance; and manage an innovative set of data science tools (Smart Data Studio), used by data scientists across the group.
Key responsibilities:
Follow and manage the engineering aspects of industrialised Data Science projects: platforms, production constraints, connections, factory compatibility
Advise and support Smart Data Studio users
Help users regarding level 2 and level 3 issues
Help users regarding industrialized data science good practices
Contribute to documentation creation and update (wikis, tutorials, …)
Contribute to tools upgrade
Support Data Science tools development and benchmarking
Help product owner and developers to define functionalities, and prioritise the Smart Data Studio roadmap
Contribute to data science tools benchmarking and evaluation
Contribute to data science tools enhancements and new functionalities
Key skills:
Must have knowledge of machine learning (scikit-learn, MLLib, vowpal wabbit), coding (Python, Scala, R), spark (Python and/or Scala), GNU/Linux, Hadoop (administration and/or development with PIG, HIVE)
Added advantage: Knowledge of H2O, Dato, Data Science challenges track record, Git, Jenkins
Passion for learning new tools, languages and frameworks
Ability to be creative and innovation-minded
Fast adaptation to changing requirements
To work with minimal direct guidance, self-motivated and proactive
Practical, hands on approach to get results
Willing and capacity to teach and transfer knowledge to the team
English - Fluent in speaking and writing
Ability to work in a multi-cultural environment
Strong oral and written communication skills
3-5 years of relevant experience
Experienced in working in an international environment and open to overseas travel"
Data Analyst,"Bengaluru, Karnataka",Apple,None,Organic,"Summary
Posted: Aug 14, 2020
Weekly Hours: 40
Role Number:200170317
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just create products — they create the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. It takes deeply dedicated, intelligent and hard-working individuals to maintain and exceed the high expectations for the exciting iPhone brand at Apple. The iPhone Operations team is seeking a Sr. Data Analytics Lead to take on the responsibility of improving superior quality and manufacturing goals through statistics, analytics, modeling, and business intelligence tools.
Key Qualifications
The role includes the following main duties:
Employ statistical techniques with big data initiatives and tools to drive major operational business decisions.
Answer complex questions through data, analysis, and clearly communicate findings to multi-functional teams for direction.
Influence repair processes and fraud detection improvements by scripting analysis on very high volumes of data at a commodity and parametric level.
Seek opportunities to improve data collection, reporting and consumption based on business needs.
Regularly collaborate with internal and external information technology teams on resolving data issues, as well as mitigation plans to avoid errors in the future.
Participate in strategic capital systems planning. Required Experience:
Excellent analytical skills, advanced level of statistics with the ability to identify and predict trends and anomalies.
You should have expertise, aptitude or prior background understanding complex data sets to be able to translate to: product testing, parametric big data, manufacturing, robotics and capital equipment.
Creative and innovative ideas to select and configure appropriate technologies and programming languages required to ensure successful business impact.
Experience in data mining very large data sets, high proficiency in SQL (Teradata, Oracle, or MySQL or other RDBMS.)
Experience in Hadoop, Hive, HDFS, Spark, AWS Redshift, Presto, and other distributed processing systems preferred.
You will have superb software development skills with proficiency in Python, R and libraries such as (scikit- learn, scipy, R, NetworkX, Spacy, and NLTK).
Data visualization experience with tools such as: Tableau, JMP, R creating dashboards and presenting data through reports.
Proven ability to handle various tasks concurrently and in a timely manner, including large, complex projects.
Effective presentation skills and be able to explain complex data and charts in a concise manner to large audiences.
Superb communication skills, both verbal and written.
Prior experience in Manufacturing, Test, and Consumer Electronics is a plus
Description
The Data Analyst utilizes data, infrastructure and intelligence tools to tackle interesting problems every day. You will be tasked with finding insights from data that will improve product operations, quality, and manufacturing efficiencies by understanding the variables impacting yield. You will drive strategic initiatives for better data collection and reporting, ensure data integrity across multiple data sources, and reduce analysis time through automation and creative solutions. You will present data to peers, managers, directors, and VPs; and highlight data patterns that could be useful for making business decisions. You will work closely with a variety of lines of business: Operations, Test Engineering, Quality, Engineering, Product Development, Customer Service, Supplier Quality, Global Supply Managers, Suppliers, Contract Manufacturers, Repair, Fraud Detection, Business Intelligence and IT teams. You will take data from disparate sources, apply statistical modeling, analyze and interpret its specific meaning, and clearly convey the significance of the assessment, tailored to individual teams, as well as the business as a whole. The position requires a software programming skill set (preferably python), utilization of statistical techniques, experience understanding data integrity, and implementing automated solutions. You will need to have a grasp of relational database management systems, design, and structured query language (SQL).
Education & Experience
Master of Machine Learning, Data Science, Statistics, Operations Research or related fields with 5+ years’ experience applying machine learning techniques to real business problems."
AI Engineer,"Chennai, Tamil Nadu",iKomet Technology Solutions,None,Organic,"Work Location: Chennai
Required Experience: 3 - 5
Job Description:
Understand the business problem, challenge of existing technologies and areas of application for AI technologies.
Coordinate between Data Scientists and Business Analysts
Automate infrastructure used by the Data Science team
Convert machine learning models into APIs so that other applications can access them
Test and deploy models
Develop minimum viable products based on machine learning
Automate processes by utilizing machine learning
Use AI to empower the company with novel capabilities
Develop required machine learning models or prototype applications applying formulated AI recipes and verify the problem/solution fit.
Involve in development of AI Platform and AInization projects.
Strong fundamental understanding of ML/DL algorithms and OpenCV.
Development of micro services for NLPasaservice.
Development of machine learning / NLP APIs.
Able to work in Linux based OS.
Experience with one or more scientific analysis and prototyping environments such as the SciPy/NumPy stack or with an ML framework such as TensorFlow or PyTorch.
Experience writing maintainable, testable, production-grade Python or Golang code.
Experience with data engineering, deep learning frameworks and related open-loop testing techniques is a plus.
Comfortable working in a fast paced, highly collaborative, dynamic work environment."
"Consultant, Data Science and Analytics","Chennai, Tamil Nadu",TransUnion,None,Organic,"What We'll Bring:
TransUnion, a global information and insights company, is seeking a highly-skilled Consultant for its Data Science & Analytics team.

You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments.

Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes.
What You'll Bring:
Protecting the health and wellness of our associates and candidates considering a career at TransUnion is our highest priority. In supporting this vision, our recruitment and new hire experience for this role is fully virtual for the time being. Candidates interviewing will get to know our team over the phone and video, and this role will operate virtually upon hire until we return to the office. Even though we’re not physically together right now, our goal is to provide you a supportive candidate and new hire experience that will immerse you in our culture and set you up for success at TransUnion. Dynamics of the Role TransUnion, a global information and insights company, is seeking a highly-skilled Consultant for its Data Science & Analytics team. You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments. Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes. The Team’s Focus The Data Science & Analytics team is an industry-recognized, client-facing department that rewards an entrepreneurial spirit. We have deep technical expertise and an established reputation as an analytic solutions provider in the consumer identity and credit information space. We have a wealth of data and industry experience within our large group of highly-trained analysts, Data Scientists, engineers, and economists. We also have a modern computing environment based on best-in-class “big data” technologies and the freedom to explore new data sources and statistical and machine learning methodologies. All of these resources will enable you to help us deliver next-generation analytic solutions for our customers. How You’ll Contribute This position is responsible for developing data-driven solutions to challenging and complex problems related to IT infrastructure/ operations, data ingestion and quality control, and enhancing customer experience. You will also be responsible for consumer credit models, strategies, and business intelligence solutions through consulting engagements and research serving TransUnion and its clients. This position requires an understanding of consumer lending, credit risk management practices, IT operations and process engineering. You will partner with internal and external cross-functional teams to drive new business initiatives and deliver long term value-added product propositions for B2B customers in the US financial services segment at TransUnion. This includes but is not limited to the development of predictive risk management and business intelligence solutions for credit card issuers, auto & mortgage lenders, collections agencies and retail banks. You will lead analytic client engagements involving descriptive, predictive, and prescriptive leveraging a variety of techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis). You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, SAS, Python, SQL, Hive, and Pig on Linux, PC, and mainframe computing platforms. You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience. You will develop project proposals, sales presentations, and promotional collateral to enable the adoption of integrated customer solutions supported by TransUnion. You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services. You will provide mentorship and training to junior colleagues and maintain progress on all initiatives under limited direct supervision. You will foster a high-performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand. What You’ll Bring Master’s or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. A track record of academic excellence At least two (2) years of professional experience performing analytic work in Financial Services, Technology, or related industries. Experience applying advanced analytics to planning and infrastructure problems is preferred. Multiple examples of demonstrated success in client-facing roles over a period of at least two (2) years Ability to travel 10-20% Strong analytical, critical thinking, and creative problem-solving skills Advanced programming skills; mastery of a statistical language such as R or SAS; experience using other programming and data manipulation languages (SQL, Hive, Pig, Python, C/C++, Java); proficiency with Microsoft Office tools Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast-paced environment Strong project management skills with the ability to manage multiple assignments effectively An understanding of current industry challenges and trends at the level needed to proactively identify customers’ analytical needs and related business opportunities
Impact You'll Make:
What We Offer
We aim high — and are reaching for new heights every day. This is a terrific time to join our team as we build on our commitment to integrity, service, reliability, and innovation. These values stand behind the decisions we make every day, as well as our relationships at work and with the customers we serve. We believe in the power to achieve and are taking it in bold new directions.
Who We Are
A global leader in credit information and information management services, TransUnion gives businesses, consumers and the global community the power to achieve their goals. Businesses count on us to better manage risk and customer relationships. Consumers are able to better manage credit to achieve their financial goals. And in communities around the world, we help build strong economies and give people the power to achieve their dreams.
Exceptional opportunities are coming as we build on this strong foundation. Our ambitious growth strategy includes substantial new investment worldwide, a wide range of new solutions to help our customers succeed like never before, and new ideas for expanding our reach in every part of our dynamic and fast-moving industry. We’re on an exciting journey and you can be a part of it.
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.
TransUnion Job Title
Consultant, Data Science and Analytics"
Data Scientist,"Bengaluru, Karnataka",Near,None,Organic,"The Opportunity
This mid-level Data scientist role provides an opportunity to be a part of the Near’s Data Science team. You’ll join a team of experts in application of data science models for a location intelligence platform. They carry out R&D, prototyping, development and deployment of best-in-class AdTech and MarTech data science solutions. The role requires to partner with key decision makers in business, product and engineering teams within the company. You will design, develop and craft narratives that help us understand the user base and pitch the product to our clients.
You will be part of one of the fastest growing Enterprise SaaS companies, where you are given the freedom to experiment and innovate new winning ways – a great opportunity for people who can work independently and are self-driven.
Tasks include
Developing core data science models and capabilities that power the Near Location Intelligence Platform and associated products.
Applying various data science methods such as time series, causal inference, experiments, machine learning, modeling, and forecasting to understand the most important aspects of our product, users, and business.
Use advanced data analytics including processing structured (payments, telecom, page clicks etc) and unstructured data in multiple formats (text, audio, video) spanning multiple domains including user profile data, geo-spatial data, network data and retail data.
Research and create intellectual property for the company that will benefit Near and its partners.
Use nonparametric and probabilistic models to generate insights keeping in mind the bias- variance trade-off.
Work closely with the Engineering team to operationalize and deploy the models.
Partner with technology and the business team to build a superior data quality pipeline that will feed the models.
Understand and prioritize the data science work based on cost effectiveness and leverage time management skills.
Attend conferences and organize workshops/meet-ups to be in touch with the data science community.
Skills and Requirements
You should hold a degree in M.Tech/MS/PhD in quantitative field (e.g. Computer Science, Econometrics, STEM fields) a plus.
Overall 3-6 years of experience with at least 3 years of working experience in any data driven company/platform, developing data science models and quantitative models.
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection.
Write complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Java, Scala, Python), PrestoDB, AWS Cloud, PyMC3/theano/tensorflow and other scientific python/R modules is a plus.
Need to be comfortable writing code for model building and bootstrap, test and own models through their lifecycle including devops and deploying into cloud.
Candidate is expected to have exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Must have completed academic projects in data science experimenting with raw data and generating insights, publications are a plus."
Machine Learning/Deep Learning Experts,"Bengaluru, Karnataka",CrunchMetrics,None,Organic,"We at CrunchMetrics are looking for talented Machine Learning Scientist with a background in Machine Learning development who desires to work on building solutions to complex challenges and can create, innovate, and define the next generation of autonomous analytics solutions. This role requires an expert level of data science knowledge as well as experience with data science techniques, systems and processes.
The position will report to the Head of Strategy and Products at CrunchMetrics and will be based in Bangalore, India
Info
Category :AI
Job Code :CMA01
No. of openings :7
Skills
Qualifications
BRIEF
6-8 years proven experience in building Machine Learning/ Deep Learning based solutions/ products.
Strong hands on skill in Python using libraries like NLTK, SkLearn or Hands on in R and Java.
Proven background in at least one of the following – Reliability models, Markov Models, Stochastic models, Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Non-parametric Methods, Multivariate Statistics.
Experience working with large data sets and tools like Elastic Search, Spark and Hive.
Excellent communication skills including the ability to present technical concepts to a wide range of audiences, both internal and external.
Ability to work effectively across teams."
Data Science Developer,"Pune, Maharashtra",Ajira AI,None,Organic,"At Ajira AI, we focus on developing smart products that leverage artificial intelligence algorithms. We build complex cloud based and mobile business applications. However make no mistake, we solve very significant systems problems along the way. Our products work across our customers ecosystems to help people.
We’re very pleased to be expanding our development team. We’re a close knit group of innovators that have previously launched very successful start-ups. Our track record building successful technology businesses and reputation is helping us grow and we’re now looking to add experienced Data Science Developers to our team in Pune.
You have hands-on experience using AI frameworks such as Tensor Flow and Keras in a work setting. You have at least a couple of years of work experience using Python/R. You’ve used multiple classification models and Pandas, Numpy, Matlab etc. You are proficient at using algorithms such as Logistic Regression, Multiple Linear Regression, Random Tree, Support Vector Machine, Naive Bayes etc. You have a track record of demonstrated success in business problem solving. Data visualization experience is a plus.
You are the kind of developer that other developers seek out to solve their technical difficulties. You keep up to date with what’s happening in the data science world and know the differences between classification, regression, clustering and time series. You know the limitations of each algorithm. You are motivated to learn new technologies.
That’s a high level summary of what we’re looking for but before we dive into the detail, you’ll probably want to know who you are going to be working for and what your work environment will be like:
Who we are:
We are an Insurtech company with a core mission of leveraging artificial intelligence algorithms and techniques to solve complex business problems. We like to think that solving these business issues for our customers helps make them better at serving their customers. Some of our applications help people who may be injured or have been in an accident. In our opinion that’s a worthwhile pursuit. While our current business vertical is insurance, we see our technology expanding to other business verticals with time. Our founders have a solid track record of starting technology companies and making them successful.
We love what we do and not the least of which is that we have the opportunity to try out and ‘play’ with the latest advances in tools and technology.
Who you’ll be working with:
We are a collaborative, tight knit group of contributors. While we’re headquartered in the Chicago area in Lisle, our software lab is located in Pune, India. We have decades of experience working with remote teams. We’re looking to expand our Developer positions in Pune, India.
You’ll find our CTO a joy to work with; someone with excellent technical skills, always willing to mentor, roll up his sleeves and get deep into the technical issues. He possesses rare technical insight and no matter the day or time he’s always willing to contribute to move things forward. Our CEO is a rare combination of technical and business skills with remarkable vision and the ability to easily cut through the most complex issues to find the simplest answer. You’ll be working side by side with them and the rest of our technical team in what will be an amazing opportunity for you.
Your work environment:
We are a group of talented and dedicated individuals and through we are a start-up, we have a ‘no insane hours’ rule.
We are not clock watchers. If you need to take off for a couple of hours to visit the doctor or dentist go ahead. We look at what you’re accomplishing not how many hours you spend in the office. We conduct meetings on a daily basis with our Chicago office so some overlapping hours are necessary.
Our Pune office space is modest. We prefer to pay you more than prevailing market wages rather than spend money on fancy office space.
Our work is performed using the latest technology and tools. We’re constantly innovating and improving our delivery capability by building our own components and tools as well as licensing new tech that we’ve tried and works in our environment.
We are an open, collaborative work environment and suggestions are not just welcome, they are appreciated. You’ll find our product roadmap is exciting and full of opportunity.
Your skills:
You keep up with technology changes and trends
You are a top notch Developer whose code not only solves complex issues but is written in such a way that the rest of your team is able to understand. This means that you’re not shy about documenting your code and you understand the need for coding standards and why everyone should use them
You are motivated. You have amazing debugging skills and are quick at identifying and fixing bugs
You are skilled at development with Python/R and using Ai frameworks such as Tensor Flow and Keras
Proficient in the use of Pandas, Numpy, Matlib, MatPlotlib and commonly used libraries
You understand ML algorithms such as Support Vector Machine, Naïve Bayes, Logistic Regression, Multiple Linear Regression, Random Tree, XgBoost etc thoroughly
You are quick to understand business problems and understand how to classify problems that exist in large datasets
Any data visualization experience is a plus as is any background in statistics
You have developed, implemented and supported a ML application successfully at work
How to apply:
Send a pdf of your resume to careers@ajiraai.com
This post can also be found at http://www.ajiraai.com/careers
We look forward to hearing from you
If you’re not available or interested in this position but know someone who might be a good fit, please pass this along
Ajira AI is an equal opportunity employer and we do not discriminate on basis of caste, creed, gender, religion, state of origin, color, race or personal orientation. You are an Indian citizen or authorized to work legally in India."
Machine Learning Engineer,"Bengaluru, Karnataka",DMI,None,Organic,"About DMI:
DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.
About the Opportunity:
We are looking for a passionate Machine Learning Engineer to work closely with our Data Scientists and Data Engineers to integrate and deploy models into our application’s production environment.
If you have a sense of adventure, take pride in solving complex data problems, and strive to build the best products on the planet, we want you on our Big Data Engineering team.

This role would be responsible for:
Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.
Creating high performance and scalable Machine Learning systems
Building reusable production data pipelines for machine learning models
Collaborating with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments
Helping to manage the infrastructure and data pipelines needed to bring an ML solution to production
Troubleshoots production machine learning model issues, including recommendations for retrain, revalidate, and improvements

We are seeking people who are passionate about:
Working with data in all forms (structured, unstructured, video, audio, etc) and using it creatively to help solve problems
Collaborating with data scientists and data engineers to make a big impact
Staying in-tune with the big data community and encouraging the organization to utilize cutting edge technologies to innovate and invent solutions.

Qualifications:
Technologies in our environment:
Skills - Experience and Requirements
You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Science, or a related technical degree.
Experience in developing and deploying machine learning systems into production
Proven ability to learn things quickly and stay up to date on breakthroughs in Machine Learning techniques
Ability to quickly prototype new approaches and productionize solutions at scale for millions of active users
Ability to work in a Linux environment
Strong experience with Python, Scala, Golang, or Java
Experience with big data tools and processing technologies such as Apache Spark, Apache Flink, and cloud platforms like GCP or AWS
Experience in building containerized solutions using Kubernetes
You have worked with automated build systems such as Jenkins. A desire to write tools and applications to automate work
Experience implementing Continuous Integration or Continuous Delivery processes in engineering teams
These qualifications would make you stand out among other applicants:
Great communication skills - someone who is passionate about evangelizing the value of advanced data science capabilities.
Experience deploying and maintaining model Microservices
Experience building maintainable data pipelines for deep learning models
Familiarity with data-oriented workflow orchestration frameworks such as Kubeflow, Airflow"
Staff Data Scientist,"Mumbai, Maharashtra",Baker Hughes,None,Organic,"Role Summary:
Baker Hughes has a new opportunity for Staff Data Scientist - India to join the team in Mumbai/Bengaluru, India.
Essential Responsibilities:
Duties shall include the following, but are not limited to:
Lead and work in cross-functional teams to translate algorithms into commercially viable products and services.
Lead, coach and contribute in development, validation, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Develop self-learning systems that can predict failures and autocorrect based on multiple data sources
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code.
Initiate and propose unique and promising modeling features, develop new and innovative algorithms and technologies, pursuing patents where appropriate
Stay current on published state-of-the-art algorithms and competing technologies.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses.
Research and evaluate emerging technology, industry and market trends to assist in project development and/or operational support activities to for multiple teams or complex scenarios.
Create reports and other artifacts to document your work and outcomes.
Communicate methods, findings, and hypotheses with stakeholders.
Qualifications/Requirements:
MS Degree in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
A minimum of “6” years as data scientist and technical hands-on coding experience.
Proven experience coding in Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modelling
Demonstrated experience in Parallel programming frameworks for GPUs, TPUs
Demonstrated ability to develop containerized solutions (Docker/Mesos etc)
Strong implementation experience with high-level languages and frameworks such as R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS
Demonstrated ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc…
Strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data including SQL and NoSQL databases
Experience with end-to-end modeling projects, from research to solutions to analytic products
Proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.
Participates in enterprise strategy development, including environmental analysis, opportunity identification, value cases and business innovation portfolio development. Reviews and/or analyzes and develops architectural requirements at domain level, aligning architectural requirements with software development strategy.
Leads and facilitates the domain’s architecture governance process based on EA’s governance structure.
Leads teams in developing plans and assessing improvement options.
Desired Characteristics:
Strong distributed systems and architecture knowledge, and experience with multitier architecture
Comprehensive knowledge of underlying principles, approaches and methodology of AI based Analytics.
Mission critical systems experience is preferred
Ability to manage complex technical projects.
Demonstrates expertise in problem solving and technical innovation.
Demonstrated experience of delivering on commitments to clients.
Demonstrates capability of 'rolling up sleeves and getting hands dirty'.
Works well in fast paced growing environment.
Provides excellent influential communication skills and business acumen to both an arbitrator and advocate for technical issues.
Locations:
Mumbai/Bengaluru, India"
Python Developer,"Coimbatore, Tamil Nadu",CDS,None,Organic,"Any Computer Science Graduate with 2+ years of working knowledge in web crawlers, web scrapers and other web tools which helps in extracting the web content using Python.
Should be expertise in Python Coding.
Should have knowledge in scraping frameworks such as Scrapy, Beautiful Soup, HTQL, Jsoup, Web-Harvest and others.
Understanding of XML, HTML5, CSS and JSON objects.
Experience with SQL and NoSQL databases.
Should be familiar with event-driven programming in Python.
Responsibilities :
Responsible for writing reusable, testable, and efficient code.
Should design and implement low-latency and high-availability applications.
Create and customize web crawlers and web spiders to extract structured and unstructured data from web.
Use NLP techniques to improve and refine the crawled data.
Build/maintain ETL infrastructure for the analysis of crawled data.
Develop APIs that interact with other applications.
Knowledge of OLAP and ETL processes is an added advantage."
Junior Data Analyst,"Chennai, Tamil Nadu",Indium Software,None,Organic,"Experience
–
No.Of.Positions
–
Location
Chennai
(willing to relocate to Hyderabad down the line )
Notice Period
–

Profile:
Bachelors or Masters Degree in Computer Science or any relevant field
Passion for problem solving by gathering descriptive insights through data extraction, slicing and dicing the data
Experienced in writing complex SQL select queries
Strong in querying logic and data interpretation
Individual contributor
Skills required (Technical, Managerial, Others):
SQL, one of the Visualisation toolset like PowerBI, Tableau, Qlikview
Database concepts
Business understanding
Good Communication skills, should be able to hold a conversation with client on a solution for 30 minutes
Good to have knowledge in R, Python, PowerBI
Responsibilities
Understand the real-time business problem, create insightful reports and build story via insights
Look at the data from different databases in different dimensions and think out of the box to find solutions
Connect different datasets to find new information, that presents implementable tactics and actions"
Data Scientist,"Pune, Maharashtra",Right Steps Consultancy,None,Organic,"Location Pune, India – Full Time
Position Expectations
Our Data Science & Machine Learning team is looking for a hands-on data scientist who can independently build statistical & mathematical models and can design & develop performant algorithms of the highest quality. Need to have an aspiration to become an exceptional data scientist with a passion for learning new technologies and high inclination towards research.
Responsibilities
You would be responsible for managing, developing, maintaining industry specific analytical models
The role would involve conducting research and prototyping innovations (new product ideas) along with data and requirements gathering.
The role would also involve testing various machine learning and analytical tools to build prototypes and production-grade systems. Familiarity with big data technologies and distributed computing concepts will be an advantage.
Qualification & Experience
Knowledge of designing & developing analytical solutions (Statistical & Machine Learning) for complex business problems. Below qualities are desired
Technical Graduates
Understanding of concepts and algorithms used in design of experiments
Understanding of R or Python’s data science stack
Understanding of business statistical/ML predictive techniques such as Regression, ANN, Bayesian methods, Decision Trees, SVM etc.
Understanding of NLP and related areas.
Thorough understanding of RDBMS,NoSQL and data management concepts , fluency in SQL scripting
Understanding of cloud computing platforms (AWS/ IBM Watson/ Google Analytics/ MS Azure)
Management Graduates
Domain knowledge in Finance (Corporate/Retail/Investment Banking) and/or Operations (Retail/ SCM/Logistics) and/or Marketing
Good understanding of Business Statistics
Knowledge of IT systems & applications in your area of expertise
General Requirements
Ability to formulate a problem statement and implement analytical solutions by understanding data and problem statement
Passionate about solving problems, quality and learning new technologies
Good communication skills
A flexibility required in terms of performing different types of responsibilities from a start-up perspective
Strong sense of team work, ownership, and accountability
Education
B.E/ B.Tech./M. Tech/ MBA in any field with significant knowledge in one or more of the following : Statistics, Mathematics, Machine Learning, Economics, Finance or Marketing.
Note
Training on core and advanced statistical techniques/methods would be provided"
Data Scientist,"Hyderabad, Telangana",CoreCompete,None,Organic,"Job Duties and Responsibilities:
Lead forecasting projects in retail, consumer goods, manufacturing, or other domains
Take responsibility for requirements gathering, solution design, development, and developing a production forecasting system
Guide team members on project work and take responsibility for their deliverables
Work with the client and broader team to handle special requirements and modify approaches to achieve project goals
Identify, analyze, and interpret trends or patterns in complex datasets and produce insights to be leveraged in the model development
Required Skills and Experience:
Ability to work with junior team members to lead multiple forecasting projects
Ability to work with data engineers and cloud/configuration engineers to develop forecasting solution
Experience of working with large volume of data in the order of millions of series to create forecasting solutions
Experience with cloud like AWS/Google Cloud or Azure and programming in SAS, R or shell scripting is a plus
Strong aptitude for analytical problem solving
Exceptional communication skills. Demonstrated ability to communicate complex concepts to business audiences
Ability to work effectively in global teams and product owners with different time zones
Understand the business opportunity and the technical context during the discovery process to ensure that our solutions have the highest likelihood of success.
Ability to work comfortably in ambiguous situations and ability to optimize team’s resources to achieve business goals
Forecasting Skills:
4-6 years of experience in forecasting and demand planning projects
Theoretical background in time series forecasting and Machine Learning modeling
Proficiency in using Python modules for time series method families like ARIMA, Exponential Smoothing (ESM), and Unobserved Component Models (UCM) in several projects
Significant experience using Python modules for Machine Learning (ML) approaches like Decision Trees, Gradient Boosting, Random Forest, and Neural Networks for aggregate prediction and use of Recurrent Neural Networks for forecasting
Experience using causal variables and feature creation for forecasting
Python and SQL Skills:
Advance level skills in SQL to manage large volume of data, knowledge of SQL commands, joins, operators, aggregate functions, partitioning datasets, nested queries etc. Experience with Big Query, Hive and Spark SQL is plus
Proficiency in reading and writing data from Database (or Datawarehouse system) and parsing through SQL codes to execute in Database using python to use computing power of database server
Proficiency in using Scikit-learn, Statsmodel and FBProphet for building machine learning and forecasting solutions. Experience of using TensorFlow and Keras are for forecasting are desired.
Extensive experience of using Python packages like Pandas, NumPy, SciPy, Matplotlib or Seaborn for data manipulation and visualization
Education:
Bachelor’s or Master’s Degree in a quantitative field (e.g., Statistics, Industrial Engineering, Applied Math/Statistics, Computer Science)"
Data Scientist- AI,"Bengaluru, Karnataka",Lymbyc Solutions,None,Organic,"Description:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.
By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.
Descriptions
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.
Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.
Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner
Skills Required:
Must have minimum of 3-5 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc"
Data Scientist,"Pune, Maharashtra",Citi,None,Organic,"Job Purpose: A Data Scientist role to help us discover information contained in vast streams of data, make data-driven decisions based on an enhanced understanding of our business performance in the financial markets for implementing Feature based surveillance scenarios.
Job Background/context:
1. Candidate should have around 8+ years development & systems design experience.
2. More than 3+ years of experience in Data science project.
3. Proven proactive problems identification & rapid trouble-shooting skills.
4. Python, Data Science and Trade Surveillance domain experience will be preferred.
Key Responsibilities:
The right candidate will be expected to be a significant player in the project evolution & deployment shouldering the following responsibilities:
Work as a collaborative member of a team spread over multiple locations (India, UK, US) Feature engineering and selection. Model selection, training, testing and validation. Model visualisation, demonstration and documentation, in an online form such as an interactive notebook. Data mining - using state-of-the-art methods. Grow our catalogue of common assets, such as code templates, libraries, utilities, services, etc.
Development Value:
Opportunities for career growth within a Surveillance domain that is expanding.
Hands-on design and development experience including experience on a production implementation of Spark ML projects with massive data volumes and unstructured data sets.
Involve and lead projects involving complex feature-based data algorithms and machine learning.
Exposure to surveillance functions in a dynamic and challenging industry with regular close collaboration with our surveillance portfolio clients.
A team with a win-together/lose-together attitude and strong sense of identity and positive culture.
Skills:
Mandatory Skills:
Excellent understanding of fundamental machine learning techniques and algorithms, such as Regression, SVM, Random Forests, etc.
Experience with common data science toolkits, with excellence in the SciPy.org stack (NumPy, SciPy, Matplotlib, Pandas, IPython, etc.) and Scikit-Learn highly desirable
Great working knowledge of Python an absolute given.
Experience with data visualisation tools, such as Matplotlib, plotly, flask, GGplot, etc.
Proficiency in using query languages, such as SQL, Spark DataFrame API, etc.
Desirable Skills:
Big Data Technologies, Deep Learning
Trade Life cycle/Market data systems
Other skills & Qualifications:
You are educated to degree level or above preferable data science.
Exceptional candidates who do not meet these criteria may be considered for the role provided they have the necessary skills and experience.
Candidate should be willing to work late in the evening India time on need basis in order to interact with US/UK onshore team and to meet urgent requests by Clients.
Exhibit sound and comprehensive communication and diplomacy skills to exchange complex information
You are academically-rigorous, but commercially-minded.
You are eager to grow your skills and possess right attitude to guide us.
Qualifications:
Ph.D. or Masters/Bachelors in STEM field
Competencies
1. Proven ability to work with teams that are geographically separated
2. Should be a self-starter with a high level of initiative.
3. Excellent oral and written communication skill as candidate is expected to work with onshore & near-shore teams
4. Should be able to lead and mentor the team effectively.
-
Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN
-
Time Type :Full time
-
Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.
Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity .
To view the ""EEO is the Law"" poster . To view the EEO is the Law Supplement .
To view the EEO Policy Statement .
To view the Pay Transparency Posting ."
Fresher/Junior Data Science Developer,"Chennai, Tamil Nadu",HTC Global Services Limited,"₹20,000 a month",Organic,"HTC Global Services hiring freshers for Junior Data Science Developer
Job Description:
HTC Global Services hiring freshers (2018 and 2019 ) for the position Junior Data Science Developer.
Candidates those who are in Chennai and immediately available to attend interview with HTC Global Services (MEPZ, Tambaram) can apply.
About HTC Global Services:
HTC Global Services (HTC) is a leading global provider of Information Technology (IT) and Business Process Services (BPS), headquartered in Troy, Michigan, USA. Established in 1990, HTC is an Inc. 500 Hall of Fame company and one of the fastest growing Asian American companies in the USA. Our client base spans over 2000 organizations across the globe. HTC acquired CareTech Solutions in December 2014 and Ciber, Inc. (Currently Ciber Global LLC) in June 2017. These acquisitions enable us to expand our operational capabilities in Healthcare IT and Technology Transformation services.
HTC is an ISO 9001 and 27001 certified company with processes compliant to SEI CMM Level 5. With over 10 global delivery centers and operating presence in several countries, we serve global clients across multiple time zones. Our ‘Business Partner’ approach enables us to offer high business value for our clients. It also brings in the benefit of repeated business for HTC. Our strategic solutions enable clients to transform and thrive in the changing world.
Designation : Fresher/ Junior Data Science Developer.
Job Requirements:
Key Skills:
Should have good knowledge in basics OOPS concepts.
Must possess good communication skill(both oral and written).
Qualification :
· Bachelors or masters in Science majored in Math/Statistics/Econometrics.
· Bachelors in Engineering with Data science/AI/ML as part of the curriculum
· Management graduates with specialisation in Analytics/Data Science/AI/ML.
Eligiblity Citeria:
· First class throughout curriculum is mandatory(from 10th standard to degree).
Certificates/Diplomas:
Should have done certification in date science, Analytics, Python from leading institutions or through online courses from Coursera/datacamp/udemy/udacity
Must to have:
Have few practical projects experience for a maximum of 2 years, active in Kaggle or other forums.
Probation period : One Year
Salary Offered : CTC 3.00 L pa
Agreement Period:
3 Years from the date of joining and should be ready to submit original documents.
Rounds of Interview:
Round 1: Aptitude (Technical and English )
Round 2: Technical & HR at the company.
Job Type: Permanant, Full-time
Salary: ₹300,000.00 per annum from Training onwards.
Benefits:
Provident fund (PF)
Paid leaves / Leave encashment
Industry:
Software Development
Interested candidates can reach me at :
Pavithra.M
Senior HR @ HTC Global Services Limited
Official Mobile Number: 9840604551
Job Types: Full-time, Fresher
Pay: From ₹20,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Analytics (Machine Learning) Internship,"Bengaluru, Karnataka",Simplify360 India Private Limited,None,Organic,"About the company:
Simplify360 is the leading social customer service platform, established in the year 2009. Since then, we have been helping brands and enterprises ease their social media journey. We have a physical presence in India and the US and function through partners in the APAC region. Our product is sold in over 100 countries directly or through partners.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Use effective text representations to transform natural language into useful features 2. Find and implement the right algorithms and tools for NLP tasks 3. Develop NLP systems according to requirements 4. Perform statistical analysis of results and refine models 5. Remain updated in the rapidly changing field of machine learning 6. Design and implement ML algorithms and models (especially deep learning models) through in-depth research and experiment with neural network models, parameter optimization, and optimization algorithms 7. Research and experiment with neural network models, parameter optimization, and optimization algorithms 8. Conduct research to advance the state of the art in deep learning and provide technical solutions for real-world challenges in various scenarios
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 7th Aug'20 and 11th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Should have an understanding of transformer learning
Number of internships/jobs available: 2
Categories: Analytics,Machine Learning,Data Science"
Computer vision engineer,"Chennai, Tamil Nadu",Deepquanty Artificial Intelligence labs,None,Organic,"Hi,
Greeting from DeepQuanty Artificial Intelligence Labs !!!
We would like to take an opportunity to introduce DeepQuanty Artificial Intelligence Labs. It is a Computer Vision Lab devoted to extracting and processing data from images using Deep Learning, Artificial Intelligence and Machine Learning. It is a start-up no more than 1 year old with four products: SnapChek, FormEasy, EasyKYC and Zapscore - all directed at the BFSI Sector. It is well funded and operational. Thus this is an opportunity to apply your cross-functional skill sets, creativity, machine learning, robotics and control systems to solve exciting product development changes.
Company Profile: -
DeepQuanty Artificial Intelligence Labs is a product startup in the space of Artificial Intelligence and Machine Learning. It has already several products in the Computer Vision space and is very well received in the BFSI industries. It has every intention to exploit all opportunities in this space by way of astute product development and taking them to several other industries as well.
DeepQuanty AI Labs has been set up by founders with over 75 man years of experience in the area of analytics and technological product developments. Specifically, the founders come from successful and ongoing ventures MarketsOf1 Analytical Marketing Services Pvt. Ltd. and Pranion Technology Ventures.
Job Description: -
We’re looking for experienced, detail-oriented individuals to join our team and work in a startup environment. This is an opportunity to apply your cross-functional skill-sets, creativity and experience in computer vision, machine learning, robotics and control systems to solve exciting product development challenges. This is a high-visibility position within our fast growing company and assumption of increased responsibilities over time is expected.
Skills and Qualification: -
Minimum 2 year of experience working in AI / Machine Learning.
Minimum 1 year of experience working in Deep Learning.
Bachelor's or Master's Degree in Computer Science or related field.
Machine Learning in Computer Vision.
Working experience in frameworks like OpenCV, Tensorflow/Keras/PyTorch, Scikit-Learn, Matplotlib, Pandas, Numpy.
Good Python knowledge.
Working experience in Flask/Django/Tornado.
Well versed with Development Environment on Linux.
Job Location: -
Chennai
Job Types: Full-time, Internship
Experience:
Python & Linux: 1 year (Preferred)
Deep learning: 1 year (Preferred)"
DATA SCIENTIST,"Bavdhan, Pune, Maharashtra",Alpha ICT LLP,None,Organic,"Should have a Master’s degree in Statistics, Mathematics, Computer Science
Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes
Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques"
Analyst - Data Science,"Bengaluru, Karnataka",Nuware Systems,None,Organic,"Responsibilities :
Data Scientist with Machine Learning, Python & R Programming Experience.
Good Attitude and Communication skills, SQL, Excel Macros.
Good to have exposure Reports and Risk analysis.
Strong hands on SQL (RDBMS)- Data mining.
Required Skills :
Experienced in Data Science and Data Analysis.
Hands on R Programming/ Basic SQL.
Knowledge on Investment Banking Domain (BFSI) added Advantage.
Good knowledge into reporting.
Good knowledge in Excel/PIVOT/MACROS/ Excel functions.
Primary Skills :
Data Science
Machine Learning
Python & R programming
Good to have :
SQL Seam framework
Excel Macros
BFSI Vertical knowledge
Experience
3 to 6 Years

Industry Type
IT Software, Software Services

Role
Software Developer/Senior Software Developer

Functional Area
Application Programming, Maintenance

Education
UG – Any Graduate – Any Specialization PG – Any PG Course – Any Specialization

Location
Bangalore

Email
referral@nuware.com

Website
www.nuware.com"
Data Scientist,"Bengaluru, Karnataka",PayPal,None,Organic,"Provide analytical insights into emerging problems, trends and portfolios
Work closely with business partners and stakeholders to determine how to design analysis and measurement approaches that will significantly improve our ability to understand and address emerging business issues
Bringing data to life and making it actionable and relevant to stakeholders through exploratory analysis of internal and external data sources using advanced and innovative analytical techniques, algorithms, and tools
Identifying present or future gaps in the team’s existing reporting and tools suite and managing portfolio monitoring, dashboards and reporting
Providing regular updates to leadership, product and other stakeholders that will simplify and clarify complex concepts and the results of analyses effectively with emphasis on the actionable outcomes and impact to business
Experience with standard statistical techniques and tools a plus
Required Qualifications
Bachelor's Degree in a quantitative discipline (Economics, Engineering, Computer Science, Math, Statistics)
1-2 years’ experience in analytics or management consulting
Proficiency using SQL and querying relational databases
Experience in at least one statistical programming language (SAS, R, Python)
Experience in at least one data visualization tool (Tableau, Qlikview)
Experience with project management
Preferred Skills:
Strong communication skills
Quick learning
Out-of-box Problem Solving
Job_Description_Summary: As a Data Scientist, you will apply your strategic and analytical skills to major company challenges. You will team with world-class professionals to identify actionable insights that ultimately impact the bottom line. We work in a space that looks deeply into emerging fraud trends and the business enablement opportunities that help the business in fuelling growth and strategic decisions. You will be able do it all in a collaborative environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation with a global team that is multi-disciplinary with broad spectrum of industry experiences, deep analytical and quantitative expertise.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Data Engineer 2,"Chennai, Tamil Nadu",PayPal,None,Organic,"In this role, the individual will be part of the engineering team in Enterprise Data Lake Organization and will be responsible for.
Participating and collaborating with Product Owner/ Cross functional team in the organization to understand the business requirements and to deliver solutions that can scale.
Creativity and out of the box thinking is required.
Proactively anticipating problems and keeping the team and management informed in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Produce quality deliverables
Ability to work in a fact paced environment
Ability to deliver from coarse grained requirements
Skills and Experience
3+ years of experience in the IT industry, experience in Data Technology space is preferred.
Shell/ Perl scripting experience
Spark streaming experience is a must
Proficiency in any programming language like C, C++ or CORE Java
Working experience in a RDBMS and big data stack; Should have strong SQL programming skills
Knowledge of data warehousing concepts
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Basic Qualifications
Bachelor/master’s in engineering/Science degree with Mathematics or equivalent experience
3+ years of experience in IT
Job_Description_Summary: Enterprise Data Lake is a newly formed team in PayPal’s product and engineering organization under Customer Experiences and Technology. Its vision is to “Provide Enterprise Product Data at lower cost and better quality”. To achieve this vision, we are looking for people with a passion and curiosity to solve customer problems with data. The internal stakeholders for the Program include but are not limited to PayPal Inc.’s Product Teams, Finance, Risk, Compliance and Strategy Teams. Our External stakeholders include Customers and Regulators amongst others. This position is focused on delivering Core Data solutions using modern technology to serve the various needs of the business. The scope of the organization is global, and its data platforms serve a wide array of functions including Merchant, Partner, Operations, and Compliance business operations. At EDL, we are committed to bringing innovation, passion and customer focus to the business of enterprise solutions. One of the charters of EDL is to deliver on data driven companywide transformational initiatives to integrate PayPal Inc. data seamlessly using Big Data platform for both operational and analytical needs. In this position you will also have the opportunity to work with stakeholders and users to understand their needs and partner with engineering to deliver the solution. This position requires an individual who is comfortable working in cross-functional teams with a very high degree of analytical and technical skills.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
AI Engineer,"Chennai, Tamil Nadu",iKomet Technology Solutions,None,Organic,"Work Location: Chennai
Required Experience: 3 - 5
Job Description:
Understand the business problem, challenge of existing technologies and areas of application for AI technologies.
Coordinate between Data Scientists and Business Analysts
Automate infrastructure used by the Data Science team
Convert machine learning models into APIs so that other applications can access them
Test and deploy models
Develop minimum viable products based on machine learning
Automate processes by utilizing machine learning
Use AI to empower the company with novel capabilities
Develop required machine learning models or prototype applications applying formulated AI recipes and verify the problem/solution fit.
Involve in development of AI Platform and AInization projects.
Strong fundamental understanding of ML/DL algorithms and OpenCV.
Development of micro services for NLPasaservice.
Development of machine learning / NLP APIs.
Able to work in Linux based OS.
Experience with one or more scientific analysis and prototyping environments such as the SciPy/NumPy stack or with an ML framework such as TensorFlow or PyTorch.
Experience writing maintainable, testable, production-grade Python or Golang code.
Experience with data engineering, deep learning frameworks and related open-loop testing techniques is a plus.
Comfortable working in a fast paced, highly collaborative, dynamic work environment."
DATA SCIENTIST,"Bengaluru, Karnataka",Inference Labs,None,Organic,"Employment: Full time.
Role: Data Scientist
Job Summary
We are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real-time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover useful and valuable information and finally supporting the engineering team to build the results into the end product. You will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.
Responsibilities and Duties
Collaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.
Bring analytical rigour and statistical methods to the challenges of measuring quality, improving security products, and understanding the behaviour of end-users, computer systems, and network devices.
Build innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.
Multi-task and work independently
‘Think like an adversary’
Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.
Identifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.
Uses appropriate methods, tools, and algorithms to analyze the data and create an implementation plan from the business problem.
Validates the results of the data analysis to avoid errors.
Interprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.
Monitors and continuously improves the data sources, usability and data
mining results.
Required Experience, Skills and Qualifications Education and Experience
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field
3-5 years of working experience in machine learning and data science projects;
2-3 years of experience in working with large scale production data sets
Good understanding of the foundations of machine learning methods
Exceptional coding skills in SQL, and Python or R
Excellent communication skills
Knowledge and Skills
Basic Qualification:
Experience with deep learning methods, models and frameworks
Familiarity with multiple programming and scripting languages (such as Java, Javascript, C/C++, Perl, etc.)
Familiarity with data visualization tools
Experience with passive and active measurement techniques
Experience with applying statistical modelling, machine learning and data mining algorithms to business problems.
A profound understanding of big data systems
Must have:
Background in statistics
Linux System knowledge as user and administrator
Experience with Vertica or other column store databases is a plus
Experience in cybersecurity, network data
Knowledge of networking concepts and devices (Firewalls, Routers, Switches,
and Load Balancers)
Knowledge of network and web related protocols (such as TCP/IP, UDP, IPSEC,
HTTP, HTTPS, DNS, SSH, routing protocols)"
Data Engineer (Talend/Bigdata),"Bengaluru, Karnataka",Palnar Transmedia,None,Organic,"Primary Responsibilities:
Lead and deliver complete application lifecycle design, development, deployment, and support for actionable BI and Advanced Analytics solutions
Design and develop data models and ETL process for structured and unstructured data that is distributed across the globe between Cloud and On-Premises
Develop and deliver solutions with data streaming capabilities for large volume of factory data
Demonstrate and document the development methodology, results and insights to the business partners and senior leadership.
Work directly with management and Business units to design, configure, support cloud deployment, and performance tuning/optimization.
Develop design documents and translates into component-level designs to accelerate development.
Competencies & Experience Required/Desired
8+ years of experience in data modeling and ETL using industrial leading tools to process the data using RDBMS, In-Memory and Bigdata data stores
5+ years of experience in deploying custom data solution using Talend
4+ years of experience in Big Data development using Cloudera Hadoop (Hive, Impala & Talend)
3+ years of experience in developing flows using data streaming, batch processing, and Microservices
2+ years of experience with AWS tools such as S3, EC2, ECS, EKS, SageMaker, Aurora, Redshift, RDS, Lambda Functions AMI, ELB, ALB, NLB, VPC, Auto Scaling configurations, DMS, Amazon FW, API Gateway, IAM, CloudTrail, and CloudFront.
Multiple experiences in implementing solutions involving unstructured data using Talend
Strong problem-solving capabilities. Results oriented. Relies on fact-based logic for decision-making.
Ability to work with multiple projects and work streams at one time. Must be able to deliver results based upon project deadlines.
Willing to flex daily work schedule to allow for time-zone differences for global team communications
Strong interpersonal and communication skills
Degree in Management Information Systems, Computer Science OR equivalent work experience in an IT organization
Additional Skills:
Having subject matter expertise in one or more of the functional areas such as Sales, Finance,
Manufacturing, production planning, purchasing, marketing, engineering
Experience in demonstrating the challenges and recommendation to leadership team in a precise manner
Prior working experience with SAP HANA, SAP ERP, SAP BW environments
Experience in visualization tools
Experience in developing basic data science models using Python or a similar language
Java development and API management experience is a great plus"
Data Analyst,"New Delhi, Delhi",MedTourEasy,"₹7,00,000 a year",Organic,"We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements

Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
BS in Mathematics, Economics, Computer Science, Information Management or Statistics"
DATA ANALYST,"Bengaluru, Karnataka",The Data Team,None,Organic,"The Data Analyst is part of the consulting and data science team of the organization and will be responsible for project delivery on data science and data analysis projects and solutions specific to the manufacturing industry. The Data Analyst will be expected to be skilled in the retrieval, preparation and analysis of data of various kinds. The Data Team offers high-impact work with diverse opportunities for data analysts to grow skills in the areas of data science, advanced analytics and related areas.
Hands on programming skills in one interpreted programming language and one compiled programming language are required for this role.

Key Skills and Experience

Good working knowledge of interpreted object-oriented programming in languages such as Python or R is required
Working knowledge of one compiled programming language, such as Java or C++ is desired
Good working knowledge of SQL data transformations is required. Exposure to data visualization, data summarization, aggregations, filters and other data transformations is desired
A working level understanding of machine learning techniques is required. Those with strong fundamentals in the underlying mathematics - linear algebra, optimization or statistics of machine learning will be considered favorably.
Knowledge of statistical data analysis or signal processing as applied to continual improvement, engineering system design, evaluation and testing are good to have
Exposure to topics such as large scale data management, cloud based compute and storage technologies are good to have
Good interpersonal, presentation and written communication skills .

Education and Work Experience Requirements

Bachelor’s degree in electrical/electronics, mechanical, industrial or computer science/engineering
Prior work experience or internships in industries such as engineering, power, construction, manufacturing or oil and gas will be considered favorably
Master’s degree in any engineering field is considered a plus
Freshers and those with less than 2 years of experience in the industry
Relevant certifications in data science, statistics, machine learning and deep learning are good to have."
Machine Learning Engineer,"Bengaluru, Karnataka",DMI,None,Organic,"About DMI:
DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.
About the Opportunity:
We are looking for a passionate Machine Learning Engineer to work closely with our Data Scientists and Data Engineers to integrate and deploy models into our application’s production environment.
If you have a sense of adventure, take pride in solving complex data problems, and strive to build the best products on the planet, we want you on our Big Data Engineering team.

This role would be responsible for:
Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.
Creating high performance and scalable Machine Learning systems
Building reusable production data pipelines for machine learning models
Collaborating with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments
Helping to manage the infrastructure and data pipelines needed to bring an ML solution to production
Troubleshoots production machine learning model issues, including recommendations for retrain, revalidate, and improvements

We are seeking people who are passionate about:
Working with data in all forms (structured, unstructured, video, audio, etc) and using it creatively to help solve problems
Collaborating with data scientists and data engineers to make a big impact
Staying in-tune with the big data community and encouraging the organization to utilize cutting edge technologies to innovate and invent solutions.

Qualifications:
Technologies in our environment:
Skills - Experience and Requirements
You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Science, or a related technical degree.
Experience in developing and deploying machine learning systems into production
Proven ability to learn things quickly and stay up to date on breakthroughs in Machine Learning techniques
Ability to quickly prototype new approaches and productionize solutions at scale for millions of active users
Ability to work in a Linux environment
Strong experience with Python, Scala, Golang, or Java
Experience with big data tools and processing technologies such as Apache Spark, Apache Flink, and cloud platforms like GCP or AWS
Experience in building containerized solutions using Kubernetes
You have worked with automated build systems such as Jenkins. A desire to write tools and applications to automate work
Experience implementing Continuous Integration or Continuous Delivery processes in engineering teams
These qualifications would make you stand out among other applicants:
Great communication skills - someone who is passionate about evangelizing the value of advanced data science capabilities.
Experience deploying and maintaining model Microservices
Experience building maintainable data pipelines for deep learning models
Familiarity with data-oriented workflow orchestration frameworks such as Kubeflow, Airflow"
Solution Architect Engineer - Cloud & Big Data,"Bengaluru, Karnataka","JPMorgan Chase Bank, N.A.",None,Organic,"Solution Architect Engineer, Cloud & Big Data
The Corporate Technology (CT) organization engineers applications and provides technology support for corporate functions across JPMorgan Chase, including Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal and all functions within the Corporate Administrative Office (CAO).
CT teams are aligned with corporate partners' evolving technology needs and the firm's ever expanding technology controls agenda.
A top CT priority is building scalable corporate systems. Teams focus on:
Functional ownership in Finance Technology, specifically leading the implementation of Financial and Regulatory reporting functions onto the Corporate Technology Data Lake and leveraging Platform Services / Finance-as-a-Service to perform data management.
Advancing the firm's Roadmap programs - Single Sourcing of Data, Architecture Convergence and Rationalization of Platforms.
Adopting industry leading technologies to support best-in-class business capabilities for high performance computation and data storage solutions.
Driving innovation across the firm's corporate technology portfolio, increasing efficiencies through process automation and Agile application development, with an emphasis on user experience and shorter development cycles
As a key member of the Finance and Treasury Tech Architecture team, you will be responsible for designing and building scalable cloud-native foundational data solutions.
In this role, you will work closely with a world class team of engineers and architects to deliver cloud-native data capabilities that will be used to inform key business decisions
You will design strategically while building applications that solve for real-world use cases. You will create logical designs, describe the deployment of the designs on a physical platform then build applications based on articulated designs, recognizing alternatives and proposing choices throughout the process.
You will create engineering designs, best practices, guidelines and procedures, as well as repeatable and scalable frameworks to successfully manage large amounts of data, ensuring compliance with data classification requirements while maintaining data integrity and accessibility.
Requirements
Bachelor's or Master's degree in Computer Science/Software Engineering or a related field
Deeply passionate about learning and innovating using the latest and greatest in big data engineering, cloud and open source
Strong design skills for individual applications (solution architecture) and across applications (enterprise architecture)
10+ years' experience working in big data environment, working with structured, semi-structured and unstructured data
Sound understanding of various data solution patterns and when to use them: ETL/ELT, RDBMS, Normalization/De-normalization, Key-Value, In-Memory, Wide Column, Columnar, Graph, Text Indexing, Streaming, Messaging
2+ years' experience designing and implementing data solutions on Amazon Web Services (AWS), using offerings such as: S3, Athena, Glue, EMR, Lambda, RDS, EC2, DynamoDB, Elasticache, Redshift
Strong software engineering and object-oriented programming skills with expertise in languages such as Python, Scala and Java; and open source frameworks/libraries, such as Apache Spark, Apache Airflow
Strong data architecture, data warehousing, data modeling and data manipulation skills, such as in SQL, Stored Procedures, MySQL, Oracle, SQL Server, PostgreSQL
Knowledge of traditional big data systems, such as Hadoop, Impala, Sqoop, Oozie, Cassandra, Hive, HBase
Experience with Agile methodologies, such as Scrum, Kanban, Lean
Hands on experience with various Business Intelligence tools such as Tableau, Looker, Superset, D3.js
Strong attention to detail and ability to manage multiple projects and stakeholders
Ability to produce quality results in an evolving, fast-paced environment
Familiar with development tools such as Jenkins, Rundeck, SVN/Crucible/Jira, Git/Stash
Bonuses
Experience building APIs, web services and/or data-as-a-service offerings
Experience with containers, Kubernetes, Docker, Amazon EKS, Amazon ECS, Amazon Fargate
Experience building apps for real-time streaming using Apache Spark Streaming, Apache Kafka and/or Amazon Kinesis
Nice to Have
Experience re-engineering and migrating on-premises data solutions to and for the cloud
Experience building on emerging cloud serverless managed services, to minimize/eliminate physical/virtual server footprint
Experience implementing security solutions for data storage and processing in the cloud
Experience with MPP cloud data-warehouse-as-a-service offerings, such as Snowflake
Familiarity with predictive analytics, data science, machine learning, deep learning
Experience with Microsoft Business Intelligence stack, specifically SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Big Data Engineer,"Bengaluru, Karnataka",Apple,None,Organic,"Summary
Posted: Jul 20, 2020
Role Number:200182043
We at Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Apple's Manufacturing Systems and Infrastructure (MSI) team is responsible for capturing, consolidating and supervising all manufacturing data for Apple’s products and modules worldwide within Apple’s Operations team. This data is stored and used during the entire product's lifecycle- from prototypes to mass production through warranty support for customers. Our environment develops product innovation, rapid iteration, and a liberating amount of autonomy. As an expert in developing software to manage large, multifaceted data sets, you'll be building platform for data ingestion, cleaning, transformation and evaluation to support a rapidly scaling organisation.
Key Qualifications
5+ years of professional experience with Big Data systems, pipelines and data processing
Hands on experience Big Data, data ingestion, data processing using Spark, Spark Streaming, Flink, HIVE, Kafka, Hadoop, HDFS, S3
Hands-on experience with design and development with NoSQL technologies Cassandra, HBase or similar scalable Key value-Stores and time series data stores like Druid, influx or similar
Understanding on various distributed file formats such as Apache AVRO, Apache Parquet and common methods in data transformation
Confirmed understanding of design and development of large scale, high efficiency and low latency applications is a plus
Understanding and experience with Micro Services is desired
Excellent problem solving and programming skills
Experience with containerization technologies like Kubernetes, Docker, Mesos, Marathon is desirable
Experience with CI/CD, debugging and monitoring applications and big data jobs is desirable
Description
- Develop solutions to answer sophisticated analytical and real-time operational questions - Help to design, architect and build the data platform using a variety of Big Data technologies - Design and develop applications involving data processing, hygiene, augmentation and transformation for distributed systems - Identify Data Validation rules and alerts based on data publishing specifications for data integrity and anomaly detection - Innovate by exploring, recommending, benchmarking, and implementing data centric platform technologies - Ensure operational and business metric health by supervising production decision points - Provide hardware architectural mentorship, estimate cluster capacity, and build roadmaps for Hadoop cluster deployment
Education & Experience
B.S., M.S., or PhD in Computer Science, Computer Engineering, or equivalent practical experience."
Data Engineer,"Bengaluru, Karnataka",PayU,None,Organic,"Role: Data Engineer
Company: PayU
Location: Bangalore/ Mumbai

About Company:

PayU is the payments and fintech business of Prosus, a global consumer internet group and one of the largest technology investors in the world. Operating and investing globally in markets with long-term growth potential, Prosus builds leading consumer internet companies that empower people and enrich communities.
The leading online payment service provider in 36 countries, PayU is dedicated to creating a fast, simple and efficient payment process for merchants and buyers. Focused on empowering people through financial services and creating a world without financial borders where everyone can prosper, PayU is one of the biggest investors in the fintech space globally, with investments totalling $700 million- to date. PayU also specializes in credit products and services for emerging markets across the globe. We are dedicated to removing risks to merchants, allowing consumers to use credit in ways that suit them and enabling a greater number of global citizens to access credit services.
Our local operations in Asia, Central and Eastern Europe, Latin America, the Middle East, Africa and South East Asia enable us to combine the expertise of high growth companies with our own unique local knowledge and technology to ensure that our customers have access to the best financial services.
India is the biggest market for PayU globally and the company has already invested $400 million in this region in last 4 years. PayU in its next phase of growth is developing a full regional fintech ecosystem providing multiple digital financial services in one integrated experience. We are going to do this through 3 mechanisms: build, co-build/partner; select strategic investments.
PayU supports over 350,000+ merchants and millions of consumers making payments online with over 250 payment methods and 1,800+ payment specialists. The markets in which PayU operates represent a potential consumer base of nearly 2.3 billion people and a huge growth potential for merchants.
Job responsibilities:
Design infrastructure for data, especially for but not limited to consumption in machine learning applications
Define database architecture needed to combine and link data, and ensure integrity across different sources
Ensure performance of data systems for machine learning to customer-facing web and mobile applications using cutting-edge open source frameworks, to highly available RESTful services, to back-end Java based systems
Work with large, fast, complex data sets to solve difficult, non-routine analysis problems, applying advanced data handling techniques if needed
Build data pipelines, includes implementing, testing, and maintaining infrastructural components related to the data engineering stack.
Work closely with Data Engineers, ML Engineers and SREs to gather data engineering requirements to prototype, develop, validate and deploy data science and machine learning solutions
Requirements to be successful in this role:
Strong knowledge and experience in Python, Pandas, Data wrangling, ETL processes, statistics, data visualisation, Data Modelling and Informatica.
Strong experience with scalable compute solutions such as in Kafka, Snowflake
Strong experience with workflow management libraries and tools such as Airflow, AWS Step Functions etc.
Strong experience with data engineering practices (i.e. data ingestion pipelines and ETL)
A good understanding of machine learning methods, algorithms, pipelines, testing practices and frameworks
Preferred) MEng/MSc/PhD degree in computer science, engineering, mathematics, physics, or equivalent (preference: DS/ AI)
Experience with designing and implementing tools that support sharing of data, code, practices across organizations at scale"
PYTHON DEVELOPER,"Dehra Dun, Uttarakhand",V3iT,None,Organic,"We are looking for a Python Developer to join our engineering team and help us develop and maintain various software products.
Python Developer's responsibilities include writing and testing code, debugging programs, and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.
Should be able to perform web scraping from a complex website using python and dump the data into the excel sheet.
Should know APIs and how to use a published API in order to capture the live data from a website.
Knowledge of HTML and CSS is an additional advantage. Ultimately, you’ll build highly responsive web applications that align with our business needs.
Assess and prioritize feature requests.
Required Skills:
Good knowledge in Python, Java, SQL, C++ Language.
Strong Core Java, Python, OOP.
Good hands-on experience in web scraping from a complex website using python and dump the data into the excel sheet.
Good hands-on experience in API's and how to use a published API in order to capture the live data from a website.
Knowledge of HTML and CSS is an additional advantage.
Writing an effective, scalable code. Developing back-end components to improve responsiveness and overall performance. Integrating user-facing elements into applications.
Coordinate with internal teams to understand user requirements and provide technical solutions.
Work experience as a Python Developer.
Expertise in at least one popular Python framework (like Django, Flask, or Pyramid).
Knowledge of object-relational mapping (ORM).
Familiarity with front-end technologies (like JavaScript and HTML5).
Implement security and data protection solutions.
Qualifications:
B.Tech 4 years in Computer Science, Information Technology, Electronics and Communication, Electrical and Electronics.
Job Type: Full time. Start date: ASAP. Experience: 1 to 2 years in Domain. Location: Dehradun, Uttarakhand. Salary: As per industry standards.(Depends on candidate interview performance) Email: careers@V3iT.com"
Associate Professional Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Assists in the application of data analysis and data modeling techniques to establish, modify, and maintain basic data structures and their entity descriptions, relationship descriptions, and attribute definitions according to client specifications.
Assists in the analysis and validation of basic database structures, models and processes to ensure definition according to business objectives and operations.
Communicates with clients about matters of significance and discrepancies related to data to ascertain correct information and correct errors.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science or related field preferred
Zero or more years of experience in programming or data analysis
Experience working with relevant programming languages and relational databases
Experience working with data modeling practices and procedures
Experience working with company software and hardware products
Other Qualifications
Basic research and data analysis skills
Communication skills to communicate with designers, management and customers
Personal computer and business solutions software skills
Ability to work in a team environment
Work Environment
Office environment"
Data Scientist,"Bengaluru, Karnataka",loyalytics consulting,"₹5,00,000 - ₹9,00,000 a year",Organic,"Experience required: 2-4 years

We are looking for a passionate Data Scientist to turn data into meaningful information that can help our clients make data informed decisions
Typical responsibilities include end to end execution of advanced data science projects primarily involving applying data mining techniques, doing statistical analysis, and building high quality prediction systems. You’ll have access to large B2B and B2C data sets on a robust analytic platform. Customer and account data is enriched with demographics and firmographics, transactional purchase history, Web behavior and cross-channel marketing campaign history. Tools and analytic environment include SAS, Tableau, R/Python and well-managed MPP RDBMS, Hadoop & Hive.
Loyalytics is a startup and our work environment is very conducive to trying and testing out a variety of new things. A high degree of passion, commitment to our customers’ priorities and willingness to learn new things on the go are some of the qualities that will help individuals succeed at Loyalytics.

Job Description:
2-4 years real world experience working as a data scientist
Hands on experience in statistical modelling software such as R, Python or SAS (optional) along with data visualization tools like Tableau/Power BI
Good understanding of statistical and predictive modeling concepts.
Strong expertise in either R or Python
Excellent analytical thinking, and problem-solving skills.
Hands on experience in working on data mining and statistical machine learning problems
In depth understanding of advance ML techniques and algorithms like regression, clustering, decision trees, Neural Networks, Gradient descent, SVM etc
Experience in project management and handling client communications
Excellent communication (written/verbal) skills, including logically structuring and delivering presentations.
Open to learning new methods/techniques in the ever-changing world of analytics. High aptitude to learn quickly, assimilate to new teams and projects, and work well under pressure with appropriate attention to detail."
Data Scientist,"Hyderabad, Telangana",CoreCompete,None,Organic,"Job Duties and Responsibilities:
Lead forecasting projects in retail, consumer goods, manufacturing, or other domains
Take responsibility for requirements gathering, solution design, development, and developing a production forecasting system
Guide team members on project work and take responsibility for their deliverables
Work with the client and broader team to handle special requirements and modify approaches to achieve project goals
Identify, analyze, and interpret trends or patterns in complex datasets and produce insights to be leveraged in the model development
Required Skills and Experience:
Ability to work with junior team members to lead multiple forecasting projects
Ability to work with data engineers and cloud/configuration engineers to develop forecasting solution
Experience of working with large volume of data in the order of millions of series to create forecasting solutions
Experience with cloud like AWS/Google Cloud or Azure and programming in SAS, R or shell scripting is a plus
Strong aptitude for analytical problem solving
Exceptional communication skills. Demonstrated ability to communicate complex concepts to business audiences
Ability to work effectively in global teams and product owners with different time zones
Understand the business opportunity and the technical context during the discovery process to ensure that our solutions have the highest likelihood of success.
Ability to work comfortably in ambiguous situations and ability to optimize team’s resources to achieve business goals
Forecasting Skills:
4-6 years of experience in forecasting and demand planning projects
Theoretical background in time series forecasting and Machine Learning modeling
Proficiency in using Python modules for time series method families like ARIMA, Exponential Smoothing (ESM), and Unobserved Component Models (UCM) in several projects
Significant experience using Python modules for Machine Learning (ML) approaches like Decision Trees, Gradient Boosting, Random Forest, and Neural Networks for aggregate prediction and use of Recurrent Neural Networks for forecasting
Experience using causal variables and feature creation for forecasting
Python and SQL Skills:
Advance level skills in SQL to manage large volume of data, knowledge of SQL commands, joins, operators, aggregate functions, partitioning datasets, nested queries etc. Experience with Big Query, Hive and Spark SQL is plus
Proficiency in reading and writing data from Database (or Datawarehouse system) and parsing through SQL codes to execute in Database using python to use computing power of database server
Proficiency in using Scikit-learn, Statsmodel and FBProphet for building machine learning and forecasting solutions. Experience of using TensorFlow and Keras are for forecasting are desired.
Extensive experience of using Python packages like Pandas, NumPy, SciPy, Matplotlib or Seaborn for data manipulation and visualization
Education:
Bachelor’s or Master’s Degree in a quantitative field (e.g., Statistics, Industrial Engineering, Applied Math/Statistics, Computer Science)"
Senior Data Scientist,"Bengaluru, Karnataka","Zendrive, Inc.",None,Organic,"“The goal is to turn data into information and information into insight.”Carly Fiorina

Can you analyse our large corpus of driving data - literally terabytes every day - from millions of smartphones connected to vehicles and coax the data to provide insights? You will need to create algorithms and build models that will help you make recommendations that will drive business impact.

As a Senior Data Scientist, you will be a member of our world-class engineering team and as a technical leader, you will be expected to excel in a fast moving environment within Zendrive while leading a team of data scientists. Our goal is to provide a safer driving experience to the world at large, and in the process, accelerate the evolution of transportation.

What we expect from you:

Articulate goals, methodologies and insights effectively within the team and leadership
Develop new models of a complex system by correlating location-based trends and events
-Create A/B experiments - work with engineers to implement them and interpret their results
Architect our data warehousing strategy
Derive insights from data and answer difficult questions

What we want you to do:

Extract driving behaviour by analysing location and motion sensor data and separating signal from noise
Formulate physical problems as Data Science problems
Design data collection strategies
Recommend useful approaches from the latest developments in Statistics and Data Science for Zendrive’s problem domain.

What you need to have:

In addition to your well-honed communication, collaboration and leadership skills, you need to possess strong intuition for data and a keen aptitude for large scale data analysis. In addition, you need to have:

-BS / MS with a minimum 5 to 7 years’ experience as a data scientist or minimum of 2 years’ relevant experience post PhD in Statistics / -Machine Learning / Signal Processing
Experience in visualisation of complex data (ggplot / matplotlib)
Expertise in analytical tools such as Python (Numpy, Pandas, Scikit-learn, Tensorflow)

What will score bonus points:

Your ability to prototype algorithms and demonstrate gains on real data will help you score bonus points. Additional points may be scored for your working knowledge of Hadoop / Spark or other big data systems and your prior experience with sensor data and / or risk analysis.

What we offer you:

Working from a remote location of your choice, until such time as we figure that it is safe to move into a more conducive office space, which may not be anytime soon. Having said that, we provide a great collaborative environment even virtually with the best engineering talent to be found anywhere in the world. Along with a competitive salary, we will be providing you the opportunity to contribute to the development of products that make a real impact on the world.

If you are excited about the job description and see yourself excelling in this role, hit the APPLY FOR THIS JOB button at the end of this page. Our Talent Acquisition team will get in touch with you."
Experienced Artificial Intelligence Developer,"Gurgaon, Haryana",Siemens AG,None,Organic,"Looking for challenging role? If you really want to make a difference - make it with us
Siemens Energy is a global pacesetter in energy, helping customers to meet the evolving demands of today’s industries and societies. Siemens Energy comprises broad competencies across the entire energy value chain and offers a uniquely comprehensive portfolio for utilities, independent power producers, transmission system operators and the oil and gas industry. Products, solutions and services address the extraction, processing and the transport of oil and gas as well as power generation in central and distributed thermal power plants and power transmission in grids. With global headquarters in Houston in the U.S. and more than 64,000 employees in over 80 countries, Siemens Energy has a presence across the globe and is a leading innovator for the energy systems of today and tomorrow, as it has been for more than 150 years.
We make real what matters. This is your role
Design, implement, test and deploy highly scalable Artificial Intelligence solutions to improve turbomachinery product design methods and processes
Work in cross-functional teams to collect data required from product R&D, operational field, testing data, and market data.
Create the conceptual, high-level, and detailed design of the software and data solutions
Define subsystems and their interfaces, allocate responsibilities to subsystems, understand solution deployment, and communicate requirements for interactions
Influence common modeling, design, and coding practices
Work with customers, stakeholders, and suppliers to implement, test, and deploy the solutions
Willingness to travel internationally for durations up to 3 months, if essential
We don’t need superheroes, just super minds
PhD/Master in a quantitative field such as Computer Science, Computer Engineering, Statistics, Economics, Mathematics, Physics
2+ years of experience with SQL, Spark, OR Hadoop.
2+ years of experience of functional programming with Python, Java, OR C++.
Demonstrated ability in the application of Machine Learning/AI in real-world industrial settings with large scale data.
Experience with Deep Learning frameworks such as TensorFlow or PyTorch
Experience with Agile software development.
Strong oral, written and interpersonal communication skills and an ability to work in a team environment.
Comfortable working in an environment where problems are not always well-defined.
Experience with managing, manipulating and visualizing large data sets (Python, R or equivalents)
Experience in working in cross-functional teams and with internal customers
Exceptional ability to build relationships
Data-driven and results-oriented approach to problem solving
Enthusiastic and motivated
Experience with industrial data / Internet of Things (IoT) desired
Experience with data acquisition, automation, and control systems desired
We’ve got quite a lot to offer. How about you?
This role is based in Gurgaon, where you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.
We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.
Find out more about Siemens careers at: www.siemens.com/careers


Organization: Siemens Energy
Company: Siemens Limited
Experience Level: Mid-level Professional
Job Type: Full-time"
Service Data Scientist,"Pune, Maharashtra",Philips,None,Organic,"Job Title
Service Data Scientist
Job Description
#LI -SR1
In this role, you have the opportunity to
Senior Service Data Scientist will build roadmap, architecture, advanced processes in line with latest technology trends to develop big data analytical models and algorithms and apply models to enhance system service diagnostics & solutions. To build predictive machine learning models and diagnostics + utilization models to increase and optimize system servicing experience.
You are responsible for
Carry out research in advanced technological areas on Predicative & Utilization data Machine learning (Big Data Analytics) for which empirical evidence may have been found, but have basically yet to be proven, or to find new principles or solutions where current technologies fail.
Guide , mentor the team on System log data Exploration, Preparation, Modelling, Implementation and Validation with SQL, R & Python data scripting and data science languages. Develop big data analytical models and algorithms and apply models to enhance system service diagnostics efficiency. Build predictive machine learning models and diagnostics models to increase and optimize system servicing experiences. Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes. Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions.
To succeed in this role, you should have the following skills and experience
Service Data Scientist will build Big Data models with latest technology trends towards predictive , proactive & utilization based service & solutions
System log data Exploration, Preparation, Modelling, Implementation and Validation with SQL, R & Python data scripting and data science languages.
Develop big data analytical models and algorithms and apply models to enhance system service diagnostics efficiency.
Build predictive machine learning models and diagnostics models to increase and optimize system servicing experiences.
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes.
Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions
Experienced with considerable exposure to delivering meaningful results through data strategies, analytics, technologies & architecture
Deep understanding and experience in developing using Artificial Intelligence, Machine Learning and Deep Learning related technologies
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machin Logs Processing, text mining and text analytics.
Strong programming skills in R, Python, Java and with other open sources Big Data map reduce stack on large datasets.
Strong Expertise on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Read to be flexible to work on multiple programming languages to support the business opportunities.
Expertise in model documentation and release processes.
Excellent written and verbal communication skills for coordinating across teams
In return, we offer you
This role comes with a competitive compensation offering and a generous holiday / vacation offering, but that’s not all. Quality is right on the top of Philips leadership agenda and that means you have the unique opportunity to come in and have a recognized voice to drive and witness exciting, transformational changes. You will be empowered to drive high quality, ground breaking innovations with a globally recognized, premium brand behind you. And when you are successful in this role’s mission, you will have an array of diverse career options open to you – across different functional areas, product lines, business groups and/or geographies. That is a commitment Philips Quality Leadership team has made and stands by.
Why should you join Philips?
Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.
To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there,you can also learn about our recruitment process, or find answers to some of the frequently asked questions.
Contact
If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.
If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)"
Data Science Trainee,"Bengaluru, Karnataka",3d-ip semiconductors,None,Organic,"The training will be for a period of 6 months
Candidates currently undergoing graduation need NOT apply (This program is only for candidates who have degrees)
Only candidates with Masters or above degree should apply
Details
Training will be in projects in Artificial Intelligence (AI)
Training will be conducted in our Bangalore office
Please share your CV to careers@3d-ipsemi.com
Qualification required
M.Tech/PhD in Computer Science or Electronics degree
Knowledge of Python programming skills is required
Candidates with prior data science experience or course will be given preference"
Data Analyst / Data Scientist | Internship | Tech-Savvy|,"Indore, Madhya Pradesh",Anaxee Digital Runners Pvt Ltd,None,Organic,"Job role:
As a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.

Job Location: Indore | Full-Time Internship | Stipend - Performance-Based |

About the company:
Anaxee Digital Runners is building India's largest last-mile verification & data collection network of Digital Runners (shared feet-on-street, tech-enabled) to help Businesses & Consumers reach remotest parts of India, on-demand. KYC | Field Verification | Data Collection | eSign | Tier-2, 3 & 4
Sounds like a moonshot? It is. We want to make REACH across India (remotest places), as easy as ordering pizza, on-demand. Already serving 11000 pin codes (57% of India) | Website: www.anaxee.com
Important: Check out our company pitch (6 min video) to understand this goal - https://www.youtube.com/watch?v=7QnyJsKedz8

Responsibilities:
Ensure that data flows smoothly from source to destination so that it can be processed
Utilize strong database skills to work with large, complex data sets to extract insights
Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes
Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure
Build tools for automating repetitive tasks so that bandwidth can be freed for analytics
Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions
Work closely with top management to prioritize information and analytic needs

Requirements:
Bachelors or Masters (Pursuing or Graduated) in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science), preferably with work experience of over [X] years.
Ability to program in any high-level language is required. Familiarity with R and statistical packages are preferred.
Proven problem solving and debugging skills.
Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.
Experience with text analytics, data mining and social media analytics.
Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc."
Data Science Internship,"Chennai, Tamil Nadu",SIMPLIFAID PVT LTD,"₹15,000 a month",Organic,"About the company:
We are into building products using cutting edge technologies using AI/ ML for the development sector. A deep-tech startup for social good that harnesses the power of digital solutions to help cities graduate to inclusive and sustainable cities. ""Our solutions are driven for societies to flourish by adopting cutting edge technologies as an enabler for its comprehensive and inclusive development"". Our Motto: We help measure the quality of service delivery and co-create action plans with municipal officials based on our location intelligence. Why do yearly performance assessments? We engage with state and national governments for conducting concurrent performance assess. We support other social enterprises, NGOs, and foundations who are on a similar mission to transform Indian cities with our location intelligence. Why don't you speak with us before making an investment in a certain location? We are here to provide you unbiased review that is most critical for your investment decision!
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on Python, machine learning, deep learning, and IoT products 2. Implementing models as APIs for consumption of business 3. Building data products using cutting edge technologies
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 3rd Aug'20 and 7th Sep'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 2
Additional details:
The intern would get an incentive of up to Rs. 10000 based on the delivery of work.
Categories: Data Science,Engineering"
Data Science Developer,"Pune, Maharashtra",Ajira AI,None,Organic,"At Ajira AI, we focus on developing smart products that leverage artificial intelligence algorithms. We build complex cloud based and mobile business applications. However make no mistake, we solve very significant systems problems along the way. Our products work across our customers ecosystems to help people.
We’re very pleased to be expanding our development team. We’re a close knit group of innovators that have previously launched very successful start-ups. Our track record building successful technology businesses and reputation is helping us grow and we’re now looking to add experienced Data Science Developers to our team in Pune.
You have hands-on experience using AI frameworks such as Tensor Flow and Keras in a work setting. You have at least a couple of years of work experience using Python/R. You’ve used multiple classification models and Pandas, Numpy, Matlab etc. You are proficient at using algorithms such as Logistic Regression, Multiple Linear Regression, Random Tree, Support Vector Machine, Naive Bayes etc. You have a track record of demonstrated success in business problem solving. Data visualization experience is a plus.
You are the kind of developer that other developers seek out to solve their technical difficulties. You keep up to date with what’s happening in the data science world and know the differences between classification, regression, clustering and time series. You know the limitations of each algorithm. You are motivated to learn new technologies.
That’s a high level summary of what we’re looking for but before we dive into the detail, you’ll probably want to know who you are going to be working for and what your work environment will be like:
Who we are:
We are an Insurtech company with a core mission of leveraging artificial intelligence algorithms and techniques to solve complex business problems. We like to think that solving these business issues for our customers helps make them better at serving their customers. Some of our applications help people who may be injured or have been in an accident. In our opinion that’s a worthwhile pursuit. While our current business vertical is insurance, we see our technology expanding to other business verticals with time. Our founders have a solid track record of starting technology companies and making them successful.
We love what we do and not the least of which is that we have the opportunity to try out and ‘play’ with the latest advances in tools and technology.
Who you’ll be working with:
We are a collaborative, tight knit group of contributors. While we’re headquartered in the Chicago area in Lisle, our software lab is located in Pune, India. We have decades of experience working with remote teams. We’re looking to expand our Developer positions in Pune, India.
You’ll find our CTO a joy to work with; someone with excellent technical skills, always willing to mentor, roll up his sleeves and get deep into the technical issues. He possesses rare technical insight and no matter the day or time he’s always willing to contribute to move things forward. Our CEO is a rare combination of technical and business skills with remarkable vision and the ability to easily cut through the most complex issues to find the simplest answer. You’ll be working side by side with them and the rest of our technical team in what will be an amazing opportunity for you.
Your work environment:
We are a group of talented and dedicated individuals and through we are a start-up, we have a ‘no insane hours’ rule.
We are not clock watchers. If you need to take off for a couple of hours to visit the doctor or dentist go ahead. We look at what you’re accomplishing not how many hours you spend in the office. We conduct meetings on a daily basis with our Chicago office so some overlapping hours are necessary.
Our Pune office space is modest. We prefer to pay you more than prevailing market wages rather than spend money on fancy office space.
Our work is performed using the latest technology and tools. We’re constantly innovating and improving our delivery capability by building our own components and tools as well as licensing new tech that we’ve tried and works in our environment.
We are an open, collaborative work environment and suggestions are not just welcome, they are appreciated. You’ll find our product roadmap is exciting and full of opportunity.
Your skills:
You keep up with technology changes and trends
You are a top notch Developer whose code not only solves complex issues but is written in such a way that the rest of your team is able to understand. This means that you’re not shy about documenting your code and you understand the need for coding standards and why everyone should use them
You are motivated. You have amazing debugging skills and are quick at identifying and fixing bugs
You are skilled at development with Python/R and using Ai frameworks such as Tensor Flow and Keras
Proficient in the use of Pandas, Numpy, Matlib, MatPlotlib and commonly used libraries
You understand ML algorithms such as Support Vector Machine, Naïve Bayes, Logistic Regression, Multiple Linear Regression, Random Tree, XgBoost etc thoroughly
You are quick to understand business problems and understand how to classify problems that exist in large datasets
Any data visualization experience is a plus as is any background in statistics
You have developed, implemented and supported a ML application successfully at work
How to apply:
Send a pdf of your resume to careers@ajiraai.com
This post can also be found at http://www.ajiraai.com/careers
We look forward to hearing from you
If you’re not available or interested in this position but know someone who might be a good fit, please pass this along
Ajira AI is an equal opportunity employer and we do not discriminate on basis of caste, creed, gender, religion, state of origin, color, race or personal orientation. You are an Indian citizen or authorized to work legally in India."
"Associate Manager, Data Strategy","Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bangalore
Schedule: Full-time
Employee Status: Permanent
Posting Date: 28/Jul/2020
Unposting Date: Ongoing
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.


The Role Responsibilities


The job focus will be to drive cross functional advanced analytics projects:
Work with partner teams to create and build next generation data products and analytics solutions
Research, design, implement and validate cutting-edge analytics and data visualization techniques to demonstrate targeted outcomes.
Use machine learning to optimize our ability to address problems in RCF functions
Work with CDO, CIO Functions and Modellers to run proofs of concept (PoC) in specific areas
Provide expertise in migrating PoC projects to productionise (where found appropriate)
Contributing/leading development of sandbox/prototype solutions coordinating with other areas of ERA as appropriate, demonstrate to users and gather feedback
Assessing problem statements & propose potential solutions by advocating and enabling data-driven analytics Perform Bespoke Tactical Risk Analysis for Senior Management:
Respond to requests from senior management to develop tactical, bespoke analyses to address urgent risk management needs.
Coordinate with ERM teams such as Stress Testing, IFRS9 and Portfolio Risk to establish how existing results/ analytics or processes can be leveraged to respond to requests. • Work with cross-functional teams to identify and prioritize actionable, high-impact analytics opportunities
Our Ideal Candidate
Bachelor or master’s degree with technical degree preferred (statistics, mathematics, computer science, etc.)
Experience working with large datasets and the expertise in data wrangling
Experience in Machine Learning using supervised learning and unsupervised learning methodologies
Extensive programming experience using R, Python, SAS and/or MATLAB
Strong analytical mindset with excellent analytical, logical, reasoning and problem-solving skills.
Previous risk management experience and sound knowledge of financial statements is desirable
Excellent written and oral communication skills at all levels (i.e. colleagues to senior management) and situations (i.e. one-on-one to presentations)
Exposure to advanced machine learning methodologies is a plus
Exposure to Web Scraping, processing unstructured data (large text) is a plus




Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Data Scientist,"Bengaluru, Karnataka",Miles,None,Organic,"Miles is looking to expand its data science and data engineering team in INDIA!
Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline
Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data - handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus
Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects
Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing"
Online Trainer-Data Science,"Jaipur, Rajasthan",Parshi Emerging Technologies Pvt Ltd,None,Organic,"Urgent Requirement for Full-Time and Part Time Trainers across all India module including: Python, R , Machine learning, Data Science
Location: Multiple location in India/ Online
Experience: 2-8+Years of relevant
Job Types: Full-time, Part-time, Contract
Salary: ₹15,000.00 - ₹100,000.00 per month
Experience:
work: 1 year (Required)
total work: 1 year (Required)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes"
Data Scientist,"Bengaluru, Karnataka",BlueJeans,None,Organic,"If you are a data junkie who would like to wrangle through huge data sets of usage, stats, clickstreams, free text feedbacks and more to predict the user experience, adoption and retention. You like to solve complex and challenging problems and articulate the results in a lucid manner. Then we’ve got the problem for you and the data to solve it.
In your role as data scientist you will :
Select features, building and optimizing classifiers using machine learning techniques
Build statistical/machine learning models to extract insights
Create automated anomaly detection systems and constant tracking of its performance
Collaborate with subject matter experts to determine relevant data sources
Communicate the insights/recommendations to a wide spectrum of stake holder
Act as a mentor to guide/train less experienced folks
Desired Skills and experience:
B.E/Masters in Computer science/Statistics or equivalent
At least 5 years of experience in predictive modelling, strong knowledge of machine learning algorithms.
Strong in R,Python (numpy, scipy etc)
Very strong SQL and data visualization
Exposure to Big Data platforms such as Spark, Mahout, Scala, AWS machine learning is a plus
Great communications skills

Verizon recently acquired BlueJeans and plans to integrate BlueJeans employees into Verizon, including its compensation and benefits programs, in due course. This position will be part of that planned integration."
Business Intelligence Developer,"Bengaluru, Karnataka",Solutionec,None,Organic,"Bangalore, India | Full-Time
At Solutionec, we believe the Aha! moment is the engine that drives human progress. Our mission is to give our clients the power to overcome limits and face complexity head-on by designing customized solutions and tools that offer leading-edge capabilities
In healthcare and life sciences, these invaluable Aha! moments are the catalysts for potential life- changing, life-improving and life-saving innovations and achievements. Solutionec’s solutions support life by enabling more frequent, more rapid and more relevant Aha! moments.
About You
BS/MS in Computer Science or equivalent
Develop, implement and optimize stored procedures and functions using SQL
Reviewing query performance and optimizing code
Data modeling to visualize database structure
Background for writing business intelligence queries or dashboards
Strong knowledge in OLAP Systems, relationship data bases
Strong experience in writing SQL queries and using any of the commercial business intelligence tools
Creating database triggers for automation, e.g., automatic email notifications
Creating table indexes to improve database performance
Review and interpret ongoing business report requirements
Analyze existing SQL queries for performance improvements
Provide timely scheduled management reporting
Investigate job failure or issues and solve as when needed"
Python Developer,"Coimbatore, Tamil Nadu",CDS,None,Organic,"Any Computer Science Graduate with 2+ years of working knowledge in web crawlers, web scrapers and other web tools which helps in extracting the web content using Python.
Should be expertise in Python Coding.
Should have knowledge in scraping frameworks such as Scrapy, Beautiful Soup, HTQL, Jsoup, Web-Harvest and others.
Understanding of XML, HTML5, CSS and JSON objects.
Experience with SQL and NoSQL databases.
Should be familiar with event-driven programming in Python.
Responsibilities :
Responsible for writing reusable, testable, and efficient code.
Should design and implement low-latency and high-availability applications.
Create and customize web crawlers and web spiders to extract structured and unstructured data from web.
Use NLP techniques to improve and refine the crawled data.
Build/maintain ETL infrastructure for the analysis of crawled data.
Develop APIs that interact with other applications.
Knowledge of OLAP and ETL processes is an added advantage."
Python for Data Science-Developer,"Pune, Maharashtra",Wipro LTD,None,Organic,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.
Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com"
Planning COE Data Scientist,"Bengaluru, Karnataka",Hewlett Packard Enterprise,None,Organic,"Supply Chain Planning and Materials CoE Data is a new role to HPE’s Planning and Materials Management organization residing in Bangalore, India. This role will be key in driving the organization through data-based recommendations/actions to achieve better results in all metrics related to Demand, Supply, and Inventory/ Materials Management and cost. The Data Scientist will be leveraging advanced analytic, technical, and business skills to drive innovative methodologies for driving improvements for the business.
Roles and Responsibilities
Defines and develops the value proposition for supply chain analytics solutions based on user needs, business value, industry requirements and understanding of advanced analytic models (statistical, operations research, predictive and prescriptive).
Conceptualizes, builds, develops, and enhances analytic models using right modeling methodology, available structured and unstructured data, cost and timing constraints to solve the large and complex business issues, discovers and delivers compelling and clear business insights across the planning and materials management organization.
Embeds analytic models into enhanced large scale business processes and operational systems by collaborating with Application Developers.
Drives improvements in planning metrics such as forecast accuracy, inventory management, service to our customers, and cost metrics.
Using unique visualization techniques, condenses large volumes of complex ideas into elegant and simple visual models.
As a data evangelist, leads weekly meetings with Planning Leaders to provide key insights and align action plans to improve business results.
Collaborates with stakeholders in Demand, Supply, and Inventory and supplier / materials Management to ensure analysis of data considers ongoing business activities including HPE strategies, existing projects, new product introductions, etc.
Participates in supply chain design strategy for resilience and digital transformation.
Develops agile and scalable models to provide end to end and real time visibility of supply chain
Provides ad hoc analytics support to planning and materials management functions as needed
Provides thought leadership on the design of visual management tools and the usage of data science, machine learning, artificial intelligence and other tools to advance supply chain performance.
Skills and Experience
10+ years of experience in data analytics
Strong analytical and problem solving skills
Ph.D or Masters in Statistics / computer science / operations research / data science / industrial engineering / supply chain / manufacturing systems
Deep understanding of machine learning/data mining algorithms and techniques
Experiences in processing and analyzing both structured and unstructured data
Proven ability to leverage analytical skills and knowledge for business value
Solid knowledge of big data processing framework and tools, such as Spark, Hadoop, MapReduce, etc.
Proficiency in one or more programming languages including but not limited to: Python, Java, Scala, R
Proficiency in statistical tools such as R, SAS
Proficiency in visualization tools such as libraries in R, Power BI, Tableau, Qlikview (PowerBi preferred)
Ability to effectively communicate analysis results to customers and negotiate options at management levels
Experience in working with supply chain, (demand planning, materials management, or inventory management preferred)
Hewlett Packard Enterprise Values:
Partner. Innovate. Act.
We live by three core values that drive our business.
Simplified, we are good partners, great innovators and we make things happen.
Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.
If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers

You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers
#GlobalOpsIN
1065569"
Professional 1 Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Designs, implements and maintains databases with respect to database dictionaries and integration of systems through database design to ensure that client requirements are satisfied.
Analyzes data requirements and documents according to required standards by utilizing prescribed tools and methods to ensure that design and implementation are according to company guidelines and client specifications.
Analyzes, designs and validates data models, structures and processes to define data structures and business operations.
Applies data analysis or data modeling techniques to establish, modify or maintain data structures and their associated components to increase efficiency of structures and components.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Coordinates and advises database designers and others using the data structures and associated components to ensure that business specifications are met.
Communicates with clients about data related discrepancies and other matters of significance to ascertain information and correct errors.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Participates in the development of training modules in data modeling techniques and incorporates data modeling into information systems development and maintenance.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science, or related field preferred
Three or more years of experience in programming or data analysis
Experience working with product configurations and company used database software and hardware
Experience working with security software packages, domain structures, user authentication and digital signatures
Experience working with data modeling practices and procedures
Experience working with relevant programming languages and relational databases
Experience working with data administration, repository management, database creation techniques, and data warehousing standards, strategies, and tools
Other Qualifications
Research, data analysis and problem-solving skills
Personal computer and business solutions software skills
Communication skills to communicate with designers, management and customers
Skills at configuring and installing various operating systems and application software
Ability to work independently and as part of a team
Ability to create and maintain formal and informal networks
Work Environment
Office environment"
Data Scientist,"Bengaluru, Karnataka",Calsoft Labs,None,Organic,"Data Scientist Bangalore As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Below are the MUST HAVES: • Experience as Data Scientist - Fortune 100 Clients - Prefer Product Base. • Data analysis experience working with large-scale data. • Strong experience using Python & SQL for analysis, modeling, and data visualization.

Advanced statistics, data mining and modeling knowledge. Requirements: • Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration. • Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework. • Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products"
Jr. Software Developer - Machine Learning / Artificial Intel...,"Navi Mumbai, Maharashtra",V2Solutions,None,Organic,"Key Responsibilities
Complete implementation, testing, and documentation of development projects and tasks
Provide timely project deliverables based on implementation plan
Prepare reference, documentation, and testing methodologies for applications and related errors
Available to review code created by Software Engineers and Programmers
Tests Base-cases, and outliers
Requirements
Experience:1-3 years
Technologies and tools: Python, R, Google Big Query, TensorFlow
Bachelor’s Degree from an accredited university in Computer Engineering, Computer Science, or related field
Understanding of data structures, data modelling and software architecture
Great attention to detail, ability to organize/prioritize multiple tasks, and meet deadlines.
Ability to work in a fast-paced environment"
Data Scientist,"Bengaluru, Karnataka",Alphonso,None,Organic,"Data Scientist
Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.
Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.
We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.
Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data
Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus"
Data Scientist,"New Delhi, Delhi",Sentieo,None,Organic,"Sentieo is powering the future of financial and corporate research in a $30B market. Our vision is to create a world where competitive organizations have the insights they need to win. Built by former hedge fund analysts, we empower competitive investors and corporations to rapidly discover insights so they can make smarter investments and execute winning strategies. Supporting a global customer base of over 900 clients, we are excited to propel Sentieo into the next phase of our company’s global growth - from advanced, unprecedented product development to accelerated team scaling and expansion. Join our team as we reimagine the future of fintech.

We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small(but growing team) where you will have a major voice in deciding which projects to undertake. We'relooking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.

What you'll do:
Selecting and engineering features to build and based on mining of our large text and
financials database.
Prototyping/Testing algorithms to help inform us what to build.
Training and tuning a variety of machine learning models.
Data mining using NLP & state-of-the-art methods.
Enhancing data collection procedures to include information that is relevant for building analytic systems.

What you'll bring:
Knowledge and hands-on working experience with ML techniques and tools.
Strong understanding of basic statistics concepts including population, confidence intervals,correlation, significance,probability,distributions, hypothesis testing, etc.
Strong grounded concepts and application knowledge of ML techniques including
linear/logistic regression,decision trees,classification,clustering,ensembles,text mining to build models.
Hands-on experience with Python and familiarity with machine learning frameworks.
Comfortable with data visualization tools like pandas,seaborn and matplotlib.
Ability to work independently and collaboratively within a team.
Life at Sentieo:
Join a fun & tight-knit team that values transparency and is serious about building and maintaining a great culture.
Comprehensive health benefits.
Flexible vacation & sick policy.
Daily Breakfast and unlimited snack food.
Fun team outings (offsites, happy hours, etc.).

EEO

Our company values diversity and believes diverse teams make innovation possible. We work on complex, difficult problems with no linear or clear solutions. We believe that a diverse team can bring different perspectives and approaches, and whose experiences reflect the full set of clients we seek to serve. As such, Sentieo is committed to a diverse representation among our employees."
Data Scientist _Bangalore,"Bengaluru, Karnataka",Thoucentric,None,Organic,"We are looking for a Data Scientist to help us create machine learning products. Data Scientist responsibilities include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand

Job Description:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Develop and maintain robust data processing pipelines and reproducible modelling pipelines
Build mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.
Explore data and communicate insights clearly to non-technical as well as technical audience
Analyze experimental results, iterate and refine models to create significant business impact
Follow strict coding standards and other software engineering best practices and be the proponent of the culture in the organization.
Requirements
Bachelor’s Degree in a Quantitative discipline
1-2 years’ experience in data science/Analytics roles
Expert Proficiency in Time Series Forecasting – Classical & Machine Learning
Proven experience as a Data Scientist or similar role
Expert ability to write robust code in Python
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn , StatsModels )
Should be proficient in evaluation metrics (MAPE, F1, RMSE, Confusion Matrix)
Should possess strong problem-solving skills
Excellent verbal and written communication skills
You take complete ownership of your work and are self-driven.
Good to Have
Deep Learning Frameworks like Tensorflow, PyTorch etc.
Familiarity in working with Azure, AWS, GCP etc.
Experience with NoSQL databases, such as MongoDB, Cassandra
Experience with containerizing applications using Docker"
Analyst - One ERP ( m/f),"Oragadam, Chennai, Tamil Nadu",Danfoss,None,Organic,"Job ID: 13240
Job location(s): Oragadam, IN
Job Description
We are currently looking for an Analyst One ERP (m/f) with global responsibility for our location in Chennai, India.


We are looking for an Analyst with data science experience that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. In this role, you will work with business teams from Global Planning & Logistic area to implement new solutions. You will work directly with large, different data sets and analyse them using the latest modelling techniques. You must be comfortable working with a wide range of stakeholders and functional teams to drive business results with their data-based insights. As a team, we will develop and build recommendations for automation, data integration and machine learning.
Job Responsibilities
Identify use cases - work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
Processing, cleansing, and verifying the integrity of data used for analysis
Data mining using state-of-the-art methods
Selecting features, building and optimizing classifiers using machine learning techniques
Creating visualizations of complex data sets for easy of understanding by business partners
Doing ad-hoc analysis and presenting results in a clear manner
Enhancing data collection procedures to include information that is relevant for building analytic systems
Creating automated anomaly detection systems and constant tracking of its performance
Analyse, Manipulate, and Validate data using SQL, R, Python, and other analytical tools
Develop, test, and pilot your solutions
Background & Skills
Bachelors / Masters with focus on Statistics, Mathematics, Economics or Business preferred
Experience with data analytics
Experience in machine learning and neural networks
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets
Experience with data visualization tools
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Experience working with and creating data architectures
A drive to learn and master new technologies and techniques

Capabilities/Mindset
Great communication skills
Data-oriented personality
Strong problem-solving skills
Self-motivated

Optional:
Big data tools (Apache Spark, Hadoop)
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Danfoss – Engineering Tomorrow
At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways – driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.

Following our founder’s mindset ‘action speaks louder than words’, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030."
Data Science Engineer - Image Database,"Bengaluru, Karnataka",Mercedes-Benz Research and Development India Priva...,None,Organic,"Aufgaben
Senior Data Architect
Summary
We are looking for a technical lead who will design, build and maintain the data pipeline for creating training datasets for our AI research engineers. Additionally he or she will be responsible for automating the large dataset creation process. The ideal candidate should have 6-10 years of industrial experience in related field as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence/Data/DW Engineer, Data Scientist etc.) and 1-2 years of experience in leading a team.

Responsibilities
1. Lead the data pipeline setup, operation and maintenance.

2. Assemble large, complex data sets that are analysis/training ready for the machine learning engineers/researchers

3. Design and build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems. Ensure high data quality for pipelines you build and make them auditable. Support design and deployment of distributed data store that will be central source of truth across the group.

4. Develop, customize, configure automation scripts/tools that help engineers to extract and analyze data from our internal data store. Develop reporting and data visualization solutions, as well as looking to build out a dynamic platform

5. Evaluate new technologies and build prototypes for continuous improvements in data engineering. Creation of new capabilities and modules in our data pipeline. Develop and maintain expertise in advanced and/or emerging data management and analytical information technologies such as data warehouse, data lake and Big Data

6. Build data connections to company's internal IT systems

7. Design, implement and continuously optimize the group’s data strategy. Provide thought leadership and lead efforts to design data integration and implement extract, transform and load (ETL) jobs/processes, detailed data warehouse models and data mappings. Provide consultation on best practices and standard practices to internal team members

8. Perform performance optimization and tuning on new and/or existing data warehouse implementations.
Qualifikationen
Requirements
1. 5+ years of hands on industry experience with a track record of manipulating, processing, and extracting value from large data sets.

2. Demonstrated ability in building data pipelines, data modeling, ETL development and familiarity with design principles. Experience building data products incrementally, integrating, and managing data sets from multiple sources. Knowledge of data warehouse technologies and relevant data modeling best practices. Experience with a DW technology (Redshift, SQL Server, etc.) and relevant data modeling. Experience processing large amounts of data, in various formats and processing data in batch mode and streaming mode

3. Excellent SQL skills. Proficiency in a scripting language (Python, Ruby, Perl etc.) and/or a major programming language (C++, Java etc.). Knowledge of R is a plus.

4. Experience with working in Spark/Hadoop and/or other distributed computing frameworks is required

5. Experience working in a multi-layered distributed architecture is essential. Experience with scalable service architecture and design

6. Exposure and knowledge of Data Security and Governance. Awareness of best practices to secure data and processes from unauthorized access.

7. Knowledge and direct experience using business intelligence reporting tools (Tableau, PowerBI etc.) is a plus.

8. Understanding of data science, machine learning, and AI is a plus.

9. Strong analytical and problem solving skills (data analysis and requirement documentation)

10. Excellent project management skills and ability to prioritize issues

11. Excellent oral and written communication, organizational and client facing skills.


Academic Qualification Profile:
B.E. / B. Tech in Computer Science
Certification or Masters in Big Data Science"
Machine Learning Engineer,"Hyderabad, Telangana",Phenom People,None,Organic,"Job Requirements
Design and implement machine learning, information extraction, probabilistic matching algorithms and models
Research and develop innovative, scalable and dynamic solutions to hard problems
Work closely with Machine Learning Scientists (PhDs), ML engineers, data scientists and data engineers to address challenges head on
Use the latest advances in NLP, data science and machine leaning to enhance our products and create new experiences
Scale machine learning algorithm that powers our platform to support our growing customer base and increasing data volume
Be a valued contributor in shaping the future of our products and services
You will be part of our Data Science & Algorithms team and collaborate product management and other team members
Be part of a fast pace, fun focused, agile team

Work Experience
3+ years of industry experience
PhD/MS/BTech in computer science, information systems, or similar technical field
Strong mathematics, statistics, and data analytics
Solid coding and engineering skills preferably in Machine Learning (not mandatory)
Proficient in Java, Python, and Scala
Industry experience building and productionizing end-to-end systems
Knowledge of Information Extraction, NLP algorithms coupled with Deep Learning
Experience with data processing and storage frameworks like Hadoop, Spark, Kafka etc."
Software Engineer Data Science,"Bengaluru, Karnataka",PayPal,None,Organic,"Risk Engineering team is responsible for Risk decision, fraud detection, risk management decision and compute services across PayPal - globally. We design, develop, enhance and support services that get called across every interaction between PayPal and it's users and partners. Our solutions need to scale across millions of such interactions, working with petabyte plus data, integrating with various other APIs in real time and yet providing high availability to the business. To achieve this we are always looking at advances in technology and science and tying those back to business needs.
Skills Required :

5-8 years of Experience as a Data Scientist with Software Engineering background
- Experience with Supervised and Unsupervised Learning - Classification, Regression, Clustering (Naive Bayes, k-NN, GBM, Neural Networks, SVM, Decision Forest etc.)
Solid knowledge in deep learning algorithms and AI system design and architecture
Experience building and deploying one or more of these technologies in production: Deep learning (e.g. CNN, RNN, LSTM, GAN, etc.), Reinforcement Learning, Accelerated compute (e.g. GPU.)
Experience profiling and optimizing software for CPUs & GPU applications.
- Experience with one or more AI/ML frameworks & libraries - TensorFlow, PyTorch, Azure ML studio, Jupyter Hub, Zeppelin, Spark ML lib, Sci-Kit Learn, Pandas etc.
knowledge of feature engineering concepts & techniques..
Ability to write excellent code in Java and Python
Deploy models in production environment as per requirements
Data Visualizations to convey insightful stories
Knowledge of Algorithms and Data structure.
Demonstrate a high level of curiosity, passion for technology, pride of ownership and strive for excellence

Responsibilities :

Use existing frameworks to define the architecture & solution for AI/ML applications that scale to enterprise grade.
Analyze existing AI/ML systems and explore existing data to improve efficiency and performance in live production environment
Fine tune open source inference engines and optimize engines based on software stack
Pre-processing, feature engineering, models training and tuning hyper-parameters and validation strategies.
Bring innovation to the risk ecosystem
Job_Description_Summary: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (Nasdaq: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 203 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies. You will be responsible for working with a team of engineers in design, development, test, and deployment of a range of products on enterprise platforms. A successful candidate will have an established background in developing customer-facing experiences, a strong technical ability, deep understanding of data science and software engineering, excellent project execution skills, great communication skills, and a motivation to achieve results in a fast paced environment.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Data Scientist,"Bengaluru, Karnataka",Sequretek,None,Organic,"About us & Vision
Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.
Why Sequretek?
You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.
Education & Experience
Education:
The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.
Key Responsibilities
Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets"
Data Science Trainer,India,Emerging India Group,None,Organic,"To teach Python, Machine learning, Deep Learning, Data wrangling, Integration with Big Data Hadoop, Scoop, Impala, Hive, Pig & Spark R with Statistics, Data Wrangling, Models, Data mining, and Algorithms. Time series and forecasting, SQL, queries, Tableau Data Visualization
Good Understanding with Hadoop, HBase, Hive, Pig, and Mapreduce, Python, R, Java, Apache spark, Impala, Hive, Pig, Machine Learning, Algorithms, Time series and forecasting, SQL, queries, Tableau Data Visualization.
Develop BigData/ Hadoop Technologies training content for Students, Working Professionals and Corporates
Conduct online and classroom training sessions by providing practical use cases and assignments
Design quality self-faced recorded training sessions on all latest BigData/ Hadoop development technologies for students, working professionals and corporates
Continuously improve on teaching methodology to suite online model to lead to high student
Work in small teams where each team member has a lot of ownership and each individual can make a big impact
Design and make the trainees develop mini or major real time projects for practical exposure
Work as a consultant or architect in development and training of real time BigData/ Hadoop Applications for corporates on part time or fulltime basis
Experience / Skills
Engineering degree or post graduate degree or Ph.D in Computer Science or equivalent experience
Minimum 2-3 years of developing and implementing Hadoop solutions in a corporate environment with a total of 3 to 5 years of experience
Experience in Hadoop (Cloudera or HortonWorks preferred), HDFS, MapReduce, Hive, Pig, HBase, R, Java, C/C++, Perl, or Python.
Experience in cassandra, MangoDB, Jaspersoft, oozie and zookeeper
Experience in developing Hadoop integrations for data ingestion, data mapping and data processing capabilities
Any past experience with optimizing computing techniques i.e. parallel processing, grid computing etc
Good interpersonal with excellent communication skills
Educational Background
B.Tech/ M.Tech/ Ph.D in computer science or equivalent from a top educational institution

Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules"
Data Scientist,"Bengaluru, Karnataka",Miles,None,Organic,"Miles is looking to expand its data science and data engineering team in INDIA!
Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline
Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data - handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus
Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects
Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing"
Big Data Engineer,"Bengaluru, Karnataka",PayU Payments Pvt Ltd,None,Organic,"Role: Big Data Engineer
Company: PayU Payments Pvt Ltd
Location: Gurgaon/Bengaluru

About Company:
PayU, the fintech-arm of Naspers, is a leading financial services provider in global growth markets. We use our expertise and heritage in cross border and local payments to extend the services we offer to merchants and consumers. Our innovative technology, developed in-house as well as through investments and strategic partnerships, empowers billions of people and millions of merchants to buy and sell online, extending the reach of financial services.
Our local operations span 18 growth markets across Asia, Central and Eastern Europe, Latin America, the Middle East and Africa. Here we deliver fast, simple and efficient financial services technology that unlocks access to more than 2.3 billion consumers in our regions.
Regulated under the Reserve Bank of India, PayU India has advanced solutions to meet every digital payment need. The company has an in-depth understanding of the vast and intricate details of the Indian market and its payment landscape. The company brings convenience and trust through continuous innovation leveraging technology.
PayU India forays into two business verticals - payment offerings under PayU Payments Services Ltd. and alternate lending under PayU Finance. Headquartered in Sohna Road, Gurgaon, the company has a presence in Mumbai, Pune and Bangalore and has a total strength of 700+ employees. Anirban Mukherjee is the CEO for PayU India working with the global CEO Laurent Le Moal.
Under the aegis of PayU Payments Services Ltd., PayU provides payment gateway solutions to online businesses through its cutting-edge and award-winning technology. In India, PayU covers nearly 60% of the airline business and 90% of the entire e-commerce business and processes over INR 120,000 crores worth of digital payments annually (at current run rates). The company offers more than 70 local payment methods and serves more than 350,000 merchants including leading e-commerce businesses in India. The company also empowers SMBs, enabling them to accept mobile and online payments with minimum development effort.
With credit being the key business priority, PayU has also developed LazyPay, an alternate lending platform to offer credit solutions such as Small Ticket Credit (Buy Now, Pay Later), App based personal loans and Point of Sale Credit (Merchant EMI). Since its launch in 2017, LazyPay has gained significant traction and has disbursed 20mn+ loans to a customer base of a million user.
PayU is bullish on investment opportunities in India. The company has been an aggressive investor, committed to the evolution of fintech in the country. PayU has spent about $250 million over the past three years in Asia's third-largest economy and is further scouting for more lucrative investment and acquisition opportunities to fuel growth.
PayU’s acquisitions in India include that of Wibmo (April 2019 worth $70 mn) and Citrus Payment Solutions (September 2016 for $130 mn). PayU has also invested in PaySense (July 2018) and ZestMoney (December 2016) in India.

Role and Background Information:
Gather and process raw data at scale.
Design and develop data applications using selected tools and frameworks as required and requested.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.


What you’d need to bring to the table:

2 – 7 years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in MapReduce is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems

So what do we offer?
A Competitive salary, including benefits
Modern offices with individual working spaces
Exceptional projects
Awesome teams that love finding ways of making things better, faster, stronger
Interesting growth prospects
ESOPs (SARs)

Education-
Bachelor of Engineering (IIT/NIT/Bits is Preferred)"
Senior Analyst - Geospatial Analytics,"Chennai, Tamil Nadu",McKinsey & Company,None,Organic,"QUALIFICATIONS
University degree in Computer Science, Engineering, Applied Mathematics, Geoinformatics, Quantitative Social Sciences or related field and excellent academic record required; Advanced degree preferred
4-6 years of deep technical experience in working with spatial data and applying advanced statistical and machine learning algorithms
Proficiency with GIS software (e.g., ArcGIS) and geospatial approaches (spatial analysis, remote sensing, network analysis, geographic visualization, etc.)
Familiarity of analytical packages such as R, Python, SAS, MATLAB, etc., and approaches (regression, decision trees, clustering, neural networks, etc.)
Ability to work with relational databases such as SQL, PostGIS etc. Knowledge of distributed database systems (Hadoop, Spark, MapReduce) will be a plus
Stakeholder management skills with ability to communicate and work with senior management effectively
Skills to communicate complex ideas effectively
WHO YOU'LL WORK WITH
You’ll be based in Chennai and will be part of our Data Analytics team.
This group provides analytics insights to consulting teams and clients across the globe. The team is composed of data scientists and data engineers who work across a variety of industries, functions and analytics methodologies and platforms.
WHAT YOU'LL DO
You will work with our client project teams on analytics focused engagements across geospatial/location analytics.
The types of projects you may work on include: decoding spatial and temporal patterns in customer behaviors, analyzing the drivers of performance to improve customer relationship management, developing an optimal distribution network configuration model for a global supply chain, or geographically optimizing a field sales force.
In this role you will be subject matter expert on advanced geospatial techniques, statistical analysis and machine learning algorithms. You will advise on state-of-the-art quantitative modeling techniques in order to derive business insights and solve complex business problems. This includes gathering and analyzing information, formulating and testing hypotheses, and developing and communicating recommendations. At times you will present the results to client management and implementing recommendations with client team members.
You’ll have the opportunity to gain new skills and build on the strengths you bring to the firm. As an analyst, you will receive exceptional training as well as frequent coaching and mentoring from local and global colleagues."
Service Data Scientist,"Pune, Maharashtra",Philips,None,Organic,"Job Title
Service Data Scientist
Job Description
#LI -SR1
In this role, you have the opportunity to
Senior Service Data Scientist will build roadmap, architecture, advanced processes in line with latest technology trends to develop big data analytical models and algorithms and apply models to enhance system service diagnostics & solutions. To build predictive machine learning models and diagnostics + utilization models to increase and optimize system servicing experience.
You are responsible for
Carry out research in advanced technological areas on Predicative & Utilization data Machine learning (Big Data Analytics) for which empirical evidence may have been found, but have basically yet to be proven, or to find new principles or solutions where current technologies fail.
Guide , mentor the team on System log data Exploration, Preparation, Modelling, Implementation and Validation with SQL, R & Python data scripting and data science languages. Develop big data analytical models and algorithms and apply models to enhance system service diagnostics efficiency. Build predictive machine learning models and diagnostics models to increase and optimize system servicing experiences. Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes. Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions.
To succeed in this role, you should have the following skills and experience
Service Data Scientist will build Big Data models with latest technology trends towards predictive , proactive & utilization based service & solutions
System log data Exploration, Preparation, Modelling, Implementation and Validation with SQL, R & Python data scripting and data science languages.
Develop big data analytical models and algorithms and apply models to enhance system service diagnostics efficiency.
Build predictive machine learning models and diagnostics models to increase and optimize system servicing experiences.
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes.
Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions
Experienced with considerable exposure to delivering meaningful results through data strategies, analytics, technologies & architecture
Deep understanding and experience in developing using Artificial Intelligence, Machine Learning and Deep Learning related technologies
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machin Logs Processing, text mining and text analytics.
Strong programming skills in R, Python, Java and with other open sources Big Data map reduce stack on large datasets.
Strong Expertise on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Read to be flexible to work on multiple programming languages to support the business opportunities.
Expertise in model documentation and release processes.
Excellent written and verbal communication skills for coordinating across teams
In return, we offer you
This role comes with a competitive compensation offering and a generous holiday / vacation offering, but that’s not all. Quality is right on the top of Philips leadership agenda and that means you have the unique opportunity to come in and have a recognized voice to drive and witness exciting, transformational changes. You will be empowered to drive high quality, ground breaking innovations with a globally recognized, premium brand behind you. And when you are successful in this role’s mission, you will have an array of diverse career options open to you – across different functional areas, product lines, business groups and/or geographies. That is a commitment Philips Quality Leadership team has made and stands by.
Why should you join Philips?
Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.
To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there,you can also learn about our recruitment process, or find answers to some of the frequently asked questions.
Contact
If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.
If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)"
Machine Learning Engineer,"Bengaluru, Karnataka",Kimberly-Clark,None,Organic,"Job Description
SU M M A R Y OF ROLE:
The IT Digital Supply Chain Data & Analytics team is organized around world-class data, advanced data science and automation to drive business value for the K-C organization. We are a group of curious people and critical thinkers focused on solving the problems of the day and opportunities of the future through applied intelligence and data science. As part of this team, the Machine Learning Engineer is responsible for integrating business, information, and technology architecture to create artificial intelligence and machine learning solutions for supply chain and manufacturing capabilities. This role is viewed as a solution innovator and expert in complex analytical and digital platform environments, encompassing both business process understanding and technical expertise.
Scope/Categories:
Role will report to a Manager in the IT Digital Supply Chain organization. Role wi ll not have any direct reports.
Key Interfaces: Data Scientists, Business Customers , Functional Engineers , Solution Enginee rs, Enterprise Data Management teams , Analytics Designers , Project Manager .
External Interfaces: Consultants , Vendors , Managed Services Providers (onshore/offshore) . Travel may include approximately 15% of work time.
Key Accountabilities :
Drive a rigorous approach leveraging data science including a rtificial i ntelligence and m achine l earning to solve problems in the context of growing Kimberly Clark brands, increasing sales, and enabling operational excellence.
Partner with Data Scientists to design and develop innovative, machine learning solutions for important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with in their area of expertise. Provide technical consulting on complex projects.
Collaborate with functional and solution engineers to develop data and model pipelines including understanding lineage and granularity of data required to perform data science and helping prepare, profile, and cleanse data needed for data science.
Assist in embedding machine learning AI outputs into key business applications including analytical and transactional solutions.
Scale up existing data science solutions (deploy to additional regions, apply to additional areas/attributes)
Support the iterative data science implementation cycle by assisting with research, design, experimentation, development, deployment, monitoring, and maintenance as required.
Communicate complex processes to business leaders – explain outputs of machine learning in business language
Produce project outcomes and isolate issues with models through continuous improvement
Research and implement best practices to enhance existing machine learning infrastructure. Contribute to new and existing data science architecture patterns.
Analyze large and complex data sets to derive valuable insights
Document solutions in appropriate service management applications and collaborate with Solution Engineers, Enterprise Architecture, and Analytics Designers to make sure that the data science solution fits within enterprise context.
Coordinate engagements with vendors as they relate to evaluation, design and delivery of business capabilities. Contribut e to the evaluation and selection of software products.
Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of K - C to deliver the end - to - end machine learning solutions.
Influences and moves the K-C culture to one that values and uses cross-business and functional data and analytics to power business performance.
Key Qualifications and Experiences :
Bachelor's degree required, Master’s degree preferred. Relevant fields include computer science/engineering, statistic s , mathematics, artificial intelligence, or operations research.
Three or more years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, Neural Networks, Random Forest, etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi , MySQL, etc.) Proficiency in SQL and Python is important.
Understanding of data structures, data modeling and software architecture . E xperience d esigning and i mplementing d ata s cience s olution s on Azure is helpful.
Familiarity with machine learning frameworks and libraries
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Experience with data integration methods and tools including ETL and virtualization.
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in retail/manufacturing environment is preferred. Basic functional knowledge in key CPG Supply Chain Area capabilities ( Planning, Procurement, Manufacturing, Logistics, Safety & Sustainability, Quality , etc.) is a big plus.
Experience collaborating with data scientists, solution architects, and engineers to identify, design, and implement highly complex, end-to-end solutions.
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Ability to operate in a digital workplace utilizing modern technologies to connect, collaborate, communicate and cooperate across a global organization and across organizational boundaries.
Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.
Ability to communicate strategies and processes around machine learning and data architecture to cross functional groups and senior levels.
Thought leader with strong connection to industry and technology user groups and networks. Keeps abreast of leading trends in digital, cloud, artificial intelligence, machine learning, block chain, virtual reality, augmented reality and combinations of technology that matter in AI & ML .
High level of communication is required. Must be self-motivated, self-disciplined and have strong time management skills. Embraces learning agility to keep abreast of new technologies and strategies.
Possesses strong leadership skills and exhibits creative thinking to be able to design inventive solutions which solve business challenges. Cultivates networking opportunities within the organization .
Kimberly-Clark and its well-known global brands are an indispensable part of life for people in more than 150 countries. Every day, 1.3 billion people - nearly a quarter of the world's population - trust K-C brands and the solutions they provide to enhance their health, hygiene, and well-being. With brands such as Kleenex, Scott, Huggies, Pull-Ups, Kotex, and Depend, Kimberly-Clark holds No.1 or No. 2 share positions in more than 80 countries. With a 135-year history of innovation, we believe in recruiting the best people and putting them in the right jobs so that they can do their best work. If fresh thinking and a passion to win inspire you, come Unleash Your Power at Kimberly-Clark.

Kimberly-Clark is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender identity or any other characteristic protected by law.

The statements above are intended to describe the general nature and level of work performed by employees assigned to this classification. Statements are not intended to be construed as an exhaustive list of all duties, responsibilities and skills required for this position.
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship. This position is subject to drug and alcohol testing, including pre-employment testing .
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time"
Data Scientist -1,"Bengaluru, Karnataka",Acko General Insurance Limited,None,Organic,"Role and Responsibilities:
Work closely with Business teams & Product Managers to identify opportunities and serve as an ambassador for data science
Translates complex functional and technical requirements into detailed architecture, design, and high performing software and applications.
Works with peer developers to make sure that all data solutions are consistent and ensures all automated processes to preserve data by managing the alignment of data availability and integration processes
Eligibility Criteria:
2 years of experience in the field of statistics, data mining and machine learning
Qualifications:
BTech/BE Premier institute like IITs/BITS/NITs
Experience in e-commerce/Online Internet companies
Skills:
Expert-level understanding of the underlying theory of Machine Learning.
You have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
Taking end-to-end ownership of problem domains and continuously improving upon quantitative solutions
Demonstrated ability to facilitate and work with minimal direction, with the proven ability to coordinate complex activities
Analytical thought leadership and stay current on developments in data mining and the application of data science"
Jr. Software Developer - Machine Learning / Artificial Intel...,"Navi Mumbai, Maharashtra",V2Solutions,None,Organic,"Key Responsibilities
Complete implementation, testing, and documentation of development projects and tasks
Provide timely project deliverables based on implementation plan
Prepare reference, documentation, and testing methodologies for applications and related errors
Available to review code created by Software Engineers and Programmers
Tests Base-cases, and outliers
Requirements
Experience:1-3 years
Technologies and tools: Python, R, Google Big Query, TensorFlow
Bachelor’s Degree from an accredited university in Computer Engineering, Computer Science, or related field
Understanding of data structures, data modelling and software architecture
Great attention to detail, ability to organize/prioritize multiple tasks, and meet deadlines.
Ability to work in a fast-paced environment"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Data Scientist,"Indore, Madhya Pradesh",GenieTalk,None,Organic,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore | Openings"
Business Data Analyst,"Chennai, Tamil Nadu",PipeCandy,None,Organic,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.
About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Business analyst who will work on custom data analysis and analytical projects for large clients. If you love playing with data and math, have an eye for detail and a strong client delivery mindset, we’d love to hear from you.
The business analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data team. This position requires experience in data analysis, the ability to understand business requirements, define analytical requirements, work with teams in getting the plans executed, and managing project delivery and client communications.
Key Responsibilities:
Works to develop and validate data analysis as per business and client requirements
Gather, evaluate and document requirements, develop an analysis plan and project plan to deliver as per requirements
Understand data sources to determine the correct source(s) and logic to ensure accurate, efficient and timely deliverable
Build, run and automate data queries, analysis and reports
Ability to effectively visualize data and communicate results of data analysis & analytical models
Collaborate with data and tech teams to ensure data/ analysis tasks are allocated and executed as per plan
Understand and have a working knowledge of customer/ transaction level data preferably in retail environment
Skills Required:
Experience in managing on data analysis delivery for client projects. Experience in managing a team is a plus
Data exploration, analysis, data interpretation, visualization, skills. Mathematical/ statistical modeling skills a plus
Strong communication and project management skills
Analyze & interpret data and communicate results to clients effectively
Analytical/ Technologies skills
Strong database/ SQL skills for data extracting, data prep and validation
Experience in Python/ R. Good skills in advanced Excel/ spreadsheets
Experience in scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Strong mathematical, analytical and problem solving skills
Qualifications & Competencies Required:
Degree in a quantitative field (Engineering, Math, Statistics, Economics, Physics)
3-4 years of experience in data analysis, with excellent ability to combine, cleanse and harmonize data for descriptive and predictive analysis
Desired:
Ability to work with business and technology teams to deliver data acquisition projects
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills
Perks
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course"
Data Engineer,"Bengaluru, Karnataka",Ipreo,None,Organic,"Position: Data Engineer

Description of Duties
The Automotive Supply Chain and Technology team at IHS Markit is in search of a Data Engineer to support its global team's ongoing research and analysis efforts. The research team produces granular forecast dataset and written analyses on the supply chain of parts supplied to automakers with technology, supplier and logistic information. The team generate forecasts on technology trends through multiple research channels and by using many connected and disconnected data sources to drive the forecast.

The position covers an array of critical data-centric activities aimed at enhancing the efficiency of our 70+ strong research team, sustaining the increasing data complexity and most importantly supporting new product development at one of IHS Markit's fastest growing product lines. The position is based in Gurgaon or Bangalore, India and reports to our U.K.-based Data and Platform operations lead.

Responsibilities and duties
Understanding business requirements to create maintainable workflows e.g. inbound/input data from analysts and external sources to feed a set of interconnected data sets and calculations
ETL process design, implementation, maintenance and documentation for large inter-connected data sets
Data cleaning and manipulation of raw data to provide to Data Science team
Creation of logical and physical data models
Utilise existing database infrastructures as well as building new DB infrastructures as required
Data acquisition exploration
Create and maintain detailed documentation of workflows

Qualifications and skills
3+ years’ experience as a data engineer with data science touchpoints
At minimum, a degree in computer science, computer engineering or a related quantitative field with proven work experience in the data engineering/scientist field
Proven experience with SQL and NoSQL databases like Oracle DB, SQL Server, Cassandra, MongoDB, MySQL, Hadoop, Spark, AWS (EC2 and S3)
Proven experience with one or more programming/scripting languages (e.g. Python, R) is highly desirable
Knowledge of OLAP and ETL processes
Familiarity with data science platforms such as KNIME is a bonus
Knowledge of API creation and maintenance
Familiar with techniques to manage large databases, including partitioning, compression and indexes as well as data mining
Ability to build models (e.g. Linear regression, logistic, Markov models) a plus
Established MS Office skills, O365 desirable
Good communication skills, collaborative team spirit, curiosity to constantly keep thinking of unique approaches and solutions.
Ability to work independently.
Experience committing to deadlines whilst multi-tasking
-
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.
We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.
IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work."
Machine Learning Engineer,"Noida, Uttar Pradesh",Whizzystack,None,Organic,"This is not a project-based position. This is a full-time, long-term position with the opportunity to travel to the client’s office in Silicon Valley two times per year.

You will be responsible for implementing machine learning and predictive modeling techniques that will have a major impact on the company.

This is an excellent opportunity for smart machine learning engineers who want autonomy and the freedom to turn their big data ideas into reality.

What You’ll Be Doing

Implement machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).
Tune SQL queries for Redshift/Hadoop.
Analyze data and performance of data products.
Implementing machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Who You Are (Experience & Skills)

Commercial machine learning experience, not just academic or research experience.
Experienced in machine learning techniques.
Experience with a variety of Big Data tech, distributed machine learning and computing frameworks (S3, Spark, Hadoop, Elasticsearch, etc.)
Experienced in creating high-performance algorithms, prototypes and predictive models.
Experience with deploying solutions in AWS
Experience with Python data science ecosystem - Pandas, SciPy, scikit-learn, NLTK, Gensim, etc.Experience with full-stack development, building large distributed systems and large scale data pipelines

What We Offer

Competitive salary.
Challenging work on complex and very innovative projects.
Work in an international environment.
Generous benefits package with all kinds of great stuff.
Trainings accustomed to your needs.
Flexible working environment.
Cozy and friendly atmosphere.

How To Apply

To apply email your resume to sid.baker@whizzystack.com with the subject line “Machine Learning”.
When applying please provide a resume and any links to your technical blog, github/bitbucket and other reviewable code examples."
Data Scientist,"Bengaluru, Karnataka",Sequretek,None,Organic,"About us & Vision
Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.
Why Sequretek?
You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.
Education & Experience
Education:
The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.
Key Responsibilities
Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets"
Machine Learning part time job/internship at Pune,"Pune, Maharashtra",SkillBit,"₹5,000 a month",Organic,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Analyzing data, developing predictive algorithms, designing, and recommending code algorithms using advanced machine learning algorithms 2. Designing, developing, and testing sales recommendation solutions 3. Performing explanatory data analysis 4. Preparing & analyzing data and identifying patterns
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 11th Aug'20 and 15th Sep'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 6
Categories: Machine Learning,Data Science"
Data Scientist,"Bengaluru, Karnataka",Miles,None,Organic,"Miles is looking to expand its data science and data engineering team in INDIA!
Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline
Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data - handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus
Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects
Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing"
DATA ANALYST,"Bengaluru, Karnataka",Inference Labs,None,Organic,"Employment: Full time.
Role: Data Analyst
Job Description
Our growing firm is looking for an experienced Data Analyst who is able to turn project requirements into custom-formatted data reports. The ideal candidate for this position is able to do complete life cycle data generation and outline critical information for each Project Manager. We also need someone who is able to analyze business procedures and recommend specific types of data that can be used to improve upon them.
Responsibilities and Duties
Use statistical methods to analyze data and generate useful business reports
Work with the management team to create a prioritized list of needs for each business segment
Identify and recommend new ways to save money by streamlining business processes
Use data to create models that depict trends in the customer base and the consumer population as a whole
Work with departmental managers to outline the specific data needs for each business method analysis project
Required Experience, Skills and Qualifications
Bachelor’s Degree in Mathematics or Computer Engineering
1.5+ years’ Data mining experience
1.5+ years in a data analyst role
Ability to collaborate effectively and work as part of a team
Strong attention to detail
Independent thinker
Excellent critical thinking skills
Good knowledge of data objects
Good Python/SQL skills
Knowledge of Data Science & R would be an add on"
Business Data Analyst,"Chennai, Tamil Nadu",PipeCandy,None,Organic,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.
About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Business analyst who will work on custom data analysis and analytical projects for large clients. If you love playing with data and math, have an eye for detail and a strong client delivery mindset, we’d love to hear from you.
The business analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data team. This position requires experience in data analysis, the ability to understand business requirements, define analytical requirements, work with teams in getting the plans executed, and managing project delivery and client communications.
Key Responsibilities:
Works to develop and validate data analysis as per business and client requirements
Gather, evaluate and document requirements, develop an analysis plan and project plan to deliver as per requirements
Understand data sources to determine the correct source(s) and logic to ensure accurate, efficient and timely deliverable
Build, run and automate data queries, analysis and reports
Ability to effectively visualize data and communicate results of data analysis & analytical models
Collaborate with data and tech teams to ensure data/ analysis tasks are allocated and executed as per plan
Understand and have a working knowledge of customer/ transaction level data preferably in retail environment
Skills Required:
Experience in managing on data analysis delivery for client projects. Experience in managing a team is a plus
Data exploration, analysis, data interpretation, visualization, skills. Mathematical/ statistical modeling skills a plus
Strong communication and project management skills
Analyze & interpret data and communicate results to clients effectively
Analytical/ Technologies skills
Strong database/ SQL skills for data extracting, data prep and validation
Experience in Python/ R. Good skills in advanced Excel/ spreadsheets
Experience in scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Strong mathematical, analytical and problem solving skills
Qualifications & Competencies Required:
Degree in a quantitative field (Engineering, Math, Statistics, Economics, Physics)
3-4 years of experience in data analysis, with excellent ability to combine, cleanse and harmonize data for descriptive and predictive analysis
Desired:
Ability to work with business and technology teams to deliver data acquisition projects
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills
Perks
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course"
Data Scientist,"Bengaluru, Karnataka",HR Devi and Associates,"₹8,00,000 - ₹11,00,000 a year",Organic,"Data Scientist
Bangalore


1.Build program expertise by improving data analytics and establishing the framework for the company's future in data science, machine learning, AI and predictive analytics.
2.Experience in statistical modeling techniques such as linear regression, logistic regression, and GLM.
3.Experience and knowledge with one or more of modern machine learning and statistical modeling techniques, e.g. GLM, GAM, decision trees, random forest, SVM, deep learning, GBM, clustering, Bayesian averaging
4.Experience using predictive analytics, machine learning, and artificial intelligence practices.
Knowledge of dashboarding to create data visualizations and Business Intelligence software.
5.Strong data mining skills with the ability to interpret data for the purposes of drawing business inferences.
6.Expertise in one or more modeling/machine learning languages such as R, Python, etc.
7.Expertise in SQL and databases.
8.Education of colleagues, business partners, and prospects in various areas related to the discipline. Strong ability to communicate technical data and concepts to audiences with varying levels of understanding.
9.Proficiency in Microsoft Office (Excel, Word, PowerPoint).
Experience
5 - 7 Years

Salary
8 Lac To 11 Lac P.A.

Industry
IT Software - Others

Qualification
B.Sc, B.Tech/B.E

Key Skills
Data scientist DATA ANALYTICS


About Company
Company Name
HRDevi Talent Acquisition


About Company
An advanced Big Data Platform Management software product to help organizations effectively deploy Big Data features in business processes and decision making. In addition to creating a ‘Centralized Data Platform’ it also provides a centralized framework to enable business, analytics, governance, capabilities, and technology to operate effectively in a shared environment.

Email ID
swati5547@gmail.com"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Data Scientist,"Bengaluru, Karnataka",Alphonso,None,Organic,"Data Scientist
Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.
Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.
We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.
Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data
Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus"
Data Engineering,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups, synchronization, and policy access.
Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their usability for the client’s data scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate an effective team
relations.
Essential Qualifications:
Bachelor’s degree in computer engineering.
Demonstrated experience and knowledge in Big Data and NoSQL databases.
Demonstrated experience and knowledge in Object-Oriented Programming.
Demonstrated experience and knowledge in distributed systems.
Proficient in programming languages: Python.
Experience designing and implementing data warehouses.
Experience developing ETL pipelines.
Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
Good Problem-solving capabilities.
Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
Proactive attitude, resolutive, used to work in a team and manage deadlines.
Ability to learn quickly.
Be familiar with agile methodologies development (SCRUM/KANBAN).
Ability to communicate effectively in English both written and spoken.
Preferred Qualifications:
Master’s degree in data engineering or related.
Experience managing deep learning datasets.
Experience managing Cassandra.
Experience working with Spark.
Experience implementing CICD pipelines for automation.
Company Profile:
Conceptualized as far back as 2015, and commencing full-time operations in 2018, Blackstraw LLc. is a software products and services company specializing in Artificial Intelligence (AI) and Machine Learning solutions for various industries. We support businesses around the world, including North America, Europe and Asia, working to simplify AI implementation through our platform that expedites data labelling, AI model-training, and, cloud or on-premise deployments.
With more than 100 years of combined work-experience, the 100+-strong Blackstraw team comprises various experts in the AI value chain. We are a fast-moving team that prides ourselves in rapidly identifying different use-cases and fine-tuning our products to suit specific business needs.
We are focused on providing solutions related to computer vision, natural language processing, Data annotation tool for deep learning models, etc. To stay competitive in business, it is key for organizations to adopt and implement smart AI solutions and service offerings. However, most companies are unable to implement AI rapidly due to the complexity of existing solutions, inadequate data and cost implications.
Our mission is to enable enterprises to adopt AI in an easier, cost-effective and time-efficient manner with a plug-and-play approach to their data.
Blackstraw operations are based out of Mumbai, Pune and Chennai in India."
Machine Learning Engineer,"Bengaluru, Karnataka",Kimberly-Clark,None,Organic,"Job Description
SU M M A R Y OF ROLE:
The IT Digital Supply Chain Data & Analytics team is organized around world-class data, advanced data science and automation to drive business value for the K-C organization. We are a group of curious people and critical thinkers focused on solving the problems of the day and opportunities of the future through applied intelligence and data science. As part of this team, the Machine Learning Engineer is responsible for integrating business, information, and technology architecture to create artificial intelligence and machine learning solutions for supply chain and manufacturing capabilities. This role is viewed as a solution innovator and expert in complex analytical and digital platform environments, encompassing both business process understanding and technical expertise.
Scope/Categories:
Role will report to a Manager in the IT Digital Supply Chain organization. Role wi ll not have any direct reports.
Key Interfaces: Data Scientists, Business Customers , Functional Engineers , Solution Enginee rs, Enterprise Data Management teams , Analytics Designers , Project Manager .
External Interfaces: Consultants , Vendors , Managed Services Providers (onshore/offshore) . Travel may include approximately 15% of work time.
Key Accountabilities :
Drive a rigorous approach leveraging data science including a rtificial i ntelligence and m achine l earning to solve problems in the context of growing Kimberly Clark brands, increasing sales, and enabling operational excellence.
Partner with Data Scientists to design and develop innovative, machine learning solutions for important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with in their area of expertise. Provide technical consulting on complex projects.
Collaborate with functional and solution engineers to develop data and model pipelines including understanding lineage and granularity of data required to perform data science and helping prepare, profile, and cleanse data needed for data science.
Assist in embedding machine learning AI outputs into key business applications including analytical and transactional solutions.
Scale up existing data science solutions (deploy to additional regions, apply to additional areas/attributes)
Support the iterative data science implementation cycle by assisting with research, design, experimentation, development, deployment, monitoring, and maintenance as required.
Communicate complex processes to business leaders – explain outputs of machine learning in business language
Produce project outcomes and isolate issues with models through continuous improvement
Research and implement best practices to enhance existing machine learning infrastructure. Contribute to new and existing data science architecture patterns.
Analyze large and complex data sets to derive valuable insights
Document solutions in appropriate service management applications and collaborate with Solution Engineers, Enterprise Architecture, and Analytics Designers to make sure that the data science solution fits within enterprise context.
Coordinate engagements with vendors as they relate to evaluation, design and delivery of business capabilities. Contribut e to the evaluation and selection of software products.
Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of K - C to deliver the end - to - end machine learning solutions.
Influences and moves the K-C culture to one that values and uses cross-business and functional data and analytics to power business performance.
Key Qualifications and Experiences :
Bachelor's degree required, Master’s degree preferred. Relevant fields include computer science/engineering, statistic s , mathematics, artificial intelligence, or operations research.
Three or more years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, Neural Networks, Random Forest, etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi , MySQL, etc.) Proficiency in SQL and Python is important.
Understanding of data structures, data modeling and software architecture . E xperience d esigning and i mplementing d ata s cience s olution s on Azure is helpful.
Familiarity with machine learning frameworks and libraries
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Experience with data integration methods and tools including ETL and virtualization.
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in retail/manufacturing environment is preferred. Basic functional knowledge in key CPG Supply Chain Area capabilities ( Planning, Procurement, Manufacturing, Logistics, Safety & Sustainability, Quality , etc.) is a big plus.
Experience collaborating with data scientists, solution architects, and engineers to identify, design, and implement highly complex, end-to-end solutions.
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Ability to operate in a digital workplace utilizing modern technologies to connect, collaborate, communicate and cooperate across a global organization and across organizational boundaries.
Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.
Ability to communicate strategies and processes around machine learning and data architecture to cross functional groups and senior levels.
Thought leader with strong connection to industry and technology user groups and networks. Keeps abreast of leading trends in digital, cloud, artificial intelligence, machine learning, block chain, virtual reality, augmented reality and combinations of technology that matter in AI & ML .
High level of communication is required. Must be self-motivated, self-disciplined and have strong time management skills. Embraces learning agility to keep abreast of new technologies and strategies.
Possesses strong leadership skills and exhibits creative thinking to be able to design inventive solutions which solve business challenges. Cultivates networking opportunities within the organization .
Kimberly-Clark and its well-known global brands are an indispensable part of life for people in more than 150 countries. Every day, 1.3 billion people - nearly a quarter of the world's population - trust K-C brands and the solutions they provide to enhance their health, hygiene, and well-being. With brands such as Kleenex, Scott, Huggies, Pull-Ups, Kotex, and Depend, Kimberly-Clark holds No.1 or No. 2 share positions in more than 80 countries. With a 135-year history of innovation, we believe in recruiting the best people and putting them in the right jobs so that they can do their best work. If fresh thinking and a passion to win inspire you, come Unleash Your Power at Kimberly-Clark.

Kimberly-Clark is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender identity or any other characteristic protected by law.

The statements above are intended to describe the general nature and level of work performed by employees assigned to this classification. Statements are not intended to be construed as an exhaustive list of all duties, responsibilities and skills required for this position.
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship. This position is subject to drug and alcohol testing, including pre-employment testing .
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time"
Data Scientist Intern,"Bengaluru, Karnataka",zBliss Technologies,None,Organic,"Internship Cohort Team Size : 3
Apply Via Naukiri Posting
https://www.naukri.com/job-listings-Data-Scientist-Intern-zBliss-Technologies-Pvt-Ltd-Bengaluru-Bangalore-Chennai-0-to-1-years-110520000083
Apply only if you can work full time at least for Five Months
and
Only if you can demonstrate the Skills listed below through Previous projects, College Projects, or self-learning exercises reflected in your resume
Skills:
Python
Thorough understanding of Pandas, Tensorflow 2, Keras and other related modules
Experience in managing datasets with millions of rows and multiple features
Strong understanding and subject expertise in Artificial Neural Network (ANN) and Recurrent Neural Network (RNN)
RNN and ANN Modeling using TensorFlow 2 and Keras
Diligence and accuracy in coding and data analysis
Conscientiousness, and Professional approach towards team work, project management, coding, and product development
Education: Students pursuing Data Science related graduate, post graduate, Doctoral, and integrated courses.
Internship Duration: The internship will be for six to nine months. We cannot accommodate internship period less than three months

Internship Project: Development and implementation of AI algorithms in Healthcare. You will be guided and coached extensively. You will need to perform and contribute positively to the project on a daily basis

This is a full time PAID Internship for six to nine months.
Location: Chennai, or Work From Home because of the COVID19 Lockdown
Application Process:
Apply through this web page.

After reviewing your resume we will send you a pre-interview Programming Assessment Exercise to test your skills in Python, Data Management and Machine Learning. You will have to complete this exercise within five days of receipt of the Exercise and send the completed Exercise back to us.

We will review your submission and if we consider your skills to match our expectations, we will do a phone interview and if possible an in-person interview. Upon successful completion of the interview process you will be given an internship offer.
Job Features
Job Category
Data Scientist Intern"
Data Science Analyst,"Mumbai, Maharashtra",Thermo Fisher Scientific,None,Organic,"About the company
Thermo Fisher Scientific Inc. (NYSE: TMO) is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them. Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.


Role Description
The Data Science Analyst will be a key member of the Corporate Digital Marketing team at Thermo Fisher India. This team is uniquely positioned to drive digital transformation across a multitude of our businesses and drive tangible strategic outcomes in key priority areas. As a data science analyst in this team, you are going to help identify and shape our strategy on how are we evaluate our current businesses, which new areas should we start looking at and how do we achieve our broader 10 year vision - all of these augmented by the power of data and analytics.

Responsibilities

Analyze revenue/financial data; market research data to identify actionable trends.
Work with cross-functional teams like Sales, Finance and IT to understand data and analytics related requirements and define potential projects
Ensure assigned deliverables are completed end-to-end.
Conduct demos and trainings as required.
Work with sometimes ambiguous requirements across functions in matrix structure

Qualification/ Skills, Knowledge and Experience
B.E. /B.Tech or B.Com or B.Sc (in Mathematics / Physics / Chemistry) degree
Fresh graduate or ~1-2 years of experience as a business analyst Gaming, Travel and/or Ride Hailing companies.
Excellent planning and execution skills with proven ability to drive results
Effective communicator (verbal, written and presentation), with a demonstrated ability to influence through a straight-forward style of communication
Advance knowledge on Microsoft Excel
Experience in SQL
Experience in Python or R
Experience with visualization tools like Power BI or Tableau
Self-starter
At Thermo Fisher Scientific, each one of our 75,000 extraordinary minds has a unique story to tell. Join us and contribute to our singular mission—enabling our customers to make the world healthier, cleaner and safer. Apply today http://jobs.thermofisher.com

Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status."
Data Science,"Mohali, Punjab",XenonStack,None,Organic,"Job Summary
We are searching for talented engineers and science majors to join our team. We are searching for top talent that will help solve some of the most challenging problems in the IT world using data science methodologies. You will have access to the best facilities, technology and expertise within the industry and will work on challenging problems that would include looking at large volumes of data and deriving insights from them. You will be working to build algorithms to solve some of our advanced initiatives. You will also have opportunities to work on several business initiatives and be empowered to lead problem solving. This is an excellent opportunity to be in high-impact teams, where you can truly develop your skill set and knowledge and bring impact to the business.
Responsibilities
Analyzing raw data, assessing quality, cleansing, structuring for downstream processing.
Design accurate and scalable prediction algorithms.
Work within a team, collaborate and add value through participation, provide comments and suggestions, work with cross-functional teams to bring analytical prototypes to production and to achieve goals.
Derive key insights for business improvement based on unstructured data from several source
Education
Masters in Technology (M.Tech)
Deep knowledge of Statistics/predictive modeling/ Data Mining/Machine Learning/clustering and classification techniques, and algorithms.
Skills Needed
Solid programming skills with Python/C/C++/Java or other equivalent language.
Familiarity with Big Data frameworks and visualization tools like Cassandra,/Hadoop/Spark/Tableau.
Who you are
A team player. You get along well with your colleagues and are always ready to help get things done. You enjoy working on projects with multiple people and share knowledge.
Passionate about learning. You thrive on complex technical challenges and are always eager to learn the latest technologies.
Organized and detailed-oriented. You think ahead of time about how best to implement new features, and your code is clean, well-organized and properly documented.
Innovative. You are always proactively looking for opportunities to problem solve using innovative methods that impact the business.
Keywords
Artificial Intelligence
Data Science
Data Scientist
Deep Learning
Machine Leaning"
Data Scientist,"Bengaluru, Karnataka",BlueJeans,None,Organic,"If you are a data junkie who would like to wrangle through huge data sets of usage, stats, clickstreams, free text feedbacks and more to predict the user experience, adoption and retention. You like to solve complex and challenging problems and articulate the results in a lucid manner. Then we’ve got the problem for you and the data to solve it.
In your role as data scientist you will :
Select features, building and optimizing classifiers using machine learning techniques
Build statistical/machine learning models to extract insights
Create automated anomaly detection systems and constant tracking of its performance
Collaborate with subject matter experts to determine relevant data sources
Communicate the insights/recommendations to a wide spectrum of stake holder
Act as a mentor to guide/train less experienced folks
Desired Skills and experience:
B.E/Masters in Computer science/Statistics or equivalent
At least 5 years of experience in predictive modelling, strong knowledge of machine learning algorithms.
Strong in R,Python (numpy, scipy etc)
Very strong SQL and data visualization
Exposure to Big Data platforms such as Spark, Mahout, Scala, AWS machine learning is a plus
Great communications skills

Verizon recently acquired BlueJeans and plans to integrate BlueJeans employees into Verizon, including its compensation and benefits programs, in due course. This position will be part of that planned integration."
Associate - Business Intelligence - Asset Management,"Mumbai, Maharashtra","JPMorgan Chase Bank, N.A.",None,Organic,"Team Description
Business Intelligence team is part of Asset Management's Global Sales Enablement organization.
The mission of the Business Intelligence (""BI"") team is to apply creativity, rigor, and data-driven thinking to help plan and execute the business growth of J.P. Morgan Asset Management. Our work is a blend of strategy, technology, data analysis, and execution with a key focus on defining data-driven distribution and marketing strategies for J.P. Morgan Asset Management.
In this role, you will be expected to apply your marketing and data science background in order to make important contributions across a diverse array of projects. The role will require in-depth data manipulation, exploration, and analysis. We are a highly collaborative team - so you will have significant potential for learning and impact.
Functional Responsibilities:
Partnering with distribution stakeholders to identify opportunities for leveraging advanced analytics
Building analytical frameworks for marketing measurement - A/B testing, campaign ROI, cost of acquisition modeling, lifetime value, etc
In-depth data exploration and data mining to develop a deep understanding of client behavior
Contributing to and enhancing data models and feature stores
Leveraging machine learning models and techniques to target opportunities and optimize processes
Developing tools and solutions to measure model performance over time
Fostering a data-driven, innovative culture
Qualifications:
Advanced degree in Statistics, Math, Engineering or other quantitative-focused field preferred
3+ years experience with analytic techniques, statistical modeling and web analytics
Experience using computer languages (Python, Pyspark, etc.) to manipulate and analyze large datasets
Proficient in Google Analytics
Knowledge of variety of machine learning algorithms (linear regression, logistic regression, SVMs, Tree-based models, neural networks, etc.) and techniques (cross validation, feature selection approaches, hyper parameter optimization, missing data imputation etc.)
Experience using machine learning libraries in Python (Sci-kit learn, tensorflow, etc.)
Skills:
A passion for technology, financial services and asset management
A balanced approach combining judgment, analytical rigor, curiosity, open-mindedness and creativity
Ability to multi-task and manage competing priorities/workflows
Proven ability to quickly learn the business, the application and adapt to ever changing priorities
Self-motivated, team player with strong work ethic
Ability to build relationships across global teamsJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Analyst - One ERP ( m/f),"Oragadam, Chennai, Tamil Nadu",Danfoss,None,Organic,"Job ID: 13240
Job location(s): Oragadam, IN
Job Description
We are currently looking for an Analyst One ERP (m/f) with global responsibility for our location in Chennai, India.


We are looking for an Analyst with data science experience that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. In this role, you will work with business teams from Global Planning & Logistic area to implement new solutions. You will work directly with large, different data sets and analyse them using the latest modelling techniques. You must be comfortable working with a wide range of stakeholders and functional teams to drive business results with their data-based insights. As a team, we will develop and build recommendations for automation, data integration and machine learning.
Job Responsibilities
Identify use cases - work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
Processing, cleansing, and verifying the integrity of data used for analysis
Data mining using state-of-the-art methods
Selecting features, building and optimizing classifiers using machine learning techniques
Creating visualizations of complex data sets for easy of understanding by business partners
Doing ad-hoc analysis and presenting results in a clear manner
Enhancing data collection procedures to include information that is relevant for building analytic systems
Creating automated anomaly detection systems and constant tracking of its performance
Analyse, Manipulate, and Validate data using SQL, R, Python, and other analytical tools
Develop, test, and pilot your solutions
Background & Skills
Bachelors / Masters with focus on Statistics, Mathematics, Economics or Business preferred
Experience with data analytics
Experience in machine learning and neural networks
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets
Experience with data visualization tools
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Experience working with and creating data architectures
A drive to learn and master new technologies and techniques

Capabilities/Mindset
Great communication skills
Data-oriented personality
Strong problem-solving skills
Self-motivated

Optional:
Big data tools (Apache Spark, Hadoop)
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Danfoss – Engineering Tomorrow
At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways – driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.

Following our founder’s mindset ‘action speaks louder than words’, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030."
Advanced Analytics Cons 3,"Bengaluru, Karnataka",WELLS FARGO BANK,None,Organic,"About Wells Fargo

Wells Fargo & Company (NYSE: WFC) is a leading global financial services company headquartered in San Francisco (United States). Wells Fargo has offices in over 30 countries and territories. Our business outside of the U.S. mostly focuses on providing banking services for large corporate, government and financial institution clients. We have worldwide expertise and services to help our customers improve earnings, manage risk, and develop opportunities in the global marketplace. Our global reach offers many opportunities for you to develop a career with Wells Fargo. Join our diverse and inclusive team where you will feel valued and inspired to contribute your unique skills and experience. We are looking for talented people who will put our customers at the center of everything we do. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.

Market Job Description

About Enterprise Global Services
:
Enterprise Global Services (EGS) enables global talent capabilities for Wells Fargo Bank NA., by supporting over half of Wells Fargo's business lines and staff functions across Technology, Business Services, Risk Services and PAM. EGS operates in Hyderabad, Bengaluru and Chennai in India and in Manila, Philippines. Learn more about EGS at our International Careers website.

Department Overview:
Product, Analytics and Modeling (PAM) brings a team member-based approach to the international talent pool focusing on analytical requirements. PAM encompasses roles that deliver meaningful insights, analysis and reporting based on skills, experience and judgment to support the Enterprise Analytics and Data Science (EADS) organization operate successfully today, and continue on the right trajectory to operate successfully in the future.

EADS is Wells Fargo's hub for a distributed, diverse and effective Analytics function. EADS facilitates cross-Enterprise practices, enables innovation and provides foundational capabilities to advance analytic practice and its impact across the Company. The objective of EADS is to mature analytics at Wells Fargo and deliver value through strategically significant partnerships, customer insights, and community leadership:
About the Role:

Analytic Consultant/Data Scientist is a partner-facing role and is responsible for delivering high impact analytic and data science projects by using analytics, in support of operational risk initiatives across consumer lending. This role supports analytics requirements for Credit Bureau Oversight and Quality reporting along with reporting for Issues Management.
EADS is the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargo's analytic community.
We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this highly consultative and visible role, you will support development analytic projects from multiple business lines using various technology and techniques ranging from but not limited to supervised, unsupervised and semi-supervised machine learning, deep-learning, NLP, optimization algorithms in both edge nodes and in big data environments (like hortonworks, MapR, Aster etc.)



Responsibilities:
Person would be required to work individually or as part of a team on data science projects and work closely with business partners across the organization.
He/she would be developing statistical/machine learning models using various techniques (supervised, unsupervised, semi-supervised) and technologies including but not limited to SAS, R, Python, Spark, H2O, Aster etc.
Work closely with data engineers, BI and UI specialists and deliver top notch analytical solution for the bank.


Market Skills and Certifications

Essential Skills:
BS degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis
6+ years of relevant experience
Experience with supervise , unsupervised & semi supervise learning
Experience with Deep-learning, Artificial intelligence techniques
Strong programing skill
Expertise in analytic tools : R, Python, Scala, Java, SAS
Big Data skills – Aster, Hadoop, SPARK, H20 and various big data distributions like Hortonworks and MapR
NLP, Text mining, Image/Voice processing, digital analytics, deep learning, machine learning
Data Engineering
Sql ,Teradata, Hadoop, Spark
Exploratory Data analysis
Provide exploratory data analysis using Python/R/SAS / SQL
Experience with Databases like oracle , Teradata, Sql server
Advance Excel skills
Data integration and clean up data for the usage
Experience with structured data and semi-structured text or Excel files
Business Intelligence
Tableau, Power BI, Shiny, Dash, HTML5
Business Analytics
Data mining and Insights
Trend Analysis , forecasting and pattern recognition
Find opportunities in the data and able to communicate to the partners
Consult with partners to define issues/information needs
Present findings to multiple levels of management
Ensure that analyses are delivered on time, while surpassing partner expectations
Ensure partner transparency throughout the life of the project
Proactively seek opportunities to increase the value of analysis
Strong oral and written communication and consultative skills
Have a sense of humor


Desired Skills:
Strong collaboration skills
Output deployment using appropriate technologies (HTML5, Shiny, Django)
Ability to translate analytical data into useful business information
Critical thinking and strong problem solving skills
Ability to learn the business aspects quickly
Ability to multi-task and prioritize between projects
Ability to work independently and as part of a team

We Value Diversity

At Wells Fargo, we believe in diversity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national or ethnic origin, age, disability, religion, sexual orientation, gender identity or any other status protected by applicable law. We comply with all applicable laws in every jurisdiction in which we operate."
Applied Scientist II,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"PhD in Computer Science, Mathematics or related field, or equivalent experience.
3+ years of hands-on experience building ML models and deploying them to production.
A strong ability in understanding statistical models and analyze them to provide rigorous solutions for business needs.
Excellent data visualization and written communication skills to translate complex models and analysis results into simple terms.
Hands on development experience in C++, Java, or other OOP language.
Experiencing with programming in R, MATLAB, Python or similar scripting languages.
Expertise in Computer Science fundamentals in data structures, algorithm design, and complexity analysis.
Demonstrated ability to communicate well and discuss complex topics with both technical and business audiences.

The Amazon Search team creates powerful, customer-focused search and advertising solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, the Amazon Search services go to work. We design, develop, and deploy high performance, fault-tolerant distributed search systems used by millions of Amazon customers every day. Our team works to maximize the quality and effectiveness of the search experience for visitors to Amazon websites worldwide.
The Product Search organization’s mission is to help customers efficiently find anything they are looking for. This charter requires us to build solutions that go beyond lexical matching and semantically understand the intent of the customer. Helping customers succeed in their mission helps us to earn their trust and win their loyalty. This is a rare and exciting opportunity, which is at the intersection of lucrative business opportunity, innovative research and a tremendous learning opportunity. The ideal candidate will have experience building machine learning models and information retrieval systems at scale. We are seeking candidates with strong rigor in principles and practices of applied machine learning, natural language processing, statistics, or graph mining.

In this role, you will...
Develop and build ML models that are deployed to production systems.
Build data pipelines necessary to collect and curate data for training large scale machine learning models.
Propose and validate hypothesis to direct our business and product road map.
Work with engineers to build low latency and scalable ML models.
Focus on identifying and solving customer problems with simple and elegant solutions.
Take complete ownership of the problem, and collaborate/mentor with your peers to deliver the right technical solution and business outcomes.
Joining this team, you’ll experience the benefits of working in a dynamic, entrepreneurial environment, while leveraging the resources of Amazon.com (AMZN), one of the world's leading internet companies. We provide a highly customer-centric, team-oriented environment in our offices located in Bangalore, India.

Knowledge of Information Retrieval theory and practice
Strong experience with Shell and Python scripting languages
Experience with presentation layer technologies such as JavaScript
Experience with PySpark, Hive and Map/Reduce technologies
Experience with SQL language
Able to thrive in a small team environment.
Strong sense of ownership with an entrepreneurial ‘think big’ mind-set"
Data Science,"Bengaluru, Karnataka",AdmyBrand,None,Organic,"Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Creating Heat Maps, should be able to develop custom codes over Google Maps API
Deduce a unique and more efficient TRP (Television Rating Point) system and similar rating system for other advertising
mediums like Radio and Print

Location: India (Bengaluru)"
Data Scientist,"Mumbai, Maharashtra",Boston Ivy Healthcare Solutions Pvt Ltd (Medikabaz...,None,Organic,"Must be able to handle periods of high stress.
 Strong analytical and problem solving skills.
 Excellent interpersonal and communication skills to effectively handle any business need.
 Knowledgeable in software development processes & lifecycle management.
 Demonstrated experience in effectively presenting technical information to non-technical audience
 5-10 years of experience in applying concepts in Data Science, Machine Learning, Algorithm development, Advanced Computing or Statistical Modeling to solve real-world problems
Work on complex, cross-functional analytical and research-oriented projects using advanced computational, machine learning and deep learning algorithms
 Work on a particular Data set or a Problem Statement
 Use relevant knowledge of machine learning and statistics to help build scalable Machine learning models and Processing Pipelines.
 Practical experience in at least one of the following programming languages: R or Python. Strong modelling skills and ability to build practical models using advanced algorithms such as Random Forests, SVM, Neural Networks. Familiarity with algorithms in recommendation systems, chatbots or structuring NLP centric processing pipeline as well as Computer Vison. Knowledge of big data frame-works such as Hadoop/Spark is a bonus. Familiar with implementing organizational processes using tools like Asana/Git/Docs/Slack/etc.
Job Types: Full-time, Volunteer
Experience:
total work: 7 years (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Bengaluru, Karnataka",Alphonso,None,Organic,"Data Scientist
Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.
Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.
We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.
Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data
Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus"
Data Scientist,"Chennai, Tamil Nadu",Jidoka Technologies,None,Organic,"We are looking for people with the right blend of technology skills, business knowledge and a passion for revolutionizing machine vision.
Explore and prototype solutions or products at intersection of computer vision, image processing, applied machine learning by leverage existing or new vision or machine learning algorithms.
Solid understanding on linear algebra, image processing, computer vision and machine learning knowledge.
Develop and prototype computer vision algorithms in Python or C++
Familiar with one or two deep learning frameworks: Tensorflow, Pytorch/Caffe2, Keras etc.
Hands on experience in one or more of the following areas: real-time object detection/segmentation/recognition/tracking, visual scene understanding, 3d vision, augmented reality
Minimum Qualifications
Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field OR Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field
Additional Preferred Qualifications
Experience with C++/CUDA/TensorRT and model compression is a plus

Send in your resume to Careers@JidokaTechnologies.com"
DATA SCIENTIST,"Bengaluru, Karnataka",Melstar Information Technologies Limited,None,Organic,"DATA SCIENTIST (Analytics & Technology)
Experience : 7+ yrs.
Location : Gurgaon & Bangalore
Qualification :Masters (preferred) or Bachelors Honors in Statistics, Economics, Computer Science, Engineering, Mathematics preferred
Technical expertise: Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation.
Curiosity: a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Problem solver: Ability to work with adhoc/ unstructured data and arrive at a potential business proposition and hence, be able to define and design customized business solution.
Storytelling: the ability to use data to tell a business-outcome impacting story and to be able to communicate it effectively.
Cleverness: the ability to look at a problem in different, creative ways.
Experienced in mathematical modeling and programming, statistical analysis, forecasting/predictive modeling, simulations, optimization, visualizations, machine learning, data mining, etc.
Proficiency in one or more statistical programming language, like R, SAS, WEKA or Python, and a database querying language like SQL.
Demonstrated ability of thought leadership and to work with ambiguous problem definitions, recognize dependencies and deliver impactful solutions through logical problem solving and technical ideations.
Ability to learn new analytical methods, technologies and apply in practical business problems.
Strong communication and interpersonal skills: Ability to communicate clearly and confidently with clients/stakeholders. Ability to tell a clear, concise, actionable story with data. Ability to work with multiple teams with different backgrounds.
Attitude to work in a fast paced and continuously changing environment.
Understanding of Big Data Technologies like Map Reduce and Hadoop.
Proficiency with any general purpose programming language Java/Python/C/C++."
ML (Machine Learning) Engineer,"Bengaluru, Karnataka",Danaher Digital,None,Organic,"Machine Learning Engineer

Danaher is a global science & technology innovator committed to helping our customers solve complex challenges and improve quality of life worldwide. Our world class brands are leaders in some of the most demanding and attractive industries, including life sciences, medical diagnostics, dental, environmental and applied solutions. Our globally diverse team of 71,000 associates is united by a common culture and operating system, the Danaher Business System, which serves as our competitive advantage. We generated $19.9B in revenue last year. We are ranked #162 on the Fortune 500 and our stock has outperformed the S&P 500 by more than 5,200% over 25 years.

At Danaher, you can build a career in a way no other company can duplicate. Our brands allow us to offer dynamic careers across multiple industries. We’re innovative, fast-paced, results-oriented, and we win. We need talented people to keep winning. Here you’ll learn how DBS is used to shape strategy, focus execution, align our people, and create value for customers and shareholders. Come join our winning team.

Danaher is committed to competitive compensation that typically has key components including base salary, variable annual incentive compensation based on personal and company performance, and long-term incentive.

Danaher Digital

Danaher Digital is our digital innovation, incubation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies to develop and commercialize emerging and disruptive digital technologies such as AI, Machine Learning (ML), Big Data, IoT, Augmented Reality (AR), Cloud (SaaS/PaaS) and other Digital frontiers. If you are driven to forge new disruptive and transformative digital apps, platforms and services by working with such cool and emerging technologies, you belong in Danaher Digital.

As a member of Danaher Digital, you will help identify new product ideas and operating models, and then design, develop and deliver them. Working together with our operating companies, you will also help foster and support an entrepreneurial culture that will push Danaher to launch new software and data products better, and faster.

To learn more about Danaher Digital and our team, please visit www.danaherdigital.com or visit www.linkedin.com/company/danaher-digital/about . Position Description
This position reports to Head of Data & Analytics and is responsible to help the Danaher Digital data science team develop, design and integrate mathematical models into production. You will be working cross-functionally with the Data Scientists, Software application developers and business groups and lead the development of innovative ML models for Danaher’s big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams. Responsibilities
Primarily responsible for productionizing pipelines/models and integrating them against our back-end services
Drive the system architecture and design decisions for Danaher Digital’s machine learning infrastructure, for both cloud and on-premise environments
Design, develop, determine test strategy, test, and maintain key software improvements related to machine learning capabilities at Danaher Digital.
Enjoy working in a collaborative team with data scientists, software leads, Product Owners/Product Managers from other business units and/or customers, to develop high-value solutions for our most complex data-based challenges.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
8+ years of commercial or open source product development experience, preferably in large scale cloud computing and/or distributed systems environments.
Knowledge in python and packages for data analysis (scikit-learn, scipy, numpy, pandas, matplotlib).
Knowledge of Deep Learning frameworks: Keras, Tensorflow, PyTorch, etc
5+ years of programming in large scale production systems, in languages such as Python, Java, Scala or C++.
Experience with one or more Container-ecosystem (Docker, Kubernetes)
Experience in building orchestration pipeline to convert plain python models into a deployable API/RESTful endpoint.
Good communication skills and team player attitude.
Bachelors in Computer Science or related fields"
Business Data Analyst,"Chennai, Tamil Nadu",PipeCandy,None,Organic,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.
About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Business analyst who will work on custom data analysis and analytical projects for large clients. If you love playing with data and math, have an eye for detail and a strong client delivery mindset, we’d love to hear from you.
The business analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data team. This position requires experience in data analysis, the ability to understand business requirements, define analytical requirements, work with teams in getting the plans executed, and managing project delivery and client communications.
Key Responsibilities:
Works to develop and validate data analysis as per business and client requirements
Gather, evaluate and document requirements, develop an analysis plan and project plan to deliver as per requirements
Understand data sources to determine the correct source(s) and logic to ensure accurate, efficient and timely deliverable
Build, run and automate data queries, analysis and reports
Ability to effectively visualize data and communicate results of data analysis & analytical models
Collaborate with data and tech teams to ensure data/ analysis tasks are allocated and executed as per plan
Understand and have a working knowledge of customer/ transaction level data preferably in retail environment
Skills Required:
Experience in managing on data analysis delivery for client projects. Experience in managing a team is a plus
Data exploration, analysis, data interpretation, visualization, skills. Mathematical/ statistical modeling skills a plus
Strong communication and project management skills
Analyze & interpret data and communicate results to clients effectively
Analytical/ Technologies skills
Strong database/ SQL skills for data extracting, data prep and validation
Experience in Python/ R. Good skills in advanced Excel/ spreadsheets
Experience in scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Strong mathematical, analytical and problem solving skills
Qualifications & Competencies Required:
Degree in a quantitative field (Engineering, Math, Statistics, Economics, Physics)
3-4 years of experience in data analysis, with excellent ability to combine, cleanse and harmonize data for descriptive and predictive analysis
Desired:
Ability to work with business and technology teams to deliver data acquisition projects
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills
Perks
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course"
Data Science Engineer,"Bengaluru, Karnataka",Bloom Consulting Services,None,Organic,"Data Science Engineer

Roles and Responsibilities:
Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto
Exploring and visualizing data to drive insights
Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their Tweets and their interests.
Designing and implementing metrics that help teams focus on what to optimize for
Transforming complicated problems into simpler, tractable ones

Requirements:
Experience with one or more object oriented languages like Scala, Java
Experience with scripting languages like Python or Ruby etc.
Experience with statistical programming environments like R or Matlab
Experience with algorithms like pattern matching (fuzzy matching algorithm), pattern generation, distance matching algorithms
Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects

What You Need for this Position
You should have knowledge of:
Hadoop
SQL
Pig
Scalding
Hive
Presto
Python
Ruby
Scala
Java
Aditional
No. of Positions
Education level
Career level
Experienced"
Data warehouse Developer,"Bengaluru, Karnataka",Rakuten,None,Organic,"Responsibilities:
Develop, enhance and maintain data pipeline applications and data models on a rotational on-call basis in a 24x7x365 environment.
Trouble-shoot the causes of adhoc daily production failures and provide effective and documented solutions.
Continuous improvement initiatives in data ingestion performance, ingestion models, data integrity and data availability.
Work with the business in analyzing and documenting new functionality requests and managing the implementation of those within an Agile ownership model.


Minimum Qualifications:
B.S. in Computer Science or in related fields.
More than 3 years’ experience with BI data driven development.
Expert SQL capability in querying Big Data/ large data sets (Teradata, Hadoop, etc.) to extract BI- insights.
Programming languages such as Python/Scala/PLSQL/Java.
Development and operation of data pipeline leveraging big data technologies such as Spark, Map Reduce, Hive, Kafka, Sqoop, NoSQL Databases as well as traditional DB and file based data integration solutions.
Database development (eg TeraData, Oracle, MySQL, SQLServer, DB2..)
Shell-scripting languages such as Bash.
Formal analysis and documentation of BI solutions.
Distributed version control system such as Git.
Initiative and the ability to work independently and in a team. We are an Agile environment.

Preferred Qualifications:
Application development using workflow engines such as Airflow, Oozie, Rundeck.
BI reporting tools, including administration, modeling, and report/dashboard development.
BI Modelling of data marts using ER hybrid, Kimball, Data Vault methodologies.
Experience in ELK Stack.
Experience in AtScale and Presto.
Operational experience in developing and supporting high availability applications / systems.
Capability to self-manage and also manage small projects."
Analyst (Data Science),"Bengaluru, Karnataka",Bloom Consulting Services,None,Organic,"Role: Analyst (Data Science)
Location: Bellandur, Bangalore

Key responsibilities
Understand, develop and take ownership of sophisticated statistical models that describe and influence our core KPIs, using Python, the Python data science stack and SQL
Generate insight for internal stakeholders and for CRM Insight Team, drive performance and set direction for the development of statistical models
Be proactive and flexible in order to get the job done; provide thought leadership in statistical techniques; and work cooperatively with colleagues and stakeholders

Key skills required
Curiosity, Skepticism, Open Minded, quality - oriented, self - driven, passionate in Data Science
Strong ownership of projects / domain / knowledge ; highly committed and professional
Master’s Degree in Statistics / Mathematics / Physics / Machine Learning / Engineering and achieved outstanding academic results
3 yrs to 5 yrs years’ practical experience as a statistician in a commercial environment
Strong experience using Python -(Mandatory)data science stack (Pandas, Sci-kit learn, Statsmodels, etc.) , working with a range of statistical modeling techniques for designing, developing and testing algorithms and hypotheses
Excellent SQL / Database experience - Mandatory
Ability to write robust code that can be automated and deployed at scale
Familiarity with software engineering techniques and tools such as version control, testing, logging, GitHub
Familiarity with Agile development
Excellent Communication - Mandatory
What You Need for this Position
You should have knowledge of:
Core KPIs
using Python
the Python data science stack
SQL.
Aditional
No. of Positions
Education level
Career level
Experienced"
Data Scientist,"Indore, Madhya Pradesh",GenieTalk,None,Organic,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore | Openings"
Python Developer,"Indian Institute Of Management, Gujarat",Senseque,None,Organic,"No. of opening - 1
0-4 years of experience
Excellent understanding of data engineering and exposure to data science and analytics Enthusiasm to work with Product and Operations to truly understand the user/business need in order to develop disruptive products.
Strong understanding of Math, Statistics and the theoretical foundations of Statistical & Machine Learning. Post Graduate Degree in Applied Mathematics and/ or Statistics is preferred.
Strong understanding of advanced data mining techniques, curating, processing and transforming data to produce sound datasets.
Strong hands on experience in application of NLP techniques and building successful ML models for production application
Experience in Supervised and Unsupervised Machine Learning including Classification, Forecasting, Anomaly detection, Pattern detection, Text Mining, using variety of techniques such as Decision trees, Time Series Analysis, Bagging and Boosting algorithms, Neural Networks, Deep Learning.
Very good coding skills in any of these languages: R, Python, C and Machine Learning libraries like scipy, numpy, pyspark, tensorflow etc
Experience in SQL and relational databases and Big Data technologies e.g. Spark/ Hadoop.
Good understanding of programming best practices and building for re-use.
Prior publication record at AI/ ML conferences would be a plus.
Broad understanding of Machine Learning techniques

Send Email at careers@senseque.com With Subject Code MLAI_00L3"
Data Scientist Bangalore,"Bengaluru, Karnataka",Equinox e Services,None,Organic,"Data Scientist
Exp: 3+ Years
We are hiring for the role of Data Scientist for a Sweden based company for their offices in Bangalore.
Bachelor in Engineering, Data Science, Maths, Stats or Computer Science
2+ years of related work experience in Data science field
Fluency in SQL for data access, manipulation, and validation
Proficiency in either R, Python or SAS for data analysis
Passion for data visualization and information design
Capable of clearly communicating complex analyses to a non-technical audience, including extensive experience presenting to leadership groups
Ability to initiate, refine, and complete projects with minimal guidance
Mail your resume to team@equinoxes.in"
Python & Data Analytics Engineer,"Chennai, Tamil Nadu",Stratmark consulting Pvt ltd,"₹3,00,000 - ₹7,00,000 a year",Organic,"We are looking for proficient Python Developers with knowledge in Analytics and scripting. Additional skills required are API, AI & ML. Candidates with the background of B.E / B.Tech / M.Sc. / M.E / M.Tech /MCA in Computer Science or Applications will be preferred
Required Skills:
Proficient in Core Python and its libraries and Modeling - regression, classification, linear etc.
Proficient in building highly scalable and optimized engines for Data Analytics.
Good knowledge in JavaScript, CSS, HTML5, XML and Object Relational Mappers (ORM).S
Strongexposure in RDBMS (MySQL, MongoDB, Document DB, MSSQL) and Servers (Apache, Ngnix)
Good in exposing and consuming APIs, RESTAPI, Web ServicesE
Experiencein Visualization tools such as Power BI, Tableaun
Knowledgein AI and ML, Deep Learning (Audio/Video/NLP, Neural Network) will be an added advantage.
Knowledgeof Multi-process architecture (MVC, MVT) and Multiple Delivery platforms.
Goodexposure in Azure DevOps and Version Controls including Git.
Verygood in Analytical, Design, Communication and presentation skills.
Job Type: Full-time
Salary: ₹300,000.00 - ₹700,000.00 per year
Experience:
Software Development: 3 years (Preferred)
Rest API: 2 years (Preferred)
Python: 2 years (Preferred)
Java Script: 2 years (Preferred)
AI & ML: 2 years (Preferred)"
Data Scientist,"Bengaluru, Karnataka",HR Devi and Associates,"₹8,00,000 - ₹11,00,000 a year",Organic,"Data Scientist
Bangalore


1.Build program expertise by improving data analytics and establishing the framework for the company's future in data science, machine learning, AI and predictive analytics.
2.Experience in statistical modeling techniques such as linear regression, logistic regression, and GLM.
3.Experience and knowledge with one or more of modern machine learning and statistical modeling techniques, e.g. GLM, GAM, decision trees, random forest, SVM, deep learning, GBM, clustering, Bayesian averaging
4.Experience using predictive analytics, machine learning, and artificial intelligence practices.
Knowledge of dashboarding to create data visualizations and Business Intelligence software.
5.Strong data mining skills with the ability to interpret data for the purposes of drawing business inferences.
6.Expertise in one or more modeling/machine learning languages such as R, Python, etc.
7.Expertise in SQL and databases.
8.Education of colleagues, business partners, and prospects in various areas related to the discipline. Strong ability to communicate technical data and concepts to audiences with varying levels of understanding.
9.Proficiency in Microsoft Office (Excel, Word, PowerPoint).
Experience
5 - 7 Years

Salary
8 Lac To 11 Lac P.A.

Industry
IT Software - Others

Qualification
B.Sc, B.Tech/B.E

Key Skills
Data scientist DATA ANALYTICS


About Company
Company Name
HRDevi Talent Acquisition


About Company
An advanced Big Data Platform Management software product to help organizations effectively deploy Big Data features in business processes and decision making. In addition to creating a ‘Centralized Data Platform’ it also provides a centralized framework to enable business, analytics, governance, capabilities, and technology to operate effectively in a shared environment.

Email ID
swati5547@gmail.com"
Deep Learning Intern WFH,Remote,Clarion Analytics LLP,None,Organic,"CLARION ANALYTICS is looking for Deep Learning Interns for its IVA team to develop and commercialise Artificial Intelligence solutions for the markets.
Role
Construct ,curate and work on problem specific datasets.
Study and develop state of the art techniques in deep learning.
Analyze and improve performance of GPU implementations.
Your Background
You are pursuing a PhD or Masters or Bachelor or equivalent in Computer Science, Artificial Intelligence, or Applied Math.
Solid understanding for deep learning and a strong algorithmic background
Excellent programming, debugging, performance analysis and test design skills.
Excellent understanding of deploying data pipelines for Computer Vision projects.
Excellent understanding of NVIDIA Jetson series and deploying Deep learning models on the edge.
Good to Have
Deep Learning experience.
Experience with DL Frameworks (e.g. TensorFlow, PyTorch, NVIDIA DeepStream).
Excellent C/C++ and Python programming skills.
GPU programming (CUDA or OpenCL).
Experience doing performance analysis and tuning.
Job Types: Full-time, Internship
Experience:
Raspbery, NVIDIA Jetson: 1 year (Preferred)
Deep Machine Learning: 1 year (Preferred)
TensorFlow, PyTorch , Caffe or other DCNN Framework: 1 year (Preferred)
NVIDIA CUDA , C/C++: 1 year (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Data Analytics part time job/internship at Multiple location...,"Chennai, Tamil Nadu",Enerjazz,"₹5,000 - ₹10,000 a month",Organic,"About the company:
We are a green energy startup based in Amsterdam funded by the EU. Our founder is from IIT and we operate from Delhi NCR in India.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Build and optimize databases for our battery testing system 2. Analyze and correlate the test data 3. Work on coding IoT for our product
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 11th Aug'20 and 15th Sep'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Must be a graduate student pursuing engineering Must have a background in maths, physics or a related field Must have excellent quantitative and analytical skills Must have advanced Excel skills Must be proficient with other Microsoft Office applications
Number of internships/jobs available: 1
Categories: Analytics,Data Science"
Machine Learning Engineer,"Bengaluru, Karnataka",UPL ltd,None,Organic,"About us

nurture.farm aspires to bring technology, digitization and best scientific practices to all farmers, big and small. We believe in bringing the best talent together, to create a team passionate for transforming the farming ecosystem. Our software engineers develop technologies that strengthen the hands of millions of farmers, making farming more profitable and sustainable. Our products need to handle information at a massive scale. We are looking for engineers who bring expertise in distributed and scalable computing, easy-to-use consumer products, UI design and mobile, machine learning, data science, networking, storage, security and much more. We’re a team that values versatility, self-motivated drive and a passion to create an impact on millions of farmers.

We’re looking for ..

builders and tinkerers, who derive pleasure from creating something from scratch,
dreamers, who are passionate about creating something that touches millions of people, and transforms lives,
sculptors, who take pride in simplicity of design, and have the keenest eye for detail when it comes to quality,
learners, who look forward to continuing to grow everyday.

If that’s you, we should chat.

Machine Learning Engineer

Minimum qualifications

BTech Computer Science, or similar field of study, or equivalent practical experience.
Software development experience in one or more general purpose programming languages.
Experience working with the following: Machine Learning Frameworks (Tensorflow, PyTorch, etc), Data Science toolkits
Conversant with Model Training, Feature Engineering, setting up training pipelines as well as bringing models into production
Familiarity with real time streaming, distributed computing
Working proficiency and communication skills in verbal and written English.

Preferred qualifications

Master’s degree, further education or experience in AI/ML, computer science or other technical related field.
Understanding of agriTech domain and application of technology in farming
Interest and ability to learn other coding languages as needed.

Responsibilities

Understand the agriculture and agtech domain and come up with concrete problem definitions based on observations from the field.
Design AI solutions to help farming, working with GIS and Remote Sensing data, and combining it with ground truth collected from the farms.
Design, develop, test, deploy, maintain and improve ML models.
Manage individual project priorities, deadlines and deliverables.
Enthusiastic to take on problems across the full-stack."
Data Scientist,"Bengaluru, Karnataka",BlueJeans,None,Organic,"If you are a data junkie who would like to wrangle through huge data sets of usage, stats, clickstreams, free text feedbacks and more to predict the user experience, adoption and retention. You like to solve complex and challenging problems and articulate the results in a lucid manner. Then we’ve got the problem for you and the data to solve it.
In your role as data scientist you will :
Select features, building and optimizing classifiers using machine learning techniques
Build statistical/machine learning models to extract insights
Create automated anomaly detection systems and constant tracking of its performance
Collaborate with subject matter experts to determine relevant data sources
Communicate the insights/recommendations to a wide spectrum of stake holder
Act as a mentor to guide/train less experienced folks
Desired Skills and experience:
B.E/Masters in Computer science/Statistics or equivalent
At least 5 years of experience in predictive modelling, strong knowledge of machine learning algorithms.
Strong in R,Python (numpy, scipy etc)
Very strong SQL and data visualization
Exposure to Big Data platforms such as Spark, Mahout, Scala, AWS machine learning is a plus
Great communications skills

Verizon recently acquired BlueJeans and plans to integrate BlueJeans employees into Verizon, including its compensation and benefits programs, in due course. This position will be part of that planned integration."
Data Scientist,"New Delhi, Delhi",Sentieo,None,Organic,"Sentieo is powering the future of financial and corporate research in a $30B market. Our vision is to create a world where competitive organizations have the insights they need to win. Built by former hedge fund analysts, we empower competitive investors and corporations to rapidly discover insights so they can make smarter investments and execute winning strategies. Supporting a global customer base of over 900 clients, we are excited to propel Sentieo into the next phase of our company’s global growth - from advanced, unprecedented product development to accelerated team scaling and expansion. Join our team as we reimagine the future of fintech.

We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small(but growing team) where you will have a major voice in deciding which projects to undertake. We'relooking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.

What you'll do:
Selecting and engineering features to build and based on mining of our large text and
financials database.
Prototyping/Testing algorithms to help inform us what to build.
Training and tuning a variety of machine learning models.
Data mining using NLP & state-of-the-art methods.
Enhancing data collection procedures to include information that is relevant for building analytic systems.

What you'll bring:
Knowledge and hands-on working experience with ML techniques and tools.
Strong understanding of basic statistics concepts including population, confidence intervals,correlation, significance,probability,distributions, hypothesis testing, etc.
Strong grounded concepts and application knowledge of ML techniques including
linear/logistic regression,decision trees,classification,clustering,ensembles,text mining to build models.
Hands-on experience with Python and familiarity with machine learning frameworks.
Comfortable with data visualization tools like pandas,seaborn and matplotlib.
Ability to work independently and collaboratively within a team.
Life at Sentieo:
Join a fun & tight-knit team that values transparency and is serious about building and maintaining a great culture.
Comprehensive health benefits.
Flexible vacation & sick policy.
Daily Breakfast and unlimited snack food.
Fun team outings (offsites, happy hours, etc.).

EEO

Our company values diversity and believes diverse teams make innovation possible. We work on complex, difficult problems with no linear or clear solutions. We believe that a diverse team can bring different perspectives and approaches, and whose experiences reflect the full set of clients we seek to serve. As such, Sentieo is committed to a diverse representation among our employees."
Data Scientist - C++ Programming,"Bengaluru, Karnataka",Eminence core solutions LLP,None,Organic,"Experience in C++ programming, C, Matlab, Python.
Must have Knowledge of NLP,CNN, RNN, LSTM.
Candidate with a Masterâ€™s Degree in Computer Science (specifically in Data Science, Machine Learning).

0.00-2.00 Years

Bachelor of Science (B.Sc), Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A), Bachelor Of Computer Application (B.C.A)"
Data Scientist,"Mumbai, Maharashtra",XPO Logistics,None,Organic,"Logistics done differently.
At XPO Logistics, we’re constantly looking for ways to improve, enhance and adapt in an ever-changing marketplace. The selected candidate will possess a combination of data science skills including data wrangling, advanced programming and statistical analysis (machine learning and data mining). Further, this individual will be able to take complex data, analyze it, draw meaningful conclusions and communicate findings in a manner that can be easily understood by a wide variety of audiences

What you’ll do on a typical day:
Strong understanding of Warehouse concepts, Labor planning, Demand forecasting and Industrial Engineering
Demonstrated ability to provide guidance and development to a group of analyst and engineers
Strong analytical skills with the ability to collect, organize, analyze and disseminate information with attention to detail and accuracy
Demonstrated experience with database design, data models and integration/extraction technologies and techniques
Experience with visualization tools (Power BI, Tableau, and Oracle’s Business Intelligence preferred)
Expertise in programming for data wrangling and statistics (R, Python)
Strong knowledge of statistics and experience using statistical modeling (logistic regression, SVMs, etc.) to solve business specific problems
Experience with text analytics (e.g. semantic analysis) is a plus

It’d be great if you also have: Primary Skills (Must Have):
Programming: Python, R, CPLEX, SQL, VBA
Visualization: Power BI, Tableau, Oracles Business
Statistical modeling techniques: Linear/logistic regression (including advanced predictor selection techniques), classification (decision trees, random forests), Support Vector Machines (SVMs), neural networks, etc.
Algorithm Development: Machine learning, Deep learning, and advanced Algorithmic solution development

Be part of something big.

XPO is a leading provider of cutting-edge supply chain solutions to the most successful companies in the world. We help our customers manage their goods most efficiently using our technology and services. Our greatest strength is our global team – energetic, innovative people of all experience levels and talents who make XPO a great place to work.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed."
Python and DAta SCIENCE Developer,"Mohali, Punjab",A2IT,None,Organic,"A2IT is a leading software development company in Mohali Chandigarh with expertise in both Cloud-based Applications and Web applications. Coding experience in Python, should be able to produce high quality code. worked on requests, pillow, scrapy, nump"
Research Data Scientist,"Bengaluru, Karnataka",Analytics Quotient,None,Organic,"KEY RESPONSIBILITIES
Contribute to the strategic development of AQ analytics and create blueprints.
Design and deliver innovative, state-of-the-art machine learning products and platforms in-line with AQ’s go-to-market strategy.
Research new or adapt existing machine learning approaches to provide decision support to some of the leading marketers in the world.
Be involved across all the different stages: from data discovery/generation and feature engineering to model building and prototype design.
Partner with various stakeholders (within AQ as well as the larger Kantar organization) to innovatively answer key business questions.
Empower the growing AQ community to generate value from existing data assets.
Frame optimal analytical solutions to business problems by leveraging the latest developments in Machine Learning.
Be a thought-leader, keeping up with the academic and industry trends.
ESSENTIAL SKILLS & QUALITIES
Excellent theoretical understanding of machine learning concepts and practice.
Experience in various statistical and machine learning models.
Strong expertise in one of the following - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Networks, Non-parametric Methods, Timeseries Models, Stochastic/ Markov Models, NLP etc.
Proficiency in statistical and other tools/languages – preferably R/ Python.
Knowledge of numerical optimisation methods.
Knowledge of NLP and related solutions.
QUALIFICATIONS
Graduate degree in Applied Statistics, Mathematics, or Computer Science from a premier institute.
4 years of experience building cutting edge analytic solutions from scratch.
SALARY & OTHER DETAILS
Salary including benefits will be based on prior experience & qualifications and will match industry standards.

To apply, please write to careers@aqinsights.com, stating the job ID you are applying for along with your resume."
Data Engineer,"New Delhi, Delhi",Terra Economics & Analytics Lab (TEAL),None,Organic,"As a Data Engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.
Your day-to-day will include either all or some of the following:
Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure
We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed
Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture
To explore our culture and the values we embody click here
Testimonials
Testimonial
I completed a 3-month internship at TEAL, primarily working on research and outreach activities for the company. During my time at TEAL, I was able to hone my writing skills under the guidance of TEAL's co-founder and CEO, Kshitij Batra. I was also given the opportunity to learn to work on different applications and test the company's flagship platform. The team members are friendly and extremely intelligent. In addition to this, everyone is very hardworking and ever-ready to do any sort of grunt work to meet the company goals, regardless of their position in the firm. Working in such a friendly and motivating environment was an amazing experience for me!
Delvin Chacko, Research Intern
My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern"
Data Scientist (Machine Learning)/Artificial Intelligence,"Lucknow, Uttar Pradesh",MNL GLUCK SERVICES PVT. LTD,"₹30,000 - ₹60,000 a month",Organic,"This is an individual contributor role in areas of AI (ML, DL and NLP). This is a hands-on experience role for developing large scale B2C applications.
You will be responsible for:
- Developing large scale B2C systems/modules
- Developing prototype for various new business use cases
- Taking end-to-end ownership of business use cases – Define, POC, Develop, Deploy and Maintain
- Building Machine learning models for Predictions, Image processing, Natural Language Processing and other related areas.
- Building Large scale system for Video, Audio, Image and Text analysis AI system
- Implement and experiment with different features and architectures for Deep-Learning models for NLP
Minimum Skills Required:
- B.E, B.Tech, M.Tech in Computer Science, EC, Mech, IT or equivalent work experience
- 3+ years of data science / mining experience;
- Knowledgeable in one or more of the following : Machine Learning / Information Retrieval / Deep Learning / NLP
- Excellent knowledge of at least two coding languages like Python, Java, Scala, R
- Language, SQL, ETL Tools, Perl and Pig;
- Should have worked on different tools like Java, SQL, Python, etc.;
- Good experience with SQL, Linux shell scripts, Perl, and AWK;
- Domain knowledge in at least two industries
- Overall knowledge of Business Intelligence; in particular, data modeling, ETL, and reporting tools;
- Extensive hands on experience working with very large data sets, including statistical analyses, data visualisation, data mining, and data cleansing/transformation;
Under-the-hood knowledge of many of these machine learning concepts:
- Supervised/unsupervised learning, loss functions, regularisation, feature selection, regression/ classification,
- Cross-validation, bagging, kernel methods, sampling, probability distributions;
- Experience prototyping and developing data mining solutions using statistical software packages (R, H2O);
- Excellent verbal and written communication;
- Good analytical and interpersonal skills;
- Strong ability to communicate deep analytical results in forms that resonate with scientific and/or business collaborators, highlighting actionable insights;
Job Type: Full-time
Salary: ₹30,000.00 - ₹60,000.00 per month"
Python for Data Science-Developer,"Pune, Maharashtra",Wipro LTD,None,Organic,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.
Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com"
Data Scientist,"Pune, Maharashtra",Pivotchain Solution Technologies,None,Organic,"Requirements
BS/MS degree in Computer science, Maths
You are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, Hive
Experienced with data visualisation tools, such as Tableau, D3.js, GGplot, etc
Past experience with Deep Learning/NLP would be an advantage (although not necessary)
Good Communication Skills
Team Player
What We Expect.?
You take pride in your knowledge of design patterns, algorithms and data structures
You are comfortable processing, cleansing, and verifying the integrity of data used for analysis
You understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etc
You understand feature selection, model performance metrics, building and optimizing machine learning models
You are good at doing ad-hoc analysis and presenting results in a clear manner
You are good at creating automated anomaly detection systems and constant performance tracking
You can code comfortably in R & Python (NumPy, sklearn, xgboost)"
Machine Learning Engineer/Data Scientist,"Bengaluru, Karnataka",Autodesk,None,Organic,"Job Requisition ID #
20WD40887
Job Title
Machine Learning Engineer/Data Scientist
Job Description
Autodesk is seeking a Machine Learning Engineer/Data Scientist to join our Sales Data Science team. We build innovative data products and machine learning solutions for Autodesk's sales teams. In this critical role, you will work alongside product development, product managers, and data engineers to tackle fundamental data science models in our Asia-Pacific (APAC) sales region.
Data, automation and advanced analytics technologies are drastically transforming our sales team in APAC and this person will be the data scientist in charge of overseeing our data science practice in Singapore, India, China, Korea, Australia, and New Zealand. As the Data Scientist for APAC, your primary responsibility will be to empower our sales teams with machine learning models and data analytics to make them more productive and better equipped to be customer-centric. You will collaborate with our Data Scientists in Barcelona and the US to build major data science products.

The ideal candidate is a strong communicator and has experience as a Data Analyst or Data Engineer who has strong Data Science leanings, and has built out multiple analytic models and machine learning algorithms before.

You will be in charge of establishing and maintaining machine learning deployment pipelines, including their associated life-cycle management systems and practices, in coordination with their architecture peers and communities of practice throughout the company

Your responsibilities will be:

Designing and implementing Machine Learning models and algorithms that enable account selection, customer targeting, and process improvements for the sales teams in APAC.
Develop and maintain model deployment pipelines for many types of machine learning including supervised and unsupervised learning as well as CNNs, RNNs or other deep learning algorithms
Working closely with data scientists, domain experts and sales team, both to understand model performance management requirements and design suitable inferencing instrumentation systems and practices that meet them
Designing and implementing outbound data engineering pipelines that serve curated datasets to business intelligence and reporting
Designing integration solutions including applications as needed to deliver inferencing outcomes or curated data sets for consumption and action
Ensuring your model deployment, outbound data engineering and integration pipelines are architecturally and operationally integrated with inbound ingestion and contextualization pipelines designed by your peer domain architects
Delivering and presenting results to sales leaders regarding their business, forecast, pipeline, and potential customers.

Education & Experience:
Very strong communicator
Advanced degrees in computer science and data science strongly preferred, though an equivalent level engineering, data science or mathematics degree, a technical undergraduate degree and relevant experience will also be considered
5+ plus years of relevant work experience
3+ years of experience working with data scientists in a data engineering or production machine learning inferencing capacity, working with various types of supervised and unsupervised learning algorithms for classification, recommendation, anomaly detection, clustering and segmentation, as well as CNNs, RNNs or other deep learning algorithms
5+ years of full-stack experience developing large scale distributed systems and multi-tier applications
5+ years of programming proficiency in, at least, one modern JVM language (e.g. Java, Kotlin, Scala) and at least one other high-level programming language such as Python
2+ years of production DevOps experience
3+ years of programming on the Apache Spark platform, leveraging both low level RDD and MLlib APIs and the higher-level APIs (SparkContext, DataFrames, DataSets, GraphFrames, SparkSQL, SparkML).
Demonstrated deep understanding of Spark core architecture including physical plans, DAGs, UDFs, job management and resource management
At least 1 year of implementation experience with Apache Airflow, and a demonstrated expert level understanding of both segmented and unsegmented Directed Acyclic Graphs and their operationalization
Experience working with Neo4J and a demonstrated ability to lead architecture efforts for its implementation
Strong technical collaboration and communication skills

Additional Qualifications:
Passion for sales and customer segmentation
Proficiency with functional programming methods and their appropriate use in distributed systems
Proficiency with AWS foundational compute services, including S3 and EC2, ECS and EKS, IAM and CloudWatch
Proficiency with Sagemaker, Kubernetes, and Docker

Preferred Qualifications
Experience with data science toolkits like: R, Pandas, Jupyter, scikit, TensorFlow, etc.
Experience with Sagemaker and data pipelines in AWS
Familiarity with statistics concepts and analysis, e.g. hypothesis testing, regression, etc.
Experience building dashboards in platform: Power BI, Tableau, Qlik, Looker, etc.
Salesforce experience is a plus
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers ."
Data Scientist,"Bengaluru, Karnataka",HR Devi and Associates,"₹8,00,000 - ₹11,00,000 a year",Organic,"Data Scientist
Bangalore


1.Build program expertise by improving data analytics and establishing the framework for the company's future in data science, machine learning, AI and predictive analytics.
2.Experience in statistical modeling techniques such as linear regression, logistic regression, and GLM.
3.Experience and knowledge with one or more of modern machine learning and statistical modeling techniques, e.g. GLM, GAM, decision trees, random forest, SVM, deep learning, GBM, clustering, Bayesian averaging
4.Experience using predictive analytics, machine learning, and artificial intelligence practices.
Knowledge of dashboarding to create data visualizations and Business Intelligence software.
5.Strong data mining skills with the ability to interpret data for the purposes of drawing business inferences.
6.Expertise in one or more modeling/machine learning languages such as R, Python, etc.
7.Expertise in SQL and databases.
8.Education of colleagues, business partners, and prospects in various areas related to the discipline. Strong ability to communicate technical data and concepts to audiences with varying levels of understanding.
9.Proficiency in Microsoft Office (Excel, Word, PowerPoint).
Experience
5 - 7 Years

Salary
8 Lac To 11 Lac P.A.

Industry
IT Software - Others

Qualification
B.Sc, B.Tech/B.E

Key Skills
Data scientist DATA ANALYTICS


About Company
Company Name
HRDevi Talent Acquisition


About Company
An advanced Big Data Platform Management software product to help organizations effectively deploy Big Data features in business processes and decision making. In addition to creating a ‘Centralized Data Platform’ it also provides a centralized framework to enable business, analytics, governance, capabilities, and technology to operate effectively in a shared environment.

Email ID
swati5547@gmail.com"
Principal Data Scientist - AI Reasoning (Global AI Accelerat...,"Bengaluru, Karnataka",Ericsson,None,Organic,"Date: Jul 22, 2020
Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.
Exciting Opportunity:
The complexity of emerging 5G networks makes manual management and operations of these networks impossible. AI technologies, including AI Reasoning, are increasingly being used to drive intelligent automation and autonomous operation of 5G networks that will drive economic and social transformation. Towards this, we have setup a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.
We use a combination of Artificial Intelligence technologies to drive thought leadership to automate and transform Ericsson offerings and operations, including new and emerging business. This includes development of models, frameworks and infrastructure where we not only drive AI based product innovation, but also push the AI technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data driven insights.
Machine Learning can produce highly impactful results, however, to build truly autonomous intelligent systems, we also need symbolic knowledge in our systems. Future applications will use a combination of machine learning and AI reasoning to build truly intelligent and intent based autonomous systems. Further, for mission critical telecom systems, safety and trust in the underlying AI algorithms will be paramount. Responsible AI, which is fast emerging as a major research topic, will be key to address issues around bias, safety, security, explainability and trustworthiness of AI algorithms in telecom systems.
Ericsson is now looking for Principal Data Scientists with a strong background in AI Reasoning for our team in Bangalore.

Role Summary:
As a Principal Data Scientist in AI Reasoning, you will build reasoning systems/frameworks for telecom that leverage the vast telecom knowledge base. This will span the range of designing simpler reasoning systems that can operate in near real time in edge/constrained environments to large/complex reasoning systems that can continually analyze the end to end network performance/KPIs to ensure optimal network operation. Such frameworks will incorporate principles of trustworthy AI systems, including safety and explainability. The solutions designed will work at the scale of large telecom systems and be highly reliable. You will interface with business stakeholders to define and formulate the right business problems.
Your knowledge and experience in AI methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other experts in AI reasoning to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of AI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple projects with a focus on AI reasoning
Manage communication, planning, collaboration with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Model the business problem statement into an AI problem.
Define the data sourcing strategy and work with stakeholders to procure data.
Contribute to the AI Intellectual Property creation for Ericsson
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand AI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Collaborate with product development teams and partners in Ericsson Businesses to industrialize AI Reasoning frameworks and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in AI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide AI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for AI needs
Present and be prominent in AI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.

Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes.
Applied experience: 8+ years of AI production level experience; and an overall industry experience of about 15+ years.
Strong knowledge and hands-on experience in one or more of the following areas:
Probabilistic graphical models - Bayesian networks, Markov networks
Semantic Graphs/Knowledge graphs, knowledge representation, ontology
Symbolic AI, logical reasoning
AI planning, Multi-objective Optimization
Explainable AI
Reinforcement Learning
Experience with logic programming or rule-based systems for knowledge representation & reasoning
Experience working with semantic web technologies such as RDF/OWL/SPARQL
Experience working with graph databases
Strong analytical skills and ability to ability to formulate problems and solve them independently even when the requirements are ambiguous
Ability to understand the problem domain quickly and ask the right questions
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability to lead AI projects from conception to deployment
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in Trustworthy AI including safety and building explainable models (XAI)
Experience in writing and presenting white papers, journal articles and technical blogs on the results

Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities

Additional Requirements:
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Data Science/ Machine Learning,"Faridabad, Haryana",Connect Infosoft Technologies,None,Organic,"Experience: 4+ to 7years
Work Location: Faridabad
Education: B.E/B.TECH, BCA, MCA/ Diploma or IT Technical qualification
Salary: Negotiable
Role: Data Science/ Machine Learning
We are looking for an energetic Machine Learning Engineer/ML Specialist with 4+ to 7years of experience. The chosen candidate will be responsible for developing all aspects of data mining, predictive analytics, solution development to name a few.
Desired Skills:
A strong track record and demonstrable interest in mining and analyzing data, looking for stories, patterns, trends and insights.
Looking for Python Machine Learning, Q Learning, Data Science, Artificial Intelligence
Experience in Deep Learning is mandatory.
Focus on developing clear and concise analytical approach for problem-solving
Skilled in working with large and complex datasets with a keen eye for detail and accuracy.
Strong understanding of ML libraries and applications e.g. Time series analysis, Neural Net, SVMs, Boosting methods and implementation using Python.
Experience in Pyspark will be an added advantage.
Develop hypotheses, design experiments, collaborate with engineering team on implementing the A/B tests, and evaluate their performance
Proven achievements resulting from data analysis and ability to succeed in both collaborative and independent work environments
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.
Answer complex business questions by using appropriate statistical techniques on available data or designing and running experiments to gather data.
Required Candidate profile
Desired Qualifications for ML Engineer/ML Specialist role:
Minimum 3 years of experience with machine learning, analytic consulting, product development
Minimum 3 years hands-on coding experience
Qualification- (B.E/B.TECH, BCA, MCA/ Diploma or IT Technical qualification).
Possess good analytical & communication skills.
Must be hard-working, motivated & willing to go extra mile in completing projects on time.
Work Location:
Faridabad, Haryana.
Interested candidates kindly revert back with your updated Resumes on mentioned e-mail id hritcompany29@gmail.com"
Data Engineer,"Bengaluru, Karnataka",Google,None,Organic,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.
Minimum qualifications:
Bachelor's degree in Computer Science or related technical field, or equivalent practical experience.
3 years of industry experience in software development, data engineering, business intelligence, data science, or related field with experience in manipulating, processing, and extracting value from datasets.

Preferred qualifications:
Master's degree in Computer Science, or related field.
Understanding of Big Data technologies and solutions (Spark, Hadoop, Hive, MapReduce) and multiple scripting and languages (YAML, Python).
Understanding of Google Cloud Platform (GCP) technologies in the big data and data warehousing space (BigQuery, Cloud Data Fusion, Dataproc, Dataflow, Data Catalog).
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences.
About the job
At Google, we work at lightning speed. So when things get in the way of progress, the Business Systems Integration team steps in to remove those roadblocks. The team identifies time-consuming internal processes and then builds solutions that are reliable and scalable enough to work within the size and scope of the company. You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation. Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently.
Data Engineers understand internal processes and what it takes to run Google at speed with its ever growing scale. As a Data Engineer, you'll focus on solving problems and creating value for Googlers by building solutions that are reliable and scalable to work with the size and scope of the company.
You will play a major role in developing, deploying, and supporting Google’s internal business applications. You will be tasked with creating custom-built software on google stack, and you will be part of teams that implement vendor sourced enterprise software, configuring that software, customizing it, and integrating with other internal systems.
Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
Responsibilities
Design, build and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Work closely with analysts and business process owners to translate business requirements into technical solutions.
Build internal solutions, with custom front ends (web, mobile) and backend services that automate business processes.
Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular and self-sustaining code, with repeatable quality and predictability.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Senior Machine Learning Engineer,"Chennai, Tamil Nadu",ADP Pvt Ltd - India,None,Organic,"Key Responsibilities:
Work with our engineering and product teams, translating their requirements and
applying the latest machine learning techniques to solve real business problems,
improve our platform, and develop new capabilities
Participate in interviews and help build a world-class team of engineers
Design, build, and train custom models and evaluate model performance
Help the team deploy production ready models to customers, to learn from customer
feedback and make frequent model improvements
Contribute to the overall architecture and implementation of our ML infrastructure, data
pipelines, inference engine(s), APIs, and products
Collaborate with our engineering and product teams to understand their machine
learning related needs and to provide guidance and support where necessary
Provide mentoring and technical direction for more junior team members where needed
Follow best practices and share them with the team
Participate in functional, technical, and code reviews
Work in an Agile environment
Skill set:
Minimum Qualifications
3+ years of hands-on experience working with neural networks and other statistical
techniques and successfully delivering and running such systems in production
A Masters or Ph.D in Computer Science or related field, concentration in Machine
Learning is preferred
Hands-on experience with ML infrastructure development and support using cloud
computing technologies
Fluent in using a neural network framework such as TensorFlow, Caffe, PyTorch, or
Theano with understanding of back-propagation and other mathematical concepts
employed by modern ML methods
Fluent in Python, including experience with packages such as NumPy and pandas
Proficient with SQL, notably writing and optimizing queries
Preferred Qualifications
Experience in data engineering and architecture
Experience in applying machine learning for a global-scale enterprise or consumer
application
Demonstrated knowledge and ability working with AWS, Google Cloud, or other
cloud-based solutions to train models, set up data pipelines, and set up inference
engines
Experience in microservices, Kubernetes, Docker, or other containerizers
Working knowledge of Node.js, JavaScript, and related technologies and frameworks
Experience with developing ML methods in Jupyter Notebooks environment
Experience with developing NLP models, e.g. for chatbots or automated assistants
Knowledge of Continuous Integration & Delivery methodologies
Excellent problem-solving skills especially debugging of complex software systems
Excellent written and verbal communication skills
A passion for applying latest technologies into the development of innovative features
and products
A collaborative attitude and demonstrated team-working ability
Self-motivated with a strong passion for learning

We’re designing a better way to work, so you can achieve what you’re working for. Consistently named one of the ‘Most Admired Companies’ by FORTUNE® Magazine, and recognized by DiversityInc® as one of the ‘Top 50 Companies for Diversity,’ ADP works with more than 740,000 organizations across the globe to help their people work smarter, embrace new challenges, and unleash their talent. “Always Designing for People” means we’re creating platforms that will transform how great work gets done, so together we can unlock a world of opportunity.

At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance."
PYTHON/DATA ANALYSIS,"Kochi, Kerala",UVJ Technologies,None,Organic,"PYTHON/DATA ANALYSIS – Job Code(PYD – 04)
Experience with Python to implement data analysis workflows in a Linux environment.
Experience evaluating and improving the efficiency of programs in a Linux environment.
Experience with command line compilation and debugging.
Experience with makefiles, coverage analysis and other forms of runtime profiling.
Experience with all phases of the Software Development Life Cycle.
Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
Working knowledge of MS Office suite of applications.
Working knowledge of Bioinformatics, Genomics, or Life Sciences
Good verbal and written communication skills.
Ability / willingness to learn bioinformatics / genomics

If you are interested in any of the positions mentioned above, Please attach your updated resume to resume@calpinetech.com with an email explaining the position you are looking for, your career goals and your expected salary. Please indicate the job code in the subject line of your email."
Data Engineer (ETL/Python),"Pune, Maharashtra",Velotio Technologies,None,Organic,"No. of open positions: 1
Velotio is looking for a Senior Data Engineer to help us architect, design and develop ETL data pipelines and data lakes for several customers across IoT, consumer and enterprise space.
Responsibilities:
Design and build data infrastructure with efficiency, reliability and consistency to meet rapidly growing data needs
Design data pipelines and data integrations to collect, clean and store large datasets (streaming and batch)
Help establish and maintain a high-level of operational excellence in data engineering
Evaluate, integrate and build tools to accelerate Data Engineering, Data Science, Business Intelligence, Reporting and Analytics as needed
Experience: 3-6 years
Qualifications:
2+ years data engineering or equivalent knowledge and ability
4+ years software engineering or equivalent knowledge and ability
Designing and maintaining at least one type of database (object, columnar, in-memory, relational) experience
Experience with any of the database types - Relational, object, tabular, key-value, triple-store, tuple-store, etc
Experience with data warehouse modernization, building data-marts, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and BI/reporting/analytic tools
Extensive hands-on experience with batch and stream data processing (e.g., DMS, Flink, Spark, Kinesis, Kafka)
Advanced SQL skills and strong proficiency in at least two of the following programming languages: Python, Scala and Java
Familiarity with pandas, SciPy, scikit-learn, seaborn, SparkML
Experience with Machine Learning production at scale is a bonus
Excellent cross-functional collaboration and communication skills"
Data Scientist,"Andheri, Mumbai, Maharashtra",Angel broking,None,Organic,"Expertise or extensive experience with Python/ R -programming
A thorough understanding of SQL databases
Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data
Experience Range:
4 - 8 years
Educational Qualifications:
Any graduation,
Skills Required :
data scientist, data analyst,
Candidate Attributes :
Should be good at R Python and Big Data"
Fresher/Junior Data Science Developer,"Chennai, Tamil Nadu",HTC Global Services Limited,"₹20,000 a month",Organic,"HTC Global Services hiring freshers for Junior Data Science Developer
Job Description:
HTC Global Services hiring freshers (2018 and 2019 ) for the position Junior Data Science Developer.
Candidates those who are in Chennai and immediately available to attend interview with HTC Global Services (MEPZ, Tambaram) can apply.
About HTC Global Services:
HTC Global Services (HTC) is a leading global provider of Information Technology (IT) and Business Process Services (BPS), headquartered in Troy, Michigan, USA. Established in 1990, HTC is an Inc. 500 Hall of Fame company and one of the fastest growing Asian American companies in the USA. Our client base spans over 2000 organizations across the globe. HTC acquired CareTech Solutions in December 2014 and Ciber, Inc. (Currently Ciber Global LLC) in June 2017. These acquisitions enable us to expand our operational capabilities in Healthcare IT and Technology Transformation services.
HTC is an ISO 9001 and 27001 certified company with processes compliant to SEI CMM Level 5. With over 10 global delivery centers and operating presence in several countries, we serve global clients across multiple time zones. Our ‘Business Partner’ approach enables us to offer high business value for our clients. It also brings in the benefit of repeated business for HTC. Our strategic solutions enable clients to transform and thrive in the changing world.
Designation : Fresher/ Junior Data Science Developer.
Job Requirements:
Key Skills:
Should have good knowledge in basics OOPS concepts.
Must possess good communication skill(both oral and written).
Qualification :
· Bachelors or masters in Science majored in Math/Statistics/Econometrics.
· Bachelors in Engineering with Data science/AI/ML as part of the curriculum
· Management graduates with specialisation in Analytics/Data Science/AI/ML.
Eligiblity Citeria:
· First class throughout curriculum is mandatory(from 10th standard to degree).
Certificates/Diplomas:
Should have done certification in date science, Analytics, Python from leading institutions or through online courses from Coursera/datacamp/udemy/udacity
Must to have:
Have few practical projects experience for a maximum of 2 years, active in Kaggle or other forums.
Probation period : One Year
Salary Offered : CTC 3.00 L pa
Agreement Period:
3 Years from the date of joining and should be ready to submit original documents.
Rounds of Interview:
Round 1: Aptitude (Technical and English )
Round 2: Technical & HR at the company.
Job Type: Permanant, Full-time
Salary: ₹300,000.00 per annum from Training onwards.
Benefits:
Provident fund (PF)
Paid leaves / Leave encashment
Industry:
Software Development
Interested candidates can reach me at :
Pavithra.M
Senior HR @ HTC Global Services Limited
Official Mobile Number: 9840604551
Job Types: Full-time, Fresher
Pay: From ₹20,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Associate Professional Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Assists in the application of data analysis and data modeling techniques to establish, modify, and maintain basic data structures and their entity descriptions, relationship descriptions, and attribute definitions according to client specifications.
Assists in the analysis and validation of basic database structures, models and processes to ensure definition according to business objectives and operations.
Communicates with clients about matters of significance and discrepancies related to data to ascertain correct information and correct errors.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science or related field preferred
Zero or more years of experience in programming or data analysis
Experience working with relevant programming languages and relational databases
Experience working with data modeling practices and procedures
Experience working with company software and hardware products
Other Qualifications
Basic research and data analysis skills
Communication skills to communicate with designers, management and customers
Personal computer and business solutions software skills
Ability to work in a team environment
Work Environment
Office environment"
Machine Learning Engineer/Data Scientist,"Bengaluru, Karnataka",Autodesk,None,Organic,"Job Requisition ID #
20WD40887
Job Title
Machine Learning Engineer/Data Scientist
Job Description
Autodesk is seeking a Machine Learning Engineer/Data Scientist to join our Sales Data Science team. We build innovative data products and machine learning solutions for Autodesk's sales teams. In this critical role, you will work alongside product development, product managers, and data engineers to tackle fundamental data science models in our Asia-Pacific (APAC) sales region.
Data, automation and advanced analytics technologies are drastically transforming our sales team in APAC and this person will be the data scientist in charge of overseeing our data science practice in Singapore, India, China, Korea, Australia, and New Zealand. As the Data Scientist for APAC, your primary responsibility will be to empower our sales teams with machine learning models and data analytics to make them more productive and better equipped to be customer-centric. You will collaborate with our Data Scientists in Barcelona and the US to build major data science products.

The ideal candidate is a strong communicator and has experience as a Data Analyst or Data Engineer who has strong Data Science leanings, and has built out multiple analytic models and machine learning algorithms before.

You will be in charge of establishing and maintaining machine learning deployment pipelines, including their associated life-cycle management systems and practices, in coordination with their architecture peers and communities of practice throughout the company

Your responsibilities will be:

Designing and implementing Machine Learning models and algorithms that enable account selection, customer targeting, and process improvements for the sales teams in APAC.
Develop and maintain model deployment pipelines for many types of machine learning including supervised and unsupervised learning as well as CNNs, RNNs or other deep learning algorithms
Working closely with data scientists, domain experts and sales team, both to understand model performance management requirements and design suitable inferencing instrumentation systems and practices that meet them
Designing and implementing outbound data engineering pipelines that serve curated datasets to business intelligence and reporting
Designing integration solutions including applications as needed to deliver inferencing outcomes or curated data sets for consumption and action
Ensuring your model deployment, outbound data engineering and integration pipelines are architecturally and operationally integrated with inbound ingestion and contextualization pipelines designed by your peer domain architects
Delivering and presenting results to sales leaders regarding their business, forecast, pipeline, and potential customers.

Education & Experience:
Very strong communicator
Advanced degrees in computer science and data science strongly preferred, though an equivalent level engineering, data science or mathematics degree, a technical undergraduate degree and relevant experience will also be considered
5+ plus years of relevant work experience
3+ years of experience working with data scientists in a data engineering or production machine learning inferencing capacity, working with various types of supervised and unsupervised learning algorithms for classification, recommendation, anomaly detection, clustering and segmentation, as well as CNNs, RNNs or other deep learning algorithms
5+ years of full-stack experience developing large scale distributed systems and multi-tier applications
5+ years of programming proficiency in, at least, one modern JVM language (e.g. Java, Kotlin, Scala) and at least one other high-level programming language such as Python
2+ years of production DevOps experience
3+ years of programming on the Apache Spark platform, leveraging both low level RDD and MLlib APIs and the higher-level APIs (SparkContext, DataFrames, DataSets, GraphFrames, SparkSQL, SparkML).
Demonstrated deep understanding of Spark core architecture including physical plans, DAGs, UDFs, job management and resource management
At least 1 year of implementation experience with Apache Airflow, and a demonstrated expert level understanding of both segmented and unsegmented Directed Acyclic Graphs and their operationalization
Experience working with Neo4J and a demonstrated ability to lead architecture efforts for its implementation
Strong technical collaboration and communication skills

Additional Qualifications:
Passion for sales and customer segmentation
Proficiency with functional programming methods and their appropriate use in distributed systems
Proficiency with AWS foundational compute services, including S3 and EC2, ECS and EKS, IAM and CloudWatch
Proficiency with Sagemaker, Kubernetes, and Docker

Preferred Qualifications
Experience with data science toolkits like: R, Pandas, Jupyter, scikit, TensorFlow, etc.
Experience with Sagemaker and data pipelines in AWS
Familiarity with statistics concepts and analysis, e.g. hypothesis testing, regression, etc.
Experience building dashboards in platform: Power BI, Tableau, Qlik, Looker, etc.
Salesforce experience is a plus
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers ."
Senior Analyst - Geospatial Analytics,"Chennai, Tamil Nadu",McKinsey & Company,None,Organic,"QUALIFICATIONS
University degree in Computer Science, Engineering, Applied Mathematics, Geoinformatics, Quantitative Social Sciences or related field and excellent academic record required; Advanced degree preferred
4-6 years of deep technical experience in working with spatial data and applying advanced statistical and machine learning algorithms
Proficiency with GIS software (e.g., ArcGIS) and geospatial approaches (spatial analysis, remote sensing, network analysis, geographic visualization, etc.)
Familiarity of analytical packages such as R, Python, SAS, MATLAB, etc., and approaches (regression, decision trees, clustering, neural networks, etc.)
Ability to work with relational databases such as SQL, PostGIS etc. Knowledge of distributed database systems (Hadoop, Spark, MapReduce) will be a plus
Stakeholder management skills with ability to communicate and work with senior management effectively
Skills to communicate complex ideas effectively
WHO YOU'LL WORK WITH
You’ll be based in Chennai and will be part of our Data Analytics team.
This group provides analytics insights to consulting teams and clients across the globe. The team is composed of data scientists and data engineers who work across a variety of industries, functions and analytics methodologies and platforms.
WHAT YOU'LL DO
You will work with our client project teams on analytics focused engagements across geospatial/location analytics.
The types of projects you may work on include: decoding spatial and temporal patterns in customer behaviors, analyzing the drivers of performance to improve customer relationship management, developing an optimal distribution network configuration model for a global supply chain, or geographically optimizing a field sales force.
In this role you will be subject matter expert on advanced geospatial techniques, statistical analysis and machine learning algorithms. You will advise on state-of-the-art quantitative modeling techniques in order to derive business insights and solve complex business problems. This includes gathering and analyzing information, formulating and testing hypotheses, and developing and communicating recommendations. At times you will present the results to client management and implementing recommendations with client team members.
You’ll have the opportunity to gain new skills and build on the strengths you bring to the firm. As an analyst, you will receive exceptional training as well as frequent coaching and mentoring from local and global colleagues."
A++ Data Scientists @ Pune – High Impact!,"Pune, Maharashtra",CareerXperts,None,Organic,"You will join a world famous Profitable Product Startup!
You Will :
Retrieve, prepare, and process a rich data variety of data sources such as social media, news, internal/external documents, emails, financial data, and operational data
Analyze and model structured data and implement algorithms to support analysis using advanced statistical and mathematical methods from statistics, machine learning, data mining, econometrics, and operations research
Perform Statistical Natural Language Processing to mine unstructured data, using methods such as document clustering, topic analysis, named entity recognition, document classification, and sentiment analysis
Utilize a diverse array of technologies and tools as needed, to deliver insights, such as R, SAS, Python, Spark, Hadoop, Qlikview, and Tableau
Translate advanced business analytics problems into technical approaches that yield actionable recommendations
Perform exploratory data analysis, generate and test working hypotheses, and uncover interesting trends and relationships.
Experience
2 to 4 years
Qualification
Master’s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, with five years of relevant experience and strong knowledge in at least one of the following fields: statistics, data mining, machine learning, statistics, operations research, econometrics, natural language processing, and/or information retrieval; PhD preferred.
Deep experience in extracting, cleaning, preparing, and modelling data; command-line scripting, data structures, and algorithms; and working in a Linux environment
Proficiency in analysis packages (e.g. R, SAS, Matlab) and programming languages (e.g. Python, Ruby, Java, Scala).
Write to Deepa.m@careerxperts.com to get connected!
Job Location
Pune"
Data Analyst - MORE - India,"Mumbai, Maharashtra",OLIVER - SEAPAC,None,Organic,"ROLE: Data Analyst
LOCATION: Mumbai, India
START DATE: 16th September, 2020
REMUNERATION:
BENEFITS: N/A
JOB LEVEL:
A LITTLE BIT ABOUT THE ROLE:
MORE are expanding the team for one of our global FMCG clients; a global umbrella group with multiple international brands under it.
This is a great opportunity working within a new team, creating impactful communications across the world and developing best practices for the various brands.
We believe that our client is unlike any other organisation. We seek long-term sustainable growth through responsible business practices and product innovation, providing our consumers with exceptional brand experiences, today and tomorrow.
A dedicated data analytics professional who can turn data into information and generate insights that drive key business decisions. He/she should be a self-starter with a drive to develop the systems on the go and can manage the analytics pipeline by himself/ herself – collect, segment, analyse, visualize and derive insights. Should have a sound understanding of key business and marketing aspects. Interact regularly with stakeholders to identify problems and implement new ideas at a fast pace in a challenging environment.
WHAT YOU WILL YOU BE DOING:
What is required
Work closely with clients/ business stakeholders to understand use cases, objectives and KPIs they want to track/optimize using data and analytics
Interpret business problem and structure analytical solution
Be able to comfortably acquire data from various sources, transform and load.
Identify, analyse and interpret trends or patterns to come up with actionable insights using statistical models. [Descriptive, diagnostic & predictive]
Design, develop and maintain analytical reports for day-to-day decision making
Create insightful dashboard to help contribute to a more competitive, proactive business approach
Identify, improve and continually develop data process and management

What good looks like
2-3 years of experience in field of analytics
Strong knowledge of R Programming, SQL and Python.
Strong understanding and practical experience in utilizing statistical & financial libraries.
Expert excel user and skilled in data wrangling/ manipulation.
Familiarity with data models and database design principles
Strong analytical skills with attention to detail and accuracy
Should be a fast leaner and a self-driven individual who can take end to end ownership of a function within the organization
Should be able to directly engage with stakeholders and improve execution & implementation speed
Good communication skills with the ability to translate data into story
Experience in statistical models & visualization tools (Power BI/Tableau)
Experience with cloud services (AWS, Azure, Google Cloud)
Experience with and excitement for working on fast-paced, agile teams with start-up DNA
Self-motivated, curious, and quick/continuous learner with a passion for innovation in data analytics/science
Bachelors' degree in a technical/quantitative subject such as mathematics, computer science, economics, etc. with strong working knowledge in statistics and mathematics.
Experience in CRM segment would be an added benefit.
A LITTLE BIT MORE ABOUT US:
MORE is a global production portal, part of Inside Ideas Group. We are a collection of creative technologists & production experts across the world, creating and maintaining world class content in the areas of Film, CGI, Motion Design, Digital and Print.
We bring scale, expertise and craft, delivering creative solutions to clients and brands across the globe.
DONE. CORRECT. ON TIME.
Our reel: https://vimeo.com/337988475
OTHER ESSENTIAL POINTS TO NOTE:
As we are working remotely, it is essential that the ideal candidate have the following in place to ensure there are no delays on delivering work timeously:
Back-up power supply, if necessary
Stable internet connectivity – fiber connection preferable (options can be discussed) in order to connect to remote servers as well as conduct virtual meetings daily
Personal computer with relevant capabilities necessary for the role

This is a snapshot of the responsibilities & desired deliverables. Other areas for delivery and responsibilities may be added or addressed during the period of employment. This document should not constitute as the sole indicator for responsibilities and delivery, but it can be used as a generic guide to help with managing your performance."
Machine Learning Engineer,"Noida, Uttar Pradesh",Whizzystack,None,Organic,"This is not a project-based position. This is a full-time, long-term position with the opportunity to travel to the client’s office in Silicon Valley two times per year.

You will be responsible for implementing machine learning and predictive modeling techniques that will have a major impact on the company.

This is an excellent opportunity for smart machine learning engineers who want autonomy and the freedom to turn their big data ideas into reality.

What You’ll Be Doing

Implement machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).
Tune SQL queries for Redshift/Hadoop.
Analyze data and performance of data products.
Implementing machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Who You Are (Experience & Skills)

Commercial machine learning experience, not just academic or research experience.
Experienced in machine learning techniques.
Experience with a variety of Big Data tech, distributed machine learning and computing frameworks (S3, Spark, Hadoop, Elasticsearch, etc.)
Experienced in creating high-performance algorithms, prototypes and predictive models.
Experience with deploying solutions in AWS
Experience with Python data science ecosystem - Pandas, SciPy, scikit-learn, NLTK, Gensim, etc.Experience with full-stack development, building large distributed systems and large scale data pipelines

What We Offer

Competitive salary.
Challenging work on complex and very innovative projects.
Work in an international environment.
Generous benefits package with all kinds of great stuff.
Trainings accustomed to your needs.
Flexible working environment.
Cozy and friendly atmosphere.

How To Apply

To apply email your resume to sid.baker@whizzystack.com with the subject line “Machine Learning”.
When applying please provide a resume and any links to your technical blog, github/bitbucket and other reviewable code examples."
Python and DAta SCIENCE Developer,"Mohali, Punjab",A2IT,None,Organic,"A2IT is a leading software development company in Mohali Chandigarh with expertise in both Cloud-based Applications and Web applications. Coding experience in Python, should be able to produce high quality code. worked on requests, pillow, scrapy, nump"
Applied Scientist Intern,"Hyderabad, Telangana",Amazon Dev Center India - Hyd,None,Organic,"A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
Experience in predictive modelling and analysis, predictive software development
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills

Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches

Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences"
Data Engineer,"Bengaluru, Karnataka",Rakuten,None,Organic,"Role: Sr. Data Engineer

What will you do?
Design, select and integrating big data tool and frameworks to build data science platform to support company-wide data analytics.
Analyze the requirements and data sources from different business units.
Transform data from multiple domains into the centralized data platform.
Understand and manage the data warehousing and data processing of large scale datasets.
What are we looking for?
Strong analytical and problem solving skills especially transforming business requirements to feasible design
Solid database knowledge and at least 5 years hands-on SQL experience working on production system.
Experience with modern day storage and compute technologies, such as MinIO, YugabyteDB, Spark, and Presto
Programming skills in Java, GoLang, Python, etc.
Experience with building stream-processing such as spark-streaming or storm

Preferred Qualifications

Experience with distributed computing tools
Familiarity with data sciences tools, such as Jupyter notebooks
Experience with GPU, Docker, Nginx
Experience of using or building BI system
Experience and knowledge of message systems such as RabbitMQ, Kafka.
Experience and knowledge of development process management like Agile"
Senior Software Developer : Data Science,"Bengaluru, Karnataka",Oracle,None,Organic,"Senior Software Developer : Data Science-20000LV8

Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications

Principal Member of Technical Staff
The Oracle Cloud Infrastructure (OCI) team can provide you the opportunity to build and operate a suite of massive scale, integrated cloud services in a broadly distributed, multi-tenant cloud environment. OCI is committed to providing the best in cloud products that meet the needs of our customers who are tackling some of the world’s biggest challenges.
We offer unique opportunities for smart, hands-on engineers with the expertise and passion to solve difficult problems in distributed highly available services and virtualized infrastructure. At every level, our engineers have a significant technical and business impact designing and building innovative new systems to power our customer’s business critical applications.
This role is available on the OCI Data Science service. We are addressing exciting challenges at the intersection of data science and cutting-edge infrastructure. We are building a cloud service for data scientists, machine learning engineers and software engineers to help them every step of the way in their machine learning development and deployment lifecycle. Our product vision includes interactive notebooks, distributed machine learning on CPU/GPU supporting wide variety of ML algorithms/libraries, distributed model serving and robust monitoring and analytics of ML models.
As a Machine Learning Developer - Accelerated Data Science on the Oracle Cloud Infrastructure Data Science team, you will have a hand in the design and delivery of a high-quality cloud service with the capabilities, scalability and performance needed to match the needs of enterprise data science teams and enterprise application development teams. You will need experience with designing and developing software for machine learning solutions - solving real-world business problems.
What You'll Do
Build accelerated data science components and machine learning solutions for a cloud service on top of the modern Infrastructure as a Service (IaaS) building blocks at OCI
Design and build distributed, scalable, fault tolerant software systems using Dask and Spark etc.
Participate in the entire software lifecycle – development, testing, CI and production operations
Develop new features for the data science platform in a variety of classical and deep learning frameworks
Work with customers and ISVs to troubleshoot data science solutions in data wrangling, data access, training models and putting them into production
Design, Develop and Document robust software components that fit the Accelerated Data Science SDK
Mentor new employees and work with less experienced software developers to increase quality of projects performed by junior engineers
Participate in on-call for the service with the team
Qualifications
4+ years of professional work experience
DevOps Experience/Familiarity: Containerization (Dockerizing python), Linux/UNIX Shell, package management/Conda etc
B.S., M.S. in Computer Science, Electrical Engineering, or software relevant field, CS, EE etc
Understanding of machine learning
Demonstrated programming abilities in Python (intermediate++)
Experience with software coding practices (unit tests, mock, logging, debugging, git, code review, etc)
Meets/exceeds Oracle's functional/technical depth and complexity for this role
Strong verbal and written communication skills
Cloud Experience with AWS, GCP, Azure, Heroku etc. highly desirable
SQL experience highly desirable
Detailed Description and Job Requirements
Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience."
Mobile AI Engineer - NLP & Speech Tech,"Chandigarh, Chandigarh",DataToBiz,"₹6,00,000 - ₹10,00,000 a year",Organic,"DataToBiz is an AI and Data Analytics Services startup. We are a team of young and dynamic professionals looking for an exceptional Mobile AI Engineer to join our team in Chandigarh. We are trying to solve some very exciting business challenges by applying cutting-edge Machine Learning and Deep Learning Technology.
Being a consulting and services startup we are looking for quick learners who can work in a cross-functional team of Consultants, SMEs from various domains, UX architects, and Application development experts, to deliver compelling solutions through the application of Data Science and Machine Learning. The desired candidate will have a passion for finding patterns in large datasets, an ability to quickly understand the underlying domain and expertise to apply Machine Learning tools and techniques to create insights from the data.
Responsibilities:
* As a Mobile AI engineer on our team, you will be responsible for solving complex data problems for various clients using deep learning techniques.
* Work with the team to extract and transform natural language data from audio and text on the mobile native application.
* Develop and implement a framework for mobile processing of language syntax and semantics as well as contextualization of audio and textual data using python
* Develop strategies and implement methods to pass NLP techniques to classification algorithms.
* Execute project plan to meet requirements and timelines.
* Identify success metrics and monitor them to ensure high-quality output for the client.
* Deliver production-ready models that can be deployed in the production system.
* Understand and identify appropriate data sources required for solving the business problem at hand.
Requirements
* 2+ years of working with Python, Machine learning with exposure to one or more DL frameworks like Tensorflow, Keras, Caffe, MXNet etc
* Minimum 2 years experience in text representation techniques and NLP algorithms to succeed in this role along with hands on Speech Analytics
* Exposure to Deep Learning algrithm implementation in either speech analytics or NLP domain
* Exposure to ML/DL techniques and algorithms to work with different data formats including voice and text unstructured data
* Strong verbal and written communication skills with other developers and business client
* Android or iOS experience will be advantageous
* Exposure to DL Model optimization & transfer learning techniques
Job Type: Full-time
Salary: ₹600,000.00 - ₹1,000,000.00 per year
Experience:
Full time Work: 2 years (Required)
NLP or Speech Tech: 1 year (Required)
Deep Learning: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19"
Principal Data Scientist,"Bengaluru, Karnataka","Cornerstone OnDemand, Inc.",None,Organic,"We're looking for a
Principal Data Scientist ( Bangalore, India)
Be a senior member of the Big-Data Machine-Learning Data Science team, and contribute to the R&D. The work centers around machine learning algorithms and data analysis techniques - especially natural language processing and deep learning.

In this role you will...
Working very closely and collaboratively with team-members in the big-data Machine-Learning Platform team.
Work on NLP through deep learning techniques towards building next-gen products on employee workforce predictive insights.
Perform preliminary data analysis to discover hidden correlations and come up with prototype models.
Work with the team for the development of at-scale efficient machine-learning-models to be able to handle large volumes of data that will be integrated with the MLP.
Active participation in the technical discussions.
You’ve got what it takes if you have...
We are looking for a candidate with a strong background in Natural Language Processing techniques and Deep-Learning using PyTorch. In particular, the candidate should have work experience with:

PyTorch and its ecosystem of libraries.
Word and document embeddings.
Transformers and Attention.
RNN, LSTM.
A background in BERT and its variants.
transfer-learning practices.
nltk.
genism
Besides this, the candidate must possess a mature understanding of, and hands-on experience in, the broad field of machine-learning and statistical methods. Must be conversant with:
scikit-learn
pandas
numpy
plotting using matplotlib, seaborn, etc.
Experience with any of the following is considered a plus:


Tensorflow
Big-data and PySpark
Beautiful Soup or Scrapy
NetworkX
R libraries
Test-driven development
Data-pipelines
Taking models to production
Java programming
GCP
Our Culture:
Our mission is to empower people, businesses and communities. A culture created less by what we do and more by who we are. When people are asked to describe the team, the answer is always the same: smart, cool, dependable, and visionary. We are not a typical tech company (paid sabbaticals, generous stock units, education reimbursement, and 100% paid employee health coverage), because, well, our employees aren't your typical techies... We're always on the lookout for new, curious and capable people who can help us achieve our goal. So if you want to work for a friendly, global and innovative company, we'd love to meet you!
What We Do:
Cornerstone OnDemand (NASDAQ: CSOD) was founded with a passion for empowering people through learning and a conviction that people should be your organization’s greatest competitive advantage. Cornerstone is a global human capital management (HCM) leader with a core belief that companies thrive when they help their employees to realize their potential. Putting this belief into practice, Cornerstone offers solutions to help companies strategically manage and continuously develop their talent throughout the entire employee lifecycle.
Cornerstone’s HCM platform is successfully used by more than 75 million people in 180+ countries and in nearly 50 languages.
Check us out on Linkedin, The Muse, Glassdoor, and Facebook!
Cornerstone takes special care to ensure the security and privacy of the data of its users."
SENIOR DATA SCIENTIST,"Chennai, Tamil Nadu",The Data Team,None,Organic,"Location: Chennai / Bangalore

The Data Team is a boutique consulting firm with strong expertise in big data and data science. The Senior Data Scientist is a key role in the organization, and will be leading project delivery on data science projects or data products. The Senior Data Scientist is an important role within the organization responsible for providing expertise, thought leadership, mentorship and leadership in the area of statistical analysis, data analysis and data science. Accordingly senior data scientists are expected to a hands-on practitioners in business analysis, hypothesis generation, data preparation, relational modelling, statistical modelling, algorithm design and scalable machine learning and deep learning. They’ll be expected to provide deep expertise in these areas. In addition, Senior Data Scientists are expected to mentor data analysts and data scientists on project deliverables, and ensure quality and timeliness in the output. The Data Team offers high-impact work with diverse opportunities in the areas of data science for Senior Data Scientists to grow into roles such as business consulting. Prior experience in doing data science and managing data science teams is required for this role. Experience in working on large scale Hadoop databases is required for this role. Past experience in bots and API development, test driven development, continuous delivery are preferred. Client facing skills are considered a plus.

Required Skills
True depth of knowledge in statistics, machine learning, cloud platforms and databases
Critical thinking skills in business with the ability to confidently face clients and mentor data scientists
A highly imaginative mind set and the ability to formulate new and relevant hypotheses from the data
Ability to perform advanced statistical analysis on diverse data sets in Python, R, Scala and Java
Ability to implement scalable machine learning and statistical analysis algorithms with frameworks such as Spark, Tensorflow or Torch
Current knowledge of cloud technologies and architectures such as on Azure, and hands on skills in implementing machine learning algorithms at scale
Expertise validating and critically evaluating machine learning algorithms and their performance
Ability to work in a Linux environment, on cloud-based virtual machines and containers
Should have managed a team in past roles in a managerial setting, or directly faced clients
Excellent interpersonal, presentation and written communication skills
Education and Work Experience Requirements
Bachelor’s degree in computer science or applied mathematics (Master’s degree or PhD preferred)
Higher degree in business, statistics, machine learning or computer science is a plus
Between 8 and 10 years of demonstrated experience in the industry including significant prior experience in data analysis and data science
Relevant certifications in data science will be considered favorably"
Analyst - One ERP ( m/f),"Oragadam, Chennai, Tamil Nadu",Danfoss,None,Organic,"Job ID: 13240
Job location(s): Oragadam, IN
Job Description
We are currently looking for an Analyst One ERP (m/f) with global responsibility for our location in Chennai, India.


We are looking for an Analyst with data science experience that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. In this role, you will work with business teams from Global Planning & Logistic area to implement new solutions. You will work directly with large, different data sets and analyse them using the latest modelling techniques. You must be comfortable working with a wide range of stakeholders and functional teams to drive business results with their data-based insights. As a team, we will develop and build recommendations for automation, data integration and machine learning.
Job Responsibilities
Identify use cases - work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
Processing, cleansing, and verifying the integrity of data used for analysis
Data mining using state-of-the-art methods
Selecting features, building and optimizing classifiers using machine learning techniques
Creating visualizations of complex data sets for easy of understanding by business partners
Doing ad-hoc analysis and presenting results in a clear manner
Enhancing data collection procedures to include information that is relevant for building analytic systems
Creating automated anomaly detection systems and constant tracking of its performance
Analyse, Manipulate, and Validate data using SQL, R, Python, and other analytical tools
Develop, test, and pilot your solutions
Background & Skills
Bachelors / Masters with focus on Statistics, Mathematics, Economics or Business preferred
Experience with data analytics
Experience in machine learning and neural networks
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets
Experience with data visualization tools
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Experience working with and creating data architectures
A drive to learn and master new technologies and techniques

Capabilities/Mindset
Great communication skills
Data-oriented personality
Strong problem-solving skills
Self-motivated

Optional:
Big data tools (Apache Spark, Hadoop)
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Danfoss – Engineering Tomorrow
At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways – driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.

Following our founder’s mindset ‘action speaks louder than words’, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030."
Data Science Specialist,"Bengaluru, Karnataka",Great Learning,None,Organic,"Data Science Specialist
Gurgaon & Bangalore
Key Responsibilities
Owning new initiatives for learning content and experience for our flagship program BABI (Business Analytics & Business Intelligence)
Ensuring ongoing review of the learning content and identifying opportunities to improve quality in terms of appropriateness, accuracy, richness.
Ensuring the efforts towards updating the content as well as creating additional content - videos, reading material, exercises and assignments.
Deliver a great learner support experience by ensuring timely response and feedback on all academic queries from learners
Leading initiatives to deliver solutions to key business problems in Operations and customer experience
Project Management for delivery excellence
Drive cross-pollination of ideas and knowledge with in-house data science team to deliver in-house solutions and translate them into learning material & case studies for learners
Use insights derived from ad-hoc data analysis to answer ad-hoc questions as well as drive processes improvements so that Great Learning’s business requirements are met
Collaborate with internal stakeholders to consistently align data interpretation with evolving business processes
Refine existing solutions & products as well as handcraft new features in the Learning Management System for superior end user experience
Create unique learning experiences that enable Great Learning customers to have a delightful learning experience and meaningful outcomes
Conceptualize, plan and execute hackathons & ad-hoc competitions,
Fostering and leveraging relationships with industry leaders in Analytics to organize conferences, panel discussions, Analytics industry sessions
Qualification:
Solid understanding and working knowledge of advanced techniques like supervised &unsupervised learning, including but not limited to, hypothesis testing, regression, clustering,decision trees, prediction techniques, model tuning and model performance measures etc.
Good aptitude, ability to think logically and problem-solve
Ability to work under pressure and tight deadlines
Ability to learn quick - ability to learn business, processes, techniques and technologies on the go
Prior experience of deploying analytics solutions
Ability to lead teams
Good understanding of what analytics is - from data to decisions
Good ability to work with complex, unstructured data from multiple sources - consolidate, analyze, interpret, clean and transform to get it ready for analysis
Ability to design approaches to solve a problem using data analysis techniques
Ability to interpret data, present/visualize metrics and extract meaningful insights to answer business problems
Good proficiency with Microsoft Office Suite
Strong working knowledge of SQL, R/Python, Excel
Excellent oral and written communication skills
Sounds like ""the"" job for you? Send in your CV @ careers@greatlearning.in & we will reach out to you accordingly."
Data Analyst (SQL),"Pune, Maharashtra",Springer Nature,None,Organic,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.
Visit: group.springernature.com and follow @SpringerNature
Springer Nature is seeking a highly motivated Data Analyst for its highly-regarded Analytics Centre of Excellences serving the Research division that includes Nature, Springer, BioMedCentral and ScientificAmerican.
As a Data Analyst, you’ll be analyzing big data from very highly trafficked websites and content. You will provide actionable analysis and insight into the behavior of researchers in both their roles as authors and users of scientific information as well as general trends in the world of research. Driving change that improves their experience with SpingerNature and supports our purpose to advance discovery.
Roles and Responsibilities
Implement online tracking, tagging and analytics infrastructure, and solutions to provide accurate, actionable data to the business
Creation and production of regular reports and analysis on website and customer behaviour and engagement to help make informed decisions
Implement cutting edge analytics solutions to help us become best-in-class data handlers
Consult with stakeholders throughout the business to shape and implement solutions in support of business objectives
Play a key role in shaping solutions, creating the right governance and safety checks to maintain tracking accuracy
Role Requirement
University degree with a strong analytical/quantitative background or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.)
Good working knowledge of SQL, Python, Google Tagmanager and Analytics
Experience in experimentation (A/B testing, MVT) and personalisation
Demonstrable experience of using data insights and analytics to add tangible value in achieving the wider goals and strategy of the business
Excellent analytical problem-solving capabilities coupled with business acumen
Well organized and accurate with good time management
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities."
Senior Data Scientist,"Chennai, Tamil Nadu",Ericsson,None,Organic,"Date: Jun 30, 2020
Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.
Senior Data Scientist – Product Development (Global AI Accelerator India)
Job Description

Ericsson Overview:
Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.
Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.
We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.
Exciting Opportunity:
It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.
Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.
Ericsson is now looking for Senior Data Scientists to significantly expand its global team for AI acceleration for our group in Chennai.
Do you have in depth understanding of Machine Learning and AI technologies?
Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?
Then, you do want to join Ericsson’s global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:
As a Senior Data Scientist, you shall build and deploy AI models into production with focus on scaling, monitoring and performance. You shall build effective AI models using stacking/ensemble techniques; and provide prediction explainability and prescriptive capability in ML models. You shall work with business stakeholders to define and formulate the right business problem.
Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.
Key Responsibilities:
Lead multiple AI/ML projects for a certain product/business
Manage communication, planning, collaboration and feedback loops with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Identify the model monitoring strategy in prod and retraining plan.
Define data sourcing, access and pipeline design. Identify and plan for sourcing external data.
Model the business problem statement into AI/ML problem.
Define the Data sourcing strategy and works with stakeholders to procure data. Contribute to IP creation for Ericsson in AI/ML
Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL Databases. Design data pipelines and flow strategies.
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Proven skills of implementing a variety of Machine Learning techniques
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability of leading AI/ML projects end-to-end with complete ownership
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in building models using semi-structured and unstructured data
Hands-on experience in designing and building AI models using Deep Neural Networks for applicable scenarios
Experience in using ensembles and stacking techniques to solve complex ML problems
Able to build and deploy AI models into production with focus on scaling, monitoring and performance
Knowledge of building explainable models (XAI) and prescriptive analytics
Experience with working in Big Data technologies such as Hadoop, Cassandra etc.
Able to Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL DBs
Knowledge of designing data pipelines and flow strategies
Familiarity with data pipelining frameworks such as Air Flow, AWS Sagemaker, etc. would be a plus
Able to design APIs for AI/ML models with focus on business, modularity and versioning
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Knowledge of Cognitive models is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G
……………………………………………………………………………………………………………………………………

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.
—"
Data Scientist,"Andheri, Mumbai, Maharashtra",Angel broking,None,Organic,"Expertise or extensive experience with Python/ R -programming
A thorough understanding of SQL databases
Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data
Experience Range:
4 - 8 years
Educational Qualifications:
Any graduation,
Skills Required :
data scientist, data analyst,
Candidate Attributes :
Should be good at R Python and Big Data"
Associate Director - Data Science & AI Engineering,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for Associate Director - Data Scientist and AI Engineering to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about implementing large scale application of AI and machine learning to financial services, AppZen is the place for you.
Must-Have:
Solid hands-on understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.

Provides the basis for the innovation strategy involving future trends and their impact on the team strategy and client businesses

Be at the forefront of the development of self and team's technical acumen and enabling upskilling of other team members to leverage advanced analytics / AI techniques

Lead and direct discovery of new tools/technologies/solutions with advanced AI / ML solutions in areas of deep learning, machine learning, NLP, Simulation etc.

Support business development activities by co-creating next-gen AI/ML solutions and help identify opportunities with new/existing clients.

Expertise on AI/ML for text/document analysis is nice to have

Demonstrating a track record of delivery within a number of large scale projects that has solved complex problems using AI/ML and statistical techniques.

Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.

Expert knowledge of a statistical computing language such as Python with expert knowledge of RDBMS and NoSQL databases

Manipulating and analyzing complex, high-volume, high-dimensional data from varying sources

Understanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context

Excellent interpersonal, communication and analytical skills

Project execution experience in complex matrix organization dealing with leadership, staff and stakeholders

M.Sc. or M.E. or M.Tech or Phd in Computer Science, Engineering, Statistics, with specialization in NLP/ AI / ML is required

Must have 15+ years of industry experience
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
SENIOR DATA SCIENTIST,"Bengaluru, Karnataka",Happiest Minds Technologies,None,Organic,"Data Scientist


About Happiest Minds Technologies
Happiest Minds, the Mindful IT Company, applies agile methodologies to enable digital transformation for enterprises and technology providers by delivering seamless customer experience, business efficiency and actionable insights. We leverage a spectrum of disruptive technologies such as: Big Data Analytics, AI & Cognitive Computing, Internet of Things, Cloud, Security, SDN-NFV, RPA, Blockchain, etc. Positioned as “Born Digital . Born Agile”, our capabilities spans across product engineering, digital business solutions, infrastructure management and security services. We deliver these services across industry sectors such as retail, consumer packaged goods, edutech, e-commerce, banking, insurance, hi-tech, engineering R&D, manufacturing, automotive and travel/transportation/hospitality.
Headquartered in Bangalore, India; Happiest Minds has operations in USA, UK, The Netherlands, Australia and Middle East.
Skills
Required Skills: Data Science, Machine Learning, Deep Learning, Python, Computer Vision
Desired Skills:
Roles and responsibilities
Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statistics
Have ability to solve Business problems using Data
Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets
High level of proficiency in statistical tools like R, Python
Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.
Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems
Good to Have
Expertise in programming languages like Java/C/C++/Python
Experience with relational databases and SQL is good to have
Experience in audio and video analytics
Relevant experience in Big Data platforms like Hadoop eco-system
Come up with innovative algorithms and solutions

Staffing Type: Permanent"
Data Scientist,"Mumbai, Maharashtra",XPO Logistics,None,Organic,"Logistics done differently.
At XPO Logistics, we’re constantly looking for ways to improve, enhance and adapt in an ever-changing marketplace. The selected candidate will possess a combination of data science skills including data wrangling, advanced programming and statistical analysis (machine learning and data mining). Further, this individual will be able to take complex data, analyze it, draw meaningful conclusions and communicate findings in a manner that can be easily understood by a wide variety of audiences

What you’ll do on a typical day:
Strong understanding of Warehouse concepts, Labor planning, Demand forecasting and Industrial Engineering
Demonstrated ability to provide guidance and development to a group of analyst and engineers
Strong analytical skills with the ability to collect, organize, analyze and disseminate information with attention to detail and accuracy
Demonstrated experience with database design, data models and integration/extraction technologies and techniques
Experience with visualization tools (Power BI, Tableau, and Oracle’s Business Intelligence preferred)
Expertise in programming for data wrangling and statistics (R, Python)
Strong knowledge of statistics and experience using statistical modeling (logistic regression, SVMs, etc.) to solve business specific problems
Experience with text analytics (e.g. semantic analysis) is a plus

It’d be great if you also have: Primary Skills (Must Have):
Programming: Python, R, CPLEX, SQL, VBA
Visualization: Power BI, Tableau, Oracles Business
Statistical modeling techniques: Linear/logistic regression (including advanced predictor selection techniques), classification (decision trees, random forests), Support Vector Machines (SVMs), neural networks, etc.
Algorithm Development: Machine learning, Deep learning, and advanced Algorithmic solution development

Be part of something big.

XPO is a leading provider of cutting-edge supply chain solutions to the most successful companies in the world. We help our customers manage their goods most efficiently using our technology and services. Our greatest strength is our global team – energetic, innovative people of all experience levels and talents who make XPO a great place to work.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed."
AI Developer,"Pune, Maharashtra",GrayRipples.com,"₹40,000 - ₹50,000 a year",Organic,"Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Salary: ₹40,000.00 - ₹50,000.00 per year
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
java: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Indore, Madhya Pradesh",GenieTalk,None,Organic,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore | Openings"
Data Science Engineer,"Bengaluru, Karnataka",IntelliPredikt Technologies,None,Organic,"You can send your CV to careers@intellipredikt.com

Job_ID : IPTB_PE_102
Job Title: Data Science Engineer
Status: OPEN
Job Description: Data scientist is responsible for data exploration, machine learning, IP generation, anomaly detection/ prediction and data visualization of massive dataset using common tools.
Qualification: MS or PhD in Data Analytics areas
Experience: 1 to 5 years of experience in data analytic's for anomaly detection and prediction"
Python Developer,"Coimbatore, Tamil Nadu",CDS,None,Organic,"Any Computer Science Graduate with 2+ years of working knowledge in web crawlers, web scrapers and other web tools which helps in extracting the web content using Python.
Should be expertise in Python Coding.
Should have knowledge in scraping frameworks such as Scrapy, Beautiful Soup, HTQL, Jsoup, Web-Harvest and others.
Understanding of XML, HTML5, CSS and JSON objects.
Experience with SQL and NoSQL databases.
Should be familiar with event-driven programming in Python.
Responsibilities :
Responsible for writing reusable, testable, and efficient code.
Should design and implement low-latency and high-availability applications.
Create and customize web crawlers and web spiders to extract structured and unstructured data from web.
Use NLP techniques to improve and refine the crawled data.
Build/maintain ETL infrastructure for the analysis of crawled data.
Develop APIs that interact with other applications.
Knowledge of OLAP and ETL processes is an added advantage."
Data Engineer - AI,"Bengaluru, Karnataka",SnapHunt Pte Ltd,None,Organic,"The Offer
Work within a rapidly evolving, fast-paced environment
Opportunity to be associated with an team that strives on innovation and growth

The Employer

Our client is a venture capital firm that invests in startups with significant impact on society. They are committed to helping them reach the next level with highly unique perspective from investing in startups across 9 countries. With a wide range of startups, they are seeking for talented individuals for roles in their portfolio companies.
The Job
You will be responsible for :
Developing scripts to process structured and unstructured data.
Recommending, developing and implementing ways to improve data reliability, efficiency and quality.
Supporting translation of data business needs into technical system requirements.
Working with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.

The Profile
You possess a degree in Computer Science, Applied Mathematics, Engineering or related field.
You have prior experience within a Data Engineer or similar role.
Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.
Expertise in Artificial Intelligence (Neural Networks, Fuzzy Logic, Evolutionary Algorithms) and Big Data would be highly valuable.
You possess strong analytical skills and are comfortable dealing with numerical data
You are adaptable and thrive in changing environments
You enjoy finding creative solutions to problems

Ref :58088075

0.00-5.00 Years"
Data Scientist,"Chennai, Tamil Nadu",Jidoka Technologies,None,Organic,"We are looking for people with the right blend of technology skills, business knowledge and a passion for revolutionizing machine vision.
Explore and prototype solutions or products at intersection of computer vision, image processing, applied machine learning by leverage existing or new vision or machine learning algorithms.
Solid understanding on linear algebra, image processing, computer vision and machine learning knowledge.
Develop and prototype computer vision algorithms in Python or C++
Familiar with one or two deep learning frameworks: Tensorflow, Pytorch/Caffe2, Keras etc.
Hands on experience in one or more of the following areas: real-time object detection/segmentation/recognition/tracking, visual scene understanding, 3d vision, augmented reality
Minimum Qualifications
Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field OR Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field
Additional Preferred Qualifications
Experience with C++/CUDA/TensorRT and model compression is a plus

Send in your resume to Careers@JidokaTechnologies.com"
Data Scientist,"Noida, Uttar Pradesh",SearchUrCollege,None,Organic,"Profile Requirements
Analyze and dig out carefully vetted, actionable insights from (mostly! pre-cleaned) data.
Turn insights into precise changes in the system; applying a toolset including calculus, statistical modeling, advanced algorithms, and machine learning to create measurable dollar impact.
Scale and generalize forecasting models and optimization algorithms to handle requirements from new markets and clients.
Travel and engage clients directly to translate their business needs into implementable science.
Fundamental math and designing robust algorithms from scratch excites you (as opposed to just running boost.fit).
You care deeply about true measurable value, not just methods; and you are willing to go the many extra miles to create it.
You are hands-on, like to get in there yourself; and can take a vague problem all the way through to designing, implementing, and proving the solution.
You pay attention to writing clean, minimal code; bugs really bother you.
You are pragmatic and have an eye for detail.
Solid understanding of machine learning fundamentals, probability, and algorithms.
At least 1-year of experience coding in R/Python .
1 – 3 years of experience in building analytical models; familiarity with common machine learning techniques.
Experience in C a big plus.
Experience in statistical inference and causal experimentation design a big plus.
Knowledge of data visualization tools like Tableau/Power Bi etc will be an added advantage
Pay Scale : 4.8 Lac – 13.0 Lac
Positions : 3"
Data Engineer - Analytics,"Bengaluru, Karnataka",Oracle,None,Organic,"Data Engineer - Analytics-20000HPW

Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications

Our Team
The Horizon Datastore team is responsible for driving growth, managing capacity and driving down the operational challenges of Oracle Cloud Infrastructure business with data driven insights from telemetry and business data sources. The Horizon Datastore is built on Oracle Cloud Technologies such as Autonomous Data Warehouse and Oracle Analytics Cloud.
Some of the main Objectives of the Horizon Datastore are:
Efficiently load and transform data into a DWH
Provide advanced orchestration to use Data Lake based approach
Integration with Oracle Autonomous DataWarehouse, Object Storage and Oracle Data Catalog
Data movement in both batch and real-time change data capture
Leverage Big Data technologies (Spark) to ingest, clean & transform data
Apply Machine Learning on DWH to proactively figure out issues
Your Opportunity
You will be responsible for applying your extensive knowledge as a data engineer and architect the Horizon Datastore. You will solve difficult problems in distributed highly available services and virtualized infrastructure which you would need to solve with DWH, Spark and ML technologies.
Our Ideal Candidate
We are looking for a strong Data Engineer who thrives on research and development projects. Be technically strong and hands on, who works efficiently with other product groups and data architects and engineering leaders to make sure we are building the right product and services using the right design principles.
Your Responsibilities
As an integral part of the OCI development team, the Data Engineer at Oracle Cloud Infrastructure will participate in
Building global scale data ingestion, analytics and prediction frameworks for Oracle Cloud Infrastructure (OCI) and its customers.
Build flexible and scalable solutions for sourcing and ingesting Petabytes worth of structured and non-structured data.
Design, build and maintain data warehouse, organize data into subject areas, understand data consumption and data visualization components using core Oracle technologies.
Work closely with business teams to develop these platforms that will drive the next generation of data science and predictive insights/intelligence.
Working directly with architects to ensure newer capabilities are built applying right design principles
Working with remote and geographically distributed teams to enable building the right products, using the right building blocks and making them consumable by other products easily
Be very technically hands-on and own/drive key end to end product/services
Ensure customer success including delivering fixes/patches as needed
Basic Qualifications
BS/MS/PhD in Computer Science or related fields.
6+ years of data management and engineering
6+ years as a Data Engineer working with Petabyte scale Data Warehouses and Data Lakes
6+ Years hands on experience with PL/SQL, ETL design and Orchestration
6+ years of data profiling, data validation and performance improvement experience for Analytical and OLTP systems
6+ years of Object Oriented software development experience, Java/Python
Strong problem solving, troubleshooting and analytical skills.
Ability to quickly learn new technologies in a dynamic environment.
Good organization, communication and interpersonal skills.
Prior experience with Agile process
Preferred Qualifications
Experience with Oracle suite of products including Oracle Database, Oracle Autonomous Data Warehouse, Oracle Application Cloud, Oracle Data Integration, OBIEE
Hands-on hardware management and operating systems experience (Unix, Linux)
Hands-on experience working with cloud technologies (OCI, AWS, Azure, GCP)
Detailed Description and Job Requirements
Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience."
Software Engineer (Backend - Data Infrastructure) - Bengalur...,"Bengaluru, Karnataka",Teikametrics,None,Organic,"About Us:

Teikametrics is a leading maker of e-commerce AI. We’re a diverse group of individuals who champion passion, character, and talent as the core tenets to creating profitable and long-lasting businesses.

Our AI helps the sellers (both large and small) on e-commerce platforms by providing deep performance analytics at a product level, as well as support for complex decision-making through a combination of econometrics and machine-learning, in a simple SaaS interface. Our software enables these independent brands to optimize their advertising, forecast demand, detect product issues and maximize overall profitability. While still at start-up size (<150 employees), the company has significant annual-recurring-revenues, and has recently raised two rounds of investment to fuel growth.

Leading sellers and brands such as Lego, Power Practical, Zipline Ski, and Mark Cuban’s Brands, gain a competitive advantage and view of trends and optimization strategies to tackle the dynamic nature of today’s e-commerce markets. For more information, please do visit our website https://www.teikametrics.com/ <!-block->As part of our global expansion plans, we are hiring in our fast-growing Bengaluru office.

Software Engineer (Data Infrastructure):

Teikametrics is looking for a (senior or junior) software engineer with strong computer science fundamentals and a background in data engineering, API integration or data processing. This role will involve building and scaling large data pipelines or services that can crawl, process and ingest massive amounts of data from multiple sources. We analyze this data and provide insights to accelerate customer business growth using Data Science and Business Intelligence.
Current data ingestion technologies at Teikametrics consist of Scala, Kafka, Rabbit, Postgres and S3 on a completely cloud based solution. The data warehousing is powered by Snowflake at the core with the data being surfaced in Mode and Sigma reports and transforms managed by DBT (Python, SQL). The architecture and stack evolve continuously as the solutions are scaled up to cater to ever-increasing customer base.

Qualified candidates should have:
2-8 years of experience working as a professional software developer. Position is flexible for juniors to seniors.
Experience with Scala, Haskell, Java or related languages
Worked upon data ingestion from public/private APIs, using OAuth or other authentication mechanisms
Knowledge of databases and experience with writing code that interfaces with the database layer - SQL/RDBMS and NoSQL
Hands-on experience with queueing systems like Kafka, RMQ etc.
Experience with stream-based data-processing at scale (Spark, Flink, Dataflow, EMR, etc.), or working with cloud based infrastructure (Docker, Kubernetes, Heroku, Aiven etc.) is an added plus
Experience writing well designed and testable code, and writing effective unit and integration tests.
Passion for working with a small team of world-class developers, solving challenging problems.
A desire to work in a collaborative environment focusing on continuous learning; participating in mentoring, tech talks, documentation, code review, and some pair programming.


Benefits:

You will be joining us at the perfect stage in our company as we are neither a struggling startup, nor a slow moving established company. You not only get to see all aspects of the product but also learn how a company is built and scaled from ground up.

You will also have a great pay, respectable work-life balance, flexible office hours and vacation time."
Workday Reporting Specialist,"Bengaluru, Karnataka",Rolls-Royce,None,Organic,"Job Description
Rolls-Royce is a world-leading provider of power systems and services, for use on land, at sea and in the air. We're proud to have a strong presence and an 80-year heritage in India and are excited about our growing future in Bengaluru. Through innovative solutions and diverse, globally renowned products, we've been focused on the growth of the aerospace sector in India. Powering more than 50% of Wide Body Aircraft to and from India, we are poised to become an engineering hub in the region and are committed to growing our local footprint for high-end technology.
As a Workday Reporting Specialist, you will be the member of the Global People Analytics Team, reporting to the People Analytics Team Leader. You will operate globally working with stakeholders inside the HR function and in the wider business community. You will be responsible for the development, implementation and maintenance of Workday custom reports, dashboards, scorecards, metrics and Prism analytics. You will be a confident communicator who can help stakeholders understand report configuration use. You will be expected to keep up to date with the Workday solution so that future enhancements can be introduced to Rolls-Royce reports as appropriate. You will be expected to be a subject matter expert on Workday reporting, calculated fields, dashboards and metrics with knowledge of Workday security, worksheets, Prism and augmented/ people analytics.
Key Accountabilities
Development and maintenance of Workday reports, dashboards and Prism analytics.
Working with key stakeholders to determine reports and dashboard requirements.
Producing high-quality and customer friendly Workday dashboards and visualizations
Support moving customers to self-service deliver model
Reviewing reporting suite to maximize system performance
Qualifications & Experience
Bachelors Or Masters (Computers Science / IT Preferred) with 5-7 years’ experience working with Workday reporting and calculated fields in a medium to large organization
1-2 years’ experience of Workday Prism
Knowledge of Workday security, worksheets and integrations
Experience of working remotely in Global teams
Minimum 5 years of experience in data analysis
Excellent analytical skills
Excellent spoken and written English, Strong communication skills
Excellent knowledge of Excel
Excellent knowledge of database joins preferably (Oracle SQL Developer)
Working knowledge of Power BI
Attention to details, Eagerness to learn and grow
We offer excellent development prospects, along with a competitive salary and exceptional benefits.
Pioneer optimum performance. Join us and you’ll develop your skills and expertise to the very highest levels, working in an international environment for a company known the world over for brilliance and innovation.
Beyond Tomorrow.
We are an equal opportunities employer. We’re committed to developing a diverse workforce and an inclusive working environment. We believe that people from different backgrounds and cultures give us different perspectives. And the more perspectives we have, the more successful we’ll be. By building a culture of respect and appreciation, we give everyone who works here the opportunity to realize their full potential.
You can learn more about our global Diversity and Inclusion strategy here
At Rolls-Royce we also support requests for flexible working arrangements wherever possible.
Job Category
Human Resources
Posting Date
13 Aug 2020; 00:08"
Senior Data Scientist,"Bengaluru, Karnataka",McAfee,None,Organic,"Job Title:
Senior Data Scientist

Location:
India, Bangalore
Role Overview:
As a senior data scientist of the Business Intelligence team, reporting into Senior Engineering Manager of Business Intelligence, the focus of this opportunity is to understand the business, product and develop insights using advanced data science algorithms from a cloud data infrastructure. You will work with global teams, engage with product, marketing and leadership teams to create insights out of data from cloud data store. You will work on data analysis, drive insights using statistical models, communicate insights around opportunities and anamolies.

Company Overview
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.
About the Role:
You will understand the product, business and data processes.
You will perform data analysis, discuss with leadership and partners to determine the focus area
You will develop insights into opportunities of business growth, customer centricity, obsession and product insights using advanced data science statistical models
Develop machine learning models that use our unique combination of threat data, user behaviour and subscription data to improve consumer value from our products
Provide data-based intelligent personalization in all our touch points consumer including marketing, product and customer service
Mine, analyse and build predictive and descriptive machine learning models on structured and unstructured data sources
Use code (Python, R, Scala) for analysing data and building statistical models.
Apply or design creative models for predictive learning, forecasting, recommendations, content ranking, and anomaly detection.
Use machine learning to help us anticipate and cater to consumer's personalised needs for threat protection.
Use data and machine learning to create unique and personalised experiences for consumers across multiple touch points with McAfee.
Create algorithms for optimising consumer journey and increasing conversion and monetization
Perform statistical analysis on the outputs of these machine learning models to help update, re-train, and then deploy new ML models
Contribute to the creation, deployment, and scaling of machine learning and predictive algorithms in a production environment
You will report to Engineering Manager
Help identify new opportunities for applying machine learning and statistics-based models for improved customer and outcomes
About You:
You have 5+ years of experience as a data scientist.
You are proficient in designing, analysing and troubleshooting controlled experiments (causal A/B tests, multivariate tests).
You have knowledge and specialist at mentoring other team members in the use of data science tools such as R, Python, SQL, MapReduce, Hadoop, Hive and Big Data technologies.
Experience with applied machine learning (like scikit-learn) and deep learning frameworks (like Keras, tesorflow or PyTorch).
Experience in optimization mathematics (linear programming, nonlinear optimization)
Experience working with large amounts of structured and unstructured data in a consumer-facing online business required.
You have experience with machine learning.
Experience with natural language processing (NLP) and text mining.
Experience with statistical modelling, and hypothesis testing.
A track record for creating raw data and analysis into well-written content.
You are a specialist in gathering requirements, prioritisation, and leading projects.
Company Benefits and Perks:
We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.
Job Type:
Experienced Hire
Primary Location:
India, Bangalore

Additional Locations:"
AI Developer,"Pune, Maharashtra",GrayRipples.com,"₹40,000 - ₹50,000 a year",Organic,"Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Salary: ₹40,000.00 - ₹50,000.00 per year
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
java: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Indore, Madhya Pradesh",GenieTalk,None,Organic,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore | Openings"
Applied Scientist Intern,"Hyderabad, Telangana",Amazon Dev Center India - Hyd,None,Organic,"A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
Experience in predictive modelling and analysis, predictive software development
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills

Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches

Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences"
Python Developers,"Bengaluru, Karnataka",Careator Technologies,None,Organic,"Greetings from Careator Technologies Private Limited., (CTPL).

CAREATOR Technologies is an emerging technology company, based on the strengths of understanding evolution of technologies right from the inception stage, offers a wide spectrum of services that span across both Application Life Cycle Management process of Software Engineering and Resource Management of Projects that deliver complex IT solutions for critical business processes. We @ CAREATOR, closely work with best MNCs (Product Based Companies & Service Based Companies) in India, UK, Australia, Canada & USA. CAREATOR is always been successful in meeting their customer needs and follows best IT practices to retain the right talented professional

We are hiring the following professionals on immediate basis. If you are interested and suitable for this position, please apply immediately.
Python Developers –
Location – Bangalore
Experience: 1-3 Yrs
No of position - Multiple
Python Developers with 1-3 years of experience in Data Science/ML/ AI related projects using Scipy, Numpy, Keras, Django, NLP, Neural Networks, Tensor Flow. Job Requirements - · Proven experience working with Python (using Django and/or Flask) · Experience working on Neural Network, Tensor Flow, Scipy Keras. · Exposure to working with API's (preferable RESTful /SOAP API's) · Experience with database technologies, especially PostgreSQL/ NoSQL databases or other data-store solutions (e.g. MongoDB, CouchDB) · Automated unit test frameworks and test coverage tools
Product Development background is required.
Analytics/Stats backgrond is a plus, and a close match always."
Principal Data Scientist,"Bengaluru, Karnataka","Cornerstone OnDemand, Inc.",None,Organic,"We're looking for a
Principal Data Scientist ( Bangalore, India)
Be a senior member of the Big-Data Machine-Learning Data Science team, and contribute to the R&D. The work centers around machine learning algorithms and data analysis techniques - especially natural language processing and deep learning.

In this role you will...
Working very closely and collaboratively with team-members in the big-data Machine-Learning Platform team.
Work on NLP through deep learning techniques towards building next-gen products on employee workforce predictive insights.
Perform preliminary data analysis to discover hidden correlations and come up with prototype models.
Work with the team for the development of at-scale efficient machine-learning-models to be able to handle large volumes of data that will be integrated with the MLP.
Active participation in the technical discussions.
You’ve got what it takes if you have...
We are looking for a candidate with a strong background in Natural Language Processing techniques and Deep-Learning using PyTorch. In particular, the candidate should have work experience with:

PyTorch and its ecosystem of libraries.
Word and document embeddings.
Transformers and Attention.
RNN, LSTM.
A background in BERT and its variants.
transfer-learning practices.
nltk.
genism
Besides this, the candidate must possess a mature understanding of, and hands-on experience in, the broad field of machine-learning and statistical methods. Must be conversant with:
scikit-learn
pandas
numpy
plotting using matplotlib, seaborn, etc.
Experience with any of the following is considered a plus:


Tensorflow
Big-data and PySpark
Beautiful Soup or Scrapy
NetworkX
R libraries
Test-driven development
Data-pipelines
Taking models to production
Java programming
GCP
Our Culture:
Our mission is to empower people, businesses and communities. A culture created less by what we do and more by who we are. When people are asked to describe the team, the answer is always the same: smart, cool, dependable, and visionary. We are not a typical tech company (paid sabbaticals, generous stock units, education reimbursement, and 100% paid employee health coverage), because, well, our employees aren't your typical techies... We're always on the lookout for new, curious and capable people who can help us achieve our goal. So if you want to work for a friendly, global and innovative company, we'd love to meet you!
What We Do:
Cornerstone OnDemand (NASDAQ: CSOD) was founded with a passion for empowering people through learning and a conviction that people should be your organization’s greatest competitive advantage. Cornerstone is a global human capital management (HCM) leader with a core belief that companies thrive when they help their employees to realize their potential. Putting this belief into practice, Cornerstone offers solutions to help companies strategically manage and continuously develop their talent throughout the entire employee lifecycle.
Cornerstone’s HCM platform is successfully used by more than 75 million people in 180+ countries and in nearly 50 languages.
Check us out on Linkedin, The Muse, Glassdoor, and Facebook!
Cornerstone takes special care to ensure the security and privacy of the data of its users."
Associate Professional Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Assists in the application of data analysis and data modeling techniques to establish, modify, and maintain basic data structures and their entity descriptions, relationship descriptions, and attribute definitions according to client specifications.
Assists in the analysis and validation of basic database structures, models and processes to ensure definition according to business objectives and operations.
Communicates with clients about matters of significance and discrepancies related to data to ascertain correct information and correct errors.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science or related field preferred
Zero or more years of experience in programming or data analysis
Experience working with relevant programming languages and relational databases
Experience working with data modeling practices and procedures
Experience working with company software and hardware products
Other Qualifications
Basic research and data analysis skills
Communication skills to communicate with designers, management and customers
Personal computer and business solutions software skills
Ability to work in a team environment
Work Environment
Office environment"
Analyst - One ERP ( m/f),"Oragadam, Chennai, Tamil Nadu",Danfoss,None,Organic,"Job ID: 13240
Job location(s): Oragadam, IN
Job Description
We are currently looking for an Analyst One ERP (m/f) with global responsibility for our location in Chennai, India.


We are looking for an Analyst with data science experience that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. In this role, you will work with business teams from Global Planning & Logistic area to implement new solutions. You will work directly with large, different data sets and analyse them using the latest modelling techniques. You must be comfortable working with a wide range of stakeholders and functional teams to drive business results with their data-based insights. As a team, we will develop and build recommendations for automation, data integration and machine learning.
Job Responsibilities
Identify use cases - work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
Processing, cleansing, and verifying the integrity of data used for analysis
Data mining using state-of-the-art methods
Selecting features, building and optimizing classifiers using machine learning techniques
Creating visualizations of complex data sets for easy of understanding by business partners
Doing ad-hoc analysis and presenting results in a clear manner
Enhancing data collection procedures to include information that is relevant for building analytic systems
Creating automated anomaly detection systems and constant tracking of its performance
Analyse, Manipulate, and Validate data using SQL, R, Python, and other analytical tools
Develop, test, and pilot your solutions
Background & Skills
Bachelors / Masters with focus on Statistics, Mathematics, Economics or Business preferred
Experience with data analytics
Experience in machine learning and neural networks
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets
Experience with data visualization tools
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Experience working with and creating data architectures
A drive to learn and master new technologies and techniques

Capabilities/Mindset
Great communication skills
Data-oriented personality
Strong problem-solving skills
Self-motivated

Optional:
Big data tools (Apache Spark, Hadoop)
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Danfoss – Engineering Tomorrow
At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways – driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.

Following our founder’s mindset ‘action speaks louder than words’, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030."
Data Scientists,"Bengaluru, Karnataka",Bloom Consulting Services,None,Organic,"Data Scientists:
Our Data Scientists are quantitative analysts who can extract meaningful insights from customer data, and leverage predictive models to optimize business performance. They support Risk management, Marketing, Capital Markets, Operations and Finance teams. This is a strategic role that sits at the heart of value creation by turning data into a long term competitive advantage.
As a Senior Data Scientist you will...
Drive the evolution of best in class Channel Analytics by:
Working with Tech & Data teams to define requirements and review solution builds
Applying insights from customer response data to build response and targeting models
Building Attribution Models and optimising offline and online Marketing Mix to drive growth
Developing and applying real time links between spend across channels and response patterns
Working with Tech and Operational teams to ensure identified wins are deliveredManaging and mentoring direct and indirect reports to deliver significant increases in productivity
Deliver cutting edge models using the latest techniques and upskill the team: Use advanced statistical analysis to design testing and predictive models whilst creating and improving on best practices to be used across the Funding Circle analytics community
Drive thought leadership across the business: Recommend optimal business strategies based on historical performance, predictive analytics and scenario analysis
Build global frameworks that are scalable across markets and help to drive business outcomes & portfolio performance
Work closely with partner teams across business and risk to ensure analytical outputs meet stakeholder expectations
Communicate effectively analytical outcomes to wide variety of internal and external constituents including senior stakeholders
Up to 20% travel

You’ve been there and done this:
Demonstrable strong Machine learning/AI experience along with proficiency in analytical tools like R and Python, Excel VBA, Tableau, SQL
Demonstrates strong knowledge of data architecture, modelling techniques, consumer behaviour patterns and the key drivers of marketing or credit performance optimization
Has exceptional analytical skills with an advanced degree in a quantitative field like mathematics, physics, computer science, statistics, economics, econometrics etc
Have strong experience in a channel or product analytics role in a major digital or financial services organization with demonstrated track record of data science delivery in channel analytics, marketing analytics and/or risk analytics
Possesses strong interpersonal skills and the ability to communicate effectively to technical and non-technical audiences
Identifies with our mission, “to build a better financial world”

For Data Scientist
Python-Anaconda (Framework)
Gradient boosting and random forest (Algorithms)
Data and Statistical modelling
AWS SageMaker (Machine learning)

What You Need for this Position
You should have knowledge of:
Python-Anaconda (Framework)
Gradient boosting and random forest (Algorithms)
Data and Statistical modelling
AWS SageMaker (Machine learning)
Aditional
No. of Positions
Education level
Career level
Experienced"
Data Scientist,"Mumbai, Maharashtra",Boston Ivy Healthcare Solutions Pvt Ltd (Medikabaz...,None,Organic,"Must be able to handle periods of high stress.
 Strong analytical and problem solving skills.
 Excellent interpersonal and communication skills to effectively handle any business need.
 Knowledgeable in software development processes & lifecycle management.
 Demonstrated experience in effectively presenting technical information to non-technical audience
 5-10 years of experience in applying concepts in Data Science, Machine Learning, Algorithm development, Advanced Computing or Statistical Modeling to solve real-world problems
Work on complex, cross-functional analytical and research-oriented projects using advanced computational, machine learning and deep learning algorithms
 Work on a particular Data set or a Problem Statement
 Use relevant knowledge of machine learning and statistics to help build scalable Machine learning models and Processing Pipelines.
 Practical experience in at least one of the following programming languages: R or Python. Strong modelling skills and ability to build practical models using advanced algorithms such as Random Forests, SVM, Neural Networks. Familiarity with algorithms in recommendation systems, chatbots or structuring NLP centric processing pipeline as well as Computer Vison. Knowledge of big data frame-works such as Hadoop/Spark is a bonus. Familiar with implementing organizational processes using tools like Asana/Git/Docs/Slack/etc.
Job Types: Full-time, Volunteer
Experience:
total work: 7 years (Preferred)
Education:
Bachelor's (Preferred)"
Data Scientist,"Ahmedabad, Gujarat",Azine Web Technologies,"₹30,000 - ₹50,000 a month",Organic,"We are looking for a Data Scientist to analyze large amounts of raw data to find patterns that will help improve our processes. We will rely on you to build data products to extract valuable business insights.
In this role, you should be highly analytical with a knack for math, statistics and reporting. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for learning and research.
Your goal will be to help our company analyze trends and use the right technology to make better decisions.
Responsibilities
· Identify valuable data sources and automate collection processes
· Undertake preprocessing of structured and unstructured data
· Analyze large amounts of information to discover trends and patterns
· Build predictive models and machine-learning algorithms
· Combine models through ensemble modeling
· Present information using data visualization techniques
· Propose solutions and strategies to business challenges
· Collaborate with engineering and product development teams
Requirements
· Proven experience as a Data Scientist or Data Analyst
· Experience in data mining
· Understanding of machine-learning and operations research
· Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
· Experience using business intelligence tools (e.g. Tableau) and data frameworks like Mongo DB
· Analytical mind and business acumen
· Strong math skills (e.g. statistics, algebra)
· Problem-solving aptitude
· Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred
Job Type: Full-time
Salary: ₹30,000.00 - ₹50,000.00 per month
Experience:
total work: 5 years (Preferred)
Data Analysis: 4 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
No"
Python Developer,"Coimbatore, Tamil Nadu",CDS,None,Organic,"Any Computer Science Graduate with 2+ years of working knowledge in web crawlers, web scrapers and other web tools which helps in extracting the web content using Python.
Should be expertise in Python Coding.
Should have knowledge in scraping frameworks such as Scrapy, Beautiful Soup, HTQL, Jsoup, Web-Harvest and others.
Understanding of XML, HTML5, CSS and JSON objects.
Experience with SQL and NoSQL databases.
Should be familiar with event-driven programming in Python.
Responsibilities :
Responsible for writing reusable, testable, and efficient code.
Should design and implement low-latency and high-availability applications.
Create and customize web crawlers and web spiders to extract structured and unstructured data from web.
Use NLP techniques to improve and refine the crawled data.
Build/maintain ETL infrastructure for the analysis of crawled data.
Develop APIs that interact with other applications.
Knowledge of OLAP and ETL processes is an added advantage."
Data Scientist,"Noida, Uttar Pradesh",Jubna,None,Organic,"Job ID: JDS01
As a Data Scientist, you will work to resolve ambiguity with data, play a crucial role in the iteration and optimization solutions, and support data-driven decision-making across the organization.
ROLE RESPONSIBILITIES
Tasked with solving a real-life business problem that requires a processing/analyzing large amounts of data and handling a variety of data sources.
Take ownership of successful completion for the end to end life cycle and implementation.
Proactively investigate, report, and where possible, address data quality issues.
S
Can envision & implement the optimal analytics technique/approach required for the problem.
Ability to work and execute projects on both structured and unstructured data in a big data environment.
Ability to work across geographies and interact with global stakeholders.
Ability to coordinate and work within multiple business units from a project management perspective.
Prior experience working in Agile methodologies/JIRA would be a plus.
MINIMUM REQUIREMENTS
BS/BE in Computer Sciences, Math, Statistics, or related field. Masters preferred.
An expert in at least one of the machine learning frameworks - Keras, Tensorflow, PyTorch, etc, as well as programming, visualization, and statistical tools such as R, JMP, SAS, Tableau, Python, Perl, Java/C++
Minimum of 4+ years of experience in data, advanced analytics, data science, and business intelligence.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases.
Proficient in Python ML libraries, Hadoop/Redshift/BigQuery.
Experience in the Ad-Tech industry is a must.
OTHER INFORMATION
Join a fun and lively young Startup based in Dubai Silicon Oasis (while operating from Noida, India). Boost your experience and learn about the different types on Online AdTech environments and models. Show your skills and potentially become a pillar of our fast-growing team.Jubna offers an Attractive compensation, Health Insurance, Travel Allowance.
Some travel to Dubai, UAE is required (10%)"
Lead Data Scientist / Machine Learning Expert,"Bengaluru, Karnataka",Bidgely,None,Organic,"Position
Bidgely is looking for extraordinary and dynamic Data Scientists to be part of its core team in Bangalore. You must have delivered advanced statistical and machine learning models as part of commercial products and created substantial intellectual property with business impact. You must enjoy working with large data and finding interesting patterns in the data through analytics experiments in a methodical and data driven scientific way. Be part of a highly energetic and
Responsibilities
Lead a team of data scientists to delivery energy analytics models and solutions from ideation to production quality code.
Provide technical direction and mentorship to the team, as well as hands-on management.
Research and develop advanced statistical and machine learning models for analysis of large-scale, high-dimensional data.
Dig deeper into data, understand characteristics of data, evaluate alternate models and validate hypothesis through theoretical and empirical approaches.
Collaborate with product management and engineering teams to elicit & understand their requirements & challenges and develop potential solutions
Stay current with the latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.
File patents for innovative solutions that add to the company portfolio.
Requirements
6-9 years of strong experience in data mining, machine learning and statistical analysis.
BS/MS/PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)
Ability to lead and deliver in a fast paced start-up environment.
Fluency in tools such as Matlab, Python etc.
Strong intuition for data and Keen aptitude on large scale data analysis
Excellent written and verbal communication skills.
Ability to collaborate across teams and strong interpersonal skills.
Email
To apply for this position, please email your resume to [email protected]."
Jr.Data Scientist,"Hyderabad, Telangana",Infogrex Technologies Private Limited,None,Organic,"The Job: Â

As a Junior Data Scientist, you will be responsible for analysing trends and creating insights to promote smart decision-making towards improving products and business decisions.

You will also be responsible for:
â€¢Building a Data Science Framework designed to handle large volume data sets
â€¢Communicating insights and findings in a simplified manner.
â€¢Assessing the effectiveness and accuracy of new data sources and gathering techniques and providing timely communications on significant issues and developments.
â€¢Developing customised data models and algorithms to apply to data sets.
â€¢Working with cross-functional teams to assess data science use cases and Product-Market fit.

The Profile: Â

â€¢You possess a Degree/Masters from a top-tier institute, ideally in Computer Science, Data Science, Mathematics or similar field.
â€¢You have at least 1 year experience, ideally within a Statistician role.
â€¢You possess strong knowledge of R, Python and SQL and experience in building and scaling models for time series.
â€¢Strong expertise in Math/ Statistics, Machine Learning and Predictive Modelling (Regression, Neural Networks etc) would be highly valuable.
â€¢You have strong interpersonal and communication skills and are adept at working with multiple stakeholders to drive desired outcomes
â€¢You possess strong analytical skills and are comfortable dealing with numerical data
â€¢You pay strong attention to detail and deliver work that is of a high standard
â€¢You are a creative problem solver and can multitask in fast-paced environments.

0.00-2.00 Years"
Connected Car Data Scientist,"Bengaluru, Karnataka",Mercedes-Benz Research and Development India Priva...,None,Organic,"Aufgaben
Job Description: Data Scientist

Education & Training
Bachelor’s degree or Masters in Computer Science/Statistics/Mathematics
Experience
7 to 9 years of experience in executing data-driven solutions to increase efficiency, accuracy, and utility of internal data processing.
Experienced at creating data regression models, using predictive data modeling, and analyzing data mining algorithms to deliver insights and implement action-oriented solutions to complex business problems.
Proficient knowledge in statistics, mathematics and data analysis
Excellent understanding of business operations and analytics tools for effective analysis of data
Experience on optimized data collection procedures and generate reports.
Experience on building predictive models and machine-learning algorithms.
Experience in designing complex reports such as Drill-down, Drill-through, Cascading, Matrix, cross tab and Map reports using Power BI or Tableau
Expertise in data storage structures, data mining, and data cleansing
Systematic problem-solving approach with strong communication skills and a sense of ownership and drive
Skills
Primary Skills
Strong hold of concepts in Statistics
Strong programming skills in R, Python, Java
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark.
Proficient with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data
Proficient in with SQl Databases like MSSql, Postgres.
Have a good exposure to Azure Analytics Products like, Data Factory, HD Insights, Azure Data Lake Storage, Data Bricks.
Experience on different data visualization tools like PowerBI , Tableau.
Secondary Skills
Tools - Qliksense , Tableau
Kusto Query Language
Job Responsibilities
Supporting the analytics needs of business by analyzing data from multiple sources
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Support in collecting, organizing, and interpreting data along with fellow colleagues.
Build predictive models and machine-learning algorithms
Use machine learning tools and statistical techniques to produce solutions to problems
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Qualifikationen
Job Responsibilities


Responsible for installation, maintenance, and providing support for Application Performance Monitoring and Instrumentation with the primary focus on AppDynamics and Azure Monitor.
Help define and implement best practices for Production Application Management monitoring
Assist engineers with production Infrastructure Monitoring
Ability to develop necessary POCs & POVs in sandbox/testing environment
Ability to support setup and configuration of the APM tool
Assist in building an APM Centre of Excellence
Operating system and server architecture knowledge of UNIX/Windows/virtual systems
Assist development teams with application and server troubleshooting and diagnostics
Programming automation (VBA /VB.Net, JAVA or major scripting languages such as Perl and Python, Unix/Linux shell scripts)"
Financial Analysis - Associate,"Mumbai, Maharashtra","JPMorgan Chase Bank, N.A.",None,Organic,"Job Responsibilities:
Design data visualizations in Tableau & QlikView and prepare high quality dashboards for various stakeholders including senior management
Good experience of working with large volume of data and creating high performance complex visualizations using multiple charts and calculations
Good experience in a fund accounting or custody/fund accounting environment
Knowledge of financial instruments and their accounting treatment
Design and maintain scripts in Alteryx to eliminate manual intervention
Learn and understand the business process and develop good understanding of data
Analyze, Design, Develop and execute automation framework/scripts, tests, debugs and documents programming to satisfy business requirements
Work with finance managers to understand the process, pain areas and propose and execute automation by leveraging Alteryx, Xceptor, VBA and Python

Requirements
Bachelor's degree in Information Science / Information Technology, Computer Science, Engineering, Mathematics, Physics, or a related field
Advance knowledge of Tableau, QlikView, QlikSense, Alteryx, Xceptor, VBA and Python
Experience with machine learning algorithms, such as neural networks/deep learning, SVM, Random Forest, linear regression, etc.
Excellent analytical and problem-solving skills. Ability to learn the process and it's nuances and propose and execute solution to make the process efficient
Team player - Ability to work in an Agile Team and follow common good practices
Excellent communication skills - written and verbal. Communicate in an effective manner
Excellent relationship building skills, strong ability to develop partnerships to drive results
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Lead Data Scientist,"Pune, Maharashtra",Qualys,None,Organic,"We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.

Responsibilities:
Designing and deploying deep learning algorithms and predictive models
Develop custom data models and algorithms to apply to data sets
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop processes and tools to monitor and analyze model performance and data accuracy
Collaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions

Qualifications:
7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred
Experience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Experience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Applied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.
Familiarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those
Experience with data cleansing, data quality assessment, and using analytics for data assessment
Excellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.
Ability to drive a project and work both independently and in a team"
Machine Learning Engineer,"Chennai, Tamil Nadu",Quantrium Tech,None,Organic,"Job Description :


We are looking for outstanding engineers to implement the novel machine learning models for various complex problems and use cases for our clients and products.
Our work might involve efficiently implementing an idea from a new research paper, building new tooling to help optimise a large scale workflow or working out how the latest open source machine learning technologies can be applied to our problem space.
We work very closely with our technology researchers and adapt the direction of our work as exciting new ideas emerge. You will be a part of a team that handles all the processes from data collection, cleaning, and preprocessing, to training models and deploying them to production.
The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field.

Who are we looking for?


The candidate should have knowledge in some of these areas, should have interest and desire to learn the others:
Knowledge of numerical programming, in Python using libraries such as Pandas, NumPy and tools such as Anaconda, Plotly, etc.
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability
Implemented deep learning solutions either commercially or as a personal project.
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Experience working with deep learning frameworks such as TensorFlow, Keras or PyTorch.
Experience working closely with data scientists or quantitative researchers in a research directed environment.
Experience with distributed compute platforms including areas such as package management, security implementation and containerisation (Docker).
Demonstrable ability to engineer high-quality maintainable software and experience with automated testing and continuous delivery (CI-CD).
The confidence to experiment with new ideas and technologies.
Ability to engineer and own solutions that will be relied upon by many users and deployed to machines in large compute clusters.
Knowledge of version control with branching and merging in GitHub or BitBucket.
Experience in working with cloud computing. (AWS, Google or Azure).
Implementing microservices in Python for serving ML models using Flask or equivalent framework.
Knowledge of Test Driven Development (TDD) using Pytest or Unit test in Python.
Technical writing is a nice to have skill for writing technical documents, process notes, technical blogs, development stories, etc.

For any candidate, this is a challenging role requiring you to combine technical knowledge and engineering skills with the ability to understand the hard data science challenges facing our researchers.

Qualification :


Engineering Graduate - B.E. / B. Tech. (Computer Science or IT)
Application Procedure :


To apply for this job, fill this application form here. The selection process consists of the following steps:
Shortlisting of Profiles (Resume) - Shortlisted based on information provided by you in your resume.
Coding Round [1 Hour] - You will be provided with one or more use cases and data with access to a cloud instance. You need to write and execute the program to resolve the problem.
Technical Interview - This will happen immediately after you clear your Coding Round, you may be asked general technological questions, best practices, approaches and solutions you used to solve the problem given to you in the coding round.
Social Discussion - This is a more general cultural discussion round to understand your capabilities as a team player and assess your passion and appetite for technology and growth.

Interested candidates can send their resume to hr@quantrium-tech.com and can reach me at 9176663397"
Data Scientist,"Chennai, Tamil Nadu",Applied Data Finance,None,Organic,"We are looking for strong Data Scientists/Analysts, who will be problem solvers, using predictive modelling techniques and machine learning algorithms, to solve complex business problems in credit and risk domains, and also provide business strategies.
Roles and Responsibilities:
Use of cutting edge machine learning techniques for solving supervised and unsupervised learning problems
Design analytical solutions for complex business problems
Dig deep into data, understand characteristics, evaluate and validate hypotheses through empirical approaches
Recommend and implement best practices around application of statistical modelling
Develop and implement predictive models solving business problems and recommend actionable insights
Mentor and train new recruits
Qualification & Experience
2+ years of experience in the field of analytics, predictive modeling or data science
Strong with programming languages like Python and data processing using SQL or equivalent
Strong with analytical and statistical packages like R, Python Scikit-Learn
Additional familiarity with C/C++ welcome
Experience with the following machine learning algorithms desirable: Gradient Boosting, Decision Trees, Logistic Regression, Random Forests, Deep Neural Networks, Ensemble methods
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com."
SENIOR DATA SCIENTIST,"Chennai, Tamil Nadu",The Data Team,None,Organic,"Location: Chennai / Bangalore

The Data Team is a boutique consulting firm with strong expertise in big data and data science. The Senior Data Scientist is a key role in the organization, and will be leading project delivery on data science projects or data products. The Senior Data Scientist is an important role within the organization responsible for providing expertise, thought leadership, mentorship and leadership in the area of statistical analysis, data analysis and data science. Accordingly senior data scientists are expected to a hands-on practitioners in business analysis, hypothesis generation, data preparation, relational modelling, statistical modelling, algorithm design and scalable machine learning and deep learning. They’ll be expected to provide deep expertise in these areas. In addition, Senior Data Scientists are expected to mentor data analysts and data scientists on project deliverables, and ensure quality and timeliness in the output. The Data Team offers high-impact work with diverse opportunities in the areas of data science for Senior Data Scientists to grow into roles such as business consulting. Prior experience in doing data science and managing data science teams is required for this role. Experience in working on large scale Hadoop databases is required for this role. Past experience in bots and API development, test driven development, continuous delivery are preferred. Client facing skills are considered a plus.

Required Skills
True depth of knowledge in statistics, machine learning, cloud platforms and databases
Critical thinking skills in business with the ability to confidently face clients and mentor data scientists
A highly imaginative mind set and the ability to formulate new and relevant hypotheses from the data
Ability to perform advanced statistical analysis on diverse data sets in Python, R, Scala and Java
Ability to implement scalable machine learning and statistical analysis algorithms with frameworks such as Spark, Tensorflow or Torch
Current knowledge of cloud technologies and architectures such as on Azure, and hands on skills in implementing machine learning algorithms at scale
Expertise validating and critically evaluating machine learning algorithms and their performance
Ability to work in a Linux environment, on cloud-based virtual machines and containers
Should have managed a team in past roles in a managerial setting, or directly faced clients
Excellent interpersonal, presentation and written communication skills
Education and Work Experience Requirements
Bachelor’s degree in computer science or applied mathematics (Master’s degree or PhD preferred)
Higher degree in business, statistics, machine learning or computer science is a plus
Between 8 and 10 years of demonstrated experience in the industry including significant prior experience in data analysis and data science
Relevant certifications in data science will be considered favorably"
Hiring For FREELANCE DATA ENGINEER - BANGALORE,"Bengaluru, Karnataka",Atyati Technologies,None,Organic,"Revonic (headquartered in Dubai) and Atyati (headquartered in Bangalore) are sister companies, both part of a private investment group, Metdist. The Group owns a portfolio of companies across various sectors in the Middle East, India and SE Asia with a core focus on capturing growth in these developing regions. Within the portfolio the Group looks for synergies between its investee companies by sharing resources, leveraging technology, local knowledge and best practice. The Group has been operating for over 70 years and is a long term business builder.

DATA ENGINEER
OBJECTIVE :We are looking for a data engineer that would like to join us on a freelance basis to work on different projects from a various set of large companies & partners that we work with.

Clients that we work with range from many industries like automotive, hospitality, retail, oil & gas to travel. The project will require data engineers who have at least 4 years' experience and we prefer that our data science team has vast experience in utilizing Microsoft Azure.

These projects can range from 1 month work all the way to 6 months of work. There is an outlook of definitive employment, once the economic situation improves globally.

RESPONSIBILITIES

* Manage data warehouse plans for a product or a group of products for multiple clients. * Interface with developers, engineers, project managers and data scientists to understand data needs. * Build data expertise and own data quality for allocated areas of ownership. * Design, build and launch new data models in production. * Design, build and launch new data extraction, transformation and loading (ETL) processes in production. * Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation * Support existing processes running in production. * Define and manage SLA for all data sets in allocated areas of ownership. * Establish Data Infrastructure to triage infra issues and drive to resolution. * Expert in developing roadmaps for with clients. * Able to manage expectations while working on multiple clients at the same time. * A desire to work in a collaborative, intellectually curious environment. * Ability to complete projects timely, accurately and with strong attention to detail, with continuous communication of progress updates to stakeholders

REQUIRED QUALIFICATION

* Industry experience as a Data Engineer with a track record of manipulating, processing, and extracting value from large datasets while maintaining the data infrastructure of all databases. * Experience building data products incrementally and integrating and managing datasets from multiple sources. * Experience building/operating highly available, automated, distributed systems of data extraction, ingestion, and processing of large data sets. * 4+ years' experience in the data warehouse space with tools like Amazon, Oracle, Red Shift, Azure, Teradata etc. * 4+ years' experience in custom ETL design, implementation and maintenance. * 4+ years' experience working with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark etc.). * 4+ years' experience with programming languages, Python preferred. Other Languages like R are a plus. * Hands on and deep experience with schema design and dimensional data modeling. * Ability to write efficient and advanced SQL statements. * Ability to analyze data to identify deliverables, gaps and inconsistencies. * Excellent communication skills including the ability to identify and communicate data driven insights. * Ability and interest in managing and communicating data warehouse plans internally and to clients. * Bachelor of Science in Engineering, Computer Science or Mathematics is required.

One of Revonic's services is to provide companies of all sizes with an infrastructure web services platform in the cloud (""cloud computing"").

As a Data Engineer with REVONIC, you will be working in an international, complex, and dynamic data environment. We are looking for an experienced Data Engineer with an uncanny ability to integrate multiple heterogeneous data sources to build efficient, flexible, and scalable data warehouse and reporting solutions. The ideal candidate has deployed analytics platforms to 5000+ users, optimizing the architecture for performance and positive end-user experience. You are enthusiastic about learning new technologies and implementing solutions using these technologies to empower internal customers and scale the platform. You demonstrate solid communication skills and the ability to partner with other colleagues across technical and non-technical teams to develop and define key business questions, then build the solutions that answer those questions.

In this role, you will serve as the expert in designing, implementing, and operating a stable, scalable, low cost environment to flow information from the data warehouse into end-user facing reporting applications such as Tableau or Microsoft PowerBI. Above all, you will bring large datasets together to answer business questions and drive data-driven decision making.


Salary: Not Disclosed by Recruiter
Industry:IT-Software / Software Services
Functional Area:IT Software - Application Programming, Maintenance
Role Category:Programming & Design
Role:Software Developer
Keyskills
Data ScienceGasMicrosoft Azure
Desired Candidate Profile
Please refer to the Job description above
Education-
Doctorate:Doctorate Not Required
Company Profile
Atyati Technologies Pvt. Ltd.
Revonic (headquartered in Dubai) and Atyati (headquartered in Bangalore) are sister companies, both part of a private investment group, Metdist. The Group owns a portfolio of companies across various sectors in the Middle East, India and SE Asia with a core focus on capturing growth in these developing regions. Within the portfolio the Group looks for synergies between its investee companies by sharing resources, leveraging technology, local knowledge and best practice. The Group has been operating for over 70 years and is a long term business builder."
Machine Learning Scientist (8 -10 yrs),"Chennai, Tamil Nadu","Agilysys, Inc.",None,Organic,"About Company

At Agilysys, Inc. we are proud of our 3,000+ customers including some of the world’s most recognizable resort, casino and cruise line brands. We specialize in market-leading point-of-sale, property management, inventory and procurement, and mobile and wireless solutions that are designed to streamline operations, improve efficiency and enhance the guest experience. We serve casinos, resorts, hotels, food service venues, stadiums, cruise lines, grocery stores, convenience stores, general and specialty retail businesses and partners. With extensive operations, throughout North America, and additional sales and support offices in Singapore and Hong Kong, as well as software development in India, we are growing. For more information, visit: www.agilysys.com.
Machine Learning Scientist
We are looking for Senior Applied Scientists who has deep passion for building machine-learning solutions and can help us take our products to the next level.
In this role, you will
Be responsible for developing, training, inferencing, evaluating, and deploying machine learning algorithms and/or models.
Design and perform experiments to continually refine and enhance our deep learning technology solutions.
Work closely with software engineers on detailed requirements, technical designs and solutions.
Provide technical leadership and research new machine learning approaches to drive innovation.
Help drive adoption of Machine Learning across the company.
Qualifications
Master’s degree in Data Science, Analytics or Computer Science with Machine Learning specialization or related discipline. A PhD is preferred.
5+ years hands-on experience in building Machine Learning solutions.
3+ years’ experience with data structures, algorithm design, problem solving and complex analysis.
Experience with implementing deep learning platforms such as TensorFlow, Keras, and Darknet
Experience with implementing deep learning models such as Inception, Faster-RCNN, SSD, YOLO3.
Strong coding knowledge, experience with Azure or AWS machine learning pipelines.
Excellent understanding of convolution neural networks and other machine vision algorithms and methodologies.
Experience working effectively with science, data processing, and software engineering teams.
Excellent oral and written communication skills, with the ability to effectively communicate complex technical concepts and solutions.
Proven hands on experience working with large data sets and training models.
Ability to extract the practical implementation information from academic papers.
Interest in working on embedded systems.
Proven track record of executing complex projects.
Preferred:
Experience in deploying machine learning models on the edge"
Data Scientist / Research Analyst,Andhra Pradesh,Franklin Templeton Investments,None,Organic,"Data Scientist / Research Analyst-834654

At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Research Analyst / Data Scientist in Investment Management team responsible for?
Partner with investment teams to provide machine learning / AI / Data Analysis expertise to enhance investment decisions and returns. Engage Chief Investment Officer (CIO) and Portfolio Managers in investment team meetings; present and share investment ideas, insights and results
What are the ongoing responsibilities of the Data Scientist?
Engaging Portfolio Managers in investment team meetings; present and share investment ideas, insights and results
Selecting/creating features from raw data, and building/optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending the data used in modeling with third party sources of information
Processing, cleaning, and verifying the integrity of data used for analysis
Conducting ad-hoc analysis and presenting results in a clear manner
Creating automated data consistency checks (e.g. between live/historical data) and unit testing techniques to ensure ongoing model performance
Building, deploying, and maintaining ML models in cloud environment

What ideal qualifications, skills & experience would help someone to be successful?
Bachelors or Master’s with 4+ years of coding and data science experience
Experience in US CLO Research is a big plus
Prior experience in Investment Management / Financial Services / FinTech is a must
Experience in Fixed Income Modeling/Quant (or) Research Experience in US Securitized Products or Corporate Credit is a plus
Professional certifications such as Certified Financial Analyst (CFA), Financial Risk Manager (FRM), or Chartered Alternative Investment Analyst (CAIA) are preferred
Requires advanced skills in Python- especially Pandas
Must be able to produce code in Python at a rapid rate
Experience with supervised/unsupervised machine learning techniques, especially tree-based algorithms, and k-means clustering. Neural networks experience is a plus, especially with RNNs and CNNs
Experience modeling and making sense of complex systems
Must have at least 4+ years of coding experience
The applicant must have a strong underlying coding ability
Must have strong applied statistics skills, such as understanding of distributions, hypothesis testing, and probability
Great communication skills and experience with data visualization tools in Python
Proficiency in SQL is a plus. Must be able to write basic queries at minimum
Experience with high performance computing is a plus (e.g. cluster computing on Azure with Spark/Hadoop)
Masters/PhD in a quantitative discipline is a plus, but is not required
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.
Highlights of our benefits include:
Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.
JOB FUNCTION: Data Science and Analytics
PRIMARY LOCATION: India-Andhra Pradesh-Hyderabad
SCHEDULE: Full-time
JOB POSTING DATE: Aug 2, 2020, 11:37:27 PM"
Lead - Data Analytics and Reporting,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bengaluru
Schedule: Full-time
Employee Status: Permanent
Posting Date: 10/Aug/2020
Unposting Date: 10/Sep/2020
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.



Purpose:
The role is at a senior level in the Digital Channels & Data Analytics team of CCIB based in Bangalore. Innovative big data and machine learning solutions are a key priority for the Bank as part of investments in creating value-add services for clients, creating or joining new consortiums and enabling new business models. This role is to contribute to the development of data projects.

Strategic data initiatives in CCIB creates differentiated digital capabilities for clients to access the Bank's transactional services in over 50 markets efficiently and securely. This includes internet and mobile banking for global business clients, direct integration options, as well as services through third parties.
The role would be suited to a candidate having experiences in data science and analytics field – developing models, rules and algorithms from structured and unstructured sources and performing deep-dive analysis to derive data-driven decisions
Proven track records in building and deploying (financial services) analytic solutions that have created significant value for customers and additional revenue based on new business models.
Experience in building dynamic dashboard (eg Tableau, Power BI) for business stakeholders will be an absolute must
Experienced working in an offshore model is required since role will be based in Bangalore with business stakeholders in Singapore and other overseas locations
Strong data defining, structuring, labelling and developing data models to capture, store, process and use this data to generate intelligent outcomes through Data Analytics
The candidate will have a profound knowledge of large data sets, data management, data governance, data science and metadata.
The role requires close partnership with Cash, Trade, and Security Services Product organisation. Other key stakeholders include global Sales and Implementation teams, Technology, and risk owners such as legal and compliance.
This role reports to the Data Analytics lead for Transaction Banking.

Key Accountabilities:
Help built a strategy & roadmap of analytics solutions that will position Standard Chartered as leading in this field
Creating effective dashboards for business stakeholders
Apply and ensure data governance framework.
Develop and implement artificial intelligence algorithms, rules and rapid prototypes from big data sets that will be fed into various business programs.
Behavioural segmentation based on client journey, profiles, transaction patterns, and app activities that will lead to highly personalized client insights.
Design and monitor A/B testing and various engagement activities.
Perform deep-dive analysis to solve various business problems arising from marketing, dynamic incentive programs, and campaign management.
Build and automate intuitive dashboards that help visualize and answer complex business problems.
Managing risks and regulatory issues associated in data analytics solutions.

Qualifications and Skills:
University Degree or equivalent, preferably in computer science, engineering or analytical discipline, e.g. mathematics, statistics, IT, economics, finance, accounting.
Minimum 8 years working experience in data analytics or business intelligence units, preferably in consultancy (eg Mu Sigma, IBM, Accenture) or financial industry.
Relevant experience in using data is a pre-requisite.
Analytical mind with sound business insights. Ability to translate the business problems and requirements into analytics solutions.
Knowledge of a variety of predictive models, machine learning algorithms and statistical techniques, e.g. logistic regression, decision tree, clustering, neural networks, support vector machines, principal component analytics, natural language processing.
Proficiency across the core statistical toolsets (SQL, SAS, R, Python), data visualization tools (Tableau, Qlik, Power BI) and Hadoop ecosystem.
In-depth knowledge of digital banking, banking products and the overall industry a strong plus
Good verbal and written communication skills.
Excellent stakeholder management skills
Self-motivated. Can-do spirit


Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
"Research Scientist, Google Research","Bengaluru, Karnataka",Google,None,Organic,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.
Minimum qualifications:
PhD in Computer Science, related technical field, or equivalent practical experience
Experience in Machine Learning, NLP/NLU, Computer Vision, Optimization, Game Theory, Computer Systems, Market Algorithms
Experience with general purpose programming languages e.g., C/C++ or Python
Contributions to research communities including publishing in top forums (e.g: NeurIPS, ICML, ACL, CVPR, KDD, AAMAS)

Preferred qualifications:
Strong publication record
About the job
As an organization, Google maintains a portfolio of research projects driven by fundamental research, new product innovation, product contribution and infrastructure goals, while providing individuals and teams the freedom to emphasize specific types of work.
As a Research Scientist, you'll setup large-scale tests and deploy promising ideas quickly and broadly, managing deadlines and deliverables while applying the latest theories to develop new and improved products, processes, or technologies. From creating experiments and prototyping implementations to designing new architectures, our research scientists work on real-world problems that span the breadth of computer science, such as machine (and deep) learning, data mining, natural language processing, hardware and software performance analysis, improving compilers for mobile platforms, as well as core search and much more.
You'll also actively contribute to the wider research community by sharing and publishing your findings, with ideas inspired by internal projects as well as from collaborations with research programs at partner universities and technical institutes all over the world.
Research in machine intelligence has already impacted Google services including Search, Maps, Android, YouTube, and Photos. Our researchers have a never-ending quest to find more information and make it accessible.
Google Research India is the latest addition to Google’s global research labs with the mission to advance fundamental Computer Science Research by building strong teams, and by partnering with the academic research community.
Applying research to solve big problems in fields like healthcare, agriculture, or education while also using it to make Google’s products more helpful for billions of users.
Google Research is building the next generation of intelligent systems for all Google products. To achieve this, we’re working on projects that utilize the latest computer science techniques developed by the best and brightest software engineers and research scientists in the world. Google Research teams collaborate closely with other teams across Google, maintaining the flexibility and versatility required to adapt new projects and foci that meet the demands of the world's fast-paced business needs.
Responsibilities
Undertake cutting edge research in the above mentioned areas.
Develop solutions for real-world, large-scale problems.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist III,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"Bachelor’s or Master’s degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics
4+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python, R), or statistical/mathematical software (e.g. R, SAS, Matlab, etc.)
2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication
A natural curiosity and desire to learn
Experience articulating business questions and using quantitative techniques to arrive at a solution using available data
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences

Description
Amazon.com strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated and friendly work environment.

We need an expert in econometric and statistical tools to extract insights at scale by building models with our world class data systems, designing advanced new experimental methods, and investigating complex behavioral patterns.

Team Introduction
Amazon Search creates powerful, customer-focused product search solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, our systems go to work. Our Search Engine team designs, builds, and delivers high performance, fault-tolerant, scalable distributed search engine used by millions of Amazon customers every day.

We are looking for a highly motivated Data Scientist who can help ensure our experience on Amazon Search is creating long-term value for our customers. This person will be responsible for architecting insights and systems to anticipate which features will improve customer’s search experience. This person will also be responsible for designing experiments and devising frameworks that measure the short-term and long-term impact of our product initiatives. Finally, this person would also derive insights using our existing data and experiments to inform new innovation and direction for Search Technologies and internal partner teams.

The ideal candidate will be an expert in the areas of data science, machine learning and statistics, having hands-on experience with multiple improvement initiatives as well as balancing technical and business judgment to make the right decisions about technology, models and methodologies. You will leverage data, experimental design, and analytics to help define new ways to evaluate, visualize and predict to understand outcome and decisions on how to improve customer engagement across customer lifecycle segments. The candidate needs experience with data science / business intelligence, analytics, and reporting systems while striving for simplicity, and demonstrating significant creativity and high judgment backed by statistical proof.

The ideal candidate should have deep expertise in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and use appropriate statistical and econometric techniques to derive insights and recommendations to leadership. You should excel at bringing large datasets together to answer business questions and drive change.

Responsibilities Scientists at Amazon are expected to develop new techniques to process large data sets, address quantitative problems, and contribute to design of automated systems around the company. Major responsibilities include:
Measure / Quantify / Expand
Design, size, and analyze field experiments at scale.
Apply econometric or statistical knowledge to improve Amazon Search (using machine learning techniques is a plus)
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Explore / Enlighten
Formalize assumptions about how Amazon Search is expected to work.
Given anomalies, whether anecdotal or identified automatically, deep dive to explain why they happen, and identify fixes.
Decide / Recommend
Build decision-making models and propose solution for the business problem you defined
Implement models based on findings in production back end systems
Analyze A/B tests and recommend ways to making them faster and more robust
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithm

Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Experience with data visualization and presentation, turning complex analysis into insight
Experience collaborating with software development teams, data scientists, business intelligence or other technical roles
Masters or PhD in applied quantitative field
Strong background in statistics methodology, applications to business problems, and/or big data.
Ability to work in a fast-paced business environment.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
Experience designing experiments, and ability to infer causal relationships"
Data Scientist III,"Mumbai, Maharashtra","General Mills Services, Inc.",None,Organic,":
General Mills is reshaping the future of food. We believe food makes us better. It nourishes our bodies, brings us joy and connects us to each other. As one of the world's leading food companies, General Mills operates in more than 100 countries and markets more than 100 consumer brands, including Cheerios, Nature Valley, Betty Crocker, Yoplait, Annie's Homegrown, Old El Paso, Epic Provisions, Blue Buffalo and more. Are you passionate about the future of food? You've come to the right table. We want the very best talent to help lead something big.
:
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
:
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business
:
Qualification: Any Graduate (Preferred Statistical background)
Experience - 6+ yrs

Statistical analysis, modeling, clustering and data mining techniques to identify trends and insights
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning a plus
Experience with data visualization tools
Experience writing complex SQL queries
Experience with Python & R, comfortable working with DataFrames
Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs"
Consultant Data Scientist-(H/F),"Bengaluru, Karnataka",Société Générale,None,Organic,"Vos missions au quotidien
Le Data Scientist exploite des données pour détecter de nouveaux leviers de création de valeur et aider à la prise de décision pour l’Entreprise, et ce dans le respect de la réglementation en vigueur sur les données :

Il comprend les enjeux du Métier et échange en permanence avec le Métier afin de s’assurer que le modèle réponde au besoin de l’utilisateur

Il identifie les besoins du Métier au regard d’une problématique ciblée et dans divers domaines de la Banque : fraude, marketing (appétence produits, moments de vie, attrition, parcours client…), gestion des risques (octroi de crédit, tarification, probabilité de défaut…) , etc.

Il élabore, en lien avec les Data Engineer, les outils nécessaires à la collecte des données dans l’exhaustivité, dans l’historique, dans la fréquence et dans la qualité suffisantes, en amont de la modélisation

Il modélise les données via les algorithmes mathématiques (machine learning, NLP, Intelligence Artificielle, …)

Il synthétise et communique les résultats des analyses de données de masse pour en extraire une connaissance décisionnelle facilement interprétable et manipulable par les bénéficiaires du dispositif qu’il conçoit, en s’appuyant sur des techniques et des expertises de visualisation


Et si c’était vous ?
Bac +5 en école d’ingénieur, master Data Science

Bon niveau d’anglais

Compétences métier :
Expertise en statistiques et mathématiques appliquées : Connaissance machine Learning, analyse prédictive à partir de différentes bases de données
Programmation informatique : Python, R, C++
Algorithmie et gestion des bases de données : SQL, noSQL, MapReduce, Hadoop
Forte curiosité intellectuelle : intérêt pour le secteur bancaire, vision sur les enjeux stratégiques
Sens du résultat, pragmatisme
Capacité à communiquer ses analyses notamment en utilisant des outils de visualisation de manière claire avec une orientation décision
Autonomie / esprit d’initiative
Esprit d’équipe / capacité d’écoute / sens des responsabilités


Plus qu’un poste, un tremplin
“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.
Pourquoi nous choisir ?
Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.

SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.


Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise.
Le groupe s’engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité sexuelle ou de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l’objet d’une discrimination.
Référence: 200003NS
Entité: SG Global Solution Centre
Date de début: Immédiat
Date de publication: 04/08/2020"
Hiring Data Science with Machine Learning and GCP,India,Vodafone,None,Organic,"Company Profile

Vodafone Intelligent Solutions (_VOIS) is a strategic arm of Vodafone Group Plc, for which it creates value by enhancing quality and efficiency of a number of processes in the IT/ ITeS domain. Established in 2006, _VOIS has evolved into a global, multi-functional organization that currently has centres across India, Egypt, Romania and Hungary with over 23,000 professionals.

In 2009, _VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 12,000 employees, _VOIS India supports global markets and group functions of Vodafone, and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Enterprise), Finance Operations, Supply Chain Operations and HR Shared Services.

Current Opening

We are hiring Data Science professionals with Machine Learning (GCP). If your profile is shortlisted for one of our open roles, the concerned recruiter will reach out to you.

Best of luck"
Data Engineer,"Bengaluru, Karnataka",DMI,None,Organic,"About DMI:
DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.
About the Opportunity:
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Data Engineer
You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.
5+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines.
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Java, Python, Scala or equivalent.
Implement data ingestion pipelines both real time and batch using best practices.
Experience with building stream-processing applications using Apache Flink, Kafka Streams or others.
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Ability to work in a Linux environment.
These qualifications would make you stand out among other applicants:
Experience in building distributed, high-volume data services.
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.
Knowledge of data science tools and their integration with data lakes.
Experience in container technologies like Docker/Kubernetes."
Risk - Quantitative Research - IBQR Data Team - Associate,"Mumbai, Maharashtra","JPMorgan Chase Bank, N.A.",None,Organic,"Description:
IBQR Data team provides excellent exposure on Credit Risk, Basel regulations, CECL/IFRS9 forecasting and stress forecasting. The team works across the Wholesale bank and is closely aligned with firm-wide partners including Quantitative Research, Finance, Model Risk Governance, Chief Data Office, Technology and the Regulatory Capital Management Office. We seek candidates with strong skills in corporate finance, data analytics, big-data architecture and communication.
Roles & Responsibilities:
Work in an Agile framework to write business requirements in the form of JIRA epics & user stories to develop data and system requirements for credit risk modelling platform
Perform data analysis to support model development and analytics
Liaise with various lines of business and risk modelers, thoroughly understand various models for BASEL, CCAR, CECL and other credit risk models
Work with multiple stakeholders to elicit, analyze, refine and document business process and data requirements
Collaborate through the entire Software Development Life Cycle (SDLC) including planning, analysis and testing of new applications and enhancements to existing applications.
Define data models , metadata and data dictionary that will enable data analysis and analytical explorations
Perform user acceptance testing and deliver demos to stakeholders by SQL queries or Python scripts
Qualifications:
Bachelor's or Master's in Computer Science, Data Analytics or equivalent discipline
Data Analysis and data manipulation skills using SQL , Python & MS Excel is Required
Data Visualization tools like Tableau, Qlik View, Power BI etc is nice to have.
Strong analytical skills in forecasting and interpreting results and comfortable working with large quantities of data
Familiarity with Traditional Credit Products (Loans, Letter of Credit, Stand By Letter of Credit, Syndications etc)
Detail oriented and strong organizational skills
Excellent communication abilities, both written and oral;
Ability to solve problems creatively while working in a dynamic and challenging environment under tight deadlines
Eagerness to learn about Credit Risk, Risk Parameters, Regulatory and Accounting conceptsJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Data Scientist,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Scientist to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about natural language understanding and machine translation, AppZen is the right place for you to apply and grow your skills.
Must-Have:
Solid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.
Ability to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations.
Expert knowledge of a statistical computing language such as Python or R Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.
Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.
Manage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful.
Excellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions.
M.Sc. or M.E. or M.Tech in Computer Science, Engineering, Statistics, or other relevant technical fieldMust have 4-6 years of industry experience.
Able to work onsite in Pune, IN
You are a team player
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
"Senior Staff Data Scientist - Artificial Intelligence, Machi...","Mumbai, Maharashtra",Baker Hughes,None,Organic,"Role Summary:
Baker Hughes has a new opportunity for Senior Staff Data Scientist - Artificial Intelligence, Machine Learning to join the team in Mumbai/Bangalore, India. He/She will be responsible for designing analytics for products and solutions, leverage strong machine learning expertise to develop new analytics for driving growth in asset, application & industry with external/internal customers.
Roles and Responsibilities:
Performs data analysis and extracts insights out of data using mathematics, statistics, information science, and computer science (including machine learning, statistical learning, and data mining, among others).
Applies existing technologies, approaches, methodologies in new combinations to design new products, systems or processes. Viewed internally and externally as a specialist in the discipline.
Presents projects plans, technical roadmaps, risks and recommendations to senior business leaders (EB and SEB) within technical space and occasionally to senior leaders in partner technical teams.
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts.
Communicates solutions across the own function and with cross-functional partner organizations.
Coach the team in development, validation, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses
Qualifications/Requirements:
Bachelor's degree from an accredited university or college. Minimum of 5 additional years of experience in Data Science.
Overall Industry Experience of 15+ years .
Proven experience in building enterprise level solutions with Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modeling
Desired Characteristics:
Masters / PhD in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
Strong oral and written communication skills. Strong interpersonal and leadership skills. Demonstated ability to analyze and resolve problems. Demonstrated ability to lead programs / projects. Ability to document, plan, market, and execute programs. Established project management skills
Locations :
Mumbai/Bangalore, India"
Machine Learning Engineer - Global AI Platform Company,"Gurgaon, Haryana",Michael Page,None,Organic,"Apply
share this job
Email Job
Save Job
Get to be a part of the growth of the Intelligence Systems team from ground up
Opportunity to drive Innovation powered by Data Science, AI and ML
About Our Client
Our client provides a platform for building bespoke software using AI and a library of building blocks to democratise software development; making it faster, more accessible and less expensive for everyone.
Job Description
The key responsibilities of Machine Learning Engineer would be to:
Build, maintain and manage data pipelines that support the modelling initiatives of data scientists
Work closely with data scientists and engineering teams to productionise machine learning models
Automate machine learning workflows
Work with wider product teams to make the right data available for model building and analysis
Implement the analytical libraries, programming languages, and frameworks in production
Engineer to scale in the cloud using methodologies such as service-oriented architectures, containerised applications and lambdas
The Successful Applicant
As a successful candidate for Machine Learning Engineer role, you should have:
Higher university degree (MSc or PhD) in Computer Science, Engineering, Mathematics, Physics etc
Hands on expertise in programming language: Python & Scala
Sound fundamental knowledge of data querying and manipulation using SQL
Practical experience in ML in research and development or academic projects
Ability to communicate with diverse stakeholders
Software engineering experience (CI/CD, Docker, Kubernetes)
Experience engineering at scale using production level architecture
What's on Offer
As a Machine Learning Engineer, an opportunity to be a part of the Intelligent Systems team based in Gurgaon and work closely and collaborate with global product and engineering teams across three locations London, New Delhi and Los Angeles."
Software Engineer – Machine Learning,"Bengaluru, Karnataka",Netradyne,None,Organic,"Role and Responsibilities
You will help design, implement and commercialize driver monitoring and driver assistance algorithms. You will have access to very large datasets and will get to deploy new algorithms/models into thousands of vehicles. As a machine learning software engineer, you may
Design and commercialize algorithms characterizing driving behavior.
Design, implement and track key metrics; and architect data-driven solutions.
Improve machine learning infrastructure for scalable training and inference.
Innovate and develop proof of concept solutions showcasing novel capabilities.
Requirements:
B. Tech, M. Tech or PhD in computer science, electrical engineering or a related area.
Excellent programming skills – Python (required) and C++ (desired).
Research or industry experience with machine learning models.
Ability to take abstract product concepts and turn them into reality.
Ability to innovate on cutting-edge problems without documented solutions.
Desired Skills:
Experience with image, video and time-series data
Experience with road scene understanding (objects, lanes, intersections, signs etc.)
Experience with person/driver scene understanding (pose, distracted, eye status etc.)
Experience with successfully applying machine learning to solve a real-world problem.
Experience with conducting successful statistical experiments.
Experience with predictive analytics
Experience:
Hiring across all levels"
Data Engineer 2,"Chennai, Tamil Nadu",PayPal,None,Organic,"In this role, the individual will be part of the engineering team in Enterprise Data Lake Organization and will be responsible for.
Participating and collaborating with Product Owner/ Cross functional team in the organization to understand the business requirements and to deliver solutions that can scale.
Creativity and out of the box thinking is required.
Proactively anticipating problems and keeping the team and management informed in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Produce quality deliverables
Ability to work in a fact paced environment
Ability to deliver from coarse grained requirements
Skills and Experience
3+ years of experience in the IT industry, experience in Data Technology space is preferred.
Shell/ Perl scripting experience
Spark streaming experience is a must
Proficiency in any programming language like C, C++ or CORE Java
Working experience in a RDBMS and big data stack; Should have strong SQL programming skills
Knowledge of data warehousing concepts
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Basic Qualifications
Bachelor/master’s in engineering/Science degree with Mathematics or equivalent experience
3+ years of experience in IT
Job_Description_Summary: Enterprise Data Lake is a newly formed team in PayPal’s product and engineering organization under Customer Experiences and Technology. Its vision is to “Provide Enterprise Product Data at lower cost and better quality”. To achieve this vision, we are looking for people with a passion and curiosity to solve customer problems with data. The internal stakeholders for the Program include but are not limited to PayPal Inc.’s Product Teams, Finance, Risk, Compliance and Strategy Teams. Our External stakeholders include Customers and Regulators amongst others. This position is focused on delivering Core Data solutions using modern technology to serve the various needs of the business. The scope of the organization is global, and its data platforms serve a wide array of functions including Merchant, Partner, Operations, and Compliance business operations. At EDL, we are committed to bringing innovation, passion and customer focus to the business of enterprise solutions. One of the charters of EDL is to deliver on data driven companywide transformational initiatives to integrate PayPal Inc. data seamlessly using Big Data platform for both operational and analytical needs. In this position you will also have the opportunity to work with stakeholders and users to understand their needs and partner with engineering to deliver the solution. This position requires an individual who is comfortable working in cross-functional teams with a very high degree of analytical and technical skills.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Full Stack Developer,"Bengaluru, Karnataka",Research Grid Ltd,"₹50,000 a month",Organic,"Company:
R.grid is an early-stage start-up that streamlines administrative medical research processes using machine learning.
Job Overview:
We are looking for a full stack developer for a minimum of 2 years to produce scalable software solutions. You’ll need to have a good understanding of research-level development (from conception to deployment). You'll be part of an international team responsible for the full software development life cycle.
As a full-stack developer, you should be comfortable around both front-end and back-end coding languages, development frameworks, and third-party libraries. You should also be a team player with a knack for visual design and utility.
You must be able to speak great English. The company does all it's business activities in English. You will also need to have references ready.
Responsibilities and Duties:
Participating in the design and creation of scalable software (research, conception, and deployment)
Writing clean, functional code on the front- and back-end
Testing and fixing bugs or other coding issues
Work with development teams and product managers to ideate software solutions
Design client-side and server-side architecture
Build the front-end of applications through appealing visual design
Develop and manage well-functioning databases and applications
Write effective APIs
Test software to ensure responsiveness and efficiency
Troubleshoot, debug and upgrade software
Create security and data protection settings
Build features and applications with a mobile responsive design
Write technical documentation
Work with data scientists and analysts to improve software
Requirements, qualifications, experience, knowledge, and skills:
Proven experience as a full-stack developer
Experience developing desktop and mobile applications
Knowledge of multiple front-end languages and libraries (e.g. HTML/ CSS, JavaScript, XML, jQuery)
Knowledge of multiple back-end languages (e.g. PHP, Python) and JavaScript frameworks (e.g. Angular, React, Node.js)
Familiarity with databases (e.g. MySQL, MongoDB), web servers (e.g. Apache) and UI/UX design
Excellent communication and teamwork skills
Great attention to detail
Organizational skills
Degree in Computer Science, Statistics or relevant field
Benefits:
Monthly pay (amount in-hand)
No Saturday work
Business casual dress
Small team
Start-up environment
Job Types: Full-time, Contract
Salary: ₹50,000.00 per month
Experience:
AWS: 2 years (Required)
database development: 3 years (Required)
javascript: 3 years (Required)
Python: 3 years (Preferred)
back-end development: 3 years (Required)
software architecture: 3 years (Preferred)
Node.js: 3 years (Required)
HTML/CSS: 3 years (Required)
Angular: 3 years (Required)
front-end development: 3 years (Required)
working for a company that does business in English: 2 years (Required)
Slack: 2 years (Preferred)
Education:
Master's (Preferred)
Language:
English (High-level) (Required)
Work Remotely:
Yes"
Data Science AI Ops Lead,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Data Science AI Ops Lead
Career Level: E1
Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Role
We are looking for an AI Ops Lead to join our Data Science & AI team in Chennai. The ideal candidate will have industry experience working in a range of different cloud environments where they devised and deployed large-scale production infrastructure and platforms for data science. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery.
The successful candidate will be part of building a new, close-knit team of deeply technical experts and together have the chance to create tools that will advance the standard of healthcare, improving the lives of millions of patients across the globe. This platform will support major AI initiatives such as clinical trial data analysis, knowledge graphs, imaging & omics for our therapy areas. You will also have responsibility to help provide the frameworks for data scientists to develop scalable machine learning and predictive models with our growing data science community, in a safe and robust manner.
As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, machine learning, and data to enable the productivity of AstraZeneca. You will help envision, build, deploy and develop our next generation of data engines and tools at scale. You will be bridging the gap between science and engineering and functioning with deep expertise in both worlds.
Key Accountabilities
Own the development roadmap to build and operationalise our data science environment, platforms and tooling.
Support any external opportunities, through close partnership and engagement such as Benevolent.AI collaboration.
Deployment of systems, applications and tooling for data science on cloud environments.
Understanding of the necessary guardrails required for different use cases and data sensitivities.
Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
Provide the necessary infrastructure and platform to support the deployment and monitoring of ML solutions in production Optimizing solutions for performance and scalability.
Liaise with the Data Engineering team to ensure that the platform and the solutions deployment therein benefit from an optimised and scalable data flow between source systems and analytical models
Implementing custom machine learning code and developing benchmarking capabilities to monitor drift of any analyses over time.
Understanding of the latest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI and Domino. Experience working on regulatory data would be helpful but not essential.
Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
Being an active member of the Data Science team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure.
Appreciation of how to optimise predictive models, run in production and monitor. Experience running a service team will be beneficial.
Testing and assessing the quality of new tools.
Line management responsibilities as well as team recruitment, training provision and coaching

Candidate Knowledge, Skills and Experience
BSc in Computer Science or related quantitative field or MSc/Ph.D degree in Computer Science or related quantitative field.
More than 2 years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
Experience managing an enterprise platform and service, handling new customer demand and feature requests.
Strong software coding skills, with proficiency in Python and Scala preferred.
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential. Certification in appropriate areas will be viewed favourably.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.
Experience provisioning computational resources in a variety of environments.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Experience with automation strategies e.g. CI/CD, gitops.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Creative, collaborative, & product focused.
Ability to just get things done.
Other
The role will have line reports and task management responsibilities within project or services may occur.
Department – Data & Analytics, S&EUIT
Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.
Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Data Visualisation, Knowledge Management, Data Science, Data Analysis and Information Governance.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Scientist -1,"Bengaluru, Karnataka",Acko General Insurance Limited,None,Organic,"Role and Responsibilities:
Work closely with Business teams & Product Managers to identify opportunities and serve as an ambassador for data science
Translates complex functional and technical requirements into detailed architecture, design, and high performing software and applications.
Works with peer developers to make sure that all data solutions are consistent and ensures all automated processes to preserve data by managing the alignment of data availability and integration processes
Eligibility Criteria:
2 years of experience in the field of statistics, data mining and machine learning
Qualifications:
BTech/BE Premier institute like IITs/BITS/NITs
Experience in e-commerce/Online Internet companies
Skills:
Expert-level understanding of the underlying theory of Machine Learning.
You have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
Taking end-to-end ownership of problem domains and continuously improving upon quantitative solutions
Demonstrated ability to facilitate and work with minimal direction, with the proven ability to coordinate complex activities
Analytical thought leadership and stay current on developments in data mining and the application of data science"
Data Scientist,"Mumbai, Maharashtra",Allerin Tech Private Limited,None,Organic,"Job Description :

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products like: automate scoring using machine learning techniques, build recommendation Engines/systems, optimize and extend the features used by our existing classifier, etc

Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Develop hypotheses and test carefully by experience; develop and improve predictive modeling algorithms; understand and work around possible limitations in models.
Analyze large datasets to produce statistical models and prediction tools.
Visualize, interpret, report, and communicate data findings creatively in various formats to various stakeholders.
Conduct critical data analysis and prepare data sources to be analyzed.
Discover patterns, find meaning and produce actionable intelligence. Work both autonomously and collaboratively when necessary in a fast-paced, competitive, multidisciplinary environment.

Desired Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
Proficient at translating unstructured business problems into an abstract mathematical framework.
BE/BTech/MCA/MTech/MSc in Computer Science
Some development experience in at least one scripting language (Julia, Python, R...).
Ability to initiate and drive projects to completion with minimal guidance.
The ability to communicate the results of analyzes in a clear and efficient manner.
Highly collaborative and curious.
Experience with any big data framework would be a plus.
2-7 years experience

Important:

Should be able to appear for personal interview in our office at Navi Mumbai. Do not apply if you can not appear for personal interview. No telephone round will be conducted.

2.00-7.00 Years"
Data Analyst,"Chennai, Tamil Nadu",Sagitec,None,Organic,"Data Scientist who is passionate about data and wants to apply machine learning techniques to solve problems for our customers. This person is expected to be proficient in the exploration and understanding of structured and unstructured data, machine learning techniques, statistical modeling methods, predictive analytics, anomaly detection, and supervised and unsupervised learning. The successful candidate will work with stakeholders to leverage data to solve critical business problems in the Benefits Administration domain.
The Data Scientist will work on all aspects of the design, development, and delivery of machine learning-enabled solutions including problem definition, data acquisition, data exploration, feature engineering, experimenting with various ML algorithms, evaluating metrics, deploying models and iteratively improving the total solution.
Duties & Responsibilities
Formulate a meaningful hypothesis that is relevant to the business objectives.
Design and train models for use in production environments.
Mine structured and unstructured data for patterns.
Utilize data from databases, Web scraping, public datasets, historians, and/or data lakes.
Rigorously build, analyze, and compare machine learning or statistical models; there is a strong emphasis on programming using the most popular machine learning languages such as Python, R, Microsoft R, TensorFlow, PyTorch, SciPy, Encog, etc.
Work with application developers to develop data-analytics products that are deployed to end-users as part of packaged solutions.
Visualize and report findings of deployed data analytics solutions to provide insights to the organization and our customers.
Deploy machine learning model and integrate model predictions in business
Setup infrastructure for machine learning, model deployment including commissioning or ML-Servers and Server Configuration
Deploy CI/CD framework to frequently deliver code/features to production
Qualifications
Experience & Education
Required
M.S. or higher in Mathematics, Statistics, or Computer Science with significant experience in data analytics and Model Building.
Preferred
5+ years experience is preferred.
Knowledge, Skills, & Ability
Required
Expertise in predictive modeling, machine learning and statistics.
Software development skills in one or more high level languages (Python/Java/R/Scala).
Experience using one or more of the following common ML software packages: scikit-learn, TensorFlow, NumPy, pandas, jupyter.
Well-versed in machine learning algorithms and their suitability for solving various problems: Regression, Bayesian, Support Vector Machines, Decision Trees, Random Forest, Clustering, Neural Networks.
Experience in using SQL/No SQL databases is an advantage
Experience working in Windows/Linux is an advantage
Experience with Big Data technologies is an advantage (Hadoop, Hive, Spark, Cassandra).
Experience with building and deploying data pipelines
Good critical thinking, technical, data collection and user interviewing skills.
Ability to work as a team member in a fast-paced environment.
Experience With Agile Software Development Processes Is Preferred.
Experience with Cloud service offerings from AWS, Azure or GCP is a plus.
Preferred
Knowledge of DataOps.
Knowledge of data versioning tools such as git, DVC
Knowledge of ML environments such as MLflow, databricks
Knowledge of ML deployment tools such as Kubeflow, Kubernetes."
4G / 5G Modem Systems Engineer (Qualcomm Research India),"Bengaluru, Karnataka",Qualcomm India Private Limited,None,Organic,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Systems Engineering
Job Overview:
Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.
- Over the last few decades the Modem systems group at Qualcomm has been instrumental in driving the mobile communication revolution which has touched every aspects of our modern life. From the early days of CDMA to 3G UMTS to 4G LTE , LTE Advanced and now onto 5G NR, Qualcomm modem systems group has been a key player in moving these technologies from concept to lab to actual mass scale real life deployments. You now have an opportunity of joining this team which drove the 4G LTE based smartphone revolution and is now best positioned to expand into new areas such as 5G NR, IoT, Vehicular communication(V2X). You can work in areas as diverse as 3GPP standardization efforts (in RAN2 and RAN4), high level architecture studies, modem algorithm design and development, Machine Learning and its application to WWAN Radio design, power efficient design, verification and commercialization. Get in on the ground floor of these new emerging technologies and help shape the future. - Minimum Requirements: - Masters degree in Engineering, Information Systems, Computer Science, or related field. - Preferred Qualifications: - PhD in Electrical & Computer Engineering. - Academic project experience or 1+ year industry experience in at least one or more of the following areas: - Communication theory, applied mathematics, RF interfaces and digital mitigation of RF distortion, low power design, signal processing, information theory, channel coding, probability and random processes, machine learning or Bayesian inference, or upper layer protocol design experience including 3GPP IMS, NAS, MAC/RLC/PDCP and RRC, IP, UDP, TCP, HTTP, routing etc. - Ability to program effectively in C/C++, Python and/or Matlab. - Experience with key machine learning tools/libraries (TensorFLow, PyTorch, Keras etc), neural networks architectures and building models - Experience with wireless standards (i.e. LTE/WiFi/5G/UMTS). - Modem architecture, software engineering and simulation design, microprocessor architecture, embedded software, data network protocols knowledge. - Up to 4 year's Systems Engineering or related work experience. - Up to 2 years' experience working in a large matrixed organization. - Strong analytical and problem-solving skills. - Passion for learning and intellectual curiosity
Applicants : If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport
To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications."
Data Scientist,India,Agnik,None,Organic,"Position: Data Scientist (Intern)
Status: Open
AGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:
1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing
2) Some Experience in Programming in C++/Java/Distributed Programming
3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics
Positions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with ""Application for Data Science Intern"" in the Subject line."
Software Engineer - GSET - Equities Strats - Market Data Dev...,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
SECURITIES

Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.

RESPONSIBILITIES AND QUALIFICATIONS:
What We Do

At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. At Goldman Sachs, our culture is one of teamwork, innovation and meritocracy. We often say our people are our greatest asset and we take pride in supporting each colleague both professionally and personally. From collaborative work spaces and mindfulness classes to working from home and flexible work options, we offer our people the support they need to reach their goals in and outside the office. Goldman Sachs Electronic Trading (GSET) has launched an initiative to become the top provider in electronic trading by building superior technology and delivering high quality products. This vision is a multi-year investment in people, platforms and products. Join the team, and participate in the development and launch of best in class products for top clients across the industry. We are looking for eager, nimble and ambitious engineers to join our growing team of visionaries, and drive Goldman Sachs Electronic Trading to achieve and exceed our goals.

Your Impact

This team is accountable for platform architecture evolution to meet the evolving needs of different business lines globally with rapid software deployment. As stewards of critical components in order execution and post-trade, the team is accountable for a high degree of software quality. The team consists of self-guided pragmatic individuals who are motivated to change the status quo in calculated ways. As a member of the team, you will play an integral role on the trading floor. This is a dynamic, entrepreneurial team with a passion for technology and the markets, with individuals who thrive in a fast-paced changing environment. The team takes a data driven approach to decision making and you should be willing to participate in the full product lifecycle from requirements gathering, design, implementation, testing, support, and monitoring trading performance for systems and strategies used by our clients.

Responsibilities

Design, build and maintain low latency, high-performance electronic trading platform components, with a focus on market data, exchange and client connectivity and risk controls.
Deliver continuous optimization for latency, scale and resiliency improvements.
Participate in system builds for various markets globally, have curiosity and interest in understanding market microstructure details, work closely with engineering, sales and product teams in globally for successful delivery of projects.
Basic Qualifications

Bachelors or Masters degree in computer science or engineering or equivalent experience
5+ years of professional experience developing deterministic high performance, low latency systems in C++ (counted in single digit microseconds)
Prior experience with FIX and binary exchange connectivity and market data protocols preferred
Strong knowledge of object oriented programming, data structures, algorithms and design patterns
Critical path analysis, performance optimization and hardware acceleration.
Linux systems programming experience including memory management, concurrent programming infrastructure, and the networking stack
Experience developing distributed architecture systems and messaging protocols
Strong analytical and problem solving skills
Comfortable in a fast-paced environment, self-motivated, results driven and commercially focused
Preferred Qualifications

Software development in C++ in the context of high performance (low-latency, high-throughput) real-time computing.
o Familiarity with STL and C++11 language extensions, Boost

o Network programming (sockets, TCP/UDP/Multicast protocols)

o Multi-threading, concurrent programming

Intimate knowledge of compilers, flow of data at hardware level (memory/caches, buses)
Some experience with FPGA or other hardware acceleration technologies
Experience processing large static datasets as well as high volume ticking data sources
Over 3 years' experience in Financial industry
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Machine Learning Science Leader,India,CareerXperts,None,Organic,"Passionate about Big Data, Machine Learning and Predictive Software? Interested in leading new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
We are looking for a dynamic Machine Learning science leader to found and head the Data Science function in Bengaluru. As Head of Data Sciences, you will lead a high performing team of scientists and engineers in the development of innovative and rigorous Machine Learning techniques that advance Machine Learning technology for advertising and convert to high impact solutions for the business.
Major responsibilities:
Recruit, coach, and manage a team of scientists and data science engineers, lead cutting-edge research projects, and influence the technical direction of the Ads business.
Innovate and leverage machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Formulate and test hypotheses, extract signals from peta-byte scale, unstructured data sets, and ensure that our display advertising business delivers the highest standards of performance
Collaborate with distributed cross-functional teams on common goals.
Experience
6 + years , Start-up / Entrepreneurial experience preferred.
Qualification
MSc or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field. (PhD preferred).
4+ years of industrial experience in machine learning and predictive modeling, including 2+ years experience in leading junior team members and guiding them on machine learning and data modeling applications.
Proficient in Java, C/C++, or Python (or similar scripting language).
Proficient in R, Matlab, or another statistical software.
Strong communication and data presentation skills.
Preferred Qualifications:
7+ years of industrial experience in predictive modeling and analysis, predictive software development.
Experience handling gigabyte and terabyte size datasets.
Experience working with advertising, retail or e-commerce data.
Experience working with distributed systems and grid computing.
Experience working with distributed teams.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences."
Job Opening for Machine Learning,"Mumbai, Maharashtra",ICS Consultancy Services,"₹10,00,000 - ₹25,00,000 a year",Organic,"Roles and responsibilities for Job Opening for Machine Learning
: Role : Researcher Role Description : Manages deliverables for s global business-facing sourcing and research capability providing exceptional research expertise and unique industry knowledge. Required to develop points of view which identify business opportunities for the Operating Groups and Service Lines. Deliver research primarily utilizing an extensive range of online and other research sources. Must have Skills : Machine Learning Good to Have Skills : Product Development Management, Research, Artificial Intelligence Job Requirements : 1:Responsibilities:a: Perform extensive applied research on Machine learning deep learning, Computer Vision, text processing NLP, speech processing virtual agent technologies b: Provide modeling guidance on Machine learning deep learning, Computer Vision, text processing NLP, speech processing virtual agent technologies to a team of developers team leads c: Work with Developers Team leads to translate research papers to working prototype design models using AI technologies define actionable insights in an agile environment 2: Professional Experience: a: 6-8 years full time design algorithmic experience in AI technologies, ability to develop interpret algorithms models knowledge in programming ML languages like Java, Scala, Python, R 3: Educational Qualification: a: Graduate or post graduate degrees B Stat/M Stat/ B Tech/B E/Post Graduate/Diploma in Data Science etc from premier institutes preferred
Job Details
Job Role
: All Roles
Industry Sector
: IT-Software/Software Services
Functional Area
: All Functions
Desired Profile
Profile Description
:N/A
Experience
: 3 - 10 (Years)
.
.
Education Details
UG Course
: B.Tech/B.E
UG Specialization
: N/A
PG Course
: M.Tech
PG Specialization
: N/A"
Data Scientist - Advanced Analytics,Bihar,IBM,None,Organic,"Introduction
As a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
Combines deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Responsibilities include working with business leaders to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Skills include mathematical optimization, discrete-event simulation, rules programming and predictive analytics. Expected to have knowledge and/or experience in the following skills with focus on data science: Data Science, Apache Ambari, MapReduce, Spark, Labmda, Resilient Distributed Dataset, Java, Zookeeper, Knox, Big Data, IBM BigInsights, Apache Hadoop, SQL, RDBMS, Python, Big SQL, BigSheets+E5Big R, Text Analytics, GPFS, HDFS, Platform Symphony, Structured And Unstructured Data, Open Source, R, POSIX, Yarn, Sqoop, Flume, JSON, XML, NoSQL, HBase, Pig, Hive, Oozie, Apache Solr, JSqsh, Data Server Manager, AQL, Data Security, Data Governance, Networking, Neural Net.



Required Technical and Professional Expertise
Domain about Watson Explorer and other Watson Analytics products
Domain in text mining (characterization, summarization, aggregation)
NoSQL Database Domain
Mastery in natural language processing algorithms, machine learning, information retrieval / retrieval and advanced analytics
Cloud platform knowledge
""Twelve Factor""
Desirable specialization in one of the following areas: Natural Language Processing, Image Processing, Video Processing, Voice Processing and Watson technologies | WEX, WDC, WEA, Big Data analytics-R, Python, Spark, Weka, Mahout, Hadoop, Hive and HBase

***All positions are eligible for people with disabilities or rehabilitated.***

Preferred Technical and Professional Expertise
N/A

About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Data Science AI ML NLP Consultant,"Gurgaon, Haryana",ChampionsIT,None,Organic,"“AI-ML-NLP-0519”
For one of our prestigious multinational clients, we are looking for AI/ML/NLP Professionals for immediate hiring. Our client is an established name in the space of software development and consultancy. This position is based at Gurgaon – Delhi NCR, India.
WHAT IS IN IT FOR YOU?

The company is known for software consulting services and is a respected name in the software industry. You will get to work in a very energetic environment with lot of dynamism. They cater to mainly US customers, and provide their services through onsite/offshore model. The work environment is conducive to innovation, and provides continuous growth opportunities.
JOB DESCRIPTION

Work on Data Science projects in the area of NLP, ML, and Cognitive analysis.
Key Responsibilities:
Understand Customer Problem and Data Requirements.
Translate Customer requirements into a Data Science Problem.
Propose a Data Science solution which may involve use of Machine Learning (Supervised & Unsupervised) and other algorithmic models
Prepare Data followed by Model development
Model Testing and Deployment
Qualifications and skills:
Engineering Degree is a MUST
2 to 4 years experience in AI/ML/NLP/Cognitive Analysis
Coding of Machine Learning models in R and/or Python language
Experience in extracting data from a variety of data sources
Proven expertise in analyzing & visualizing data
-Experience in deploying on AWS, Google Cloud Platform or - Microsoft Azure will be preferred.
Quick learner of newer models, libraries and modeling techniques
Excellent communication and presentation skills
About the client
Our client is an established Software development and consultancy organization with its headquarters in US. They are a respected name in Insurance and Healthcare software and services. They have a large spectrum of customers all over US, and have development centers in India. They believe in hiring smart people and giving them a chance to grow at a rapid pace.
Come, be part of a winning team."
Machine Learning Engineer Intern (Image Recognition in Biome...,"Bengaluru, Karnataka","Kaleidoscope Business Solutions, Inc","₹25,000 - ₹45,000 a month",Organic,"Job Summary
The Machine Learning Engineer Intern is a hands-on individual contributor who loves to transform raw data into valuable insight. You are self-directed and love to take a problem from its early definition into a concrete plan and have your hands in all steps of the process, from data collection and preparation to model selection and training, all the way through deployment of proof of concept and ideally to production.
Responsibilities and Duties
- Create processes to clean and augment our existing data set of 50000+ images
- Select appropriate image recognition models for classification and object detection
- Train models, including hyper parameter tuning and local / cloud processing
- Report on model accuracy and utility
- Develop proof-of-concept applications that implement your models to demonstrate business value
- Deploy proof-of-concept applications to internal beta testers
- Work with our engineers to deploy your models into real-world applications that help us improve patients' lives while making our healthcare system more efficient
Build neural network architectures for the KBS platform.
Develop prototypes and execute experiments to help guide engineering efforts.
Explore new model families and machine learning algorithms.
Experience with Deep Learning and CNNs
Key Skills
machine learning, deep learning , computer vision, react, neural networks
Required Experience and Qualifications
Requirements:
- Min BS in Computer Science, Electrical Engineering, Applied Mathematics or Physics
- 1+ years experience in Computer Vision, Machine Learning, Image Analysis
- Strong background in Python and Linux
- Strong foundations in probability, linear algebra, and optimization.
- Background in statistical modeling and inference.
- Experience with 3rd party Vision/Math tools such as Keras, Pytorch, TensorFlow, OpenCV, AWS, etc
Pluses:
- Experience with TensorFlow Lite on mobile
- Experience working with MobileNet SSD architecture
- Experience with object detection and/or digit recognition
- Swift / Objective C / Java / C++ experience on mobile devices
- Experience building APIs or microservices in Python or Node.js
- Exposure to React Native
Preferred Qualifications
Experience with large-scale industrial applications of statistical modeling and inference.
Experience with statistical modeling across a diverse range of data sets and domains.
Masters in Computer Science (AI/ML specialization), Statistics, Mathematics (Probability), or equivalent.
Benefits
**We:
Give you the newest MacBook Pro with accessories and best equipment / work setup to make you feel productive and empowered to do your best work once you complete one full year with Kaleidoscope Business Solutions.
We care about your professional development and give you Personal Innovation Fund (education reimbursement) once you complete one full year with Kaleidoscope Business Solutions.
Offer you opportunities for international travel
Provide a modern office environment
Offer competitive salary and bonuses
Contribute to open source software
About Kaleidoscope Business SolutionsWe're a AI software consulting firm headquartered in San Francisco with offices in India. We are a growing 10+ team of engineers, designers and project managers working with a client roster of leading organizations from around the world. Our clients are a mix of venture-backed start-ups, Fortune 500 brands, and innovative NGOs.
View our website for more details. www.kb.solutions
Still not sure about applying to us?
If you're interested in applying for this job, we need three important things from you after you click the ""Apply for this job"" button below:
- a short cover letter (paragraph) describing why this seems like a good fit to you- a link to your GitHub profile (if any)- your LinkedIn profile (if any)
If the idea of working with smart people on cutting-edge technology to save lives is appealing... apply!
Also, if you put the words ""Can't wait for MACHINE LEARNING!"" in your cover letter, it will please us to know that you took the time to read this post and have good attention to detail.
We're looking forward to hearing from you!
Job Types: Full-time, Temporary, Internship, Contract
Salary: ₹25,000.00 - ₹45,000.00 per month
Experience:
machine learning: 1 year (Required)
Deep Learning: 1 year (Required)
Education:
Bachelor's (Required)
Location:
Bengaluru, Karnataka (Preferred)
Industry:
Software Development
Work Remotely:
Yes"
Data Science AI Ops Lead,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Data Science AI Ops Lead
Career Level: E1
Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Role
We are looking for an AI Ops Lead to join our Data Science & AI team in Chennai. The ideal candidate will have industry experience working in a range of different cloud environments where they devised and deployed large-scale production infrastructure and platforms for data science. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery.
The successful candidate will be part of building a new, close-knit team of deeply technical experts and together have the chance to create tools that will advance the standard of healthcare, improving the lives of millions of patients across the globe. This platform will support major AI initiatives such as clinical trial data analysis, knowledge graphs, imaging & omics for our therapy areas. You will also have responsibility to help provide the frameworks for data scientists to develop scalable machine learning and predictive models with our growing data science community, in a safe and robust manner.
As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, machine learning, and data to enable the productivity of AstraZeneca. You will help envision, build, deploy and develop our next generation of data engines and tools at scale. You will be bridging the gap between science and engineering and functioning with deep expertise in both worlds.
Key Accountabilities
Own the development roadmap to build and operationalise our data science environment, platforms and tooling.
Support any external opportunities, through close partnership and engagement such as Benevolent.AI collaboration.
Deployment of systems, applications and tooling for data science on cloud environments.
Understanding of the necessary guardrails required for different use cases and data sensitivities.
Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
Provide the necessary infrastructure and platform to support the deployment and monitoring of ML solutions in production Optimizing solutions for performance and scalability.
Liaise with the Data Engineering team to ensure that the platform and the solutions deployment therein benefit from an optimised and scalable data flow between source systems and analytical models
Implementing custom machine learning code and developing benchmarking capabilities to monitor drift of any analyses over time.
Understanding of the latest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI and Domino. Experience working on regulatory data would be helpful but not essential.
Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
Being an active member of the Data Science team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure.
Appreciation of how to optimise predictive models, run in production and monitor. Experience running a service team will be beneficial.
Testing and assessing the quality of new tools.
Line management responsibilities as well as team recruitment, training provision and coaching

Candidate Knowledge, Skills and Experience
BSc in Computer Science or related quantitative field or MSc/Ph.D degree in Computer Science or related quantitative field.
More than 2 years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
Experience managing an enterprise platform and service, handling new customer demand and feature requests.
Strong software coding skills, with proficiency in Python and Scala preferred.
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential. Certification in appropriate areas will be viewed favourably.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.
Experience provisioning computational resources in a variety of environments.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Experience with automation strategies e.g. CI/CD, gitops.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Creative, collaborative, & product focused.
Ability to just get things done.
Other
The role will have line reports and task management responsibilities within project or services may occur.
Department – Data & Analytics, S&EUIT
Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.
Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Data Visualisation, Knowledge Management, Data Science, Data Analysis and Information Governance.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer- Software Engineer,"Chandigarh, Chandigarh",XenonStack,None,Organic,"Job Summary
We are looking for a passionate Software Engineer to design, develop and implement Solution for Data Engineering and Product Development for DevOps, BigData and Data Science. The successful candidate will be able to build high-quality, innovative and fully performing software in compliance with coding standards and technical design.
Job Description
Design, develop, test, deploy, maintain and improve the software.
Manage individual projects priorities, deadlines and deliverables.
Efficient Code and Documentation of the Project.
Proper Github Process Flow Implementation and Coding Best Practices.
Review and influence ongoing design, architecture, standards and methods for operating services and systems.

Requirements
Software development experience in one or more general purpose programming languages.
Building Data Solutions for High Volume of Transaction Data.
Strong Knowledge of Algorithms and Data structures.
Knowledge about test-driven development.
Strong knowledge of Databases - SQL/NoSQL Databases and Graph Databases.
Working proficiency and communication skills in verbal and written English.

Preferred qualifications
Experience with one or more general purpose programming languages including but not limited to: Java, C/C++, C#, Objective C, Python, JavaScript, or Go.
Interest and ability to learn other coding languages as needed.
Keywords
Software Engineer
Data Structures
C
Golang
Python Developer
Data Analytics
C++
Java Developer"
Data Scientist,"Pune, Maharashtra",Talentica Software India,None,Organic,"The Company
Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay). We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology. The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.
We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.
Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras
Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval
Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms."
Professional 1 Data Analyst,"Gurgaon, Haryana",DXC,None,Organic,"Job Description:
Essential Job Functions
Designs, implements and maintains databases with respect to database dictionaries and integration of systems through database design to ensure that client requirements are satisfied.
Analyzes data requirements and documents according to required standards by utilizing prescribed tools and methods to ensure that design and implementation are according to company guidelines and client specifications.
Analyzes, designs and validates data models, structures and processes to define data structures and business operations.
Applies data analysis or data modeling techniques to establish, modify or maintain data structures and their associated components to increase efficiency of structures and components.
Participates in the development and maintenance of data standards to ensure consistency across databases.
Coordinates and advises database designers and others using the data structures and associated components to ensure that business specifications are met.
Communicates with clients about data related discrepancies and other matters of significance to ascertain information and correct errors.
Investigates and resolves technical matters of significance within databases by analyzing and researching possible causes and making appropriate corrections to ensure client satisfaction.
Participates in the development of training modules in data modeling techniques and incorporates data modeling into information systems development and maintenance.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in information systems, computer science, or related field preferred
Three or more years of experience in programming or data analysis
Experience working with product configurations and company used database software and hardware
Experience working with security software packages, domain structures, user authentication and digital signatures
Experience working with data modeling practices and procedures
Experience working with relevant programming languages and relational databases
Experience working with data administration, repository management, database creation techniques, and data warehousing standards, strategies, and tools
Other Qualifications
Research, data analysis and problem-solving skills
Personal computer and business solutions software skills
Communication skills to communicate with designers, management and customers
Skills at configuring and installing various operating systems and application software
Ability to work independently and as part of a team
Ability to create and maintain formal and informal networks
Work Environment
Office environment"
Global Data Lead – Supply,"Bengaluru, Karnataka",Alcon,None,Organic,"Tactical PlannerResponsible for driving and managing the Master Production Schedule for the tactical horizon (3 to 24 months) ensuring capacity & resources are in place to support agreed demand plan to satisfy the Customer requirements and to keep the inventory at the next handover point of the supply chain at the agreed target level.Customer Service CoordinatorInterface between the site and its customers acting as the primary contact providing visibility of the supply plan to the customers and maintains the Service Level Agreements (SLAs).Responsible for ensuring a timely implementation of all Life Cycle projects as launches/ changes/ transfers/divestment by coordination of involved stakeholders from different functions. Ensures compliance with Regulatory and GMP, law, SOPs, HSE and Code ofConduct.

-Tactical Planner: -Establishes optimal master production schedule for the tactical horizon from month 3 / 4 to 24 months, including Production volumes based on demand, rough cut capacity analysis and resources allocation resulting in anticipated operational costs and inventory levels -Aligns Master Production Schedule (MPS) to the production plan approved in S&OP -Coordinates action plans to remediate to resources constraints and manages supply KPI reporting and analysis. -Ensures right level of SKU Inventories at the next point of the supply chain. -Owns planning parameters in ERP System. -Confirms supply orders, firmed production orders at the entry point of the time fence. -Leads action plans to achieve supply performance target and drives for continuous improvement. -Facilitate Supply Review Meeting and actively support the entire S&OP processCustomer Service Coordinator: -Ensures that the customers have clear visibility of the current valid supply plan and monitor the delivery commitments in terms of quantities and timelines, in accordance to the Service Level Agreements (SLAs). -Acts as the point of contact for the GOCA process and all order-related topics. -Manages backlog and backorders between the Site and customers/ next supply points and ensures direct communication with Customer and internal and external stakeholders. -Is responsible for creating and maintaining SLAs with related Planning Parameter setup in alignment with the customers. -Is responsible for Monthly Demand Review Meeting (midterm horizon 3 to 24 months) incl. demand assumptions, recognizing trends, showing variances to last demand submissions, as input to Supply Review meeting and Monthly Business Review (MBR) meeting within Sales & Operations (S&OP) process. -Manages demand control activities (short term -3/4 months, within the time fence) and pro-ides inputs to Master Planning Schedule (MPS) and detailed scheduling. -Leads the implementation of LC projects, in order to ensure compliant drug supplies, on time and in right quality and deliver and maintains a detailed Change Over Plan (COP) for LC projects regarding implementation dates, according to the overall strategic project/ program plan, in order to allow for early local Master Data set-up and planning at site and in countries. -Is responsible for the up-to-date assortment at SKU level of the assigned brands. • Execute setup and maintenance of new material master setup and change requests in Alcon ERP systems to support manufacturing and supply chain product launch activities. Requires heavy interaction and coordination across manufacturing and supply chain stakeholders. • Perform daily Material Master Maintenance operations consisting of both global and local manufacturing and supply chain extensions, including process improvements, business rules development, managing ticketing systems and generation of metrics. Ensure that the Alcon business rules defined in the GDM Data Dictionary are applied. • Leverage technology to promote Active and Passive Governance using industry best practices by generating applicable metrics to demonstrate improvemnt of data quality KPIs. • Work closely with other business teams like Supply Chain Planning, Finance, Quality, Regulatory Affairs and Manufacturing to address and resolve master data issues in a timely manner. • Lead process reenginnering and simlificatin efforts to mitigate points of failure, and implement new business processes by documenting revisions to exising or development of new SOPs. • Analyze large amounts of data to support ERP data validation / cleansing activities, operational and project-oriented, and contribute to governance process enhancement. • Maintain compliance with internal, and external controls standards and SOPs (i.e. Alcon Finance Controls Management, Alcan Profit Margin Reporting standards, and Alcon’s Global

-Inventory Management -Gap Analysis -Cost Efficiency and efficiency of supply processes

Operational Excellence Organizational Savvy Stakeholder Engagement Project Excellence Interpersonal Savvy Breakthrough Analysis
Minimum requirements
Operations Management and Execution Project Management Collaborating across boundaries Functional Breadth English Customer Relationship Management Product Life Cycle Management Inventory Management Supply Planning Demand Planning Knowledge of all relevant policies and practices Supplier Relationship Management

• Bachelors Degree in Business, Supply Chain, or Science/Engineering. Masters Degree preferred • 7 years in Master Data Management; Medical Device industry and SAP Master Data Management experience preferred. • Good working skills with MS Office suite; Advance experience in advance MS Excel, MS Access and MS Visio preferred. • 7 years developing solutions to complex problems which may require some ingenuity and innovation. Ensures solutions are consistent with organization precedents and policies. • 7 years interacting with senior internal and external personnel on significant matters often requiring coordination between organizations.
Division
ALCON
Business Unit
NON-NVS AL MFG-TECH OPERATIONS
Country
India
Work Location
Bangalore
Company/Legal Entity
Alcon Ind
Functional Area
Technical Operations
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
Innovation Research Analyst (Remote Position),"Bengaluru, Karnataka",StartUs Insights,"₹45,000 - ₹90,000 a month",Organic,"Are you fascinated by the world of startups and disruptive innovation?
Great — join StartUs Insights, an international data science company (with teams in Austria, Ukraine and India) analyzing startups and emerging technologies to anticipate trends, new business models and innovation areas.
WHY THIS POSITION IS RIGHT FOR YOUR CAREER:
We provide clients from various industries (automotive, health, energy, industry 4.0 etc.) with actionable insights into what impacts their future business. Diversity is in our DNA. We welcome applicants from different backgrounds: science, technology, engineering, mathematics, analytics, economics. Experience or educational background in the following industries will also be accepted: logistics, machinery, engineering (civil, construction, mechanical, electronics), energy or other industries of our focus (read more here). Apply now!
Requirements
Work experience: You have at least 2 years of relevant work experience and strong educational background in: science, technology, engineering, mathematics, analytics or economics OR You have at least 2 years of relevant work experience industries such as: logistics, machinery, engineering (civil, construction, mechanical, electronics) or energy
You are curious about emerging technologies, startups and the digitalization of our society
You are advanced in English
You have strong project management and problem-solving skills
You are at least upper-intermediate in Excel. Experience with other data analytics tools is beneficial
We offer
Work in a company where your input influences further product development
Have constant communication and mentorship from senior analysts from our Vienna Headquarters as well as Ukraine and India
Take part in our personal development programs
Get a clear view of your KPIs and progression possibilities from day one
Enjoy remote work and don’t waste your valuable time commuting
Package includes 25 paid work-free days per year, public holidays and trips to headquarters in Vienna
Responsibilities
Manage analytics and research projects that identify emerging technologies, startups and trends
Work with our AI-driven tool to recognize innovative solutions and technology trends
Execute quality control and timeline management for client reports and internal analytics
Manage content strategies and analysts researching for our Research Blog: www.startusinsights.com/innovators-guide/
Preferrable Start Date: 1st of September 2020
Working hours: 40 hours per week with a fixed schedule
Job Type: Full-time
Salary: ₹45,000.00 - ₹90,000.00 per month
Experience:
work: 2 years (Required)
total work: 2 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Data Engineer,"Bengaluru, Karnataka",IHS Markit,None,Organic,"Position: Data Engineer

Description of Duties
The Automotive Supply Chain and Technology team at IHS Markit is in search of a Data Engineer to support its global team's ongoing research and analysis efforts. The research team produces granular forecast dataset and written analyses on the supply chain of parts supplied to automakers with technology, supplier and logistic information. The team generate forecasts on technology trends through multiple research channels and by using many connected and disconnected data sources to drive the forecast.

The position covers an array of critical data-centric activities aimed at enhancing the efficiency of our 70+ strong research team, sustaining the increasing data complexity and most importantly supporting new product development at one of IHS Markit's fastest growing product lines. The position is based in Gurgaon or Bangalore, India and reports to our U.K.-based Data and Platform operations lead.

Responsibilities and duties
Understanding business requirements to create maintainable workflows e.g. inbound/input data from analysts and external sources to feed a set of interconnected data sets and calculations
ETL process design, implementation, maintenance and documentation for large inter-connected data sets
Data cleaning and manipulation of raw data to provide to Data Science team
Creation of logical and physical data models
Utilise existing database infrastructures as well as building new DB infrastructures as required
Data acquisition exploration
Create and maintain detailed documentation of workflows

Qualifications and skills
3+ years’ experience as a data engineer with data science touchpoints
At minimum, a degree in computer science, computer engineering or a related quantitative field with proven work experience in the data engineering/scientist field
Proven experience with SQL and NoSQL databases like Oracle DB, SQL Server, Cassandra, MongoDB, MySQL, Hadoop, Spark, AWS (EC2 and S3)
Proven experience with one or more programming/scripting languages (e.g. Python, R) is highly desirable
Knowledge of OLAP and ETL processes
Familiarity with data science platforms such as KNIME is a bonus
Knowledge of API creation and maintenance
Familiar with techniques to manage large databases, including partitioning, compression and indexes as well as data mining
Ability to build models (e.g. Linear regression, logistic, Markov models) a plus
Established MS Office skills, O365 desirable
Good communication skills, collaborative team spirit, curiosity to constantly keep thinking of unique approaches and solutions.
Ability to work independently.
Experience committing to deadlines whilst multi-tasking
-
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.
We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.
IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.
For information please click on the following links:
IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement
-
Current Colleagues
If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site."
Lead - Data Analytics and Reporting,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bengaluru
Schedule: Full-time
Employee Status: Permanent
Posting Date: 10/Aug/2020
Unposting Date: 10/Sep/2020
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.



Purpose:
The role is at a senior level in the Digital Channels & Data Analytics team of CCIB based in Bangalore. Innovative big data and machine learning solutions are a key priority for the Bank as part of investments in creating value-add services for clients, creating or joining new consortiums and enabling new business models. This role is to contribute to the development of data projects.

Strategic data initiatives in CCIB creates differentiated digital capabilities for clients to access the Bank's transactional services in over 50 markets efficiently and securely. This includes internet and mobile banking for global business clients, direct integration options, as well as services through third parties.
The role would be suited to a candidate having experiences in data science and analytics field – developing models, rules and algorithms from structured and unstructured sources and performing deep-dive analysis to derive data-driven decisions
Proven track records in building and deploying (financial services) analytic solutions that have created significant value for customers and additional revenue based on new business models.
Experience in building dynamic dashboard (eg Tableau, Power BI) for business stakeholders will be an absolute must
Experienced working in an offshore model is required since role will be based in Bangalore with business stakeholders in Singapore and other overseas locations
Strong data defining, structuring, labelling and developing data models to capture, store, process and use this data to generate intelligent outcomes through Data Analytics
The candidate will have a profound knowledge of large data sets, data management, data governance, data science and metadata.
The role requires close partnership with Cash, Trade, and Security Services Product organisation. Other key stakeholders include global Sales and Implementation teams, Technology, and risk owners such as legal and compliance.
This role reports to the Data Analytics lead for Transaction Banking.

Key Accountabilities:
Help built a strategy & roadmap of analytics solutions that will position Standard Chartered as leading in this field
Creating effective dashboards for business stakeholders
Apply and ensure data governance framework.
Develop and implement artificial intelligence algorithms, rules and rapid prototypes from big data sets that will be fed into various business programs.
Behavioural segmentation based on client journey, profiles, transaction patterns, and app activities that will lead to highly personalized client insights.
Design and monitor A/B testing and various engagement activities.
Perform deep-dive analysis to solve various business problems arising from marketing, dynamic incentive programs, and campaign management.
Build and automate intuitive dashboards that help visualize and answer complex business problems.
Managing risks and regulatory issues associated in data analytics solutions.

Qualifications and Skills:
University Degree or equivalent, preferably in computer science, engineering or analytical discipline, e.g. mathematics, statistics, IT, economics, finance, accounting.
Minimum 8 years working experience in data analytics or business intelligence units, preferably in consultancy (eg Mu Sigma, IBM, Accenture) or financial industry.
Relevant experience in using data is a pre-requisite.
Analytical mind with sound business insights. Ability to translate the business problems and requirements into analytics solutions.
Knowledge of a variety of predictive models, machine learning algorithms and statistical techniques, e.g. logistic regression, decision tree, clustering, neural networks, support vector machines, principal component analytics, natural language processing.
Proficiency across the core statistical toolsets (SQL, SAS, R, Python), data visualization tools (Tableau, Qlik, Power BI) and Hadoop ecosystem.
In-depth knowledge of digital banking, banking products and the overall industry a strong plus
Good verbal and written communication skills.
Excellent stakeholder management skills
Self-motivated. Can-do spirit


Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Data Scientist,"Chennai, Tamil Nadu",Applied Data Finance,None,Organic,"We are looking for strong Data Scientists/Analysts, who will be problem solvers, using predictive modelling techniques and machine learning algorithms, to solve complex business problems in credit and risk domains, and also provide business strategies.
Roles and Responsibilities:
Use of cutting edge machine learning techniques for solving supervised and unsupervised learning problems
Design analytical solutions for complex business problems
Dig deep into data, understand characteristics, evaluate and validate hypotheses through empirical approaches
Recommend and implement best practices around application of statistical modelling
Develop and implement predictive models solving business problems and recommend actionable insights
Mentor and train new recruits
Qualification & Experience
2+ years of experience in the field of analytics, predictive modeling or data science
Strong with programming languages like Python and data processing using SQL or equivalent
Strong with analytical and statistical packages like R, Python Scikit-Learn
Additional familiarity with C/C++ welcome
Experience with the following machine learning algorithms desirable: Gradient Boosting, Decision Trees, Logistic Regression, Random Forests, Deep Neural Networks, Ensemble methods
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com."
Data Science - Principal Software Engineer,"Bengaluru, Karnataka",Citrix,None,Organic,"We believe work is not a place, but rather a thing you do. Our technology revolves around this core philosophy. We are relentlessly committed to helping people work and play from anywhere, on any device. Innovation, creativity and a passion for ever-improving performance drive our company and our people forward. We empower the original mobile device: YOU!
What we're looking for:
You will join a crack team of experienced and talented engineers, with years of history delivering high-quality Analytics products and Solutions, in a fast-paced business environment. You will be collaborating with fellow engineering teams across the globe
Position Overview:
Citrix is expanding its Advanced (Appsec) Analytics team with professionals in the ML/AI/Data Science domains.

Roles responsibilities
Research & develop Machine Learning models for security problems, in the areas of Application Security, Networking, Application & Data.
Suggest, collect and synthesize requirements, and create effective features.
Apply research methodologies to identify the Machine Learning models for the problem at hand.
Basic Qualifications
Bachelors/Masters/PhD in CS/IT/EE/Mathematics and computing with 12+ years of experience
Experience in implementing and deploying Machine Learning solutions (using various models, such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Hidden Markov Models, Conditional Random Fields, Topic Modeling, Game Theory, Mechanism Design, etc.)
Extensive background in statistical analysis and modeling (distributions, hypothesis testing, probability theory, etc.)
Strong hands-on experience with statistical packages and ML libraries (e.g. R, Python scikit learn, Spark MLlib, etc.)
Experience in effective data exploration and visualization (e.g. Excel, Power BI, Tableau, Qlik, etc.)
Experience in developing and debugging in one or more of the languages C/C++, Java, Scala, Python, or R
Ability to work in cross-functional teams
Excellent written and verbal communication skills in English; the ability to convey your message to team members and other stakeholders
Preferred Qualifications
Experience in Application Security Domain, AppFW, BOT, etc
Experience working with relational and NoSQL/Graph databases
Unsupervised & Deep Learning Experience
Familiar with Big Data frameworks (Hadoop or Spark) and cloud infrastructures
Experience in applying Machine Learning techniques
Ability and willingness to multi-task and learn new technologies quickly
What you’re looking for:
Our technology is built on the idea that everyone should be able to work from anywhere, at any time, and on any device. It’s a simple philosophy that guides everything we do — including how we work. If you’re an engineer, we’ll give you plenty of ways to test your skills on cutting edge technology. We want employees to do what they do best, every day.
Be bold. Take risks. Imagine a better way to work. If this sounds like you then we’d love to talk.
Functional Area:
Software Development
About us:
Citrix is a cloud company that enables mobile workstyles. We create a continuum between work and life by allowing people to work whenever, wherever, and however they choose. Flexibility and collaboration is what we’re all about. The Perks: We offer competitive compensation and a comprehensive benefits package. You’ll enjoy our workstyle within an incredible culture. We’ll give you all the tools you need to succeed so you can grow and develop with us.
Citrix Systems, Inc. is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination on the basis of age, race, color, gender, sexual orientation, gender identity, ethnicity, national origin, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions, marital status, protected veteran status and other protected classifications.
Citrix uses applicant information consistent with the Citrix Recruitment Policy Notice at https://www.citrix.com/about/legal/privacy/citrix-recruitment-privacy-notice.html
Citrix welcomes and encourages applications from people with disabilities. Reasonable accommodations are available on request for candidates taking part in all aspects of the selection process. If you are an individual with a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at (877) 924-8749 or email us at ASKHR@citrix.com for assistance.
If this is an evergreen requisition, by applying you are giving Citrix consent to be considered for future openings of other roles of similar qualifications."
Senior Software Engineer - Python/Go,"Bengaluru, Karnataka",Akamai,None,Organic,"Are you excited by the opportunity to develop and produce security tools?
Would a place where you are free to innovate excite you?

Join our World-Class Cloud Security Organization

Our team is part of the Cloud Security organization. We help thousands of the largest enterprises around the world protect their websites and secure their transactions over the internet. As a Gartner recognized web security market leader, we have a proven record of delivering best in class security products and experiences to our customers.
Achieve high-impact milestones contributing to our success

As a Senior Software Engineer you will be developing using Golang and/or Python involving complex threat detection algorithms in an ultra-high traffic environment and as well creating developer productivity tools and services. Our team is partnered with all security product teams inside the company such as the Product Dev, Threat Research, Data Science, OPS, Stability, QA, and many other teams for maintaining network stability by improving monitoring processes and developing tools.

As a Senior Software Engineer you will be responsible for:
Developing using Golang and/or Python for our Security Product tools.
Write data API’s and multi-server applications to meet product needs using Golang.
Develop schemas, migrations, and manage NoSQL databases (REDIS and Cassandra).
Architect modular services; Use Agile methodologies, DevOps, CI/CD."
Data Science Engineer,"Pune, Maharashtra",Alliance Recruitment Agency,None,Organic,"Location: pune
State: pune
PostalCode: 411038
Recruiter: Disha Chauhan - +91 70697 10005
Created Date: 01-10-2019
Desired Skills:
Excellent understanding of machine learning techniques and algorithms, such as k-NN,
Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc.
Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Responsibilities:
We are looking for a data scientist that will help us discover the information hidden in vast
amounts of data, and help us make smarter decisions to deliver even better products. Your
primary focus will be in applying data mining techniques, doing statistical analysis, and building
high-quality prediction systems integrated with our products.
Experience Requirements: Selecting features, building and optimizing classifiers using machine learningtechniques Data mining using state-of-the-art methods Extending the company’s data with third-party sources of information when needed Enhancing data collection procedures to include information that is relevant for buildinganalytic systems Processing, cleansing, and verifying the integrity of data used for analysis Doing the ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of itsperformance
Industry: IT
Salary Range: As Per Industry Standards."
Data Science Engineer,"Bengaluru, Karnataka",IntelliPredikt Technologies,None,Organic,"You can send your CV to careers@intellipredikt.com

Job_ID : IPTB_PE_102
Job Title: Data Science Engineer
Status: OPEN
Job Description: Data scientist is responsible for data exploration, machine learning, IP generation, anomaly detection/ prediction and data visualization of massive dataset using common tools.
Qualification: MS or PhD in Data Analytics areas
Experience: 1 to 5 years of experience in data analytic's for anomaly detection and prediction"
Lead Data Analytics & Reporting,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bengaluru
Schedule: Full-time
Employee Status: Permanent
Posting Date: 10/Aug/2020
Unposting Date: 10/Sep/2020
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.



Purpose:
The role is at a senior level in the Digital Channels & Data Analytics team of CCIB based in Bangalore. Innovative big data and machine learning solutions are a key priority for the Bank as part of investments in creating value-add services for clients, creating or joining new consortiums and enabling new business models. This role is to contribute to the development of data projects.
Strategic data initiatives in CCIB creates differentiated digital capabilities for clients to access the Bank's transactional services in over 50 markets efficiently and securely. This includes internet and mobile banking for global business clients, direct integration options, as well as services through third parties.
The role would be suited to a candidate having experiences in data science and analytics field – developing models, rules and algorithms from structured and unstructured sources and performing deep-dive analysis to derive data-driven decisions
Proven track records in building and deploying (financial services) analytic solutions that have created significant value for customers and additional revenue based on new business models.
Experience in building dynamic dashboard (eg Tableau, Power BI) for business stakeholders will be an absolute must
Experienced working in an offshore model is required since role will be based in Bangalore with business stakeholders in Singapore and other overseas locations
Strong data defining, structuring, labelling and developing data models to capture, store, process and use this data to generate intelligent outcomes through Data Analytics
The candidate will have a profound knowledge of large data sets, data management, data governance, data science and metadata.
The role requires close partnership with Cash, Trade, and Security Services Product organisation. Other key stakeholders include global Sales and Implementation teams, Technology, and risk owners such as legal and compliance.
This role reports to the Data Analytics lead for Transaction Banking.

Key Accountabilities:
Help built a strategy & roadmap of analytics solutions that will position Standard Chartered as leading in this field
Creating effective dashboards for business stakeholders
Apply and ensure data governance framework.
Develop and implement artificial intelligence algorithms, rules and rapid prototypes from big data sets that will be fed into various business programs.
Behavioural segmentation based on client journey, profiles, transaction patterns, and app activities that will lead to highly personalized client insights.
Design and monitor A/B testing and various engagement activities.
Perform deep-dive analysis to solve various business problems arising from marketing, dynamic incentive programs, and campaign management.
Build and automate intuitive dashboards that help visualize and answer complex business problems.
Managing risks and regulatory issues associated in data analytics solutions.

Qualifications and Skills:
University Degree or equivalent, preferably in computer science, engineering or analytical discipline, e.g. mathematics, statistics, IT, economics, finance, accounting.
Minimum 8 years working experience in data analytics or business intelligence units, preferably in consultancy (eg Mu Sigma, IBM, Accenture) or financial industry.
Relevant experience in using data is a pre-requisite.
Analytical mind with sound business insights. Ability to translate the business problems and requirements into analytics solutions.
Knowledge of a variety of predictive models, machine learning algorithms and statistical techniques, e.g. logistic regression, decision tree, clustering, neural networks, support vector machines, principal component analytics, natural language processing.
Proficiency across the core statistical toolsets (SQL, SAS, R, Python), data visualization tools (Tableau, Qlik, Power BI) and Hadoop ecosystem.
In-depth knowledge of digital banking, banking products and the overall industry a strong plus
Good verbal and written communication skills.
Excellent stakeholder management skills
Self-motivated. Can-do spirit


Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
AI Developer,"Pune, Maharashtra",GrayRipples.com,"₹40,000 - ₹50,000 a year",Organic,"Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Salary: ₹40,000.00 - ₹50,000.00 per year
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
java: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Senior Data Scientist and Machine Learning Engineer,"Bengaluru, Karnataka",McAfee,None,Organic,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:
McAfee is looking for an experienced data scientist to work on our next-gen threat assessment platform. You will work with experienced developers, security researchers and data scientists to understand and implement solutions to the problems found in today’s fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.

Company Overview
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.
About the role:
You will collect and analyse data to spot trends and help us face the challenges of an evolving security landscape.
Design, debug and test complex software in the field of data science.
Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with team members (developers and malware researchers) to develop and review designs and requirements to analyse data and build ML models.
Knowledge of security practises, procedures and capabilities to perform non-repetitive, work. You will report to the Engineering Manager.
About You:
You have the following required skills:
Display understanding of and ability to use programming languages: C++, Python, C#, and SQL. Have a knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Have ability to think and research creatively. Create“stories” told by the data and presents them to other scientists.
5+ years’ experience working in security research, data mining or natural language processing. Use predictive modelling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect and explore insights from structure and unstructured data .
Develop software, algorithms and applications to apply mathematics to data, perform large-scale experimentation and build data-driven apps to translate data, solve a variety of business problems and ensure strategy. Assist business with casual inferences & observations with finding patterns , relationships in data.
Have understanding of internal business segment (partners).
Typically requires expertise in relational database structures, research methods, machine learning, Cloud-based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL).
Typically have advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.
Company Benefits and Perks:
We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.
Job Type:
Experienced Hire
Primary Location:
India, Bangalore

Additional Locations:"
Data Science Internship,"Bengaluru, Karnataka",OTO Capital,"₹12,000 a month",Organic,"About the company:
In the recent years - consumers have changed and love to upgrade faster. They shift from one city to another for better career options, value access over ownership and perceive ownership as an additional responsibility of care and maintenance. Hence, there is a big need of providing him/her a hassle-free option to own (cars, bikes, etc.) without much commitment. OTO envisions the concept of 'Own Together' enabling ownership (starting with cars) in a new way of financing with flexible usage terms. With OTO, consumers pay for a car with up to 25% low, all-in, month-to-month payment. We aim to redefine the $40 Billion+ market of Car Ownership in India at first. We have already partnered with 100+ showrooms & corporates to provide this offering to the car purchasers at a point of sales.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. â€¢ Work with the data science team and contribute to the ongoing project 2. â€¢ Research about different techniques that can be used to achieve the goal of the project 3. â€¢ Practically understand the problem statement and Implement the research done to develop custom data models and algorithms 4. â€¢ Extract, Harmonize, clean, and merge data from different data sources for further use 5. â€¢ Build machine learning solutions to drive optimization and improvement in product and business strategies 6. â€¢ Develop processes and tools to monitor and analyze model performance and data accuracy
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
â€¢ Some experience working with large data i.e. mining, cleaning, manipulating data sets, and building statistical models â€¢ Research-oriented mind-set â€¢ Strong problem-solving skills with a drive to learn and master new technologies and techniques â€¢ Knowledge about statistical computer languages (Python, R, SQL, etc.) to draw insights from large data sets â€¢ Knowledge of machine learning and statistical techniques (OCR, clustering, decision tree learning, artificial neural networks, regression, statistical tests, etc.) and their real-world advantages/drawbacks â€¢ Knowledge about automobile and finance industry will be an extra advantage
Number of internships/jobs available: 2
Categories: Data Science"
Associate - Quant Modeling,"Bengaluru, Karnataka","JPMorgan Chase Bank, N.A.",None,Organic,"Responsibilities:
Apply critical thinking skills and perform advanced analytics with the goal of solving complex and multi-faceted business problems.
Generate deep insights through the analysis of data and understanding of business processes and turn them into actionable recommendations.
Perform advanced quantitative and statistical analysis of large datasets to identify trends, patterns, and correlations that can be used to improve business performance.
Know what type of algorithm to use and how to implement them
Build and deploy prototype solutions to demonstrate ideas and prove concepts.
Develop presentations to summarize and communicate key messages to senior management sponsors and colleagues.
Become a subject matter expert and trusted advisor in the analytics discipline.
Collaborate with others in the organization to develop new ideas and brainstorm potential solutions.
Actively contribute to the continuous learning mindset of the organization by bringing in new ideas and perspectives that stretch the thinking of the group
Mentor junior team members

Qualifications/Skills
Deep quantitative/programming background with a graduate degree (M.S., Ph.D.) in Statistics, Engineering, Computer Science, Mathematics, Operations Research, or Economics,
6-9 years of related experience preferred
Hands-on experience with Machine Learning and Artificial Intelligence
Ability to write code and develop production-ready analytical applications
Significant experience working with very large scale (structured and unstructured) data
Expertise in at least one of the following: Python, R
Excellent written and oral communication skills to clearly present analytical findings and business recommendations. Highly motivated, productive, and teamwork oriented.
Good project management skills (clear goal setting, well-organized, detailed planning, and ability for tight-timeline deliverables).
Able to translate ambiguous business problems into a conceptual mathematical framework
Passionate about continuous learning and professional development
Deeply curious; creative and imaginative
Ability to influence and become a trusted advisor
Ability to convey complex concepts to non-technical audiences
Effective communication and presentation skills
Can work both independently and collaboratively
Shift Timings - 2pm -11pm IST . This may vary due to business requirementsJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Senior Data Scientist,"Hyderabad, Telangana",TCPWave,None,Organic,"Salary
DOE
Number of positions
1
Description
A senior data scientist will assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need. And, use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help customers build DL models.
Minimum Qualification
A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
7+ years of industry experience in predictive modelling, data science and analysis.
Technical Skills
Experience using Python and/or R and SparkML.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience working with GPUs to develop models.
SQL
Responsibilities
Experience giving data presentations."
Senior / Lead Data Scientist,"Yelachenahalli, Karnataka",Tekion,None,Organic,"Job Location: Bangalore
https://tekion.com/
Description:
Tekion is looking for an experienced Data Scientist to help shape the future of Automotive Industry. At Tekion we transform the end to end experience of customers in automotive. Are you motivated by solving tough problems, business-focused and have a passion for data driven decisions? The successful candidate will be a self-starter, comfortable with ambiguity, have an affinity for building from scratch, demonstrate strong attention to detail, and have the ability to work in a fast-paced, complex and ever-changing environment.
You’ll be able to bring your unique skills and expertise to shape the direction of our Data Science team. You will have an opportunity to work with state of art machine learning algorithms on large datasets. We are looking for highly motivated data scientists interested in delivering the next level of innovation for Tekion.
Core responsibilities include:
Work directly with application/product teams to define, develop and implement the right ML solution for the problem at hand.
Come up with new solutions for solving automotive industry business problems.
Define the correct evaluation metrics for offline and online evaluation. Creating and tracking accuracy and performance metrics.
Incorporating new data sources and implementing creative methodologies to improve model performance.
Helping build production systems that take inputs from multiple models and support decision making.
Should be equally comfortable with digging in to customer requirements as you are drilling into design with development teams and developing production ready learning models. Should consistently bring strong, data-driven business and technical judgment to decisions.
Required Qualifications:
Masters, PhD in Data Science, Mathematics, Operations Research or related field. The right candidate has a background in probability and statistics, applied mathematics, or computational science and a history of solving difficult problems with good business impact using a scientific approach.
Experience working with ML algorithms and frameworks.
Significant experience in Data Science and Machine Learning with a strong proven track record in delivering positive business impact.
5+ years of hands-on experience with analytics, data science and big data experience in a business context.
Experience in programming in Python or similar languages and maintaining code repositories in git.
Experience with data visualization and presentation, turning complex analysis into insights.
Preferred qualifications:
Experience in Recommendation Engine, Natural Language Processing.
Domain knowledge of automotive industry.
Enjoys discovering and solving problems; proactively seeking clarification of requirements and direction; being a self-starter who takes responsibility when required.
Strong interpersonal, verbal, visual and presentation skills, ability to communicate complex findings in a simple manner to executives.
Ability to work collaboratively across multiple products and application teams.
A willingness to learn, share and improve.
Job Type: Full-time
Education:
Bachelor's (Preferred)"
Online Trainer-Data Science,"Jaipur, Rajasthan",Parshi Emerging Technologies Pvt Ltd,None,Organic,"Urgent Requirement for Full-Time and Part Time Trainers across all India module including: Python, R , Machine learning, Data Science
Location: Multiple location in India/ Online
Experience: 2-8+Years of relevant
Job Types: Full-time, Part-time, Contract
Salary: ₹15,000.00 - ₹100,000.00 per month
Experience:
work: 1 year (Required)
total work: 1 year (Required)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes"
Machine Learning,"Noida, Uttar Pradesh",Umbrella Infocare,None,Organic,"Job Profile
Develop statistical models and validate them on a regular basis.
Selecting and transforming features, building and optimizing classifiers using
machine learning techniques.
Integrating data from multiple sources including third party sources.
Data mining using state-of-the-art methods.
Creating automated anomaly detection systems and constant tracking of its performance.
Creating automated evaluation environment of complex models and constant tracking of relevant performance.
Educate other departments on data science methodologies, concepts and algorithmic advancements."
Data Scientist,"Noida, Uttar Pradesh",Jubna,None,Organic,"Job ID: JDS01
As a Data Scientist, you will work to resolve ambiguity with data, play a crucial role in the iteration and optimization solutions, and support data-driven decision-making across the organization.
ROLE RESPONSIBILITIES
Tasked with solving a real-life business problem that requires a processing/analyzing large amounts of data and handling a variety of data sources.
Take ownership of successful completion for the end to end life cycle and implementation.
Proactively investigate, report, and where possible, address data quality issues.
S
Can envision & implement the optimal analytics technique/approach required for the problem.
Ability to work and execute projects on both structured and unstructured data in a big data environment.
Ability to work across geographies and interact with global stakeholders.
Ability to coordinate and work within multiple business units from a project management perspective.
Prior experience working in Agile methodologies/JIRA would be a plus.
MINIMUM REQUIREMENTS
BS/BE in Computer Sciences, Math, Statistics, or related field. Masters preferred.
An expert in at least one of the machine learning frameworks - Keras, Tensorflow, PyTorch, etc, as well as programming, visualization, and statistical tools such as R, JMP, SAS, Tableau, Python, Perl, Java/C++
Minimum of 4+ years of experience in data, advanced analytics, data science, and business intelligence.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases.
Proficient in Python ML libraries, Hadoop/Redshift/BigQuery.
Experience in the Ad-Tech industry is a must.
OTHER INFORMATION
Join a fun and lively young Startup based in Dubai Silicon Oasis (while operating from Noida, India). Boost your experience and learn about the different types on Online AdTech environments and models. Show your skills and potentially become a pillar of our fast-growing team.Jubna offers an Attractive compensation, Health Insurance, Travel Allowance.
Some travel to Dubai, UAE is required (10%)"
Applied Scientist Intern,"Hyderabad, Telangana",Amazon Dev Center India - Hyd,None,Organic,"A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
Experience in predictive modelling and analysis, predictive software development
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills

Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches

Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences"
Senior Data Scientist,"Pune, Maharashtra",PhonePe,None,Organic,"PhonePe's mission is to make it easy and secure for our customers to use and manage their
money via a purely digital, mobile experience. The data science team at PhonePe
contributes to this mission by using the power of big data and advances in machine learning
to help various stakeholders in the business. Most important of these are our users, to whom
we seek to provide the best possible experience by showing them information and insights
that are most relevant and interesting to them. Additionally, we ensure that our own business
partners also benefit from how they can best serve customers via the PhonePe platform.
Finally, we help our own teams understand and utilize data to improve their own processes
and planning efforts. The volume of data, and the variety of problems mean that data
scientists can have a visible and a real, positive impact on millions of our users.
Responsibilities
We plan to expand our data science team, and we are looking for senior data scientists who
will work on applications related to financial services. They will work in a dynamic
environment, and with cross-functional teams to assist those teams in every possible
manner to ensure that our products help our users derive most value. They will be expected
to work with product, business, and engineering teams to
help them understand what data science can do for them and set the right
expectations,
analyze large volumes of data, and implement and deploy solutions as necessary,
be able to clearly communicate results and recommendations to various stakeholders,
evaluate the effectiveness of the solutions and improve upon them in a continuous
manner. We expect them to have a mix of a strong technical background, the ability
to understand the business implications of their work, and the ability to empathize
with our users and work towards helping PhonePe give them the best experience,
and
help and mentor junior members to become better data scientists.
Qualifications
A Bachelor's or higher degree in a quantitative discipline (computer science, statistics,
engineering, applied mathematics)
6-7 years relevant work experience with a Bachelor’s degree, or 3-4 years relevant
experience with a Master's degree
Specific technical skills include
o Expertise in Java, Python, R, shell scripting languages.
o Expertise in querying relational, non-relational, graph databases.
o Ability to clearly communicate and work with people of different backgrounds.
o Experience in big data technologies (Spark, MapReduce, Pig, Hive)
o Experience using machine learning (structured, text, video data) libraries
(preferably in Python), deep learning (Tensorflow, PyTorch)
o Experience using visualization libraries
Good to have: Hands-on experience with source control and deployment tools (Git,
Jenkins, etc.)."
Applied Statistical Researcher,"Mumbai, Maharashtra",Morningstar,None,Organic,"Morningstar is looking for an applied social scientist, to conduct survey research and statistical analyses on the financial behavior and behavioral obstacles among investors and investment professionals. You’ll dig deep into the data to understand the varied profiles of individuals and the financial professionals that serve them, develop original survey instruments to extend our knowledge, and identify potential opportunities to improve the investor ecosystem.

Responsibilities

In this role, you’ll work hand in hand with our diverse behavioral science team (in Mumbai and in Chicago), and partner with leading academics around the world to:

Conduct original research, including on issues of retirement planning, investing, and spending and savings behavior: for the United States, India, and other countries.
Identify and source key datasets around the world to power these analyses.
Partner with the data team to systematically load and process these data sources to make them available to you and other researchers on the team.
Develop new statistical instruments to measure the preferences and beliefs of individual investors and financial professionals.
Developed rigorous statistical models to explain individual behavior and traits, cross sectionally and over time, and ensure the robustness of your findings.
Write up your results, for industry and academic publication.
Share your results via internal meetings, conferences and other forums.

Requirements
Postgraduate social science training: particularly in economics, psychology, or sociology.
Demonstrated expertise with statistical analyses for social science: regressions, MLE, etc.
Significant expertise designing surveys and analyzing survey data.
Complete command of American and International English for developing surveys.
Training and experience in behavioral science (behavioral economics, behavioral finance), a strong plus.
Deeper knowledge of machine learning and predictive analytics techniques (clustering and classification, decision trees, random forests, etc.) are a strong plus.
Professional experience developing models of financial decision-making (investment, retirement, or savings) is ideal.
Demonstrated ability writing about social science findings for a general audience.
Experience and enjoyment in public speaking is useful, but not required.
At least two years of experience using R, Python, STATA or a similar statistical language.
Independent, creative thinker with a strong interest in financial behavior.

Morningstar is an equal opportunity employer. The position is based in our Mumbai office.
I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity"
Senior Data Scientist,"Chennai, Tamil Nadu",Applied Data Finance,None,Organic,"We are looking for a strong Senior Analyst/Senior Data Scientist, who will guide model development. The person will be part of data science team that continuously interacts with underwriting analysts and developers that drive solutions to the complex business problems, in credit and risk domains.
Roles and Responsibilities:
In addition to the responsibility of analyst/Data Scientist, additional responsibilities:
Good understanding of the underlying business and workings of cross functional teams for successful execution.
Good written and oral communication, and ability to convey technical details to teams working across multiple time zones.
Mentor a small team of analysts.
Qualification & Experience:
4+ years of experience in the field of credit rist analytics, marketing analytics backgrounds
Proven experience working in teams with end to end real time implementation
Strong with programming languages like Python and data processing using SQL or equivalent and ability to experiment with newer open source tools
Strong with analytical and statistical packages like R, Python Scikit-Learn
Familiarity with deep learning, xgboost, scikit, apache spark, GPU based machine learning
Good communication skills and ability to articulate complex scientific and technical matters to the business group
Ability to successfully interact with business and software teams for execution
Experience in newer machine learning algorithms
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Experience in risk and credit score domains are a big plus
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com."
Data Scientist,"Bengaluru, Karnataka",Bottomline Technologies,None,Organic,"Bottomline is at the forefront of digital transformation. We are a growing global market leader uniquely equipped to address the changing needs of how businesses pay and get paid. Our culture of Working with and for each other enables us to delight our customers. We empower our teams to think like owners driving customer delight, helping them grow their business and win in their markets.
We are looking for Data Scientist to innovate, win, and grow with us in Bangalore, India.
As a member of Central Data & Analytics Team, you will be developing software to be used for a range of machine learning and data mining techniques, including predictive modeling, anomaly detection, customer profiling and segmentation, recommendations, text analytics, and big data analytics in solving our business problems. You will take an idea from conception and experimentation to design and implementation to deployment and production. In this role, you will interact with a team of experts in Machine Learning and Data Mining.
How you'll contribute:
Exposure to the sate-of-the-art of data analytics products and solutions.
Ability to prototype statistical analysis algorithms
Experience in coding structures for storing and processing complex, high volume, and multi-dimensional data
Experience in optimizing space/time tradeoffs for computationally expensive processes
Exposure to different Machine Learning techniques
Familiar with Agile software development process.
What will make you successful:
At least 2 years' professional experience in with major programming languages such as Java, Python, Scala
A completed graduate degree in Computer Science, Engineering or any other heavily numerate subject
Understanding of the full software development lifecycle (conduct data analysis and build large-scale machine-learning models/pipelines)
Experience in Big Data technologies (Hadoop, Spark), large relational and NoSQL databases
Experience in data pre-processing, Machine Learning, and data visualization
Experience in quantitative analysis and translation of findings into actionable insights
Outstanding communication and presentational skills
You'll love Botttomline because in everything we do we seek to delight our customers and we are passionate about building a company of which we can all be proud, and this starts with building amazing teams filled with team members that challenge you every day.
Start your #LifeAtBT
Public cloud AWS, ML, DL, NPL, Python, Java, Scala, Hadoop, Spark, Docker, Kubernetes, Agile, Scrum"
Data Scientist,"Mumbai, Maharashtra",Tata Communications,None,Organic,"Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
- 3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions

Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:
Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks
Innovative Solution&Group:
Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders
Stakeholder Management:
Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills"
Senior Data Scientist and Machine Learning Engineer,"Bengaluru, Karnataka",McAfee,None,Organic,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:
McAfee is looking for an experienced data scientist to work on our next-gen threat assessment platform. You will work with experienced developers, security researchers and data scientists to understand and implement solutions to the problems found in today’s fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.

Company Overview
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.
About the role:
You will collect and analyse data to spot trends and help us face the challenges of an evolving security landscape.
Design, debug and test complex software in the field of data science.
Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with team members (developers and malware researchers) to develop and review designs and requirements to analyse data and build ML models.
Knowledge of security practises, procedures and capabilities to perform non-repetitive, work. You will report to the Engineering Manager.
About You:
You have the following required skills:
Display understanding of and ability to use programming languages: C++, Python, C#, and SQL. Have a knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Have ability to think and research creatively. Create“stories” told by the data and presents them to other scientists.
5+ years’ experience working in security research, data mining or natural language processing. Use predictive modelling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect and explore insights from structure and unstructured data .
Develop software, algorithms and applications to apply mathematics to data, perform large-scale experimentation and build data-driven apps to translate data, solve a variety of business problems and ensure strategy. Assist business with casual inferences & observations with finding patterns , relationships in data.
Have understanding of internal business segment (partners).
Typically requires expertise in relational database structures, research methods, machine learning, Cloud-based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL).
Typically have advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.
Company Benefits and Perks:
We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.
Job Type:
Experienced Hire
Primary Location:
India, Bangalore

Additional Locations:"
Data Analyst (SQL),"Pune, Maharashtra",Springer Nature,None,Organic,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.
Visit: group.springernature.com and follow @SpringerNature
Springer Nature is seeking a highly motivated Data Analyst for its highly-regarded Analytics Centre of Excellences serving the Research division that includes Nature, Springer, BioMedCentral and ScientificAmerican.
As a Data Analyst, you’ll be analyzing big data from very highly trafficked websites and content. You will provide actionable analysis and insight into the behavior of researchers in both their roles as authors and users of scientific information as well as general trends in the world of research. Driving change that improves their experience with SpingerNature and supports our purpose to advance discovery.
Roles and Responsibilities
Implement online tracking, tagging and analytics infrastructure, and solutions to provide accurate, actionable data to the business
Creation and production of regular reports and analysis on website and customer behaviour and engagement to help make informed decisions
Implement cutting edge analytics solutions to help us become best-in-class data handlers
Consult with stakeholders throughout the business to shape and implement solutions in support of business objectives
Play a key role in shaping solutions, creating the right governance and safety checks to maintain tracking accuracy
Role Requirement
University degree with a strong analytical/quantitative background or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.)
Good working knowledge of SQL, Python, Google Tagmanager and Analytics
Experience in experimentation (A/B testing, MVT) and personalisation
Demonstrable experience of using data insights and analytics to add tangible value in achieving the wider goals and strategy of the business
Excellent analytical problem-solving capabilities coupled with business acumen
Well organized and accurate with good time management
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities."
Lab Application Scientist,"Mumbai, Maharashtra",Merck KGaA,None,Organic,"Profile Laboratory Application Scientist (Analytical Chemistry)

Your role:
Develop analytical applications for Pharma QC, Food & Beverage and others using analytical techniques such as HPLC, GC and related techniques
Handle customer troubleshooting inquiries related to sample prep, HPLC, GC and related techniques
Present and report to leadership on performance and activities as required
Proper handling, care and maintenance of analytical instrumentation
Legibility and commitment in documentation reporting and management, similar to cGMP practices.
Awareness and familiarity with regulatory requirements in the pharmaceutical and allied industries.
Lab management responsibilites for ordering consumables using procurement systems and proper maintaining of records and storage conditions of reagents.
Positive team player possesing collaborative and networking ability
Good teaching ability for training other laboratory staff or non-scientists
Willing to travel occasionally to support customer related technical queries

Who you are:
MSc. or PhD. in Chemistry/Analytical Chemistry/Biochemistry/Life Science or related field.
At least 3 years experience in analytical method development/method validation in a pharma, academia or testing laboratory.
Hands-on experience and deep knowledge in HPLC, GC, and/or related MS techniques is a must.
Good problem-solving skills and analytical thinking to solve scientific problems.
Excellent written and oral communication skills.
Proficiency in Microsoft Office, Excel and chromatography data systems.
Job Requisition ID: 209232
Location: Mumbai
Career Level: C - Professional (1-3 years)
Working time model: full-time
US Disclosure
The Company is an Equal Employment Opportunity employer. No employee or applicant for employment will be discriminated against on the basis of race, color, religion, age, sex, sexual orientation, national origin, ancestry, disability, military or veteran status, genetic information, gender identity, transgender status, marital status, or any other classification protected by applicable federal, state, or local law. This policy of Equal Employment Opportunity applies to all policies and programs relating to recruitment and hiring, promotion, compensation, benefits, discipline, termination, and all other terms and conditions of employment. Any applicant or employee who believes they have been discriminated against by the Company or anyone acting on behalf of the Company must report any concerns to their Human Resources Business Partner, Legal, or Compliance immediately. The Company will not retaliate against any individual because they made a good faith report of discrimination.

North America Disclosure
The Company is committed to accessibility in its workplaces, including during the job application process. Applicants who may require accommodation during the application process should speak with our HR Services team at 855 444 5678 from 8:00am to 5:30pm ET Monday through Friday."
Machine Learning Scientist (8 -10 yrs),"Chennai, Tamil Nadu","Agilysys, Inc.",None,Organic,"About Company

At Agilysys, Inc. we are proud of our 3,000+ customers including some of the world’s most recognizable resort, casino and cruise line brands. We specialize in market-leading point-of-sale, property management, inventory and procurement, and mobile and wireless solutions that are designed to streamline operations, improve efficiency and enhance the guest experience. We serve casinos, resorts, hotels, food service venues, stadiums, cruise lines, grocery stores, convenience stores, general and specialty retail businesses and partners. With extensive operations, throughout North America, and additional sales and support offices in Singapore and Hong Kong, as well as software development in India, we are growing. For more information, visit: www.agilysys.com.
Machine Learning Scientist
We are looking for Senior Applied Scientists who has deep passion for building machine-learning solutions and can help us take our products to the next level.
In this role, you will
Be responsible for developing, training, inferencing, evaluating, and deploying machine learning algorithms and/or models.
Design and perform experiments to continually refine and enhance our deep learning technology solutions.
Work closely with software engineers on detailed requirements, technical designs and solutions.
Provide technical leadership and research new machine learning approaches to drive innovation.
Help drive adoption of Machine Learning across the company.
Qualifications
Master’s degree in Data Science, Analytics or Computer Science with Machine Learning specialization or related discipline. A PhD is preferred.
5+ years hands-on experience in building Machine Learning solutions.
3+ years’ experience with data structures, algorithm design, problem solving and complex analysis.
Experience with implementing deep learning platforms such as TensorFlow, Keras, and Darknet
Experience with implementing deep learning models such as Inception, Faster-RCNN, SSD, YOLO3.
Strong coding knowledge, experience with Azure or AWS machine learning pipelines.
Excellent understanding of convolution neural networks and other machine vision algorithms and methodologies.
Experience working effectively with science, data processing, and software engineering teams.
Excellent oral and written communication skills, with the ability to effectively communicate complex technical concepts and solutions.
Proven hands on experience working with large data sets and training models.
Ability to extract the practical implementation information from academic papers.
Interest in working on embedded systems.
Proven track record of executing complex projects.
Preferred:
Experience in deploying machine learning models on the edge"
Grayripples | Artificial Intelligence Developer | Machine Le...,Remote,GrayRipples.com,None,Organic,"GrayRipples is seeking AI Developer interested to deepen their software skills and broaden expertise using or creating new tools, techniques, and processes.Be part of a global company and collaborate with other world class peers in the fields of machine learning, deep learning, systems, compilers, frameworks, or DevOps.
Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Work from home option is also available, location is not a constraint for the right candidate!!
Job Types: Full-time, Part-time, Temporary
Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes"
Data Engineer (Talend/Bigdata),"Bengaluru, Karnataka",Palnar Transmedia,None,Organic,"Primary Responsibilities:
Lead and deliver complete application lifecycle design, development, deployment, and support for actionable BI and Advanced Analytics solutions
Design and develop data models and ETL process for structured and unstructured data that is distributed across the globe between Cloud and On-Premises
Develop and deliver solutions with data streaming capabilities for large volume of factory data
Demonstrate and document the development methodology, results and insights to the business partners and senior leadership.
Work directly with management and Business units to design, configure, support cloud deployment, and performance tuning/optimization.
Develop design documents and translates into component-level designs to accelerate development.
Competencies & Experience Required/Desired
8+ years of experience in data modeling and ETL using industrial leading tools to process the data using RDBMS, In-Memory and Bigdata data stores
5+ years of experience in deploying custom data solution using Talend
4+ years of experience in Big Data development using Cloudera Hadoop (Hive, Impala & Talend)
3+ years of experience in developing flows using data streaming, batch processing, and Microservices
2+ years of experience with AWS tools such as S3, EC2, ECS, EKS, SageMaker, Aurora, Redshift, RDS, Lambda Functions AMI, ELB, ALB, NLB, VPC, Auto Scaling configurations, DMS, Amazon FW, API Gateway, IAM, CloudTrail, and CloudFront.
Multiple experiences in implementing solutions involving unstructured data using Talend
Strong problem-solving capabilities. Results oriented. Relies on fact-based logic for decision-making.
Ability to work with multiple projects and work streams at one time. Must be able to deliver results based upon project deadlines.
Willing to flex daily work schedule to allow for time-zone differences for global team communications
Strong interpersonal and communication skills
Degree in Management Information Systems, Computer Science OR equivalent work experience in an IT organization
Additional Skills:
Having subject matter expertise in one or more of the functional areas such as Sales, Finance,
Manufacturing, production planning, purchasing, marketing, engineering
Experience in demonstrating the challenges and recommendation to leadership team in a precise manner
Prior working experience with SAP HANA, SAP ERP, SAP BW environments
Experience in visualization tools
Experience in developing basic data science models using Python or a similar language
Java development and API management experience is a great plus"
Data Engineer,"Bengaluru, Karnataka",AliveCor,None,Organic,"Data Engineer
AliveCor produces and delivers rich, informative, clinical-grade, personal heart data that can be easily understood by patients - anytime, anywhere. As a Data Engineer, you will architect and improve our data infrastructure, develop new products, and support medical science while protecting user privacy. The ideal candidate has a strong background in engineering, as well as experience in statistical analysis, data analysis tools, SQL and Python. You will work closely with our product management, engineering, and AI teams to architect and build fast and efficient databases, pipelines, and services.
Responsibilities
Work with structured and unstructured real-world medical data
Design, build and launch efficient and reliable data pipelines to move complex data
Write high-quality, efficient, testable code in Python, C++, or Go.
Build data expertise and own data quality
Collaborate with software and AI engineers to design and implement data architecture
Integrate with 3rd party analytics tools and APIs (Mixpanel, Google Analytics)
Build horizontally scalable infrastructure to support ML training and data mining research
Qualifications and Skills:
B.E. in Computer Science or a related discipline, or related practical experience
Minimum 4 years of Experience with Data Engineering & Data Architecture
Experience using advanced SQL and databases in a business environment with large-scale datasets (Hadoop, Hive, Presto)
Experience with statistical modeling and analyzing large data sets
Experience with product analytics tools and APIs (Mixpanel, Google Analytics)
AWS expertise (S3, EC2, Lambda, Redshift, Athena) is a plus
Experience developing scalable microservices also a plus
Familiarity with Kimball's data warehouse lifecycle

About Us
AliveCor is on a mission to define modern healthcare through data, design and disruption. We’ve pioneered the creation of FDA-cleared machine-learning techniques, transformed wearable medtech to put proactive heart care at everyone’s fingertips. Kardia is the most clinically validated mobile EKG technology. AliveCor was named as one of the Top 10 Most Innovative Companies in Health for 2017 by Fast Company as part of the publication’s annual ranking of the world’s Most Innovative Companies. AliveCor was awarded the 2015 Tech Pioneer by the World Economic Forum and one of the 50 Smartest Companies in 2015 by the MIT Technology Review. AliveCor recently announced a collaboration with Mayo Clinic that will result in new machine learning capabilities to unlock previously hidden health indicators in EKG data, potentially improving heart health as well as overall health care for a variety of conditions. AliveCor is a privately held company headquartered in Mountain View, CA.
AliveCor is an equal opportunity employer and will not discriminate against any employee or applicant on the basis of age, colour, disability, gender, national origin, race, religion, sexual orientation, or any other classification protected by federal, state, or local law.
Watch the following video demonstrating our product.
KardiaMobile: How's your heart?
https://www.youtube.com/watch?v=8I9xosgA-Ig"
Data Scientist -1,"Bengaluru, Karnataka",Acko General Insurance Limited,None,Organic,"Role and Responsibilities:
Work closely with Business teams & Product Managers to identify opportunities and serve as an ambassador for data science
Translates complex functional and technical requirements into detailed architecture, design, and high performing software and applications.
Works with peer developers to make sure that all data solutions are consistent and ensures all automated processes to preserve data by managing the alignment of data availability and integration processes
Eligibility Criteria:
2 years of experience in the field of statistics, data mining and machine learning
Qualifications:
BTech/BE Premier institute like IITs/BITS/NITs
Experience in e-commerce/Online Internet companies
Skills:
Expert-level understanding of the underlying theory of Machine Learning.
You have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
Taking end-to-end ownership of problem domains and continuously improving upon quantitative solutions
Demonstrated ability to facilitate and work with minimal direction, with the proven ability to coordinate complex activities
Analytical thought leadership and stay current on developments in data mining and the application of data science"
Data Scientist III,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"Bachelor’s or Master’s degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics
4+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python, R), or statistical/mathematical software (e.g. R, SAS, Matlab, etc.)
2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication
A natural curiosity and desire to learn
Experience articulating business questions and using quantitative techniques to arrive at a solution using available data
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences

Description
Amazon.com strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated and friendly work environment.

We need an expert in econometric and statistical tools to extract insights at scale by building models with our world class data systems, designing advanced new experimental methods, and investigating complex behavioral patterns.

Team Introduction
Amazon Search creates powerful, customer-focused product search solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, our systems go to work. Our Search Engine team designs, builds, and delivers high performance, fault-tolerant, scalable distributed search engine used by millions of Amazon customers every day.

We are looking for a highly motivated Data Scientist who can help ensure our experience on Amazon Search is creating long-term value for our customers. This person will be responsible for architecting insights and systems to anticipate which features will improve customer’s search experience. This person will also be responsible for designing experiments and devising frameworks that measure the short-term and long-term impact of our product initiatives. Finally, this person would also derive insights using our existing data and experiments to inform new innovation and direction for Search Technologies and internal partner teams.

The ideal candidate will be an expert in the areas of data science, machine learning and statistics, having hands-on experience with multiple improvement initiatives as well as balancing technical and business judgment to make the right decisions about technology, models and methodologies. You will leverage data, experimental design, and analytics to help define new ways to evaluate, visualize and predict to understand outcome and decisions on how to improve customer engagement across customer lifecycle segments. The candidate needs experience with data science / business intelligence, analytics, and reporting systems while striving for simplicity, and demonstrating significant creativity and high judgment backed by statistical proof.

The ideal candidate should have deep expertise in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and use appropriate statistical and econometric techniques to derive insights and recommendations to leadership. You should excel at bringing large datasets together to answer business questions and drive change.

Responsibilities Scientists at Amazon are expected to develop new techniques to process large data sets, address quantitative problems, and contribute to design of automated systems around the company. Major responsibilities include:
Measure / Quantify / Expand
Design, size, and analyze field experiments at scale.
Apply econometric or statistical knowledge to improve Amazon Search (using machine learning techniques is a plus)
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Explore / Enlighten
Formalize assumptions about how Amazon Search is expected to work.
Given anomalies, whether anecdotal or identified automatically, deep dive to explain why they happen, and identify fixes.
Decide / Recommend
Build decision-making models and propose solution for the business problem you defined
Implement models based on findings in production back end systems
Analyze A/B tests and recommend ways to making them faster and more robust
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithm

Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Experience with data visualization and presentation, turning complex analysis into insight
Experience collaborating with software development teams, data scientists, business intelligence or other technical roles
Masters or PhD in applied quantitative field
Strong background in statistics methodology, applications to business problems, and/or big data.
Ability to work in a fast-paced business environment.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
Experience designing experiments, and ability to infer causal relationships"
Data Analyst,"Chennai, Tamil Nadu",Sagitec,None,Organic,"Data Scientist who is passionate about data and wants to apply machine learning techniques to solve problems for our customers. This person is expected to be proficient in the exploration and understanding of structured and unstructured data, machine learning techniques, statistical modeling methods, predictive analytics, anomaly detection, and supervised and unsupervised learning. The successful candidate will work with stakeholders to leverage data to solve critical business problems in the Benefits Administration domain.
The Data Scientist will work on all aspects of the design, development, and delivery of machine learning-enabled solutions including problem definition, data acquisition, data exploration, feature engineering, experimenting with various ML algorithms, evaluating metrics, deploying models and iteratively improving the total solution.
Duties & Responsibilities
Formulate a meaningful hypothesis that is relevant to the business objectives.
Design and train models for use in production environments.
Mine structured and unstructured data for patterns.
Utilize data from databases, Web scraping, public datasets, historians, and/or data lakes.
Rigorously build, analyze, and compare machine learning or statistical models; there is a strong emphasis on programming using the most popular machine learning languages such as Python, R, Microsoft R, TensorFlow, PyTorch, SciPy, Encog, etc.
Work with application developers to develop data-analytics products that are deployed to end-users as part of packaged solutions.
Visualize and report findings of deployed data analytics solutions to provide insights to the organization and our customers.
Deploy machine learning model and integrate model predictions in business
Setup infrastructure for machine learning, model deployment including commissioning or ML-Servers and Server Configuration
Deploy CI/CD framework to frequently deliver code/features to production
Qualifications
Experience & Education
Required
M.S. or higher in Mathematics, Statistics, or Computer Science with significant experience in data analytics and Model Building.
Preferred
5+ years experience is preferred.
Knowledge, Skills, & Ability
Required
Expertise in predictive modeling, machine learning and statistics.
Software development skills in one or more high level languages (Python/Java/R/Scala).
Experience using one or more of the following common ML software packages: scikit-learn, TensorFlow, NumPy, pandas, jupyter.
Well-versed in machine learning algorithms and their suitability for solving various problems: Regression, Bayesian, Support Vector Machines, Decision Trees, Random Forest, Clustering, Neural Networks.
Experience in using SQL/No SQL databases is an advantage
Experience working in Windows/Linux is an advantage
Experience with Big Data technologies is an advantage (Hadoop, Hive, Spark, Cassandra).
Experience with building and deploying data pipelines
Good critical thinking, technical, data collection and user interviewing skills.
Ability to work as a team member in a fast-paced environment.
Experience With Agile Software Development Processes Is Preferred.
Experience with Cloud service offerings from AWS, Azure or GCP is a plus.
Preferred
Knowledge of DataOps.
Knowledge of data versioning tools such as git, DVC
Knowledge of ML environments such as MLflow, databricks
Knowledge of ML deployment tools such as Kubeflow, Kubernetes."
Job Opening for Machine Learning,"Mumbai, Maharashtra",ICS Consultancy Services,"₹10,00,000 - ₹25,00,000 a year",Organic,"Roles and responsibilities for Job Opening for Machine Learning
: Role : Researcher Role Description : Manages deliverables for s global business-facing sourcing and research capability providing exceptional research expertise and unique industry knowledge. Required to develop points of view which identify business opportunities for the Operating Groups and Service Lines. Deliver research primarily utilizing an extensive range of online and other research sources. Must have Skills : Machine Learning Good to Have Skills : Product Development Management, Research, Artificial Intelligence Job Requirements : 1:Responsibilities:a: Perform extensive applied research on Machine learning deep learning, Computer Vision, text processing NLP, speech processing virtual agent technologies b: Provide modeling guidance on Machine learning deep learning, Computer Vision, text processing NLP, speech processing virtual agent technologies to a team of developers team leads c: Work with Developers Team leads to translate research papers to working prototype design models using AI technologies define actionable insights in an agile environment 2: Professional Experience: a: 6-8 years full time design algorithmic experience in AI technologies, ability to develop interpret algorithms models knowledge in programming ML languages like Java, Scala, Python, R 3: Educational Qualification: a: Graduate or post graduate degrees B Stat/M Stat/ B Tech/B E/Post Graduate/Diploma in Data Science etc from premier institutes preferred
Job Details
Job Role
: All Roles
Industry Sector
: IT-Software/Software Services
Functional Area
: All Functions
Desired Profile
Profile Description
:N/A
Experience
: 3 - 10 (Years)
.
.
Education Details
UG Course
: B.Tech/B.E
UG Specialization
: N/A
PG Course
: M.Tech
PG Specialization
: N/A"
Senior Data Scientist,"Hyderabad, Telangana",TCPWave,None,Organic,"Salary
DOE
Number of positions
1
Description
A senior data scientist will assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need. And, use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help customers build DL models.
Minimum Qualification
A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
7+ years of industry experience in predictive modelling, data science and analysis.
Technical Skills
Experience using Python and/or R and SparkML.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience working with GPUs to develop models.
SQL
Responsibilities
Experience giving data presentations."
Director- Big data and Machine Learning,"Bengaluru, Karnataka",Michael Page,None,Organic,"Apply
share this job
Email Job
Save Job
Opportunity to be a part of the Research lab of one of the leading FS firm
Opportunity to lead the Big Data and Machine Learning initiatives in FS firm
About Our Client
Our client is a global Financial services firm planning to expand their Big data and Machine Learning capabilities and are looking for candidates who come with rich experience in Machine Learning, Deep Learning, Data Science, Data Mining, Information Retrieval, High Performance Computing and related technical areas. The team is working on challenging research problems with real life relevance pertaining to progress the state of the art in science and develop products to solve business problems for the institution.
Job Description
As Director- Big data and Machine Learning, you will:
Develop new innovative technology solutions to business problems and demonstrate research solutions and prototypes
Transform research prototypes to products in collaboration with engineering teams and demonstrate quantifiable business benefits
Actively contribute to relevant scientific communities by publishing scholarly articles and invention disclosures, attending conferences and delivering presentations
Identify new research opportunities and spearhead innovation opportunities for the company
Develop strong collaborations with colleagues from global modelling and engineering teams as well as partners from business groups in areas of mutual interest
Pursue breakthrough research in a challenging and stimulating environment and demonstrate thought leadership
The Successful Applicant
As a successful candidate for Director- Big data and Machine Learning, you should have:
At least 8 years of experience in all areas of Machine Learning and expertise in selected topics such as unsupervised and supervised techniques, active learning, transfer learning, neural models, reinforcement learning, graphical models, Gaussian processes, Bayesian models, ertise in one or more of the following areas: Machine Learning, Deep Learning, Data Science, High Performance Computing, Algorithms
Experience of solving practical problems by developing novel techniques pertaining to above areas. Track record of deploying solution leading to business and societal benefits would be hugely favoured.
Strong programming and coding experience in languages such as R, Python, C, C++, Java; experience on hadoop/ other large scale distributed computing platforms is desirable
Strong track record of creation of intellectual property i.e. patents and papers in reputed conferences and journals - especially for senior positions.
Qualification and experience: Ph.D., Masters and UGs in Computer Science / Electrical Engineering / Operations Research / Statistics/ Mathematics from institutes of global repute.
What's on Offer
Opportunity to be lead the Big data and Machine Learning team for a leading global Financial Services institution"
Data Scientist,"Bengaluru, Karnataka",Maximus Human Resources,None,Organic,"About Us :
At Maximus, we understand the significance of blending business processes and technology with human values. Started in 2007, we recruited for Sales and Marketing and Advertising Industries. Over the period, we have entered into IT, ITES and ERP sectors, across all levels. And now we recruit across various industries for multinational corporations. We spend time and effort in meeting and understanding our Clients, their requirements, and job specifications. On the other hand we recognize the core competencies of the aspirants, counsel them into making the right career move. Our support goes beyond the stated minimum guidelines and our approach is end to end.
About Company :
The company is a world leader in Precision Medicine and the global pioneer of Therapy Response Index (TRI). We help physicians and payers navigate to the most efficacious, cost-effective treatments for patients in a transparent and timely manner. Companys’ key therapeutic areas are oncology, immunology, dermatology and infectious diseases. Its’ unique biosimulation platform is a unified representation of biological knowledge, curated from heterogeneous datasets, capable of accurately modeling the response of patients to drug therapies. Founded in 2005 and backed by Artiman Ventures and Sequoia Capital, Company has the world’s strongest trans-disciplinary team of molecular biologists, cellular pathway modelers, and internet software technologists working towards a common goal – attacking serious diseases to improve the lives of patients.
Roles and Responsibility :
Data Scientist
Requirements and Qualification:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software
architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch)
and libraries (like scikit-learn). Understanding of algorithms like KNN,
Naive Bayes , SVM , Decision Forests etc
Experience with data visualization tools like D3.js , Ggplot etc is
desired .
Knowledge of databases like MYSQL , NOSQL is desired .
Excellent communication skills
Ability to work in a team with data oriented personality
Outstanding analytical and problem-solving skills
B.Tech/B.E in Computer Science or similar field; Master?s degree is a
plus
Duties and Responsibilities:
Study and transform data science prototypes . Selecting features ,
building and optimizing classifiers using machine learning
techniques .
Data mining using state of art methods
Research and implement appropriate ML algorithms and tools
Select appropriate data sets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field

Recruiter Name : Madhuri
Recruiter Number : 9113636092
Recruiter Email Id : Madhuri@maximusindia.co.in"
Machine Learning Science Leader,India,CareerXperts,None,Organic,"Passionate about Big Data, Machine Learning and Predictive Software? Interested in leading new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
We are looking for a dynamic Machine Learning science leader to found and head the Data Science function in Bengaluru. As Head of Data Sciences, you will lead a high performing team of scientists and engineers in the development of innovative and rigorous Machine Learning techniques that advance Machine Learning technology for advertising and convert to high impact solutions for the business.
Major responsibilities:
Recruit, coach, and manage a team of scientists and data science engineers, lead cutting-edge research projects, and influence the technical direction of the Ads business.
Innovate and leverage machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Formulate and test hypotheses, extract signals from peta-byte scale, unstructured data sets, and ensure that our display advertising business delivers the highest standards of performance
Collaborate with distributed cross-functional teams on common goals.
Experience
6 + years , Start-up / Entrepreneurial experience preferred.
Qualification
MSc or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field. (PhD preferred).
4+ years of industrial experience in machine learning and predictive modeling, including 2+ years experience in leading junior team members and guiding them on machine learning and data modeling applications.
Proficient in Java, C/C++, or Python (or similar scripting language).
Proficient in R, Matlab, or another statistical software.
Strong communication and data presentation skills.
Preferred Qualifications:
7+ years of industrial experience in predictive modeling and analysis, predictive software development.
Experience handling gigabyte and terabyte size datasets.
Experience working with advertising, retail or e-commerce data.
Experience working with distributed systems and grid computing.
Experience working with distributed teams.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences."
Senior Data Scientist,"Bengaluru, Karnataka",GSN Games,None,Organic,"Looking for Women in Data Science

GSN Games is looking for a Senior Data Scientist to join our team in Bangalore!
About The Analytics & Data Science Team:
Our incredibly talented team provides the data, analytics, and algorithms necessary to make GSN Games a fun and rich experience for players.
What You’ll Do
The GSN Data Science team delivers machine-learning based tools, products and insights that help to move the needle in the business of our games. You will lead a team of Data Scientists and collaborate with other members of the Data Engineering and Data Analytics teams to conceptualise, develop and roll-out ML-based products and features to help games grow and make our games more fun. This is an exceptional opportunity to apply Data Science, Software Engineering, and organizational skills to drive actionable insights across a portfolio of games.
You will:
Collaborate with other data scientists and data analysts to build, tune, and optimize machine learning models to optimize all aspects of the business.
Partner with studios to solve business-critical questions. Sometimes these questions are brought to us, and sometimes we bring these questions to the game teams.
Proactively explore the data to find new insights and opportunities for growth and optimization.
Help develop best practices with data and analytic techniques across the game studios.
Keep up with industry trends and developments, and make sure our technologies are cutting edge.
About You
3 to 5 years experience working as a data scientist developing Machine Learning based products.
Strong background in probability, statistics, and machine learning.
Fluent in Python
Strong software engineering skills, including distributed systems, data pipelines, machine learning production systems, and scaling solutions.
Working knowledge of AWS and/or GCP.
Strong hands-on experience with SQL.
Experience with A/B testing and other forms of causal inference, and good skills in data visualization.
Excellent communication skills.
BS in a quantitative field such as math, physics, economics, or computer science (MS preferred)
Bonus points for experience in games."
Field Application Scientist - Pharma Analytics,"Pune, Maharashtra",Thermo Fisher Scientific,None,Organic,"Job Title: Field Application Scientist - Pharma Analytics
Job Location: Bengaluru / Hyderabad / Pune / Mumbai / Ahmedabad
About Company:
Thermo Fisher Scientific Inc. is the world leader in serving science, with revenues of more than $25 billion and approximately 75,000 employees globally. Our Mission is to enable our customers to make the world healthier, cleaner and safer. We help our customers accelerate life sciences research, solve complex analytical challenges, improve patient diagnostics, deliver medicines to market and increase laboratory productivity. Through our premier brands – Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific and Unity Lab Services – we offer an unmatched combination of innovative technologies, purchasing convenience and comprehensive services.
About Team:
Life Sciences Solutions Group - Bioproduction
Role &amp; Responsibilities
Purpose of the Role:
Field Application Scientist (FAS) – Pharma Analytics is a technical role and involves training customers on Thermo Fisher Scientific SEQ rapid molecular methods for pharmaceutical manufacturing to help ensure the quality and safety of pharmaceutical products, especially when accuracy and time-to-results are critical. The SEQ assays are developed for multiple platforms, including but not limited to Q- PCR, thermal cyclers, CE – genetic analyzers, Next Gen sequencing, sample preparation and automation platforms. For their targeted applications using the specific SEQ assays the FAS should be well aware of bioprocessing workflow for vaccine and biosimilar mAbs, r-proteins , Cell and gene therapy as well as regulatory expectations to provide guidance to customers based on regional US-FDA and EU lot release testing guidelines for contamination and impurity testing . FAS is also expected to support the sales team and the customer during the purchase process, to help the customer chose the most appropriate products for their R&amp;D and manufacturing projects. FAS is expected to actively participate in various seminars, scientific discussions (pre &amp; post sale), proof of concept studies and product training for external &amp; internal (commercial team) customers.
Responsibilities
Provide training on site as well as in house lab facilities on SEQ solutions and participate in pre-sales discussions, conferences, meetings.
Drive customer workshop for customers in South Asia (India, Bangladesh, Sri Lanka, Nepal)
Responsible for imparting knowledge transfer to customer related to workflows in DNA / RNA analysis, DNA Sequencing, REAL TIME (Q- PCR) and ancillary procedures.
Troubleshooting and In-depth Analysis -in case of any deviations from normal data are part of the necessary skill set for FAS role.
Provide remote support to users- either by telephonic / chats or email communications.
Provide post sales support to commercial teams.
Provide Customer support on quality issues by resolving customer complaints for SEQ products and escalation to Global BU and manufacturing teams via appropriate channels
Support to internal teams as and when required.
Responsible for delivering revenue targets for business area of responsibility and have budgetary responsibility for marketing spends in the region.
Desired Experience:
Must have 5 – 8 years of experience in working with customers and supporting demos, evaluations and validation studies
Demonstrated experience in driving for continuous improvement of processes
Willingness to be flexible and adaptable in a complex, matrixed environment
Able to adapt quickly to changing needs caused by time, budget, or business constraints
Comfortable working in a fast-paced environment
Strong communication and presentation skills are essential
Experience gathering VOC and utilizing CRM tools
Multidisciplinary background preferred having qPCR experience. NGS, CE, and sample extraction platform experience preferred. Protein detection experience (e.g. ELISA) a plus.
Preferred Skills:
Experience in working with regulated (GMP) customers
Experience in QC lot release testing and assay development
Demonstrated experience communicating and coordinating work across functions, cultures, and time zones
At Thermo Fisher Scientific, each one of our 75,000 extraordinary minds has a unique story to tell. Apply today http://jobs.thermofisher.com.
Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status."
Data Analyst,"Bengaluru, Karnataka",Rockstar Games,None,Organic,"At Rockstar Games, we create the games we would want to play ourselves.
A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.
Rockstar India is on the lookout for talented Data Analyst who possess a passion for Game Analytics. This is a full-time permanent position based out of Rockstar's unique game development studio in Bangalore.
WHAT WE DO
The Rockstar Player Insights & Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with a number of departments to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses and machine learning applications.
RESPONSIBILITIES
Analyze, synthesize, and interpret product and player data to determine observations and trends.
Monitor and maintain the health of our dashboards, data sources, and data collection systems.
Collaborate with game and development teams to ensure that the implementation of metrics corresponds to the observed values.
Contribute to the development and enhancement of the data collection systems.
Drive requirements for data collection and for data modeling with data engineers.
Document new and modified data sources, tables, fields, reports, and dashboards.
QUALIFICATIONS
Minimum 4+ years in a similar position or a position requiring data preparation, data validation, and report building and monitoring.
Bachelor's degree in Computer Science, Engineering, Statistics, or related field.
SQL knowledge and hands-on experience is a must.
Demonstrated analytical ability, problem-solving skills, and entrepreneurial spirit in a results-oriented environment.
Expertise, aptitude, or prior background understanding complex and large data sets.
History of seeking and acting on opportunities to improve data documentation, upgrade processes and reports, or increase data quality.
Excellent written and verbal communication skills with the ability to express thoughts logically and succinctly.
Strong team spirit and dynamic team player.
PLUSES
Please note these are desired skills and not required to apply for the position.
Experience with Hadoop and/or Impala.
Advanced SQL skills, programming experience, fluency in R and/or Python.
Experience with statistical techniques and big data.
Basic understanding of data warehousing, data modeling concepts, and database documentation.
Game industry experience and passion for Rockstar Games strongly preferred.
HOW TO APPLY
Please apply with a CV and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.
Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.
If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race."
Data Scientist,"Pune, Maharashtra",GridEdge Technologies,None,Organic,"Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com"
Bioinformatics Analyst,"Chennai, Tamil Nadu",PerkinElmer,None,Organic,"PerkinElmer is a global technology leader driving growth and initiative in the Environmental and Human Health Science markets. The company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world.
PerkinElmer Genomics is one of the world’s largest providers of newborn screening services, and offers comprehensive genetic testing solutions that help provide insight into the complex nature of rare and inherited diseases. The PerkinElmer DNA Sequencing Services business provides state of the art DNA/RNA measurement services. We are looking for an innovative Bioinformatics Analyst to utilize bioinformatics tools to analyze clinical data generated in our highly advanced DNA sequencing center.
This person will work closely with our bioinformaticians in the United States to process and manage Next Generation Sequencing (NGS) data, as well as other molecular testing data such as Sanger and MLPA. There are also opportunities for the Bioinformatics Analyst to develop new data processing pipelines, software applications, databases and custom scripts. Additional responsibilities include exploring and/or evaluating state of the art bioinformatics tools, maintaining sample tracking logs and delivering results to customers.
Required Skills:
Bachelor or Master degree in bioinformatics, biostatistics, computer sciences or equivalent in Life Sciences discipline.
Programming skills and proficient in programming languages including Perl/Python, R, SQL and shell scripting.
Preferred Qualifications:
Experience in building and delivering NGS data analysis pipelines and software applications is a plus.
Strong programming skills and proficient in programming languages including Perl/Python, R, SQL and shell scripting.
Strong oral and written communication and interpersonal skills required.
Ability to work independently as well as work with others in a team.
Experience in working in a clinical laboratory environment."
Senior Data Scientist and Machine Learning Engineer,"Bengaluru, Karnataka",McAfee,None,Organic,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:
McAfee is looking for an experienced data scientist to work on our next-gen threat assessment platform. You will work with experienced developers, security researchers and data scientists to understand and implement solutions to the problems found in today’s fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.

Company Overview
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.
About the role:
You will collect and analyse data to spot trends and help us face the challenges of an evolving security landscape.
Design, debug and test complex software in the field of data science.
Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with team members (developers and malware researchers) to develop and review designs and requirements to analyse data and build ML models.
Knowledge of security practises, procedures and capabilities to perform non-repetitive, work. You will report to the Engineering Manager.
About You:
You have the following required skills:
Display understanding of and ability to use programming languages: C++, Python, C#, and SQL. Have a knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Have ability to think and research creatively. Create“stories” told by the data and presents them to other scientists.
5+ years’ experience working in security research, data mining or natural language processing. Use predictive modelling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect and explore insights from structure and unstructured data .
Develop software, algorithms and applications to apply mathematics to data, perform large-scale experimentation and build data-driven apps to translate data, solve a variety of business problems and ensure strategy. Assist business with casual inferences & observations with finding patterns , relationships in data.
Have understanding of internal business segment (partners).
Typically requires expertise in relational database structures, research methods, machine learning, Cloud-based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL).
Typically have advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.
Company Benefits and Perks:
We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.
Job Type:
Experienced Hire
Primary Location:
India, Bangalore

Additional Locations:"
"Senior Data Scientist (Data Analysis, Machine Learning)","Mumbai, Maharashtra",HERE Technologies,None,Organic,"What's the role?:
At HERE Technologies in Automotive Product Engineering organization, we are looking for highly skilled, self-motivated, Sr/Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects, IT to develop, deploy, and maintain applications in multiple environments.

What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making.
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs.
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling.
Function as a predictive modeling or application team lead.
Who are you?:
MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.
5+ years related, professional experience.
Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.
Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc.
Programming experience with SQL, shell script, Python, etc.
Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.
Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques.
Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.

Preferred Qualifications:
Development experience with C++/Python/Shell Script
Development experience with Docker
Development experience with GIS data
Development experience with Relational Database/ NoSQL Database""

What we Offer
We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!
Who are we?:
Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE."
Machine Learning part time job/internship at Pune,"Pune, Maharashtra",SkillBit,"₹5,000 a month",Organic,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Analyzing data, developing predictive algorithms, designing, and recommending code algorithms using advanced machine learning algorithms 2. Designing, developing, and testing sales recommendation solutions 3. Performing explanatory data analysis 4. Preparing & analyzing data and identifying patterns
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 11th Aug'20 and 15th Sep'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 6
Categories: Machine Learning,Data Science"
Data Engineer Manager,Andhra Pradesh,TTEC,None,Organic,"Data Engineer Manager
When everything's connected, how we connect is everything.. . and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a
Manager, Data Engineer
.

At TTEC, we help global brands provide a great experience to their customers, build customer loyalty, and grow their business. We were founded on one guiding principle: customer experiences that are simple, inspired, and more human deliver lasting value for everyone. Your role brings that principle to life.

TTEC, a 50,000 employee, global customer experience pioneer, is opening a new information technology and data science center of excellence in Hyderabad where you'll have the opportunity to get in on the groundfloor of this expansion.

As a technologist, we know you're in high demand. And we know it's important you find the right fit for your future. Have ideas you want to contribute? We're listening. Looking for exposure to different clients, different technologies? It's what we do. Want to make an impact on the future? We're innovating every day. Teamwork key? You'll have the opportunity to work on global projects with a knowledge-thirsty, international team. Join our inclusive information technology team and you'll help create meaningful employee experiences that drive memorable customer experiences.

The successful candidate will be an experienced, highly motivated self-starter with the ability to solve data analysis problems. They will have experience using software languages to manipulate large amounts of data. The primary responsibility of this role is to manage a team of data engineers to manipulate and analyze large datasets to answer business questions by generating insightful reports and output. The candidate will work in a team of data programmers and business analysts to develop deliverables that support data-driven marketing strategies.


What you'll be doing
Manage a team of Data Engineers and Sr. Data Engineers
Manage and manipulate multiple large data sets, including: defining populations and variables, performing calculations and summarizations, and creating solutions to address client business questions
Prepare complex analytic deliverables, combining multiple programming outputs to create cohesive reports
Acquire a strong understanding of research topics and a thorough knowledge of the data and programming efforts involved
Synthesize business questions, translate from concept to code, in order to produce client deliverables
Help design analytic data set specifications: synthesize business questions, translate from concept to code, in order to produce client deliverables Lead in delivery of analytic projects
Mentor team members
Introduce new methodologies and efficiencies to increase productivity
Contribute to the definition and development of key findings and marketing-oriented conclusions

What you'll need to be successful
Ability to coach and support a team of data engineers to drive business results in a timely manner
Progressive career growth in the field of data engineering / data informatics
Degree in a STEM field, Masters preferred
4+ years of professional experience working with large-scale relational databases, and ability to manipulate/ analyze / maintain relational databases
Proficient in SAS Programming with hands on experience with SAS/BASE, SAS/SQL, SAS/MACROS, SAS/GRAPH, SAS/STAT
In depth knowledge of one or more of the following: Teradata , SQL, R, Python, Unix Scripting
Capability to execute complete analysis process from data extraction / manipulation through QC, report and delivery of data and reports
Ability to create automated process and knowledge on CronTab, Autosys or related tools
Aptitude in Microsoft Excel
Ability to work independently and mentor junior team members
Strong attention to detail
Strong verbal and communication skills
Comfortable working in team-oriented, deadline driven environment

Experience in following areas a plus
Knowledge of AWS, Hadoop ecosystem, Pig Latin or HiveQL
Experience with SAS GRID server, SAS Viya, Oracle, Seibel
Exposure to Tableau, Power BI or other BI tools
Ability to write Pig Latin scripts
Knowledge of statistical concepts
Business, economics, or quantitative methods background

TTEC Values
Lead Everyday * Do the Right Thing * Reach for Amazing * Seek First to Understand * Act as One * Live life Passionately

Learn more about our business at TTEC.com or our culture at TTECjobs.com. #ExperienceTTEC

Primary Location
: India-Andhra Pradesh-Hyderabad
Job
: Information Technology

JSGYM"
Senior Data Scientist,India,Emerging India Group,None,Organic,"We are looking for a senior Data Scientist with 7+ years of progressive experience in mining large complex data sets, using a variety of advanced quantitative/modelling techniques. Candidate should have a knack to manage and deliver end to end projects with a proficiency to handle and deliver strategic insights to support crucial business decisions.
Candidate should have great analytical skills with an acumen for analysis, math and statistics and should be well versed with the concepts of machine learning. A rich experience in delivering analytics projects including social media analytics and big data is required.
RESPOSIBILITIES
Understanding business objectives and developing models based on structured and unstructured data to derive relevant metrics
Make the most effective use of the available Big Data infrastructure and Data Science techniques to address the business issues
Build effective presentations to communicate complex analysis and findings suitable for a wide array of audiences
Proactively plan and prioritize work according to criticality and shifting priorities/ strategies, while balancing need to drive longer-term initiatives
Mentor and coach junior team members
SKILLS
Proven experience as a Data Scientist or Data Analyst
Preparing and maintaining project, stage and exception plans as required
Identifying and obtaining support and advice required for the management, planning and control of the project
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Presentation of insights using data visualization techniques
Problem-solving aptitude
Excellent communication and presentation skills
TOOLS & TECHNOLOGY
Familiar with statistical modelling tools such as Python, R, SAS etc. with proficiency in Python
Knowledge and experience of working with SQL and NoSQL databases
Experience in story telling with tools like Tableau, Power BI etc.
Experience with unstructured data using Hadoop
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms

Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules"
Data Engineer,"Bengaluru, Karnataka",Rakuten,None,Organic,"Role: Sr. Data Engineer

What will you do?
Design, select and integrating big data tool and frameworks to build data science platform to support company-wide data analytics.
Analyze the requirements and data sources from different business units.
Transform data from multiple domains into the centralized data platform.
Understand and manage the data warehousing and data processing of large scale datasets.
What are we looking for?
Strong analytical and problem solving skills especially transforming business requirements to feasible design
Solid database knowledge and at least 5 years hands-on SQL experience working on production system.
Experience with modern day storage and compute technologies, such as MinIO, YugabyteDB, Spark, and Presto
Programming skills in Java, GoLang, Python, etc.
Experience with building stream-processing such as spark-streaming or storm

Preferred Qualifications

Experience with distributed computing tools
Familiarity with data sciences tools, such as Jupyter notebooks
Experience with GPU, Docker, Nginx
Experience of using or building BI system
Experience and knowledge of message systems such as RabbitMQ, Kafka.
Experience and knowledge of development process management like Agile"
Machine Learning Scientist (8 -10 yrs),"Chennai, Tamil Nadu","Agilysys, Inc.",None,Organic,"About Company

At Agilysys, Inc. we are proud of our 3,000+ customers including some of the world’s most recognizable resort, casino and cruise line brands. We specialize in market-leading point-of-sale, property management, inventory and procurement, and mobile and wireless solutions that are designed to streamline operations, improve efficiency and enhance the guest experience. We serve casinos, resorts, hotels, food service venues, stadiums, cruise lines, grocery stores, convenience stores, general and specialty retail businesses and partners. With extensive operations, throughout North America, and additional sales and support offices in Singapore and Hong Kong, as well as software development in India, we are growing. For more information, visit: www.agilysys.com.
Machine Learning Scientist
We are looking for Senior Applied Scientists who has deep passion for building machine-learning solutions and can help us take our products to the next level.
In this role, you will
Be responsible for developing, training, inferencing, evaluating, and deploying machine learning algorithms and/or models.
Design and perform experiments to continually refine and enhance our deep learning technology solutions.
Work closely with software engineers on detailed requirements, technical designs and solutions.
Provide technical leadership and research new machine learning approaches to drive innovation.
Help drive adoption of Machine Learning across the company.
Qualifications
Master’s degree in Data Science, Analytics or Computer Science with Machine Learning specialization or related discipline. A PhD is preferred.
5+ years hands-on experience in building Machine Learning solutions.
3+ years’ experience with data structures, algorithm design, problem solving and complex analysis.
Experience with implementing deep learning platforms such as TensorFlow, Keras, and Darknet
Experience with implementing deep learning models such as Inception, Faster-RCNN, SSD, YOLO3.
Strong coding knowledge, experience with Azure or AWS machine learning pipelines.
Excellent understanding of convolution neural networks and other machine vision algorithms and methodologies.
Experience working effectively with science, data processing, and software engineering teams.
Excellent oral and written communication skills, with the ability to effectively communicate complex technical concepts and solutions.
Proven hands on experience working with large data sets and training models.
Ability to extract the practical implementation information from academic papers.
Interest in working on embedded systems.
Proven track record of executing complex projects.
Preferred:
Experience in deploying machine learning models on the edge"
Data Scientist III,"Mumbai, Maharashtra","General Mills Services, Inc.",None,Organic,":
General Mills is reshaping the future of food. We believe food makes us better. It nourishes our bodies, brings us joy and connects us to each other. As one of the world's leading food companies, General Mills operates in more than 100 countries and markets more than 100 consumer brands, including Cheerios, Nature Valley, Betty Crocker, Yoplait, Annie's Homegrown, Old El Paso, Epic Provisions, Blue Buffalo and more. Are you passionate about the future of food? You've come to the right table. We want the very best talent to help lead something big.
:
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
:
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business
:
Qualification: Any Graduate (Preferred Statistical background)
Experience - 6+ yrs

Statistical analysis, modeling, clustering and data mining techniques to identify trends and insights
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning a plus
Experience with data visualization tools
Experience writing complex SQL queries
Experience with Python & R, comfortable working with DataFrames
Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs"
Analyst Data Scientist,"Mumbai, Maharashtra",Camsdata,None,Organic,"Build an in-depth understanding of the problem domain and available data assets
Research, design, implement, and evaluate machine learning approaches and models
Perform ad-hoc exploratory statistics /data mining tasks on diverse datasets - small scale to big data
Participate in data architecture and engineering decision-making to support analytics
Take initiative in evaluating and adapting new approaches from data science research
Investigate data visualization and summarization techniques for conveying key findings
Communicate findings and obstacles to stakeholders to help drive the delivery to market
Code your solutions (this is a hands-on position requiring strong programming skills)
Key Requirements:
Professional experience as a data scientist or a related software engineering role
Graduate degree (MS) in mathematics, computer science or other quantitative discipline
Thorough understanding of probability and statistics, Bayesian methods, time series analysis
Strong programming skills (in any language)
Great communication skills, team player, self-starter, demonstrated strong work ethic
Desire to use modern technologies as a disruptive influence within the Finance domain
Preferred:
Expertise in Statistics, Empirical Data Analysis, Machine Learning or Natural Language Processing
Experience and in-depth knowledge of Python and other modern programming languages
Experience in a specialized statistical computing environment, preferably R
Experience in practical data processing, data mining, text mining and information retrieval tasks
Experience in scalable data management tools - Relational and NoSQL databases
Knowledge of Big Data architectures a strong plus
Knowledge of Pythons data analysis and machine learning libraries a strong plus
Exp: 3 to 8 yrs
Location: Bangalore/Mumbai/Hyderabad/Chennai/Pune/NCR"
Data Scientist -1,"Bengaluru, Karnataka",Acko General Insurance Limited,None,Organic,"Role and Responsibilities:
Work closely with Business teams & Product Managers to identify opportunities and serve as an ambassador for data science
Translates complex functional and technical requirements into detailed architecture, design, and high performing software and applications.
Works with peer developers to make sure that all data solutions are consistent and ensures all automated processes to preserve data by managing the alignment of data availability and integration processes
Eligibility Criteria:
2 years of experience in the field of statistics, data mining and machine learning
Qualifications:
BTech/BE Premier institute like IITs/BITS/NITs
Experience in e-commerce/Online Internet companies
Skills:
Expert-level understanding of the underlying theory of Machine Learning.
You have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
Taking end-to-end ownership of problem domains and continuously improving upon quantitative solutions
Demonstrated ability to facilitate and work with minimal direction, with the proven ability to coordinate complex activities
Analytical thought leadership and stay current on developments in data mining and the application of data science"
Big Data Engineer,"Bengaluru, Karnataka",ADCI - BLR 14 SEZ,None,Organic,"1+ years of experience as a Data Engineer or in a similar role
Experience with data warehousing, and building ETL pipelines
Experience in SQL
Bachelor's degree in Information Systems, Computer Science, Finance, Accounting, Economics, Mathematics or a related technical discipline.
4+ years of Cognos TM1 work experience in developing end-to-end analytics solutions, including system configuration, model building, data security, and reporting.

Within Amazon’s Corporate Financial Planning & Analysis team (FP&A), we enjoy a unique vantage point into everything happening within Amazon. As part of that, our team designs, builds & maintains an integrated planning & reporting platform that enables hundreds of finance representatives across the globe.
In addition to requiring a high level of technical expertise in spark ,scala & python , this role is about understanding the needs of the business, the data behind it, and how to transform this information into technical solutions that allow the business to make swift, informed decisions. Ideal candidates will have expertise in all phases of the software development life cycle in building models that scale over time while balancing accuracy, flexibility and speed.
The data flowing through our platform directly contributes to decision-making by our CFO and all levels of finance leadership. If you’re passionate about building tools that enhance productivity, improve financial accuracy, reduce waste, and improve work-life harmony for a large and rapidly growing finance user base, come join us!

- Experience advocating and proliferating best practices in reporting and analysis, including data integrity, test design, analysis, validation, and documentation - Experience in providing risk assessment for new functionality and enhancements, and identify process improvement opportunities to drive innovation - Relevant corporate finance experience exhibiting knowledge of financial planning functions and related processes. - Excellent communication (verbal and written) and interpersonal skills, and an ability to effectively communicate with both business and technical teams. - Quick learner with a positive attitude and professional demeanor, and strong analytical and troubleshooting skills.- Direct experience using Business Intelligence (BI) reporting tools,
- Advanced knowledge of SQL, Oracle, OLAP, and data warehousing concepts. - Familiarity and development experience with web services technologies is a strong plus (e.g. HTTPS, REST, XML, JSON, etc).
JAVA/PERL/Ruby/Python scripting language experience.
- Experience with third-party ETL tools (IBM DataStage or Data Manager, Informatica, etc). - Familiarity with AWS solutions such as EC2, DynamoDB, S3, Redshift, and Aurora.

Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
"Senior Data Scientist (Data Analysis, Machine Learning)","Mumbai, Maharashtra",HERE Technologies,None,Organic,"What's the role?:
At HERE Technologies in Automotive Product Engineering organization, we are looking for highly skilled, self-motivated, Sr/Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects, IT to develop, deploy, and maintain applications in multiple environments.

What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making.
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs.
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling.
Function as a predictive modeling or application team lead.
Who are you?:
MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.
5+ years related, professional experience.
Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.
Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc.
Programming experience with SQL, shell script, Python, etc.
Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.
Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques.
Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.

Preferred Qualifications:
Development experience with C++/Python/Shell Script
Development experience with Docker
Development experience with GIS data
Development experience with Relational Database/ NoSQL Database""

What we Offer
We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!
Who are we?:
Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE."
Data Engineer - Beginner (Hyderabad),"Hyderabad, Telangana",Zessta,None,Organic,"Responsibilities:
Develop flowcharts, layouts and documentation to identify requirements and solutions.
Write well-designed, testable code.
Produce specifications and determine operational feasibility.
Ready to learn new technologies.
Skills and Experience:
1 to 3 years of experience as a data Engineer.
Good Knowledge of basic SQL queries, joins, filters, aggregate function.
Understanding of Python Lists and dictionaries, text handling.
Knowledge of Data Structures, Algorithms.
Basic scripting(Python or Unix) Skills.
Strong in Computer Science.
Education:
Bachelors or Masters from premier Institutes preferred ."
Senior Machine Learning Engineer,"Bengaluru, Karnataka",Ushur,None,Organic,"Ushur is transforming the way businesses communicate, with cutting-edge AI and automation technologies. Previously using outdated emails and phone calls, businesses are now automating their conversations with automated text-messaging using Ushur’s platform. We are creating breakthrough experiences for our enterprise customers by deploying the best of web, mobile and data analytics technologies. We focus on fast, iterative development with an emphasis on design-right philosophy. Currently, at Ushur, we are experiencing unprecedented & exciting growth with endless opportunities to innovate!

The Role

Ushur seeks a Senior Engineer with Machine Learning Expertise to join a high-impact team to enhance the Language Intelligence framework that is at the core of industry’s leading Micro-Engagement Platform from Ushur.

What you’ll be doing…

As one of the key members of of the Language Intelligence team, your responsibilities will include:
Design, develop and support machine learning and deep learning models involving
Ushur’s Language Intelligence that encompasses the spectrum of NLP and NLU to support information processing as well as drive the Ushur micro-engagements with users.
Responsible for designing and/or adapting various algorithms, undertaking experiments and impacting the Ushur Micro-engagement Platform.
Construct comprehensive knowledge graphs to support various applications that are delivered over the Ushur Platform.
Research and employ modern algorithms into the Ushur Platform to keep innovating with efficiency, impacting the feature-base of Ushur’s Platform.

Collaborating with engineers from AI & other teams on data analysis and feature design efforts

Qualifications

MS/PhD in Computer Science or related field
At least 3 years hands-on working experience in the AI/ML Area
Demonstrable experience with NLP/NLU techniques, language data
Strong knowledge of NLP tasks and techniques, NER, training machine learning models, neural networks
Strong programming skills in Python or Java and fluency in data manipulation (SQL/Spark/Pandas) and machine learning kits like scikit-learn, Keras/Tensorflow, XGBoost, Gensim
Excellent verbal & written communication, strong organizational skills and attention to detail

Why Join us?

We are passionate about Ushur, our product, and helping our employees grow and develop in their career in a caring, collaborative environment. We offer a very competitive compensation plan & stock options for the ideal candidates."
Delivery Manager - Data Science,"Hyderabad, Telangana",Aptagrim Consulting,None,Organic,"Required Skills:
Provide technical and thought leadership to the team
Working knowledge of Deep Learning Architectures/Convolutional Neural Networks
Working knowledge of Supervised Learning, Adversarial Learning
Working knowledge of Image Processing and Computer Vision algorithms
Excellent Python & R language coding skills
Working Knowledge with deep learning frameworks (like Tensorflow or PyTorch)
Working Knowledge with GPU/CUDA programming
Deep knowledge of Mathematics, Probability, Statistics and Algorithms
Understanding of data structures, data modeling, and software architecture
Excellent communication skills
Outstanding analytical and problem-solving skills
Presentation skills with a high degree of comfort with both large and small audiences
Good to have:
Demonstrate previous experience/references in developing data science solutions at scale for production systems"
Data Engineer,"Bengaluru, Karnataka",Rakuten,None,Organic,"Role: Sr. Data Engineer

What will you do?
Design, select and integrating big data tool and frameworks to build data science platform to support company-wide data analytics.
Analyze the requirements and data sources from different business units.
Transform data from multiple domains into the centralized data platform.
Understand and manage the data warehousing and data processing of large scale datasets.
What are we looking for?
Strong analytical and problem solving skills especially transforming business requirements to feasible design
Solid database knowledge and at least 5 years hands-on SQL experience working on production system.
Experience with modern day storage and compute technologies, such as MinIO, YugabyteDB, Spark, and Presto
Programming skills in Java, GoLang, Python, etc.
Experience with building stream-processing such as spark-streaming or storm

Preferred Qualifications

Experience with distributed computing tools
Familiarity with data sciences tools, such as Jupyter notebooks
Experience with GPU, Docker, Nginx
Experience of using or building BI system
Experience and knowledge of message systems such as RabbitMQ, Kafka.
Experience and knowledge of development process management like Agile"
Senior Consultant - ETL Testing,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Senior Consultant
Location: TRIL GTC Chennai
GCL: D1
Role
The role holder (ETL Test Engineer) will be responsible for requirement analysis, test preparation and end to end test execution of Science Data Hub starting from Source CTMS application into Data Lake and the subsequent ODS and Marts until the final business reports. The ETL Test Engineer will work closely with Data Analysts, Development Team, Ingestion Team, Scrum Master and Product Owner to understand the business feature and the underlying data needs and complexity to prepare test scenarios and test scripts independently to perform ETL Validations on all entities within Science Data Hub. One key responsibility of the ETL Test Engineer will be to work collaboratively with the business team to support UAT Testing and clarify and close observations.
The key tasks of ETL Test Engineer will be (i) Test preparation and requirement analysis to understand ETL Data Model, Design and prepare test scenarios; (ii) support and fill any gaps in Data Model and Data Analysis and support Scrum Teams to improve the quality of ETL framework and suggest improvements; iii) Validate datasets containing millions of records from Clinical Trial applications in an Automated approach; iv) Leverage Automation as much as possible and increase the speed and efficiency of the Testing Process; v) Feedback continuously to the business and Tech Leads in GTC and Hub on the data challenges and provide appropriate recommendations.
The ETL Test Engineer will be an integral and respected part of the data engineering team and specifically the DataOps Testing team, whose input and expertise will be instrumental in ensuring the success of R&D Data Hub delivery.
Key Accountabilities
Report to the Test Manager continuously on all the Test Metrics, challenges and possible deviations from the approved ways of working.
Perform peer review of all test deliverables from the testing team to ensure maximum test coverage.
Take complete ownership of the SIT Testing and perform regression testing for every release in PreProd Environment and also support business in UAT Testing.
Perform analysis on priority issues from Production and help in root cause analysis for the same.
Create Test Strategies and Test Plans for all feature-driven development within Science Data Hub by using AZ approved software and in-built tools.
Deliver Test Artefacts like Test Summary Report and Requirements Traceability Matrix before Production deployment to Platform Lead and Quality Managers to give confidence on the data quality post go live.
Engage in stakeholder communications on the quality of testing and continuously support process improvements and new ideas to get maximum quality from the testing process.
Support test data preparation, identify possible source data issues and propose Technical Enablers to continuously improve the System design and model.
Document all best practises and solutions in AZ Approved storage repositories.
Assist Quality Managers, Data Governance and Data Privacy team to ensure the industry the best practises are maintained.
Support all required documentation to ensure the validation and quality of the GxP Systems are maintained.
Participate and drive all Lean initiatives to remove and optimise repetitive tasks.
Development of subject matter expertise in sub-domains of the Science & Enabling Unit portfolio – understanding of the business process, data flows, data provenance, data restrictions and data use.
Highly Desirable Knowledge, Skills and Experience
6+ experience on ETL Testing with strong experience working in Data Engineering projects and Enterprise Dataware house systems.
B.Tech in Computer Science.
A strong understanding of databases and source systems.
Experience writing complex SQL queries and validation of Enterprise Data Warehouse Applications.
Strong invalidation of Visual Analytics reports using tools like Power BI, Microstrategy, etc. and running different types of the test within the same.
Strong in ETL Testing with any industry ETL tool like Talend, Informatica, Data Stage.
Good knowledge in any RDBMS like AWS Redshift/Postgres/Oracle/SQL Server.
Identifies, manages, and resolves defects during testing cycles leveraging a test management tool like JIRA, HP ALM. Also, supports or leads UAT process, when appropriate.
Should be strong in testing fundamentals.
R Scripting or Python experience and knowledge of CI/CD Pipeline.
Knowledge of Automation and Automation framework within ETL space.
UNIX and shell programming knowledge.
Additional skills and experience sought
In addition, these are the bonus skills (not mandatory) for this position:
IT Experience in working with Clinical Trial datasets.
Excellent communication and facilitation skills.
Good written and verbal skills, fluent English.
Experience of delivering solutions within IT projects delivered through Agile methodologies.
Working with API testing and data extraction testing from API.
Knowledge of XQuery and XML validations.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Lead Data Scientist,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"Experience: 5-10 Years.
Job Type: Full-time.
Location: Chennai or Mumbai.
Duties & Responsibilities:
Responsibilities include Identity, develop and implement the appropriate Computer Vision algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains, as well as provide actionable insights with a clear impact on ROI. Define and develop, maintain and evolve data models, tools and capabilities. Communicate your findings to the appropriate teams through visualisations. Collaborate and communicate findings to diverse stakeholders. Ability to build, train and lead a team of data scientists.
Preferred Qualification:
Bachelors/ Masters/ PhD degree in Math, Computer Science, Information Systems, Machine Learning, Statistics or related technical degree with the ability to break complex business problems.
5-10 years total experience with a minimum of 2 years of experience in a related position, as a
data scientist building computer vision solutions for various types of business problems.
Advanced knowledge of statistical techniques, machine learning algorithms and deep
learning frameworks like Tensorflow, Keras, Pytorch.
Minimum 3 years of Programming background and expertise in building models using at
least one of the following languages: Python, R, Java, C, C++.
Implementation of deep learning-based models for image classification, Document
classification models, object detection, logo detection, Object tracking.
Strong individual planning and project management skills, able to juggle multiple tasks and
priorities Self-motivated and driven to deliver agreed results on-time.
Strong storytelling & articulation skills – ability to convert the analytical output into clear,
concise, and persuasive insights & recommendations for technical & non-technical audience.
Strong influence and relationship management skills; comfortable interacting with all
management levels; Prior experience in providing strategic analysis and consulting.
Track record of delivering strong business results.
Company Profile:
Conceptualized as far back as 2015, and commencing full-time operations in 2018, Blackstraw LLc. is a software products and services company specializing in Artificial Intelligence (AI) and Machine Learning solutions for various industries. We support businesses around the world, including North America, Europe and Asia, working to simplify AI implementation through our platform that expedites data labelling, AI model-training, and, cloud or on-premise deployments.
With more than 100 years of combined work-experience, the 100+-strong Blackstraw Team comprises various experts in the AI value chain. We are a fast-moving team that prides ourselves in rapidly identifying different use-cases and fine-tuning our products to suit specific business needs.
We are focused on providing solutions related to computer vision, natural language processing, Data annotation tool for deep learning models, etc. To stay competitive in business, it is key for organizations to adopt and implement smart AI solutions and service offerings. However, most companies are unable to implement AI rapidly due to the complexity of existing solutions, inadequate data and cost implications.
Our mission is to enable enterprises to adopt AI in an easier, cost-effective and time-efficient manner with a plug-and-play approach to their data.
Blackstraw operations are based out of Mumbai, Pune and Chennai in India.
If you think you fit in with the above requirements we’d love to talk to you about working in our organization."
"Data Scientist, Global Supply Chain","Bengaluru, Karnataka",Cepheid,None,Organic,"Job Title – Data Scientist
Job Location – Bangalore, India
About Us
At Cepheid, we are passionate about improving healthcare through faster, more accurate diagnostic tests. With our GeneXpert® System, we’ve taken the most sophisticated molecular technology and packaged it into an automated, easy-to-use format that has quickly become the platform of choice worldwide.
Through strong molecular biology capabilities and ongoing product innovation, we are focused on developing tests for healthcare-associated infections, sexual health, critical infectious disease, virology, and oncology applications.
From the largest laboratories to small physician offices, our game-changing solution delivers critical answers when clinicians and patients need them most. Whether testing for tuberculosis in a mobile clinic in Botswana, for CT/NG in an OB/GYN practice in Madrid, or for a broad range of healthcare associate infections (HAI) in a hospital lab in New York City, Cepheid is positively impacting the quality of patient care and saving lives every day. Make a difference in healthcare and join us on this mission!

Job Description :
Responsible for developing production/supply plans that take into account forecasts, availability of material and manufacturing capacity. Is responsible for identifying and maintaining the appropriate planning parameters in ERP systems to optimize subassembly production and raw material supply plans. May also be responsible for providing materials to manufacturing areas based on planned production schedules and for the appropriate shipping of finished goods to various distribution centers utilizing material handling equipment in support of management policies for customer delivery and inventory levels. Includes planners and inventory control roles.
Critical thinker who enjoys data analytics, creativity, naturally curious, and is a problem solver utilizing database and analytical skills. High growth company building analytics function - requires flexibility, holistic thinking, time prioritization, execution of rapid transformations, and capability of effectively influence. Responsible for complex cross functional programs to successful and timely decision points supporting world class supply chain operations.
Accountable for moving analytics to strategy within a program or model working with business partners. Responsible for automation opportunities around execution and reporting. Develop multi-echelon analytics for targeted business deliverables. Valued candidates have a breadth of work experience or educational coursework to ensure highest level of partnership and capability to understand business requirements and anticipating solutions.

ESSENTIAL JOB RESPONSIBILITIES:
Must be able to accommodate flexible working hours in order to work with USA counterpart
Concise communication complex and controversial analytics and findings to non-technical business stakeholders using clear language, visualization and other means
Develop and facilitate organizing and conducting relevant, concise, statistical figures, presentations from big data with concise recommendations for solutions around clear patterns and trends
Develop reporting, data systems, and new process to meet business needs
Lead and participate in cross-functional projects within a formalized Project Management Organization (PMO) structure.

MINIMUM REQUIREMENTS:
Education or Experience (in years):
Bachelor's degree with 10 years of experience OR Master’s degree with 5 years of experience

Knowledge and skills:
Enthusiastic and friendly team player who can motivate colleagues and contribute to shared objectives in efforts to accomplish departmental goals.
Ability to translate analytics to implications, action, and strategy through influence and presentation
Technical expert in broad supply chain areas, supporting management, creative new solutions, and execution of wide breadth of tactical execution and strategic initiatives
Persistence, statistics, and software engineering skills - necessary for understanding data biases and for debugging logging output.
Strategic multi factory global analytics from large data sets of structured and unstructured data from disparate global data systems and sources
Data expertise will enable design experiments and data-driven decision making
Analytics and model deployment experience and value-stream mapping
Data warehouse knowledge, and data cleaning and validation to ensure completeness and uniformity
Member of cross functional project team to ensure successful on time, high quality, and UAT deliverables.
Knowledge of enterprise resource planning (ERP), supply chain concepts, and quality metric methodology
Lean awareness and ideally experience of structured continuous improvement (Daily Management, Standard Work, Problem Solving, Kaizen, and Gemba Walks.)

PREFERRED REQUIREMENTS (optional):
Prefer B.S. Statistics, Mathematics, Computer Science, or Industrial Engineering with 3-5 yrs of experience
Preferred: MBA, MS, SQL database and querying languages, Python, R, VBA, Power BI, Tableau
Preferred Certifications: Data Science from IIT Universities, IBM Data Science Professional from Coursera

TRAINING RESPONSIBILITIES:
Complete all assigned and required training satisfactorily and on time

Danaher Corporation Overview
Danaher is a global science & technology innovator committed to helping our customers solve complex challenges and improve quality of life worldwide. Our world class brands are leaders in some of the most demanding and attractive industries. A globally diverse team of 81,000 associates, we are united by our culture and operating system, the Danaher Business System, which is our competitive advantage. In 2015, we generated $20.6B in revenue and our market cap exceeded $60B. We are #149 on the Fortune 500 and our stock has outperformed the S&P 500 by more than 2,000% over 20yrs.
At Danaher, you can build a career in a way no other company can duplicate. Our brands allow us to offer dynamic careers across multiple industries. We’re innovative, fast-paced, results-oriented, and we win. We need talented people to keep winning. Here you’ll learn how DBS is used to shape strategy, focus execution, align our people, and create value for customers and shareholders. Come join our winning team."
Data Analyst,"Chennai, Tamil Nadu",IDP Education Ltd,None,Organic,"IDP Education Limited is an ASX listed company that is 50% owned by 38 Australian universities and headquartered in Melbourne, Australia. IDP’s core business lines include student placement to Australia, US, UK, Canada and New Zealand institutions, English-language testing and training.
We are setting out to be the world's leading platform and connected international student community through building tons of new products to put our customers at the heart of everything we do.
For over 50 years our global network of 93 offices has been helping students to achieve their goals through studying abroad. By pursuing a global education at the beginning of their careers, we help them experience life-changing opportunities. For more than 5,000 employees in more than 50 countries, IDP Education is a specialist employer of choice in major cities across the globe.
If you share our passion in helping people to pursue their dreams through education and thrive in an innovative agile digital culture then come and join us as we undergo our digital revolution.
POSITION PURPOSE
This position will support IDP Student Placement Data service for our global customers, working closely with various cross functional groups, clients and third-party vendors to resolve incidents and fulfilling service requests pertaining data and reports. You will ensure high data integrity and confidential is maintained within IDP maintained systems, tools and adhere to the standard set of processes.
RESPONSIBILITIES
Support customer on data management workgroup resolutions with agreed SLA’s using incident ticketing tools namely ServiceNow
To adhere to ITIL processes for Requests, Incident Management
Perform data management activities that includes but not limited to data import, data export and data update of any IDP maintained systems / tools / processes
Decipher the information and present to stakeholders and customers
Analyse and display data in an accurate and meaningful manner on demand
Support in data collection and use data mining techniques for various business requirements
Produce reports, dashboards in acceptable frequency and on a recurring cycle
Develop functional requirements for reports based on discussions and design sessions with the key customers & stakeholders
Translate requirements to dissect and translate the underlying request into the reports
Document findings and recommendations and communicate effectively though both verbal and written channels
Prepare accurate data files for distribution using secured transferrable channels
Prepare and assist in data unit testing for various IDP systems and projects
Conduct periodic data analysis, perform RCA for any targets missed and customer escalation
WHAT WE'RE LOOKING FOR
Essential Requirements
Bachelor’s degree or relevant professional in computer science application, computer systems analysis, or a related field.
2 years of professional experience, with minimum of 1 Year of experience working on business data analysis
Strong understanding of relational database concepts
Good Computing skills with strong understanding of using Microsoft Office tools like Excel, SQL & other related platforms
Ability to effectively articulate data, data flows challenges and solution across integrated platform
Experience in supporting customers around the globe and willing to work in shift hours (flexibility)
Personal profile: analytical, inquisitive, service and team-oriented, friendly demeanour adopter.
Desirable Requirements
Experience working on Cloud based applications and standard Business Analytics tools
Experience in effectively working with the ITIL framework

WORKING AT IDP
IDP Education’s ongoing success comes from our highly committed and caring employees around the globe. We encourage teamwork in order to leverage our people's diverse talents and expertise through effective collaboration and cooperation throughout our business.
We strive to provide a working environment where people are encouraged to excel, be creative and seek new ways to solve problems, take initiative, generate opportunities and be accountable for their actions.

We believe in developing dynamic, inclusive work places that encourage and celebrate cultural differences and views, and provide opportunities for personal, professional and career development all around the world. We respect diversity in our people: their ideas, work styles and perspectives as well as offering flexibility to ensure employees enjoy a satisfying balance of work and personal life."
Data Analyst,"Chennai, Tamil Nadu",Sagitec,None,Organic,"Data Scientist who is passionate about data and wants to apply machine learning techniques to solve problems for our customers. This person is expected to be proficient in the exploration and understanding of structured and unstructured data, machine learning techniques, statistical modeling methods, predictive analytics, anomaly detection, and supervised and unsupervised learning. The successful candidate will work with stakeholders to leverage data to solve critical business problems in the Benefits Administration domain.
The Data Scientist will work on all aspects of the design, development, and delivery of machine learning-enabled solutions including problem definition, data acquisition, data exploration, feature engineering, experimenting with various ML algorithms, evaluating metrics, deploying models and iteratively improving the total solution.
Duties & Responsibilities
Formulate a meaningful hypothesis that is relevant to the business objectives.
Design and train models for use in production environments.
Mine structured and unstructured data for patterns.
Utilize data from databases, Web scraping, public datasets, historians, and/or data lakes.
Rigorously build, analyze, and compare machine learning or statistical models; there is a strong emphasis on programming using the most popular machine learning languages such as Python, R, Microsoft R, TensorFlow, PyTorch, SciPy, Encog, etc.
Work with application developers to develop data-analytics products that are deployed to end-users as part of packaged solutions.
Visualize and report findings of deployed data analytics solutions to provide insights to the organization and our customers.
Deploy machine learning model and integrate model predictions in business
Setup infrastructure for machine learning, model deployment including commissioning or ML-Servers and Server Configuration
Deploy CI/CD framework to frequently deliver code/features to production
Qualifications
Experience & Education
Required
M.S. or higher in Mathematics, Statistics, or Computer Science with significant experience in data analytics and Model Building.
Preferred
5+ years experience is preferred.
Knowledge, Skills, & Ability
Required
Expertise in predictive modeling, machine learning and statistics.
Software development skills in one or more high level languages (Python/Java/R/Scala).
Experience using one or more of the following common ML software packages: scikit-learn, TensorFlow, NumPy, pandas, jupyter.
Well-versed in machine learning algorithms and their suitability for solving various problems: Regression, Bayesian, Support Vector Machines, Decision Trees, Random Forest, Clustering, Neural Networks.
Experience in using SQL/No SQL databases is an advantage
Experience working in Windows/Linux is an advantage
Experience with Big Data technologies is an advantage (Hadoop, Hive, Spark, Cassandra).
Experience with building and deploying data pipelines
Good critical thinking, technical, data collection and user interviewing skills.
Ability to work as a team member in a fast-paced environment.
Experience With Agile Software Development Processes Is Preferred.
Experience with Cloud service offerings from AWS, Azure or GCP is a plus.
Preferred
Knowledge of DataOps.
Knowledge of data versioning tools such as git, DVC
Knowledge of ML environments such as MLflow, databricks
Knowledge of ML deployment tools such as Kubeflow, Kubernetes."
Senior Data Scientist- AI,"Bengaluru, Karnataka",Lymbyc Solutions,None,Organic,"Description:
Background:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.
By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.
Description:
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.
Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.
Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner
Skills Required:
Must have minimum of 5-7 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc"
Associate Director - Data Science & AI Engineering,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for Associate Director - Data Scientist and AI Engineering to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about implementing large scale application of AI and machine learning to financial services, AppZen is the place for you.
Must-Have:
Solid hands-on understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.

Provides the basis for the innovation strategy involving future trends and their impact on the team strategy and client businesses

Be at the forefront of the development of self and team's technical acumen and enabling upskilling of other team members to leverage advanced analytics / AI techniques

Lead and direct discovery of new tools/technologies/solutions with advanced AI / ML solutions in areas of deep learning, machine learning, NLP, Simulation etc.

Support business development activities by co-creating next-gen AI/ML solutions and help identify opportunities with new/existing clients.

Expertise on AI/ML for text/document analysis is nice to have

Demonstrating a track record of delivery within a number of large scale projects that has solved complex problems using AI/ML and statistical techniques.

Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.

Expert knowledge of a statistical computing language such as Python with expert knowledge of RDBMS and NoSQL databases

Manipulating and analyzing complex, high-volume, high-dimensional data from varying sources

Understanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context

Excellent interpersonal, communication and analytical skills

Project execution experience in complex matrix organization dealing with leadership, staff and stakeholders

M.Sc. or M.E. or M.Tech or Phd in Computer Science, Engineering, Statistics, with specialization in NLP/ AI / ML is required

Must have 15+ years of industry experience
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
AI NLP ENGINEER,"Pune, Maharashtra",NLPBOTS,None,Organic,"Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.
To succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.
What we look for: -
Advanced proficiency in the following:
1. Python
2. Natural Language Processing
3. Deep Learning
4. Machine Learning
5. Numpy, Scipy, Pandas
6. Data Science
7. MongoDB
8. NoSQL
9. SQL
10. Big Data
Experience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)
Self driven individual with a drive to learn the latest in the technology.
Exceptional team player.
Ability to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.
Good understanding and knowledge of enterprise PDLC.
Research mindset with the courage to try things and learn from them."
Data Scientist,"Pune, Maharashtra",GridEdge Technologies,None,Organic,"Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com"
Game Analyst,"Bengaluru, Karnataka",Kwalee,None,Organic,"Kwalee is an expanding, independent mobile games developer and publisher based in the beautiful town of Leamington Spa, England, within the area known as Silicon Spa where over 3,000 game developers work.
Kwalee is one of the world's fastest growing studios and has rapidly become the largest hyper-casual publisher in the UK. Thanks to hit games including Draw it, Looper, Jetpack Jump, Shootout 3D, Go Fish!, Plank! and Rocket Sky, Kwalee has hundreds of millions of players across the globe, placing us within the top 5 mobile developers worldwide.
The company was founded in 2011 by David Darling CBE - awarded by the Queen, co-founder of Codemasters and comprises of a highly skilled and creative team that has doubled its size in the last year. The team includes many industry veterans and the original creator of the Micro Machines video games (yes, you read well, we have celebrities here!).
As a Game Analyst you have a passion for data, statistics and mobile games so this job is perfect for you. You'll be part of a development team that will be based in the new office that we're going to open in Bangalore.
What you tell your friends you do
“I'm a guru with numbers, give me some data and I'll tell you what to do to get the best results""
What you will really be doing
Analysing how players play our games and providing insights and suggestions for how to improve the KPIs to make the games as successful as possible.
Analysing A/B tests and identifying the winning group.
Making and maintaining dynamic spreadsheets, presentations and dashboards that allow everyone to see the key data easily.
How you will be doing this
You’ll be part of an agile, multidisciplinary and creative team and work closely with them.
You'll think creatively and be motivated by challenges and constantly striving for the best.
You’ll work with cutting edge technology, if you need software or hardware to get the job done efficiently, you can get it.
Skills and requirements:
Maths or Computing Science background
At least 2 years of experience in Data Analysis, if some of it is in the gaming industry that would be a plus
Very strong skills in statistics and Excel
Knowledge and/or experience with Python
Passion for mobile games
Excellent communication skills
Team

Our talented team is our signature. We have a highly creative atmosphere with around 70 staff where you’ll have the opportunity to contribute daily to important analytics decisions. You’ll work within an extremely experienced and passionate team, including David Darling and the creator of the original Micro Machines video game.

We do we offer
We offer a generous benefits package to all our employees that includes a team profit sharing scheme from day 1 of employment among other perks.
Our philosophy
We firmly believe in creativity and innovation and that a fundamental requirement for a successful and happy company is having the right mix of individuals. With the right people in the right environment anything and everything is possible."
Data Scientist III,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"Bachelor’s or Master’s degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics
4+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python, R), or statistical/mathematical software (e.g. R, SAS, Matlab, etc.)
2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication
A natural curiosity and desire to learn
Experience articulating business questions and using quantitative techniques to arrive at a solution using available data
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences

Description
Amazon.com strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated and friendly work environment.

We need an expert in econometric and statistical tools to extract insights at scale by building models with our world class data systems, designing advanced new experimental methods, and investigating complex behavioral patterns.

Team Introduction
Amazon Search creates powerful, customer-focused product search solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, our systems go to work. Our Search Engine team designs, builds, and delivers high performance, fault-tolerant, scalable distributed search engine used by millions of Amazon customers every day.

We are looking for a highly motivated Data Scientist who can help ensure our experience on Amazon Search is creating long-term value for our customers. This person will be responsible for architecting insights and systems to anticipate which features will improve customer’s search experience. This person will also be responsible for designing experiments and devising frameworks that measure the short-term and long-term impact of our product initiatives. Finally, this person would also derive insights using our existing data and experiments to inform new innovation and direction for Search Technologies and internal partner teams.

The ideal candidate will be an expert in the areas of data science, machine learning and statistics, having hands-on experience with multiple improvement initiatives as well as balancing technical and business judgment to make the right decisions about technology, models and methodologies. You will leverage data, experimental design, and analytics to help define new ways to evaluate, visualize and predict to understand outcome and decisions on how to improve customer engagement across customer lifecycle segments. The candidate needs experience with data science / business intelligence, analytics, and reporting systems while striving for simplicity, and demonstrating significant creativity and high judgment backed by statistical proof.

The ideal candidate should have deep expertise in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and use appropriate statistical and econometric techniques to derive insights and recommendations to leadership. You should excel at bringing large datasets together to answer business questions and drive change.

Responsibilities Scientists at Amazon are expected to develop new techniques to process large data sets, address quantitative problems, and contribute to design of automated systems around the company. Major responsibilities include:
Measure / Quantify / Expand
Design, size, and analyze field experiments at scale.
Apply econometric or statistical knowledge to improve Amazon Search (using machine learning techniques is a plus)
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Explore / Enlighten
Formalize assumptions about how Amazon Search is expected to work.
Given anomalies, whether anecdotal or identified automatically, deep dive to explain why they happen, and identify fixes.
Decide / Recommend
Build decision-making models and propose solution for the business problem you defined
Implement models based on findings in production back end systems
Analyze A/B tests and recommend ways to making them faster and more robust
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithm

Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Experience with data visualization and presentation, turning complex analysis into insight
Experience collaborating with software development teams, data scientists, business intelligence or other technical roles
Masters or PhD in applied quantitative field
Strong background in statistics methodology, applications to business problems, and/or big data.
Ability to work in a fast-paced business environment.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
Experience designing experiments, and ability to infer causal relationships"
Deep Learning Intern WFH,Remote,Clarion Analytics LLP,None,Organic,"CLARION ANALYTICS is looking for Deep Learning Interns for its IVA team to develop and commercialise Artificial Intelligence solutions for the markets.
Role
Construct ,curate and work on problem specific datasets.
Study and develop state of the art techniques in deep learning.
Analyze and improve performance of GPU implementations.
Your Background
You are pursuing a PhD or Masters or Bachelor or equivalent in Computer Science, Artificial Intelligence, or Applied Math.
Solid understanding for deep learning and a strong algorithmic background
Excellent programming, debugging, performance analysis and test design skills.
Excellent understanding of deploying data pipelines for Computer Vision projects.
Excellent understanding of NVIDIA Jetson series and deploying Deep learning models on the edge.
Good to Have
Deep Learning experience.
Experience with DL Frameworks (e.g. TensorFlow, PyTorch, NVIDIA DeepStream).
Excellent C/C++ and Python programming skills.
GPU programming (CUDA or OpenCL).
Experience doing performance analysis and tuning.
Job Types: Full-time, Internship
Experience:
Raspbery, NVIDIA Jetson: 1 year (Preferred)
Deep Machine Learning: 1 year (Preferred)
TensorFlow, PyTorch , Caffe or other DCNN Framework: 1 year (Preferred)
NVIDIA CUDA , C/C++: 1 year (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Python Developer,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"About the job :
Responsibilities :
Package code and create executables/binaries in python code and c#
code.
Coding practices need to be very good to write Memory, Disk IO and CPU efficient codes
and developer must have an understanding of background services which can go inactive or
paused mode.
Should be comfortable in creating own data streaming strategies if required.
Hands-on experience in a full-stack python application development.
Experience in creating REST API using Flask/Django Framework.
Good understanding of database (Postgresql/MySQL/Oracle/SQL Server).
Must have a very clear understanding of network protocols – HTTP, TCP (sockets), RTSP
(streaming).
Should know basics in low-level coding on strings, objects, bytes, integers using binary
operators.
Should be able to run packaged deep learning code – written in PyTorch, TensorFlow, Yolo,
Open CV.
Qualifications and Experience :
Bachelors in Computer Science/ Information Technology.
Minimum 3+ years of experience as a python developer.
Should know HTTP APIs development in python (Flask, Tornado).
Should knowing c# .net desktop/UI application development.
Good to have Agile Software Development Experience, AWS/AZURE/Google Cloud-based
application development."
Data Engineer,"Bengaluru, Karnataka",Huron Consulting Group Inc.,None,Organic,"Huron is redefining what a global consulting organization can be. Advancing new ideas every day to build even stronger clients, individuals and communities. We’re helping our clients find new ways to drive growth, enhance business performance and sustain leadership in the markets they serve. And, we’re developing strategies and implementing solutions that enable the transformative change they need to own their future.

As a member of the Huron corporate team, you’ll help to evolve our business model to stay ahead of market forces, industry trends and client needs. Our accounting, finance, human resources, IT, legal, marketing and facilities management professionals work collaboratively to support Huron’s collective strategies and enable real transformation to produce sustainable business results.

Join our team and create your future
Position Summary:
4 to 7 years of hands on experience as a data lake, data warehouse, /analytics developer
Experience with Data Modeling and data mapping methodologies
Good technical abilities in AWS (S3, lambda, kinesis), Python and SQL : problem solving, coding and debugging skills
Hands on experience with Database (such as Oracle, MS SQL Server, MySQL, PostgreSQL), NoSQL (such as HBase, MongoDB, Cassandra, Cosmos, Arango, Orient) and Data Warehousing (such as Microsoft Azure DW, Redshift, Teradata, Vertica) and data migration, ETL (AWS Glue, Azure Data Factory, Informatica, SSIS, etc.) and integration
Building highly scalable, robust & fault-tolerant systems and capabilities
Experienced in creating large data pipelines (via tools and code level- Python R | Spark)
Creating a complete solution by integrating a variety of programming languages & tools together.
Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external partners/virtual teams.
Qualifications:
Experience with Big Data, Basic Data Science, Statistics, Machine Learning & Modeling is a plus
Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps 3.
About Huron:
At Huron, we’re redefining what a consulting organization can be. We go beyond advice to deliver results that last. We inherit our client’s challenges as if they were our own. We help them transform for the future. We advocate. We make a difference. And we intelligently, passionately, relentlessly do great work…together.
Are you the kind of person who stands ready to jump in, roll up your sleeves and transform ideas into action? Then come discover Huron.
Whether you have years of experience or come right out of college, we invite you to explore our many opportunities. Find out how you can use your talents and develop your skills to make an impact immediately. Learn about how our culture and values provide you with the kind of environment that invites new ideas and innovation. Come see how we collaborate with each other in a culture of learning, coaching, diversity and inclusion. And hear about our unwavering commitment to make a difference in partnership with our clients, shareholders, communities and colleagues.
We offer a competitive compensation/benefits package. Huron is an equal opportunity employer. We recruit, employ, compensate, transfer, promote and train without regard to race, color, creed, religion, national origin, sex, marital status, pregnancy, disability, sexual orientation, veteran status, age, FMLA status or any other basis protected by law.
LI:"
Data Scientist,"Pune, Maharashtra",Talentica Software India,None,Organic,"The Company
Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay). We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology. The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.
We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.
Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras
Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval
Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms."
"Data Engineer, Loss Prevention","Bengaluru, Karnataka",ASSPL - Karnataka,None,Organic,"Basic Qualifications
1.Bachelor of Engineering Degree
2.2+ years of experience as an analyst or engineer in the data/Business Intelligence space
3.Proficient in SQL
4.Proven analytical approach to solve business problems.

Job Description
Amazon is looking to hire an insightful, results-oriented business intelligence engineer to join the team. The person will play a key role in generating and driving analysis for Loss Prevention in Amazon India.

The ideal candidate is an experienced analyst who has demonstrated proficiency in analytics driven business solutions. The person would be a Data resource for the team and would work to generate actionable intelligence and insights for the team through rigorous data analysis and structured reporting, ensuring their efforts are focused in the appropriate areas. The person would deep-dive and bring out pointers that will help bring in continuous improvement/changes in processes from the Loss Prevention standpoint, thereby helping in reducing the losses across Amazon network. They are comfortable in analyzing data from multiple sources to create strategic recommendations in a thoughtful, concise manner and obtaining organizational buy-in at senior levels. They are well-organized, can manage multiple analyses/projects simultaneously, and is intellectually curious. Successful candidates will be expected to demonstrate our leadership principles: a bias for action, deep-dive, ownership and customer-obsession.

Key Responsibilities includes
1.Converting data into digestible business intelligence and actionable information
2.Writing high quality SQL codes to retrieve and analyze data.
3.Working with large data sets, automate data extraction, and build monitoring/reporting dashboard
4.Interacting with internal stakeholders to deep-dive outlier events
5.Analyze and solve business problems with focus on understanding root causes and driving forward-looking opportunities

6.Communicating complex analysis and insights to our stakeholders and business leaders, both verbally and in writing.

Preferred Qualifications
1.Exposure to e-commerce or retail company handling large complex data sources
2.Experience with data visualization using Tableau or similar tools
3.Have theoretical and working knowledge of Data Science
4.Experience with scripting tools like Python is a plus"
Data Scientist,"Bengaluru, Karnataka",TALCHEMIST,None,Organic,"Data Scientist
Large Banking MNC
5 - 10 years
Bangalore
QUALIFICATION
Bachelor’s or Masters Technology Degree in Computer science or Equivalent
Job Description
The senior data scientist will get the opportunity to work in an agile software development enviornment addressing machine learning and optimization analytics problems. The senior data scientist will be part of cross diciplinary data science team working on software development projects, typically involving large, complex data sets. They will work with technical team in development and deployment and application of predictive analytics.
Key Skills Required
Demonstrated skill of data cleansing, data qualityy assesment. Use the descriptive statistics, feature extraction and predictive analytics on real datasets. Skills at data visualization and storytelling for an audience of stakeholders. Experience in working with Hadoop and spark will be added advantages."
Data Engineer,"Bengaluru, Karnataka",PayU,None,Organic,"Role: Data Engineer
Company: PayU
Location: Bangalore/ Mumbai

About Company:

PayU is the payments and fintech business of Prosus, a global consumer internet group and one of the largest technology investors in the world. Operating and investing globally in markets with long-term growth potential, Prosus builds leading consumer internet companies that empower people and enrich communities.
The leading online payment service provider in 36 countries, PayU is dedicated to creating a fast, simple and efficient payment process for merchants and buyers. Focused on empowering people through financial services and creating a world without financial borders where everyone can prosper, PayU is one of the biggest investors in the fintech space globally, with investments totalling $700 million- to date. PayU also specializes in credit products and services for emerging markets across the globe. We are dedicated to removing risks to merchants, allowing consumers to use credit in ways that suit them and enabling a greater number of global citizens to access credit services.
Our local operations in Asia, Central and Eastern Europe, Latin America, the Middle East, Africa and South East Asia enable us to combine the expertise of high growth companies with our own unique local knowledge and technology to ensure that our customers have access to the best financial services.
India is the biggest market for PayU globally and the company has already invested $400 million in this region in last 4 years. PayU in its next phase of growth is developing a full regional fintech ecosystem providing multiple digital financial services in one integrated experience. We are going to do this through 3 mechanisms: build, co-build/partner; select strategic investments.
PayU supports over 350,000+ merchants and millions of consumers making payments online with over 250 payment methods and 1,800+ payment specialists. The markets in which PayU operates represent a potential consumer base of nearly 2.3 billion people and a huge growth potential for merchants.
Job responsibilities:
Design infrastructure for data, especially for but not limited to consumption in machine learning applications
Define database architecture needed to combine and link data, and ensure integrity across different sources
Ensure performance of data systems for machine learning to customer-facing web and mobile applications using cutting-edge open source frameworks, to highly available RESTful services, to back-end Java based systems
Work with large, fast, complex data sets to solve difficult, non-routine analysis problems, applying advanced data handling techniques if needed
Build data pipelines, includes implementing, testing, and maintaining infrastructural components related to the data engineering stack.
Work closely with Data Engineers, ML Engineers and SREs to gather data engineering requirements to prototype, develop, validate and deploy data science and machine learning solutions
Requirements to be successful in this role:
Strong knowledge and experience in Python, Pandas, Data wrangling, ETL processes, statistics, data visualisation, Data Modelling and Informatica.
Strong experience with scalable compute solutions such as in Kafka, Snowflake
Strong experience with workflow management libraries and tools such as Airflow, AWS Step Functions etc.
Strong experience with data engineering practices (i.e. data ingestion pipelines and ETL)
A good understanding of machine learning methods, algorithms, pipelines, testing practices and frameworks
Preferred) MEng/MSc/PhD degree in computer science, engineering, mathematics, physics, or equivalent (preference: DS/ AI)
Experience with designing and implementing tools that support sharing of data, code, practices across organizations at scale"
Data Informatics Associate,"Bengaluru, Karnataka",Covance,None,Organic,"Job Overview:
Global Specimen Solutions (GSS) is wholly owned company of Covance Inc., providing specialty services in the holistic specimen tracking space. GSS improves translational science through industry best practices and a uniquely powerful pipeline data management analytics solution. GSS reduces the time, cost and risk of specimen based research, while building robust, healthy data pipelines that optimize research opportunities.

Job Summary
Reviews vendor data feed for completeness and accuracy against client instance definition. Evaluates appropriateness of vendor data for standard loading and configure if found appropriate. If vendor data is not found appropriate for standard loading, creates request, with requirements definition, to data loader development group. Develops data point mapping, based data loader being used, and import to GSS operations data feed management system. Executes test data load and review results for accuracy and completeness of data point mapping. Remediate errors and omissions from review. Performs QC evaluation on data feeds mappings created by other Clinical Data Informatics Leads and/or Clinical Data Informatics Specialists. Maintains and utilizes a strong knowledge of SOPS and validation work procedures/standards in relation to the System Development Life Cycle. Essential Job Duties:
Function Specific Demonstrate the ability to multi-task and manage data feed configurations and date point mapping development. Plan and establish timelines to meet or exceed business expectations for data feed configurations and date point mapping development. QC data feed configurations and date point mappings. Strong troubleshooting and analytical skills for identification of errors and omissions for remediation. Utilize strong working knowledge of SOPs, validation standards, and work procedures to suggest potential improvements and to provide training and guidance to all staff.

Customer Facing There are no customer facing job functions in this position.

Metrics Support management of metrics. Assist with investigating or resolving issues of quality as directed. Staff and Financial Management Understand implications of activities to project budgets.

Process Improvement Suggest process improvements where issues are seen. Support Six Sigma process improvement teams.

Training / SOPs Reviews training materials for staff. Mentor and support other GSS employees in their understanding and adoption of data feed configuration and date point mapping development. Active member of SOP review teams as assigned.
Other Lead or assist with special projects as designated. Perform other duties as assigned by management.

Principal Contacts and Scope of Communications Internal: GSS Client Project Managers, ClinRegOps (will need to get exact title of STPers from Doug), Data Architect, Data Monitor Specialist and Data Monitor Lead. Extrenal: None Education/Qualifications:
Bachelores degree preferably in the sciences or related field, or two (2) years in a data analysis and/or profiling position. Experience: Minimum 2 years data informatics experience or equivalent work experience in a regulated (FDA, EPA, etc.) environment. Strong attention to detail. Strong analytical skills, preferably in a GCP environment. Experience with 21 CFR Part 11 in a pharmaceutical, biotechnology, CRO or related industry. Problem Solving/Logic Skills. Strong communication and interpersonal skills. Working knowledge of SQL and RDMS structures and relationships Strong MS/Office skills in particular with Excel and Word. Understanding of database query tools, such as DEForge or Navicat, preferred."
Data Visualization,"Chennai, Tamil Nadu",Bloom Consulting Services,None,Organic,"Looking for a person who is good at visually communicating the Story !!
A good end to end Experience in Data Visualisation tools like Tableau, QlikView, Microstrategy, Superset, imply, etc
Hands-on Experience in SQL, Data Analysis Skills
Hands-on experience with Big Data Tools and skills (Spark Streaming, Kafka, Druid, Hive, HBase, etc..)
Web UI Design with JAVA would be nice to have
Use of AWS Stack knowledge would be good to have
Proficiency of relational and dimensional data modeling and core reporting
Self Starter with an attitude to try new things and do POC's

DATA SCIENCE:

Must to have:
Python
Data and Statistical modeling
AWS SageMaker (Machine learning)
SAS
What You Need for this Position
You should have knowledge of:
Python
Data and Statistical modelling
AWS SageMaker
SAS
Aditional
No. of Positions
Education level
Career level
Experienced"
Data Science Engineer,"Pune, Maharashtra",Alliance Recruitment Agency,None,Organic,"Location: pune
State: pune
PostalCode: 411038
Recruiter: Disha Chauhan - +91 70697 10005
Created Date: 01-10-2019
Desired Skills:
Excellent understanding of machine learning techniques and algorithms, such as k-NN,
Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc.
Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Responsibilities:
We are looking for a data scientist that will help us discover the information hidden in vast
amounts of data, and help us make smarter decisions to deliver even better products. Your
primary focus will be in applying data mining techniques, doing statistical analysis, and building
high-quality prediction systems integrated with our products.
Experience Requirements: Selecting features, building and optimizing classifiers using machine learningtechniques Data mining using state-of-the-art methods Extending the company’s data with third-party sources of information when needed Enhancing data collection procedures to include information that is relevant for buildinganalytic systems Processing, cleansing, and verifying the integrity of data used for analysis Doing the ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of itsperformance
Industry: IT
Salary Range: As Per Industry Standards."
Ai Scientist,"Mumbai, Maharashtra",Accrete.AI,None,Organic,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.
About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology"
Game Analyst,"Bengaluru, Karnataka",Kwalee,None,Organic,"Kwalee is an expanding, independent mobile games developer and publisher based in the beautiful town of Leamington Spa, England, within the area known as Silicon Spa where over 3,000 game developers work.
Kwalee is one of the world's fastest growing studios and has rapidly become the largest hyper-casual publisher in the UK. Thanks to hit games including Draw it, Looper, Jetpack Jump, Shootout 3D, Go Fish!, Plank! and Rocket Sky, Kwalee has hundreds of millions of players across the globe, placing us within the top 5 mobile developers worldwide.
The company was founded in 2011 by David Darling CBE - awarded by the Queen, co-founder of Codemasters and comprises of a highly skilled and creative team that has doubled its size in the last year. The team includes many industry veterans and the original creator of the Micro Machines video games (yes, you read well, we have celebrities here!).
As a Game Analyst you have a passion for data, statistics and mobile games so this job is perfect for you. You'll be part of a development team that will be based in the new office that we're going to open in Bangalore.
What you tell your friends you do
“I'm a guru with numbers, give me some data and I'll tell you what to do to get the best results""
What you will really be doing
Analysing how players play our games and providing insights and suggestions for how to improve the KPIs to make the games as successful as possible.
Analysing A/B tests and identifying the winning group.
Making and maintaining dynamic spreadsheets, presentations and dashboards that allow everyone to see the key data easily.
How you will be doing this
You’ll be part of an agile, multidisciplinary and creative team and work closely with them.
You'll think creatively and be motivated by challenges and constantly striving for the best.
You’ll work with cutting edge technology, if you need software or hardware to get the job done efficiently, you can get it.
Skills and requirements:
Maths or Computing Science background
At least 2 years of experience in Data Analysis, if some of it is in the gaming industry that would be a plus
Very strong skills in statistics and Excel
Knowledge and/or experience with Python
Passion for mobile games
Excellent communication skills
Team

Our talented team is our signature. We have a highly creative atmosphere with around 70 staff where you’ll have the opportunity to contribute daily to important analytics decisions. You’ll work within an extremely experienced and passionate team, including David Darling and the creator of the original Micro Machines video game.

We do we offer
We offer a generous benefits package to all our employees that includes a team profit sharing scheme from day 1 of employment among other perks.
Our philosophy
We firmly believe in creativity and innovation and that a fundamental requirement for a successful and happy company is having the right mix of individuals. With the right people in the right environment anything and everything is possible."
Data Science Engineer,"Bengaluru, Karnataka",IntelliPredikt Technologies,None,Organic,"You can send your CV to careers@intellipredikt.com

Job_ID : IPTB_PE_102
Job Title: Data Science Engineer
Status: OPEN
Job Description: Data scientist is responsible for data exploration, machine learning, IP generation, anomaly detection/ prediction and data visualization of massive dataset using common tools.
Qualification: MS or PhD in Data Analytics areas
Experience: 1 to 5 years of experience in data analytic's for anomaly detection and prediction"
Lead / Sr. ML/AI Engineer,"Salem, Tamil Nadu",Dattendriya Data Science Solutions,None,Organic,"Location : Chennai / Salem
Roles and Responsibilities :
Candidate will be responsible for building Machine Learning/ Deep learning models for NLP, forecasting and other applications. The candidate will be responsible for converting blue sky ideas into implementation.
Should be able to create solutions and try various algorithms to solve the problem.
Work with the Engineering Team to design, code, train, test, deploy and iterate on enterprise scale machine learning systems. Also be able to work in a R&D mode for certain open-ended problems.
Should be able to work alongside an excellent, cross-functional team and manage teams in ensuring timely delivery.
General Requirement :
Experience in applying machine learning techniques NLP, CV or other application areas
Strong analytical and problem-solving skills
Deep understanding of ML/ DL techniques such as: classification, clustering, model optimization etc.
Solid programming/ engineering skills including but not limited to Python, C/C++.
Proven ability to apply, debug, and develop machine learning models for real-world applications
Ability to lead and manage a team and be comfortable with deadlines and milestones
Strong verbal and written communication skills
Required Skillset :
Strong programming skills in Python along with C/C++ or R, ML/ DL toolkits such as Scikit-learn, NLTK, spaCy, TensorFlow, Keras, PyTorch
Strong experience in Engineering/ deployment tools in Cloud and other environments: AWS (Lambda, S3, SageMaker, Texteract, NoSQL etc.), Hadoop, Git, Spark MLib, Data Visualization tools etc.
Good understanding of ML and DL theoretical concepts and algorithms and hands-on experience in implementing or improving algorithms
Experience in NLP and NLU (NLTK, Spacy, Flair, etc.)
Writing code for production environments and ability to profile code for optimizing runtime, memory etc.
Prior experience in Pharma/Healthcare / Life Science will be a Big Plus but not Mandatory.

We seek self-driven and passionate individuals for the following positions. The candidate must have a minimum Graduate degree such as BE / B.Tech / MCA degree along with some programming experience. We would also welcome bright B.Sc / M.Sc candidates specialized in Physics / Maths / Computer Science with some exposure to programming."
Python Lead – Distinguished Founders – Mission Critical,"Bengaluru, Karnataka",CareerXperts,None,Organic,"Are you passionate about Python? You are known for your views on “how to build scalable Internet Products” and “Engineering Excellence”. You have deep Interest to work on Core Platforms? Then, we are looking for you!!
We have a topnotch role of a Tech Lead who is passionate about writing clean code and is vivid about leading and mentoring a team of young engineers to solve hard Computer Science Problems (Distributed Systems, Machine Learning, NLP, and Computer Vision).
Experience
6+ years
Qualification
6+ years of core experience in writing clean production level Python code.
Proven Ability to build large enterprise-grade systems.
Strong mathematics background.
Experience and/or desire to work in a fast paced start-up environment.
Compensation – Better than the best in the industry.
Responsibilities
On being a Python Developer with us!
At the heart of the design and integration of automated vision and serialization systems, you will thrive in an agile and multidisciplinary team.
Leverage our platform and our open source projects to perform distributed information extraction, retrieval and data processing.
Identify and resolve performance and scalability issues with distributed crawling at scale.
Write to deepa.m@careerxperts.com to get connected!
Job Location
Bengaluru"
Python Developer,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"About the job :
Responsibilities :
Package code and create executables/binaries in python code and c#
code.
Coding practices need to be very good to write Memory, Disk IO and CPU efficient codes
and developer must have an understanding of background services which can go inactive or
paused mode.
Should be comfortable in creating own data streaming strategies if required.
Hands-on experience in a full-stack python application development.
Experience in creating REST API using Flask/Django Framework.
Good understanding of database (Postgresql/MySQL/Oracle/SQL Server).
Must have a very clear understanding of network protocols – HTTP, TCP (sockets), RTSP
(streaming).
Should know basics in low-level coding on strings, objects, bytes, integers using binary
operators.
Should be able to run packaged deep learning code – written in PyTorch, TensorFlow, Yolo,
Open CV.
Qualifications and Experience :
Bachelors in Computer Science/ Information Technology.
Minimum 3+ years of experience as a python developer.
Should know HTTP APIs development in python (Flask, Tornado).
Should knowing c# .net desktop/UI application development.
Good to have Agile Software Development Experience, AWS/AZURE/Google Cloud-based
application development."
Lead Data Analytics & Reporting,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bengaluru
Schedule: Full-time
Employee Status: Permanent
Posting Date: 10/Aug/2020
Unposting Date: 10/Sep/2020
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.



Purpose:
The role is at a senior level in the Digital Channels & Data Analytics team of CCIB based in Bangalore. Innovative big data and machine learning solutions are a key priority for the Bank as part of investments in creating value-add services for clients, creating or joining new consortiums and enabling new business models. This role is to contribute to the development of data projects.
Strategic data initiatives in CCIB creates differentiated digital capabilities for clients to access the Bank's transactional services in over 50 markets efficiently and securely. This includes internet and mobile banking for global business clients, direct integration options, as well as services through third parties.
The role would be suited to a candidate having experiences in data science and analytics field – developing models, rules and algorithms from structured and unstructured sources and performing deep-dive analysis to derive data-driven decisions
Proven track records in building and deploying (financial services) analytic solutions that have created significant value for customers and additional revenue based on new business models.
Experience in building dynamic dashboard (eg Tableau, Power BI) for business stakeholders will be an absolute must
Experienced working in an offshore model is required since role will be based in Bangalore with business stakeholders in Singapore and other overseas locations
Strong data defining, structuring, labelling and developing data models to capture, store, process and use this data to generate intelligent outcomes through Data Analytics
The candidate will have a profound knowledge of large data sets, data management, data governance, data science and metadata.
The role requires close partnership with Cash, Trade, and Security Services Product organisation. Other key stakeholders include global Sales and Implementation teams, Technology, and risk owners such as legal and compliance.
This role reports to the Data Analytics lead for Transaction Banking.

Key Accountabilities:
Help built a strategy & roadmap of analytics solutions that will position Standard Chartered as leading in this field
Creating effective dashboards for business stakeholders
Apply and ensure data governance framework.
Develop and implement artificial intelligence algorithms, rules and rapid prototypes from big data sets that will be fed into various business programs.
Behavioural segmentation based on client journey, profiles, transaction patterns, and app activities that will lead to highly personalized client insights.
Design and monitor A/B testing and various engagement activities.
Perform deep-dive analysis to solve various business problems arising from marketing, dynamic incentive programs, and campaign management.
Build and automate intuitive dashboards that help visualize and answer complex business problems.
Managing risks and regulatory issues associated in data analytics solutions.

Qualifications and Skills:
University Degree or equivalent, preferably in computer science, engineering or analytical discipline, e.g. mathematics, statistics, IT, economics, finance, accounting.
Minimum 8 years working experience in data analytics or business intelligence units, preferably in consultancy (eg Mu Sigma, IBM, Accenture) or financial industry.
Relevant experience in using data is a pre-requisite.
Analytical mind with sound business insights. Ability to translate the business problems and requirements into analytics solutions.
Knowledge of a variety of predictive models, machine learning algorithms and statistical techniques, e.g. logistic regression, decision tree, clustering, neural networks, support vector machines, principal component analytics, natural language processing.
Proficiency across the core statistical toolsets (SQL, SAS, R, Python), data visualization tools (Tableau, Qlik, Power BI) and Hadoop ecosystem.
In-depth knowledge of digital banking, banking products and the overall industry a strong plus
Good verbal and written communication skills.
Excellent stakeholder management skills
Self-motivated. Can-do spirit


Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Senior Data Scientist,"Mumbai, Maharashtra",Morningstar,None,Organic,"As a Senior Data Scientist, you will be a leading expert and primary contributor in the implementation of Artificial Intelligence (AI) within Data Collections software applications, API’s and other data products. This role requires significant interaction with both upstream and downstream stakeholders across Technology, Data, Products, Sales/Service, and Research.
The Senior Data Scientist will transition approved Data Collections AI products from a prototype phase to a fully-fledged, scalable, and consumer service. Often, these services must be integrated into Morningstar’s platform of financial products, so that our clients can use these software tools in the investment decision-making process.
We are looking for an individual who possesses strong technical development skills, an ability to distill analyst requirements into the technical specifications for robust code, and a passion for investment research.
This position reports to the Senior Tech Manager of the Data Collection technology team.
Responsibilities:
Design & develop enterprise solutions to be flexible, scalable & extensible.
Improve complex data flow, data structures and db design to move to next platform.
Be a Role Model to the team to collaborate on good object-oriented designs & domain modeling. Enforce good agile practices like test driven development, Continuous Integration.
Build solutions that incorporate numerical techniques such as linear algebra, machine leaning, statistics, and optimization.
Hands-on development will be an integral part of the responsibilities.
Develop areas of continuous and automated deployment.
Introduce and follow good development practices, innovative frameworks and technology solutions that help business move faster.
Follow best practices like estimation, planning, reporting and improvement brought to processes in every day work.
Requirements:
Minimum of 5 years of experience in software engineering
An advanced degree in engineering, computer science, statistics or related field

Expertise with either Python or Java is essential, while experience with both is desirable; other programming language skills are highly desirable. Experience with Python packages like pandas, scikit-learn, TensorFlow, numpy, NLTK is a plus.
Basic knowledge of statistical/ML/AI algorithms
Experience with DevOps tools (e.g. Splunk, Git, uDeploy, Jenkins, Control-M) is desirable
Experience with Agile software engineering practices
Experience with back-end XML, relational, and file-based databases (e.g. SQL, Postgres, Redshift, Netezza, HDFS)
Experience developing and deploying solutions using services in the Amazon AWS ecosystem (Lambda, EC2, RDS, EMR)
Experience with the Hadoop stack (MapReduce, Pig, Hive, Nifi, Spark) is desirable
Experience with at least one statistical modeling language (e.g. R, MATLAB, Python)

Intermediate knowledge of statistical methods is desirable
Familiarity with common data cleaning and munging techniques
Familiarity with automation tools such as Puppet or Chef is a plus.
Familiarity with data visualization is a plus (e.g. Tableau, Shiny, d3)
Familiarity with statistical software, linear algebra, optimization, and information visualization is a plus.
Familiarity with mutual fund, fixed income, and equity data is a plus
Fluent in both oral and written English.
Morningstar is an equal opportunity employer.

I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity"
Data Scientist,"Bengaluru, Karnataka",Processware Systems,None,Organic,"Experience : NA
Qualification : Bachelors in Computer Science.
Functional Area : IT Software (Banking)
Employment Type : Full time
Location : Bangalore
Job Description


We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Applications include Fraud Analytics, Automated credit scoring using Machine Learning Techniques, Recommendation system for credit products.

Responsibilities


Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Designing algorithms to solve specific issues faced by the financial sector.
Skills and Qualifications


Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable.
Great communication skills.
Experience with data visualisation tools, such as Microsoft SSRS.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases, such as MongoDB, Cassandra.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills .
Data-oriented personality.
Bachelors in Computer Science with relevant experience is preferred.
Email : hr@processwaresystems.com
Phone No : 080-26572188, 26579635"
Python Data Engineer,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Engineering expert to come and work on our growing Data pipeline and AI applications. You will be working with a team of highly skilled and motivated engineers and professionals. If you are a polyglot programmer who likes to build AI and data applications, AppZen is the right place for you to apply and grow your skills.
Must Haves:
Solid understanding of data fundamentals and tools
Excellent knowledge of Python fundamentals and application
Built applications for containerized deployment
AI/ ML frameworks and toolkits viz. TensorFlow, Scikit learn, xgBoost is an advantage
Expertise in Elasticsearch setup, development and maintenance is a must
Expertise required in other database like Postgres, Redis
Familiar with AWS services, especially S3, big data services and DevOps tools
B.E. or B.Tech in Computer Science, Engineering, or other relevant technical field.
Must have 5-7 years of industry experience.
Must Have:
Able to work onsite in Pune, IN

Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
Senior Analyst - Data Science,"Gurgaon, Haryana",Cvent,None,Organic,"Cvent is a global meeting, event, travel, and hospitality technology leader, with more than 4,000+ employees worldwide. As a leading cloud-based technology company, we have over 28,000+ customers, including 80% of the Fortune 100 companies, in more than 100 countries.
Cvent’s software solutions optimize the entire event management value chain and have enabled clients around the world to manage hundreds of thousands of meetings and events. In addition to helping event planners navigate every aspect of the event process, we also provide an integrated platform to hoteliers to help create qualiﬁed demand for their hotels, manage that demand more eﬃciently, and measure their business performance in real-time.

About this role:
Cvent Analytics team is looking to hire Senior Analyst and is currently accepting applications. The selected incumbent will typically focus on data analysis and ML modeling. He/she would be involved in analysis for various areas across the organization i.e. in Sales, Marketing, Technology, & Client Services.
The person is expected to understand end-to-end business processes. Independently extract, prepare and analyze data to support business initiatives (e.g. revenue, profitability, performance, variance analysis etc.). Develop solutions with minimal support. Develop strategies using techniques and algorithms of data analysis & machine learning models for making meaningful and actionable recommendations.
Present and share data with other team members and to leadership.

Key Job Responsibilities:
§ Stakeholder & Project Management
o Strong collaboration skills to work with various stakeholders in the project team to ensure smooth flow and delivery of the project and its deliverables.
o Collaborate with stakeholders at different levels to understand current processes, data being generated and identify optimization or growth opportunities.
o Strong ability to augment data and insights to drive scale and efficiency for our stakeholders and partners.
o Person would be required to work individually or as part of a team on data science & analytical projects and work closely with business partners across the organization
o He/she would be developing statistical/machine learning models using various techniques (supervised, unsupervised, semi-supervised) and technologies including but not limited to R, Python etc.
o Work closely with data engineers, BI and UI specialists and deliver top notch analytical solution
o Define business problem and translate it into analytical problem.
What you’ll Need:
§ Relevant experience of 3-5 years in data modelling and analytics.
§ Bachelor’s Degree (in technology, statistics, sciences, or mathematics) and/or Engineering with good academic record (MBA Preferred)
§ Strong analytical and problem-solving skills with an ability to distill data into important, relevant insights for business leaders.
§ Good knowledge of concepts in Statistics and expertise in Machine Learning and Text analytics.
§ Good knowledge of regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining techniques.
§ Extensive hands-on knowledge and experience of Python/R, MS-Excel, MS-SQL and MS-PowerPoint
§ Excellent project and time management skills; consultative experience and exposure, proven competence for meeting deadlines, multi-tasking under pressure and managing work under ambiguity
§ Strong and articulate verbal and written communication skills with attention to precision of language and ability to organize information logically
§ Self-driven and can work with geographically spread teams"
QA Engineer API/Backend Systems (NOT a Permanent F/T positio...,"Bengaluru, Karnataka",Applause,"₹4,50,000 - ₹8,00,000 a year",Organic,"IMPORTANT: This is NOT a Permanent F/T position
Are you an experienced QA Tester interested in working with Applause as we engage a global client in the Banking & Financial Services sector for a multi-year project?
We’re looking for interested QA Engineers/Testers/Analysts who bring a solid depth of experience in software QA manual testing of midrange, backend systems, along with a technical background in testing of APIs and data validations/verifications. As this is a highly data-intensive role, strong attention to detail is a must!
If you’ve gotten this far and are still interested in this type of opportunity, review the terms, responsibilities and qualifications below to see if this a great fit, and then… Apply!
-------------------------------------------------------------------------------------------------------
*NOTE: This response survey must be filled out for consideration: https://bit.ly/3jhhWUC
**NOTE: If your rate requirement exceeds the indicated range below, do NOT apply
-------------------------------------------------------------------------------------------------------
Prerequisites (REQUIREMENTS to take part in the interview: selection process):
*Complete response survey noted above
Attend video conference screening and technical rounds
Consent to background checks and associated screens
Terms:
Duration - 12 months (open-ended with multi-year expectations)
Work type - Freelance (potentially contract)
Location - Remote but must be India-based
**Rate - 4 to 8 lakh rupees maximum annual depending on experience, skills
Work hours - 8:00 AM to 6:00 PM IST OR 3:00 PM to 12:00 AM IST shift
Capacity - Up to 40 hours per week
Day-to-day Responsibilities:
API testing using SoapUI, Postman, REST Assured
SQL queries against rDBMS for data validations/verifications
Perform manual functional test case driven and exploratory testing
Develop and revise test plan and test case documentation
Document, report and escalate priority defects; retest status for patched bugs
Attend related Scrum stand-ups and team meetings
Must-have Qualifications & Experience:
B.S. degree in Computer Science, Engineering or related field
2 to 5 years experience in a formal software role such as QA Engineer, Analyst, Tester
2+ years of API testing using SoapUI, Postman, REST Assured
1+ years SQL experience writing and running queries against relational databases
1+ years of UNIX/Linux experience
Software QA testing methodology knowledge
Experience with Waterfall / Agile development methodologies
Good English communication skills, both spoken and written
Self-starter who can take initiative, work with minimal supervision and begin projects independently
Attend related Scrum stand-ups and team meetings
Preferred:
Core Java, J2EE technology experience
Banking, Financial Services or Insurance domain experience
Job Types: Full-time, Contract
Pay: ₹450,000.00 - ₹800,000.00 per year
Experience:
API testing: 2 years (Required)
Software QA: 2 years (Required)
SQL query: 2 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Principal Machine Learning Engineer,"Bengaluru, Karnataka",CareerXperts,None,Organic,"Build a Product Information Marketplace with information about every product in the world!
You would provide technical thought leadership on hard, business impacting problems. Reporting directly into the VP of engineering, this role involves shaping the engineering/architecture vision the standpoint of delivering data science solutions. As a subject matter expert, the incumbent is also responsible for mentoring data scientists and Software Engineers in the team.
Experience
Startup / Product Development / Machine Learning with more than 7 years of experience.
Qualification
What We’re Looking For
Mathematical maturity to critically analyze academic literature from venues such as KDD, ICDM, SDM, ICML and NIP
Ability to propose hypothesis and design experiments in the context of specific problems.
Should come from a strong engineering background. You should be able to Code! Data tech stack such as Hadoop, MapReduce, HDFS, Spark, Scalding, Scala/Python/C++
A scientific temperament that seeks to rigorously validate hypothesis/ideas.
Ability and preference to work in a group rather than individually.
Good at explaining/communicating complex ideas/concepts both verbal and written.
Dedication and diligence in understanding the application domain, collecting/cleaning data and conducting experiments.
Creativity in model and algorithm development.
An obsession to develop algorithms/models that directly impact business.
Master’s/Phd. in Computer Science/Statistics is a plus.
Responsibilities
Job Expectations
Understand business needs and formulate formal problem definitions (with corresponding metrics).
Collect relevant data from production systems/Use crawling and parsing infrastructure to put together data sets.
Survey academic literature and identify potential approaches for exploration.
Craft, conduct and analyze experiments to evaluate models/algorithms.
Communicate findings and take algorithms/models to production.
This is a High Impact role and you will work with Awesome Folks! Write to deepa.m@careerxperts.com to get connected!
Job Location
Bengaluru"
Data Engineer,"Bengaluru, Karnataka",Huron Consulting Group Inc.,None,Organic,"Huron is redefining what a global consulting organization can be. Advancing new ideas every day to build even stronger clients, individuals and communities. We’re helping our clients find new ways to drive growth, enhance business performance and sustain leadership in the markets they serve. And, we’re developing strategies and implementing solutions that enable the transformative change they need to own their future.

As a member of the Huron corporate team, you’ll help to evolve our business model to stay ahead of market forces, industry trends and client needs. Our accounting, finance, human resources, IT, legal, marketing and facilities management professionals work collaboratively to support Huron’s collective strategies and enable real transformation to produce sustainable business results.

Join our team and create your future
Position Summary:
4 to 7 years of hands on experience as a data lake, data warehouse, /analytics developer
Experience with Data Modeling and data mapping methodologies
Good technical abilities in AWS (S3, lambda, kinesis), Python and SQL : problem solving, coding and debugging skills
Hands on experience with Database (such as Oracle, MS SQL Server, MySQL, PostgreSQL), NoSQL (such as HBase, MongoDB, Cassandra, Cosmos, Arango, Orient) and Data Warehousing (such as Microsoft Azure DW, Redshift, Teradata, Vertica) and data migration, ETL (AWS Glue, Azure Data Factory, Informatica, SSIS, etc.) and integration
Building highly scalable, robust & fault-tolerant systems and capabilities
Experienced in creating large data pipelines (via tools and code level- Python R | Spark)
Creating a complete solution by integrating a variety of programming languages & tools together.
Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external partners/virtual teams.
Qualifications:
Experience with Big Data, Basic Data Science, Statistics, Machine Learning & Modeling is a plus
Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps 3.
About Huron:
At Huron, we’re redefining what a consulting organization can be. We go beyond advice to deliver results that last. We inherit our client’s challenges as if they were our own. We help them transform for the future. We advocate. We make a difference. And we intelligently, passionately, relentlessly do great work…together.
Are you the kind of person who stands ready to jump in, roll up your sleeves and transform ideas into action? Then come discover Huron.
Whether you have years of experience or come right out of college, we invite you to explore our many opportunities. Find out how you can use your talents and develop your skills to make an impact immediately. Learn about how our culture and values provide you with the kind of environment that invites new ideas and innovation. Come see how we collaborate with each other in a culture of learning, coaching, diversity and inclusion. And hear about our unwavering commitment to make a difference in partnership with our clients, shareholders, communities and colleagues.
We offer a competitive compensation/benefits package. Huron is an equal opportunity employer. We recruit, employ, compensate, transfer, promote and train without regard to race, color, creed, religion, national origin, sex, marital status, pregnancy, disability, sexual orientation, veteran status, age, FMLA status or any other basis protected by law.
LI:"
Machine Learning Intern,"Hyderabad, Telangana",Leben Care Technologies,None,Organic,"Leben Care is offering 3/ 6/ 9 month internships in the areas of deep machine learning and computer vision . The internships will require novel research as well as development for solving challenging problems . We are seeking qualified and highly motivated graduate students (Masters, PhD) interested in working on these problems.
The interns will have an opportunity to work on large public domain datasets; publish in top-tier conferences such as CVPR, ICCV, ECCV, NIPS, ICML and SIGGRAPH; work with business-proprietary use cases and datasets leading to inventions and patents.
Qualifications/ Experience
A BS/ MS degree in Computer Science, Electrical Engineering or related field.
Hands-on experience in machine learning / computer vision . Prior publication record in relevant top-tier conferences/ journals highly desirable.
Technical Skills
Proficiency in C, C++, Python. Experience using OpenCV, Caffe, Theano / Torch.
Experience on application development in Linux/ Windows desirable.
General Skills
Excellent communication, problem-solving and analytical skills, ability to learn quickly.
A strong passion for empirical research and for answering hard questions with data.
Ability to work both autonomously and in a team.
Number of Positions
2
Location
Hyderabad, India
How to Apply
Please send a cover letter and resume to hr@leben.ai. Please put “Machine Learning Intern” in the subject line."
Data Transformation Analyst I,"Bengaluru, Karnataka",IHS Markit,None,Organic,"Should have Geology/Earth Science/Petroleum Engineering background with B.Sc or M.Sc degree with 2+ Years of Experience
Good computer skills and basic knowledge on MS-Office suite
Good understanding of petroleum geology and main drilling procedures.
Experience in the oil and gas industry is preferred.
Interest in managing and handling geo-technical information.
Ability to convert technical information into a usable format for entry into databases.
Confident user of MS Excel main functions.
Good written and oral communication skills in English.
Good team player with proactive behavior
The Well Analyst will be responsible for sourcing, analysis, research, data entry, maintenance and quality control of the exploration and production wells data within the IHS Markit US /Intl Energy database
Well information processing, entry and validation in the Oracle database
Support data sourcing process related to the exploration and production activity in the region of responsibility
Manage historical entries in the database. Participate in data improvement projects through global, country, basin or area reviews conducted by the team
Ensure consistency and alignment between the well database and IHS Markit upstream reports
Support Regional Directors and SMEs in resolving client queries/requests relating to well data
-
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.
We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.
IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.
For information please click on the following links:
IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement
-
Current Colleagues
If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site."
Machine Learning Lead Engineer – Billion Dollar Startup,"Chennai, Tamil Nadu",CareerXperts,None,Organic,"You will join a Billion Dollar Pre IPO Startup!
Experience
4-12 Years of Experience
Qualification
Bachelors or Master’s degree in Computer science or related field
A strong grounding in Data structures and algorithms, Database concepts
Good oral and written communication skills, analytical and problem-solving skills
Hands-on programming experience in JVM languages and Python
Experience in building scalable, high-performance, low latency systems
Foundation in basic math concepts
Background in big data tech, streaming applications
Prior experience in building and deploying ML systems
Familiarity with Machine learning algorithms
Ability to design ML systems end-to-end; this includes big-data handling, pre-processing, model generation logic, model persistence including choice of online data stores, etc., systems for consuming active feedback (online learning), web services to publish model predictions to consumers.
Responsibilities
Deliver scalable, low latency, and high-performance ML solutions for different products
Build ML pipelines end-to-end, including stages such as data pre-processing, model generation, cross-validation, and active feedback
Build efficient systems for processing large amounts of data; be proficient with distributed programming frameworks such as Hadoop/Spark
Drive solutions and implementation leveraging different open source libraries and distributed systems
Work closely with Data Scientists and come up with scalable system and model architectures for enabling real-time ML/AI services
Liaise with architects and engineers from other product teams to build solutions and drive adoption
Elicit quality attributes of the system and define metrics to establish its success.
Write to deepa.m@careerxperts.com to get connected! #HighBarOfEntry
Job Location
Chennai"
Data Engineer (Talend/Bigdata),"Bengaluru, Karnataka",Palnar Transmedia,None,Organic,"Primary Responsibilities:
Lead and deliver complete application lifecycle design, development, deployment, and support for actionable BI and Advanced Analytics solutions
Design and develop data models and ETL process for structured and unstructured data that is distributed across the globe between Cloud and On-Premises
Develop and deliver solutions with data streaming capabilities for large volume of factory data
Demonstrate and document the development methodology, results and insights to the business partners and senior leadership.
Work directly with management and Business units to design, configure, support cloud deployment, and performance tuning/optimization.
Develop design documents and translates into component-level designs to accelerate development.
Competencies & Experience Required/Desired
8+ years of experience in data modeling and ETL using industrial leading tools to process the data using RDBMS, In-Memory and Bigdata data stores
5+ years of experience in deploying custom data solution using Talend
4+ years of experience in Big Data development using Cloudera Hadoop (Hive, Impala & Talend)
3+ years of experience in developing flows using data streaming, batch processing, and Microservices
2+ years of experience with AWS tools such as S3, EC2, ECS, EKS, SageMaker, Aurora, Redshift, RDS, Lambda Functions AMI, ELB, ALB, NLB, VPC, Auto Scaling configurations, DMS, Amazon FW, API Gateway, IAM, CloudTrail, and CloudFront.
Multiple experiences in implementing solutions involving unstructured data using Talend
Strong problem-solving capabilities. Results oriented. Relies on fact-based logic for decision-making.
Ability to work with multiple projects and work streams at one time. Must be able to deliver results based upon project deadlines.
Willing to flex daily work schedule to allow for time-zone differences for global team communications
Strong interpersonal and communication skills
Degree in Management Information Systems, Computer Science OR equivalent work experience in an IT organization
Additional Skills:
Having subject matter expertise in one or more of the functional areas such as Sales, Finance,
Manufacturing, production planning, purchasing, marketing, engineering
Experience in demonstrating the challenges and recommendation to leadership team in a precise manner
Prior working experience with SAP HANA, SAP ERP, SAP BW environments
Experience in visualization tools
Experience in developing basic data science models using Python or a similar language
Java development and API management experience is a great plus"
Google Certified Professional Data Engineer (BigQuery),"Bengaluru, Karnataka",SPX FLOW,None,Organic,"This position will be part of Celeros Flow Technology. Celeros Flow Technology is a divestiture company of SPX Flow and this role will be based at Bangalore location. The India registered company for Celeros is Flow P&E India Private Limited. Spun out of the SPX Flow, the company fully concentrates on serving key market sectors where its solutions will have maximum traction. These are - Oil & Gas, Power, Chemical Processing, Water Treatment and Marine. Our product line consists of Pumps, Valves, Filters, Closures etc. To know more about our company please visit https://www.celerosft.com/en-us
Google Certified Professional Data Engineer
Google Certified Professional Data Engineer will work as a part of Celeros BI & Analytics team and will be responsible for designing, developing, and deploying modern data warehouse solutions in Google BigQuery platform. This person should have prior experience of extracting data from multiple source systems including SAP, AS/400 and other legacy ERP systems including flat files. Experience and knowledge of SAP systems and data sources is critical for this role. This person will support data feeds to Power BI and Looker reporting platforms. This position will be based at our Bangalore office and will be part of our global IT team.
Key Responsibilities
Design, develop and deploy modern data warehouse solutions in Google BigQuery platform.
Gather and document business requirements and translate it into technical design documents .
Map and extract data from SAP and other legacy ERP as source systems.
Create technical documentation, e.g. data flow diagrams, end user guide and technical operations guides.
Monitor data load jobs and perform root cause analysis of production issues.
Lead the efforts in building end to end streaming and batch data analytics pipelines. From data ingestion, processing, storage, analysis, machine-learning to visualization. Understand big-data principles and best practices. Deliver projects in data analytics, machine learning and AI.
Design architectures, publish reference code and establish data structure design based on business requirements. Should be pretty hands on.
Perform code reviews, ensure code quality and encourage a culture of excellence.
Required Skills:
Mandatory Certification: Google Certified Professional Data Engineer
5+ years of strong technology experience in the field of Big Data, Data Analytics, Data Science or Machine Learning.
Strong analytical skills.
At least one full implementation project experience with SAP as the source system and BigQuery as the target data warehouse.
Ability to support integration between Power BI & Looker with BigQuery data warehouse.
Experience with building modern data warehouse solutions in Big Query.
Experience with SAP and other legacy ERP as source systems would be an additional advantage.
Experience of working with Power BI , Looker, Data Studio or similar reporting platform.
Familiarity with standard source repositories (GIT, BitBucket)
Experience and solid knowledge in Agile (Scrum) Methodologies
Experience with managing a customer relationship with a US/UK based customer.
Desired Skills:
Working Knowledge of BI & visualization tools like Google Data Studio, Qlik Sense, Micro-strategy etc
Knowledge of cloud platforms like Google Cloud Platform, AWS, Azure
Familiarity with standard source repositories (GIT, BitBucket)
Hands-on experience in building Machine Learning and Deep Learning Models with Python, numpy, scipy, scikit-learn, pandas, Tensorflow, Keras, PyTorch etc.
Big Data experience - should have experience in building end to end data analytics pipelines with products like Apache Beam, Kafka, Spark etc.
Should understand and be able to command architecture design for Machine Learning systems.
Knowledge of implementing IoT and predictive analytics.
Membership of recognized professional accounting body
Required Education
B.E/ B.Tech in CS or MCA / Masters in Business Systems Analysis from recognized universities and institutes in India .
Excellent Communication skills in English Language."
"Senior Big Data Engineer, ED&A - ICC, India Capability Cente...","Bengaluru, Karnataka",Nike,None,Organic,"Become a Part of the NIKE, Inc. Team
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.
Nike is embracing Big Data technologies to enable data-driven decisions. We’re looking to expand our Big Data Engineering team to keep pace. As a Sr. Big Data Engineer, you will work with a variety of talented Nike teammates and be a driving force in technical initiatives that will accelerate analytics at Nike. You will be working on projects that build data artifacts to answer questions about consumer behavior, commerce trends, consumer touchpoint preferences and more!

Here are some tasks that you could do day to day:


Design and implement distributed data processing pipelines using Spark, Hive, Python, and other tools and languages prevalent in the Hadoop ecosystem. You will be given the opportunity to own the design and implementation. You will collaborate with Product managers, Data Scientists, Engineering folks to accomplish your tasks.

Publish RESTful API’s to enable real-time data consumption using OpenAPI specifications. This will enable many teams to consume the data that is being produced.

Explore and build proof of concepts using open source NOSQL technologies such as HBase, DynamoDB, Cassandra and Distributed Stream Processing frameworks like ApacheSpark, Flink, Kafka stream.

Take part in DevOps by building utilities, user defined functions and frameworks to better enable data flow patterns.

Work with architecture/engineering leads and other teammates to ensure high quality solutions through code reviews, engineering best practices documentation.

Experience in Business Rule management systems like Drools will also come in handy.
Some combination of these qualifications and technical skills will position you well for this role:


MS/BS degree in a computer science or related discipline

3+ years’ experience in large-scale software development/Big Data technologies

Programming skills in Java/Scala, Python, Shell scripting, and SQL

Development skills around Spark, MapReduce, and Hive

Strong skills around developing RESTful API’s
NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.
NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
"Lead Software Engineer (Scala/Python/ML) - Bengaluru, India","Bengaluru, Karnataka",Teikametrics,None,Organic,"About Us

Teikametrics is a leading maker of e-commerce AI. We’re a diverse group of individuals who champion passion, character, and talent as the core tenets to creating profitable and long-lasting businesses.

Our AI helps the sellers (both large and small) on e-commerce platforms by providing deep performance analytics at a product level, as well as support for complex decision-making through a combination of econometrics and machine-learning, in a simple SaaS interface. Our software enables these independent brands to optimize their advertising, forecast demand, detect product issues and maximize overall profitability. While still at start-up size (<150 employees), the company has significant annual-recurring-revenues, and has recently raised two rounds of investment to fuel growth.

Leading sellers and brands such as Lego, Power Practical, Zipline Ski, and Mark Cuban’s Brands, gain a competitive advantage and view of trends and optimization strategies to tackle the dynamic nature of today’s e-commerce markets. For more information, please do visit our website https://www.teikametrics.com/ <!-block->As part of our global expansion plans, we are hiring in our fast-growing Bengaluru office.

Lead Software Engineer (ML Platform)

We are looking for a Technical Lead to build a team under the Data Science directorate tasked with expanding our prediction and control services to new retail channels and ad types. Candidates should have an understanding of machine-learning and statistical modeling concepts, strong software engineering fundamentals, and management skills for operating a small team.

The Data Science team's predictive services are developed in Python on top of AWS Sagemaker, orchestrated by Airflow and backed by a data warehouse in Snowflake. Our back-end code emphasizes a ‘functional-first’ Scala stack with cats and fs2.

The team's mandate is to maintain feature parity for all retail channels and advertising types in both Scala and Python codebases. This entails updating statistical predictive services, the data flows that back them, and the invoking code that knits those services together to produce automated actions or recommendations for human review.

Qualified candidates should have:
8+ years of experience working as a professional software developer.
Strong Scala, ideally with cats/fs2 OR Strong Python with experience using some subset of the Python ML ecosystem (numpy/scipy/pandas, Tensorflow, etc.).
Strong SQL/RDBMS skills and experience writing code that interfaces with the database layer.
Proficiency with a statically typed language and generics.
Interest in learning functional programming.
Understanding of machine-learning model lifecycle; training, evaluation, serving.
Desire to manage a team and experience mentoring developers.
Desire to work in a collaborative environment focusing on continuous learning; participating in tech talks, code review, and pair programming.
It's a bonus to have
Experience with Airflow
Experience with functional programming.
Understanding of machine-learning model lifecycle; training, evaluation, serving.


Benefits

You will be joining us at the perfect stage in our company as we are neither a struggling startup, nor a slow moving established company. You not only get to see all aspects of the product but also learn how a company is built and scaled from ground up.
You will also have a great pay, respectable work-life balance, flexible office hours and vacation time."
Data Scientist,"Pune, Maharashtra",GridEdge Technologies,None,Organic,"Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com"
Software Engineer- Data Engineer,"Chandigarh, Chandigarh",XenonStack,None,Organic,"Job Summary
We are looking for a passionate Software Engineer to design, develop and implement Solution for Data Engineering and Product Development for DevOps, Big Data and Data Science. The successful candidate will be able to build high-quality, innovative and fully performing software in compliance with coding standards and technical design.
Key Requirements
Design, develop, test, deploy, maintain and improve the software.
Efficient Code and Documentation of the Project.
Proper Github Process Flow Implementation and Coding Best Practices.
Review and influence ongoing design, architecture, standards and methods for operating services and systems.


Technical Requirements
Software development knowledge in one or more general purpose programming languages.
Strong Knowledge of Algorithms and Data structures.
Knowledge about test-driven development.
Strong knowledge of Databases - SQL/NoSQL Databases and Graph Databases.
Working proficiency and communication skills in verbal and written English.


Preferred qualifications:
Interest and ability to learn other coding languages as needed.
Working proficiency and communication skills in verbal and written English.
Keywords
Data Structures
Data Bases
Data Analysis
Algorithms
Software Development"
Senior Java Full Stack Developer,Remote,LovCash India Pvt Ltd,"₹75,000 - ₹92,000 a month",Organic,"About Lov.Cash
Lov.Cash is a mobile financial services platform aimed at consumers and businesses in emerging markets. We are developing innovative, accessible & affordable financial services solutions such as mobile wallets & payment terminals (POS) for sending and receiving digital currency. Lov.Cash provides an alternative to cash and improves the security and safety for traders and their shoppers.
Senior Java Full Stack Developer - 100% Remote
Lov.Cash is looking for a Java/J2EE and Full Stack Developer expert to help us design and develop core modules in Spring Boot and Microservices.
The ideal candidate will be technical expert in::
Reviewing architecture and design documents
Providing feedback on approach and estimates
Recommend development options
Creating tech designs and specifications
Doing coding development, testing, and debugging of software.
Security best practices for micro services
Conducting code reviews.
Must Have Technical Skill
*
Angular Experience
Front-End scripting with JavaScript or Typescript, HTML5
Minimum 5+ years of overall experience with Java/J2EE (Java 8)
Development with Spring Boot and Microservices
Hands-on experience on business process development and/or Integration with system tools
MAVEN / GIT
Spring framework, REST Services, Spring Data (ORM), JPA, Postman, SOAP,
Advanced knowledge and experience with Unit Testing -- Junit & Mock Frameworks
Knowledge of AWS services
Experience in API modeling and design process
Education:
Bachelor in Computer Science / Software Engineering r related IT field or equivalent combination of experience and education
Job Types: Full-time, Contract
Salary: ₹75,000.00 - ₹92,000.00 per month
Experience:
Java / J2EE: 5 years (Required)
Freelance / contract: 2 years (Preferred)
Industry:
Software Development
Work Remotely:
Yes"
Software Engineer C/C++/Python/Perl,"Chennai, Tamil Nadu",Checktronix India,None,Organic,"Job Location – Chennai / Dharmapuri
Experience – 1 to 2 years
Qualifications – At least a bachelor's degree in IT related disciplines such Information Technology, Computer Science, Electronics and Communication.
We are looking for a software engineer to work in a global company with products and teams across the globe.
Responsibilities
Work with C/C++/Python/Perl/Continuous Integration/Continuous Deployment.
Design and implement services and components meeting functional and non-functional requirements.
Unit test cases preparation and code review.
Cross-functional team coordination across the globe (analytics team, data feed team, data base team and web development team etc.)
Product delivery, test report submission and documentation.
Product version control (data and source).
Participate in agile development process.
Requirements
Minimum 1 years of experience in C/C++/Python/Perl and build automation.
Knowledge with Modern C++ (C++11/ C++14/C++17) preferred.
Must have experience in continuous integration & continuous deployment.
Good knowledge in tools such as Git, TeamCity, GoCD etc.,
Familiarity with Data Structures and Algorithms.
Knowledge of Text Mining, NLP and Machine learning frameworks like Tensorflow preferred.
Distributed computing background.
Development and debugging in Visual Studio and KDevelop.
Knowledge with Visual Studio 2015/2017 preferred.
Hands on experience in XML, XSD, JSON, MSSQL, PostgreSQL, GDB, RabbitMQ, Elastic Search, Docker, SQL.
Strong knowledge of software implementation best practices.
Understanding of Agile methodologies.
Ability to adapt quickly to an existing, complex environment.
Excellent debugging and troubleshooting skills while solving a problem and optimizing the overall application.
Excellent problem solving and analytical skills while dealing with tough scenarios during coding, development and testing phases.
Development in Windows and Linux.
Experience developing service oriented architectures and an understanding of design for scalability, performance and reliability.
Experience in memory leak analysis tools (VLD/MemLeak/Valgrind) and static code analysis/profiling tools (Very Sleepy, Callgrind) etc.
Knowledge in JIRA, Confluence, Aha!.
Strong Communication Skills (Verbal and Written)."
Innovation Research Analyst (Remote Position),"Bengaluru, Karnataka",StartUs Insights,"₹45,000 - ₹90,000 a month",Organic,"Are you fascinated by the world of startups and disruptive innovation?
Great — join StartUs Insights, an international data science company (with teams in Austria, Ukraine and India) analyzing startups and emerging technologies to anticipate trends, new business models and innovation areas.
WHY THIS POSITION IS RIGHT FOR YOUR CAREER:
We provide clients from various industries (automotive, health, energy, industry 4.0 etc.) with actionable insights into what impacts their future business. Diversity is in our DNA. We welcome applicants from different backgrounds: science, technology, engineering, mathematics, analytics, economics. Experience or educational background in the following industries will also be accepted: logistics, machinery, engineering (civil, construction, mechanical, electronics), energy or other industries of our focus (read more here). Apply now!
Requirements
Work experience: You have at least 2 years of relevant work experience and strong educational background in: science, technology, engineering, mathematics, analytics or economics OR You have at least 2 years of relevant work experience industries such as: logistics, machinery, engineering (civil, construction, mechanical, electronics) or energy
You are curious about emerging technologies, startups and the digitalization of our society
You are advanced in English
You have strong project management and problem-solving skills
You are at least upper-intermediate in Excel. Experience with other data analytics tools is beneficial
We offer
Work in a company where your input influences further product development
Have constant communication and mentorship from senior analysts from our Vienna Headquarters as well as Ukraine and India
Take part in our personal development programs
Get a clear view of your KPIs and progression possibilities from day one
Enjoy remote work and don’t waste your valuable time commuting
Package includes 25 paid work-free days per year, public holidays and trips to headquarters in Vienna
Responsibilities
Manage analytics and research projects that identify emerging technologies, startups and trends
Work with our AI-driven tool to recognize innovative solutions and technology trends
Execute quality control and timeline management for client reports and internal analytics
Manage content strategies and analysts researching for our Research Blog: www.startusinsights.com/innovators-guide/
Preferrable Start Date: 1st of September 2020
Working hours: 40 hours per week with a fixed schedule
Job Type: Full-time
Salary: ₹45,000.00 - ₹90,000.00 per month
Experience:
work: 2 years (Required)
total work: 2 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
Data Analyst,"Mumbai, Maharashtra",Course5,None,Organic,"If you meet our position requirements and can see yourself at Course5, we invite you to apply by e-mailing your resume and cover letter to careers@course5i.com. Please include the job title in your subject line. Sorry, no telephone calls please.
1
Company Course5 Intelligence Pvt. Ltd.
Position Title Sr. Data Scientist
Location Mumbai

OVERVIEW

COURSE5 INTELLIGENCE

We enable organizations to make the most effective strategic and tactical moves relating to their customers,
markets, and competition at the rapid pace that the digital business world demands. Founded in 2000, our business
areas include Market Intelligence, Big Data Analytics, Digital Transformation, Artificial Intelligence, and Analytics.
Rapid advances in Artificial Intelligence and Machine Learning technology have enabled us to create disruptive
technologies and accelerators under our Course5 Intelligence suites that combine analytics, digital, and research
solutions to provide significant and long-term value to our clients.
More information is available at www.course5i.com

GLOBAL OFFICES

United States | India | United Kingdom | Singapore | United Arab of Emirates

SPECIFIC RESPONSIBILITIES

At Course5, we drive Digital Transformation for businesses through Analytics, Insights, and Artificial Intelligence.
We build for organizations the capabilities and intelligence to make the most effective strategic and tactical
moves related to customers, markets, and competition. Over these years, we have built various solutions and
products catering to the Marketing, Merchandising, CX, Sales, Supply Chain, Research and Operations teams of
the fortune 500 enterprises, and we are proud to serve the top 4 companies in the world in-terms of their
market cap.
We are using best of breed technologies in all our solutions and products, such as Hadoop, Spark, Cassandra,
MongoDB, Kafka, Storm, AWS S3, AWS EMR, Redshift, Azure DW, Azure Data Factory and Azure Data Bricks. The
successful candidate will be working in a fast paced, dynamic team environment, building brand new commercial
products which are at the heart of our business.
The candidate will work along with other data scientists, developers, architects and analysts to develop products
that generate key actionable insights for our clients using different mediums such as Chatbot, Voicebot,
Collaboration Portal, Visualization platforms like PowerBI and Tableau by applying various machine learning and
data science techniques on proprietary as well as open data sources. The person will need to coordinate with
Product Managers, Industry Analysts and Technology experts to develop and deliver the product in accordance
with customer requirements and agreed timeline.

Drive complex analytical projects by leading and participating in tasks that use advanced statistical
modeling and machine learning techniques 
Apply knowledge of various machine learning techniques and best practices in data science to improve
existing analytics products or develop new products 
Research new or adapt existing machine learning approaches to novel practical problems 
Employ efficient algorithms for data mining and visualization 
Work with business stakeholders and product managers to deliver outstanding products that exceed
customer expectations

2 
Handle project management and stakeholder management activities and take full ownership of quality
and timeliness of product deliverables. 
Train and mentor junior team members on use of correct statistical techniques and logical frameworks
for problem solving

REQUIRED KNOWLEDGE, SKILLS AND ABILITIES 
4-5 years of progressive experience in Advanced Analytics / Data Science 
Good understanding of fundamental concepts in statistics, predictive modeling and forecasting,
statistical learning, machine learning and experience applying them in real world projects 
Ability to perform complex data analysis and statistical modelling in one or more: Python, R, Java, Scala 
Knowledge of RDBMS concepts and experience working with SQL 
Understanding of data visualization principles and experience with data visualization tools 
Master’s degree in a quantitative discipline (Computer Science, Data Science, Mathematics, Statistics) or
data science certification from premier institute. 
Experience in leading complex analytical projects, leading data scientists and managing stakeholders 
Experience working with unstructured/semi-structured data 
Experience using big data tools for data manipulation and modeling (Spark, BigQuery, Hive, MongoDB,
Cassandra etc.)"
Machine Learning Engineer,"Hyderabad, Telangana",Phenom People,None,Organic,"Job Requirements
Design and implement machine learning, information extraction, probabilistic matching algorithms and models
Research and develop innovative, scalable and dynamic solutions to hard problems
Work closely with Machine Learning Scientists (PhDs), ML engineers, data scientists and data engineers to address challenges head on
Use the latest advances in NLP, data science and machine leaning to enhance our products and create new experiences
Scale machine learning algorithm that powers our platform to support our growing customer base and increasing data volume
Be a valued contributor in shaping the future of our products and services
You will be part of our Data Science & Algorithms team and collaborate product management and other team members
Be part of a fast pace, fun focused, agile team

Work Experience
3+ years of industry experience
PhD/MS/BTech in computer science, information systems, or similar technical field
Strong mathematics, statistics, and data analytics
Solid coding and engineering skills preferably in Machine Learning (not mandatory)
Proficient in Java, Python, and Scala
Industry experience building and productionizing end-to-end systems
Knowledge of Information Extraction, NLP algorithms coupled with Deep Learning
Experience with data processing and storage frameworks like Hadoop, Spark, Kafka etc."
Machine Learning Engineers,"Pune, Maharashtra",Hyper-dimension R&D Pvt. Ltd.,"₹6,00,000 - ₹8,00,000 a year",Organic,"Hyperdimensions is Transdisciplinary innovative ‘AI/ML and Data Driven’ firm providing a wide range of IT Services & Solutions, products & platforms that help Process data, automate business process & discover knowledge and insights from digital data using advanced algorithms. we are looking forward to hire Machine Learning Engineer for our firm.
Job Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Skill Set:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras, Tensorflow or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
Job Location: Pune(for now work from home)
Company : Hyper-dimension R&D Pvt. Ltd. (www.hyper-dimensions.com)
Job Types: Part-time, Contract
Salary: ₹600,000.00 - ₹800,000.00 per year
Experience:
Machine Learning: 2 years (Preferred)
total work: 3 years (Preferred)
Work Remotely:
Yes"
Principal Machine Learning Engineer,"Bengaluru, Karnataka",CareerXperts,None,Organic,"Build a Product Information Marketplace with information about every product in the world!
You would provide technical thought leadership on hard, business impacting problems. Reporting directly into the VP of engineering, this role involves shaping the engineering/architecture vision the standpoint of delivering data science solutions. As a subject matter expert, the incumbent is also responsible for mentoring data scientists and Software Engineers in the team.
Experience
Startup / Product Development / Machine Learning with more than 7 years of experience.
Qualification
What We’re Looking For
Mathematical maturity to critically analyze academic literature from venues such as KDD, ICDM, SDM, ICML and NIP
Ability to propose hypothesis and design experiments in the context of specific problems.
Should come from a strong engineering background. You should be able to Code! Data tech stack such as Hadoop, MapReduce, HDFS, Spark, Scalding, Scala/Python/C++
A scientific temperament that seeks to rigorously validate hypothesis/ideas.
Ability and preference to work in a group rather than individually.
Good at explaining/communicating complex ideas/concepts both verbal and written.
Dedication and diligence in understanding the application domain, collecting/cleaning data and conducting experiments.
Creativity in model and algorithm development.
An obsession to develop algorithms/models that directly impact business.
Master’s/Phd. in Computer Science/Statistics is a plus.
Responsibilities
Job Expectations
Understand business needs and formulate formal problem definitions (with corresponding metrics).
Collect relevant data from production systems/Use crawling and parsing infrastructure to put together data sets.
Survey academic literature and identify potential approaches for exploration.
Craft, conduct and analyze experiments to evaluate models/algorithms.
Communicate findings and take algorithms/models to production.
This is a High Impact role and you will work with Awesome Folks! Write to deepa.m@careerxperts.com to get connected!
Job Location
Bengaluru"
"Lead Big Data Engineer, ED&A - ICC, India Capability Center...","Bengaluru, Karnataka",Nike,None,Organic,"Become a Part of the NIKE, Inc. Team
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At Nike, it’s about each person bringing skills and passion to a challenging and constantly evolving game.

Do you have a passion for digital technology, innovation and problem solving? Are you curious about how to turn billions of events and signals into meaningful information that not only provides insights into the present but also help predict the future? Are you interested in applying Data Streaming and Big Data Technology along with Machine Learning to help deliver personalized experiences? If so, come join the talented team of engineers that are a driving force behind data engineering solutions at Nike.

The following qualifications and technical skills will position you well for this role:


MS/BS in Computer Science, or related technical discipline

7+ years of industry experience, 3+ years of relevant big data experience

Strong programming experience, Scala preferred

Experience working with Big Data streaming services such as Kinesis, Kafka, etc.

Experience working with NoSQL data stores such as HBase, DynamoDB, etc.

Experience building domain-driven Microservices

Experience provisioning RESTful API’s to enable real-time data consumption

Experience in Python or Java

Experience working with Hadoop and Big Data processing frameworks (Spark, Hive, Nifi, Spark-Streaming, Flink, etc.)

Experience with SQL and SQL Analytical functions

Experience participating in key business, architectural and technical decisions

Experience designing, estimating and executing for complex software projects

Experience providing guidance and mentoring junior engineers
These are the characteristics that we strive for in our own work. We would love to hear from candidates who embody the same:


Desire to work collaboratively with your teammates to come up with the best solution to a problem

Demonstrated experience and ability to deliver results on multiple projects in a fast-paced, agile environment

Excellent problem-solving and interpersonal communication skills

Strong desire to learn and share knowledge with others
NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.
NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Software Engineer 1,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
RESPONSIBILITIES:
Accountable to perform data & application management with an ability to work in fast paced environment.
Good understanding RDBMS concepts, with knowledge of writing SQL queries
Should be proficient in any one programming languages like java/.net
Ability to come up quickly with programming logic for a given requirement is mandatory
Should have strong analytical and problem solving ability
Should be proactive with a zeal to learn and have an inquisitive attitude
Understanding the importance of adherence to processes and defined service levels would be important
Should be flexible to learn and move around technologies
Should be good team player and pitch in to support off hours/weekends/holidays when required
Should be willing to work in any shift or 24/7 model as required by the project
Good verbal/written communication skills is mandatory
Flexible enough to adjust to changes in work, technology, team, etc.

Soft Skills
Very good communication skills - English Written / Spoken
Fast Learner
Good Analytical and problem solving skills
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Senior Research Engineer,"Bengaluru, Karnataka",Nuance,None,Organic,"Company Overview / PrÃ©sentation de lâentreprise::
Nuance is the pioneer and leader in conversational artificial intelligence (AI) innovations that bring intelligence to everyday work and life. We deliver solutions that understand, analyze, and respond to people, amplifying human intelligence to increase productivity and improve security. With decades of both domain and AI expertise, we work with thousands of organizations across a wide range of industries.

Join our team! At Nuance, we are constantly reinventing how people connect with technology and with each other. Our AI-powered solutions empower organizations to transform “business as usual.” For decades, the world’s leading financial, healthcare, telecommunications, retailers, and government organizations have trusted Nuance to bring them award-winning solutions that deliver more meaningful outcomes and empower a smarter, more connected world. From clinical speech recognition technologies that free physicians to spend more time caring for patients to real-time intelligence that powers billions of customer interactions, we’re deeply committed to helping organizations push the boundaries of what’s possible.
Job Summary / Sommaire du poste: :
Position summary:
Nuance communications Inc. Bangalore India data engineering team is seeking a skilled and motivated senior research data engineer with data engineering and machine learning experience. The successful candidate will have experience with big data processing and some hands-on experience building ML models. The candidate will have experience collaborating with remote colleagues and stakeholders.

Principal dutues and responsibilities:
Develop training and testing data sets used to train text data de-identification ML models.
Implement and manage annotation workflows with job control reporting and QA.
Maintain and update annotator tagging guidelines and training materials. Ensure that the guidelines properly support the tag sets and can be clearly understood by the annotators.
Build and test ML models, model evaluation including creating results dashboard, improving model performance.
Implement QA automation to detect quality problems in text data.
Document all code and processes.

Required skills:
Minimum years of work experience: 5+ years in technical industry
Python scripting and Linux tools, process automation tools commonly used for text data engineering.
Text parsing and cleaning, transforming regex, xml schema handling, json, pandas.
Modern code repository usage.
Data mining, big data processing tools and methods.
Experience using modern machine learning toolkits such as Tensorflow, pytorch or similar.
Ability to translate requirements into specific short term actions with accurate ETAs; regular tracking and reporting on status of activities, and deliverables.
Ability to work proactively, collaboratively, and independently and with other team members including with remote international staff.
Clear concise verbal and written communication, effectively use remote communication and collaboration tools.

Preferred skills:
Experience developing automated text data de-identification pipelines.
Cloud computing, containers, object storage.
Continuous integration of repositories (git).
Familiarity with process monitoring and reporting via dashboards.
Experience in Natural Language Processing, text data parsing and encoding, or data mining .
Experience working with multi language data.
Education: Minimum of BS in Computer Science, Engineering, or equivalent

Additional Information / Informations additionnelles::
Nuance offers a compelling and rewarding work environment. We offer market competitive salaries, bonus, equity, benefits, meaningful growth and development opportunities and a casual yet technically challenging work environment. Join our dynamic, entrepreneurial team and become part of our continuing success.
LI Code:
#LI-MB1"
Data Scientist,"Pune, Maharashtra",Talentica Software India,None,Organic,"The Company
Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay). We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology. The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.
We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.
Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras
Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval
Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms."
Data Engineer,"Bengaluru, Karnataka",PayU,None,Organic,"Role: Data Engineer
Company: PayU
Location: Bangalore/ Mumbai

About Company:

PayU is the payments and fintech business of Prosus, a global consumer internet group and one of the largest technology investors in the world. Operating and investing globally in markets with long-term growth potential, Prosus builds leading consumer internet companies that empower people and enrich communities.
The leading online payment service provider in 36 countries, PayU is dedicated to creating a fast, simple and efficient payment process for merchants and buyers. Focused on empowering people through financial services and creating a world without financial borders where everyone can prosper, PayU is one of the biggest investors in the fintech space globally, with investments totalling $700 million- to date. PayU also specializes in credit products and services for emerging markets across the globe. We are dedicated to removing risks to merchants, allowing consumers to use credit in ways that suit them and enabling a greater number of global citizens to access credit services.
Our local operations in Asia, Central and Eastern Europe, Latin America, the Middle East, Africa and South East Asia enable us to combine the expertise of high growth companies with our own unique local knowledge and technology to ensure that our customers have access to the best financial services.
India is the biggest market for PayU globally and the company has already invested $400 million in this region in last 4 years. PayU in its next phase of growth is developing a full regional fintech ecosystem providing multiple digital financial services in one integrated experience. We are going to do this through 3 mechanisms: build, co-build/partner; select strategic investments.
PayU supports over 350,000+ merchants and millions of consumers making payments online with over 250 payment methods and 1,800+ payment specialists. The markets in which PayU operates represent a potential consumer base of nearly 2.3 billion people and a huge growth potential for merchants.
Job responsibilities:
Design infrastructure for data, especially for but not limited to consumption in machine learning applications
Define database architecture needed to combine and link data, and ensure integrity across different sources
Ensure performance of data systems for machine learning to customer-facing web and mobile applications using cutting-edge open source frameworks, to highly available RESTful services, to back-end Java based systems
Work with large, fast, complex data sets to solve difficult, non-routine analysis problems, applying advanced data handling techniques if needed
Build data pipelines, includes implementing, testing, and maintaining infrastructural components related to the data engineering stack.
Work closely with Data Engineers, ML Engineers and SREs to gather data engineering requirements to prototype, develop, validate and deploy data science and machine learning solutions
Requirements to be successful in this role:
Strong knowledge and experience in Python, Pandas, Data wrangling, ETL processes, statistics, data visualisation, Data Modelling and Informatica.
Strong experience with scalable compute solutions such as in Kafka, Snowflake
Strong experience with workflow management libraries and tools such as Airflow, AWS Step Functions etc.
Strong experience with data engineering practices (i.e. data ingestion pipelines and ETL)
A good understanding of machine learning methods, algorithms, pipelines, testing practices and frameworks
Preferred) MEng/MSc/PhD degree in computer science, engineering, mathematics, physics, or equivalent (preference: DS/ AI)
Experience with designing and implementing tools that support sharing of data, code, practices across organizations at scale"
Big Data Architect,India,DBS Bank,None,Organic,"Big Data Architect

Job Description
We are looking for a Big Data Architect who can define and own end to end architecture for Big Data Analytics Solutions for Consumer Banking Group.
The person should also drive our data analytics and ML application architecture while engaging with business analysts, marketing, operations teams in Consumer Banking Group to understand their needs and create big data analytics solutions that meet the business needs.
Should also be well versed with Data Sciences, Machine learning and Deep Learning based solutions and frameworks. Apply technical knowledge to architect solutions that meet business and IT needs infusing key analytics and ML technologies where appropriate

Key Responsibilities
You will work closely with Big Data Engineering and Data Science team to implement, troubleshoot, and optimise distributed applications based on modern big data technologies like Hadoop, Spark, Kafka, etc. in both an on premise and cloud deployment model to solve large scale processing problems.
Lead the transformation of a peta-byte scale batch-based processing platform to a near real-time streaming platform using technologies such as Kafka and Spark.
Maintain and advance deep technical skills and knowledge, keeping up to date with market trends and competitive insights, and share within the technical community
Develop deep relationships with key business stakeholders and decision makers to drive cloud adoption within their company to enable them to be cloud advocates
Do you have?
Technical Degree, min of bachelor’s in computer science or adjacent fields with 18+ years of software development experience.
10+ years of expertise in Big Data technologies including Apache Spark, Apache Kafka, Hadoop, No-SQL databases such as Hbase, Cassandra, OLAP columnar storage systems, Bit Map indexes to handle millions of consumers and thousands of attributes while allowing real-time querying and segmentation
Hands on experience in expert level support to data scientists, data engineers, and operations to deliver high quality analytics, machine learning data pipelines, APIs and end to end solutions.
Transition several 100’s of existing applications (based in Teradata, Informatica, Qlik View, SAS based analytics and ML models) to modern big data analytics applications based on Hadoop, Spark, Kafka etc
Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management and engineers)
Ability to travel up to 25% of the time

Are you experienced in…
Must have hands on coding skills in Java or Python
Building data services and applications on both structured and unstructured streaming data
Operationalising Machine Learning workflows to scale
Breadth of technical experience and expertise in Business Intelligence, Big Data and Data Science
Proven track record of driving architecture decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills
Hunger to Learn & Teach – Genuine interest to learn new technologies and share it with rest of the engineering team to keep them up-to-date on technology trends.
Problem solver – Enjoy new and meaningful technology or business challenges which require you to think and respond quickly
Open source – Prefer open source technologies and build it yourself mentality, open source contribution is highly preferred.
Team player – Enjoy working collaboratively with a talented group of people to tackle challenging business problems so we all succeed (or fail fast) as a team

Preferred Skills….
Experience with big data analytics and data science solutions developed in large cloud computing infrastructures such as Amazon Web Services, Azure Cloud, and/or Google Cloud
Prior experience as a data architect in designing large, complex enterprise data environments, for both structured and unstructured data. Expertise in data modelling, data governance, data mastering, meta-data management, data security and compliance, data lifecycle management, data-tiering and data archiving
Presence in open source projects will be huge plus.
Experience with Personalisation, Recommendation, Audience Segmentation systems

What else should I know?
It doesn’t matter if you’re not from banking! – We’re more interested in your technical capabilities and ability to think critically"
Data Scientist,India,TCG Digital,None,Organic,"Location
India / US / Europe

Experience
2 Years

Academic Qualification:

B.S, B.E., B.Tech/MBA from top-tier Engineering /B-School OR
Masters in Statistics/Economics from leading University

Overview

Continuous, growth opportunities for career progression and personal development
Professional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate training
Competitive and performance-oriented compensation and employee benefits package
Industry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.

Roles and responsibilities

Will involve teamwork as well as work in which individual contribution will be needed.
Clear, articulate and confident written and verbal communication skills.
Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.
The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.
Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:
Interacting with business stake holders for gathering requirements
Analysing data to develop key insights on business trends and performance
Applying statistical/mathematical algorithms as needed to address specific business problems
Proficiency in using query languages such as SQL(preferable), Hive, Pig, R, SAS, Python

Additional Skills (preferred)

Will involve teamwork as well as work in which individual contribution will be needed.
Intermediate querying and scripting skills in SQL
Experience in relevant field such as Statistics, Computer Science or Applied Math.

SPOC
Buddhadeb Bhattacharjee

Mail to
Buddhadeb.bhattacharjee@tcg-digital.com"
Lead Data Scientist,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"Experience: 5-10 Years.
Job Type: Full-time.
Location: Chennai or Mumbai.
Duties & Responsibilities:
Responsibilities include Identity, develop and implement the appropriate Computer Vision algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains, as well as provide actionable insights with a clear impact on ROI. Define and develop, maintain and evolve data models, tools and capabilities. Communicate your findings to the appropriate teams through visualisations. Collaborate and communicate findings to diverse stakeholders. Ability to build, train and lead a team of data scientists.
Preferred Qualification:
Bachelors/ Masters/ PhD degree in Math, Computer Science, Information Systems, Machine Learning, Statistics or related technical degree with the ability to break complex business problems.
5-10 years total experience with a minimum of 2 years of experience in a related position, as a
data scientist building computer vision solutions for various types of business problems.
Advanced knowledge of statistical techniques, machine learning algorithms and deep
learning frameworks like Tensorflow, Keras, Pytorch.
Minimum 3 years of Programming background and expertise in building models using at
least one of the following languages: Python, R, Java, C, C++.
Implementation of deep learning-based models for image classification, Document
classification models, object detection, logo detection, Object tracking.
Strong individual planning and project management skills, able to juggle multiple tasks and
priorities Self-motivated and driven to deliver agreed results on-time.
Strong storytelling & articulation skills – ability to convert the analytical output into clear,
concise, and persuasive insights & recommendations for technical & non-technical audience.
Strong influence and relationship management skills; comfortable interacting with all
management levels; Prior experience in providing strategic analysis and consulting.
Track record of delivering strong business results.
Company Profile:
Conceptualized as far back as 2015, and commencing full-time operations in 2018, Blackstraw LLc. is a software products and services company specializing in Artificial Intelligence (AI) and Machine Learning solutions for various industries. We support businesses around the world, including North America, Europe and Asia, working to simplify AI implementation through our platform that expedites data labelling, AI model-training, and, cloud or on-premise deployments.
With more than 100 years of combined work-experience, the 100+-strong Blackstraw Team comprises various experts in the AI value chain. We are a fast-moving team that prides ourselves in rapidly identifying different use-cases and fine-tuning our products to suit specific business needs.
We are focused on providing solutions related to computer vision, natural language processing, Data annotation tool for deep learning models, etc. To stay competitive in business, it is key for organizations to adopt and implement smart AI solutions and service offerings. However, most companies are unable to implement AI rapidly due to the complexity of existing solutions, inadequate data and cost implications.
Our mission is to enable enterprises to adopt AI in an easier, cost-effective and time-efficient manner with a plug-and-play approach to their data.
Blackstraw operations are based out of Mumbai, Pune and Chennai in India.
If you think you fit in with the above requirements we’d love to talk to you about working in our organization."
Data Analytics part time job/internship at Multiple location...,"Chennai, Tamil Nadu",Enerjazz,"₹5,000 - ₹10,000 a month",Organic,"About the company:
We are a green energy startup based in Amsterdam funded by the EU. Our founder is from IIT and we operate from Delhi NCR in India.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Build and optimize databases for our battery testing system 2. Analyze and correlate the test data 3. Work on coding IoT for our product
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 11th Aug'20 and 15th Sep'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Must be a graduate student pursuing engineering Must have a background in maths, physics or a related field Must have excellent quantitative and analytical skills Must have advanced Excel skills Must be proficient with other Microsoft Office applications
Number of internships/jobs available: 1
Categories: Analytics,Data Science"
Data Scientist,India,Agnik,None,Organic,"Position: Data Scientist (Intern)
Status: Open
AGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:
1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing
2) Some Experience in Programming in C++/Java/Distributed Programming
3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics
Positions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with ""Application for Data Science Intern"" in the Subject line."
Data Analyst,"Bengaluru, Karnataka",Liventus,None,Organic,"We’re looking for a Data Analyst who will be responsible for assisting in the efficient planning, collection, and maintenance of data sources to join our analytics team. If you meet the following requirements, wish to enter a creative, collaborative, and fun environment, and work alongside people dedicated to the success of our company, please apply online at careers.liventus.com
Apply Online
Job Responsibilities:
Build Tableau reporting
Identify, clean, and combine data to solve relevant business problems
Research and troubleshoot data related questions, tickets, and issues
Monitor and maintain our existing data to ensure it remains clean, accurate, consistent, and impactful
Transform data into meaningful insight and recommendations for business partners from various areas and companies, including but not limited to the Executive and Sales teams
Work with other members of Data Analytics team to develop business workflows that will help us make better decisions and be more efficient in our daily work
Coordinate development of test data, system testing, and documentation for all phases of our data migration processes (ETL)
Stay up-to-date on emerging technologies
Occasionally perform ad hoc reporting to answer specific business questions from upper management
Support users by developing thorough and complete documentation
Job Requirements:
Candidate must have the following:
3 - 6 years of experience in data analysis using query tools required
Strong Tableau report building skills
Strong SQL skills with the ability to perform advanced queries and create stored procedures
Experience with dashboard reporting, scorecards, and executive presentations focused on analytics
Understanding of CRM reporting capabilities
Ability to gather business requirements and translate to technical specifications
Bachelor’s degree in Management of Information Systems (MIS), Mathematics, Statistics, Computer Science, or Business with an analytics focus
Data manipulation skills within Excel, such as VLOOKUP, Pivot Tables, VBA, etc.
An understanding of statistical and predictive modeling techniques and concepts
Strong analytic/problem-solving, documentation, and prioritization skills
A desire to learn new things and an ability to adapt to change and innovation
Ability to work on a team and manage individual prioritized workload
Candidate must be able to effectively communicate in English (written & verbal)
Knowledge of any scripting language e.g. Shell script, JavaScript, etc.
Knowledge of any ETL Tool e.g. SSIS
Benefits:
Group Mediclaim policy
Accident policy
Parental Health Insurance
Retirement benefits (Provident Fund)
Gratuity"
Senior Software Engineer - Data Science and Machine Learning,"Pune, Maharashtra",VSH SOLUTIONS,None,Organic,"Overview
We are looking for creative people with analytical minds and machine learning experience to transform diverse datasets into decisions and value for our customers. Responsibilities:
Design and implement machine learning solutions for recommendation and classification
Use machine learning platforms and services to build solutions and bots, esp. for startups as part of our startup studio
Building and improving data-intensive web services
Developing complex, multi-step data pipelines that unify various data sources into one cohesive platform for data access
Unit, integration, and data integrity test development
Qualifications:
Experience building RESTful APIs & multi-tiered web applications in Python, Java, RoR or Go
Understanding of SQL and data warehousing concepts
Understanding of leading NoSQL solutions such as Cassandra and MongoDB
Experience with Git
Experience with atleast a few of these components: ElasticSearch, Caffe, Pandas, R, Matlab, SciPy
Bachelor’s Degree in Computer Science or Engineering
Location: Pune, India To apply for this job, please write to us at jobs@vshsolutions.com"
Data Analytics (Machine Learning) Internship,"Bengaluru, Karnataka",Simplify360 India Private Limited,None,Organic,"About the company:
Simplify360 is the leading social customer service platform, established in the year 2009. Since then, we have been helping brands and enterprises ease their social media journey. We have a physical presence in India and the US and function through partners in the APAC region. Our product is sold in over 100 countries directly or through partners.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Use effective text representations to transform natural language into useful features 2. Find and implement the right algorithms and tools for NLP tasks 3. Develop NLP systems according to requirements 4. Perform statistical analysis of results and refine models 5. Remain updated in the rapidly changing field of machine learning 6. Design and implement ML algorithms and models (especially deep learning models) through in-depth research and experiment with neural network models, parameter optimization, and optimization algorithms 7. Research and experiment with neural network models, parameter optimization, and optimization algorithms 8. Conduct research to advance the state of the art in deep learning and provide technical solutions for real-world challenges in various scenarios
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 7th Aug'20 and 11th Sep'20
are available for duration of 4 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Should have an understanding of transformer learning
Number of internships/jobs available: 2
Categories: Analytics,Machine Learning,Data Science"
Big Data Developer,"Noida, Uttar Pradesh",Algoscale,None,Organic,"Position title
Big Data Developer
Description
Strong Data Structure and Algorithms Knowledge
Excellent knowledge of OOP concepts
Experience with distributed platforms (Hadoop, Spark) a must
Proficiency in one programming language preferably Java or Scala
NoSQL database experience on a platform such as Hbase, MongoDB, Cassandra, Redis required
Experience with machine learning algorithms, predictive & text analytics is a huge plus
Required Skills
Defining job flows for Hadoop and spark.
Take end-to-end responsibility of the Hadoop/Spark life cycle in the organization
Manage and monitor Hadoop and spark cluster
Qualifications
Bachelors/ Masters in Computer Science or Electronics.
Zero to one year of professional software development experience
Contacts
careers@algoscale.com"
Senior Data Scientist,"Bengaluru, Karnataka",Nanobi,None,Organic,"Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience
Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.
Responsibilities
The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work."
Python Back-End Developers,"Bengaluru, Karnataka",D Cube Analytics,None,Organic,"Bachelors / Masters
Experience
2 to 6 years
We are looking for a candidate with at least 3 years experience in Big Data technologies like Hadoop, PySpark, Spark Streaming, Hive, Spark SQL and DataFrames with Python/Scala.
Additional Technical Skills:
Extensive experience on Spark/Scala, Hive queries on Databricks.
Strong Knowledge of the AWS ecosystem in Data and Analytics
Hands-on experience with ETL processes
Knowledge of workflow scheduler like AWS Airflow and Oozie.
Proficient in at least one of the SQL languages (MySQL, PostgreSQL) and ability to write complex SQLs.
Working knowledge of build tools (PyBuilder) and version control systems (Git).
Experience in implementing systems tracking data quality and consistency.
General Attributes
Ability to work productively with team members, identify and resolve tough issues in a collaborative manner.
Experience with designing data pipelines
Good understanding of complex processing needs of big data and has experience in developing codes and modules to address those needs.
Experience in applying machine learning techniques to real-world problems in a production environment
Deep understanding of Data and the Data Ecosystem
Life sciences background with experience in the Data & Analytics platform is a big plus."
Validation Engineer,"Bengaluru, Karnataka",Qualcomm India Private Limited,None,Organic,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Hardware Engineering
Job Overview:
Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.
General Summary Plans, designs, and develops electronic systems, circuits, components, integrated circuitry, mechanical systems, equipment and packaging, optical systems, and/or DSP systems. Conducts simulations and analyses of designs. Develops emulation solutions. Evaluates, characterizes, and develops the manufacturing solution for leading-edge products in the most advanced processes. Interfaces with various cross-functional teams (e.g. Designers, Software/System Engineering, Architecture Development, Business Groups, Customers, Customer Engineering) to drive and incorporate the latest test solutions in the production program to improve the yield, test time, and quality. Evaluates reliability of materials, properties, and techniques used in production. The responsibilities of this role include:
Working under close supervision.
Taking responsibility for own work and making decisions with limited impact; Impact of decisions is readily apparent; errors made typically only impact timeline (i.e., require additional time to correct).
Using verbal and written communication skills to convey basic, routine factual information about day-to-day activities to others who are fully knowledgeable in the subject area.
Completing most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.
Exercising some creativity to troubleshoot technical problems or deal with novel circumstances.
Using deductive problem solving to solve moderately complex problems; most problems have defined processes of diagnosis/detection; some limited data analysis may be required. The responsibilities of this role do not include:
Financial accountability (e.g., does not involve budgeting responsibility).
Influence over key organizational decisions.
Role in strategic planning.
Principal Duties & Responsibilities
Develops basic features and components of hardware designs in line with product proposals or roadmaps, under the supervision of more experienced engineers.
Applies basic design rules and processes for electronic hardware, equipment, and/or integrated circuitry with minimal supervision from more experienced engineers.
Reads device specification sheets and interprets basic details required to design various hardware features with minimal guidance from more experienced engineers.
Evaluates devices and documents performance over various operating conditions and configurations.
Assists in the assessment of common design features to identify potential flaws (e.g., electrical, mechanical, hardware), compatibility issues, and/or compliance issues under the supervision of more experienced engineers.
Documents basic details about materials, components, chipsets, and assemblies for a device, and records important changes to design with minimal supervision from more experienced engineers.
Troubleshoots basic issues with product designs.
Provides reasonable schedule for own tasks to project lead.
Develops understanding of Qualcomm products.
Seeks basic knowledge of industry trends, competitor products, and advances in various engineering fields from publically available information; requires minimal consultation with more experienced engineers to understand and apply advanced concepts. Additional responsibilities may also include: Develops design implementation, analysis, methodology, flows, and automation for development and validation of System on Chip, electronic parts, components, integrated circuitry, and packaging. Provides design solutions to evaluate, characterize and develop the design implementation solution for leading-edge products in the most advanced processes. Interfaces with various cross functional teams (RF, Analog and Digital IC designers, Software, System Engineering, Test Engineers, Customer Engineering, and Operations) to drive and incorporate the latest design solutions in the production program to improve yield, productivity, and quality.
IT Core Competencies N/A
Required Competencies (All competencies below are required upon entry)
Analytical Skills - The ability to collect information and identify fundamental patterns/trends in data. This includes the ability to gather, integrate, and interpret information from several sources.
Building Trusting Relationships - The ability to build trusting, collaborative relationships and rapport with different types of people and businesses. This includes delivering on commitments and maintaining confidential information, as well as being approachable, showing interest in the other person, and relating well to people regardless of personality or background.
Communication - The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.
Creating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.
Decision Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.
Documentation - The ability to appropriately document software and/or hardware specifications and processes to promote knowledge transfer to other engineers.
Getting Work Done - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.
Hardware Design - Knowledge of and the ability to understand advanced or complex hardware design elements in order to carry out designs, upgrades, and technology roadmaps.
Hardware Infrastructure - The ability to implement and integrate IT hardware for use in business environments and assist in designing its main features according to business needs. This includes the ability to track and report operational problems. This also includes the ability to compare IT hardware across one's own organization and its competitors.
Project Management - The ability to use organizational skills for purposes of planning and decision-making. This includes developing and communicating objectives, timelines, assignments, and goals. This also includes the ability to scope projects, orchestrate multiple activities at once, and use resources efficiently across functional areas within the enterprise.
Additional Competencies N/A
Minimum Qualifications
Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.
Preferred Qualifications
1+ years experience with circuit design (e.g., digital, analog, RF).
1+ years experience utilizing schematic capture and circuit simulation software.
1+ years experience with hardware design and measurement instruments such as oscilloscopes, spectrum analyzers, RF tools, etc.
Physical Requirements
Frequently transports between offices, buildings, and campuses up to ½ mile.
Frequently transports and installs equipment up to 5 lbs.
Performs required tasks at various heights (e.g., standing or sitting).
Monitors and utilizes computers and test equipment for more than 6 hours a day.
Continuous communication which includes the comprehension of information with colleagues, customers, and vendors both in person and remotely.
Applicants : If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport
To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications."
Data Analytics team lead,India,Larsen & Toubro Infotech Limited,None,Organic,"Expert proficiency in programming, programmatic thinking, pseudo code writing. Knowledge of statistics and programming fundamentals. Tools – Expert in SQL, Expert in Python. Knowledge and comfort in Unix environment. Knowledge of SAS will be a plus. Competencies – Proficiency in verbal and written communications. Ability to take a business problem and ask insightful questions to guide development of solution. Education – BE/BTech/BSc from reputable institute – with exposure to mathematics and programming. ME/MTech/MBA/MSc/MCA will be considered a plus. Experience – 5-7 years working in business analytics and data science. End to end implementation of projects from requirement gathering to deliverables sharing a must. Experience leading teams will be considered a plus."
Data Engineer 1,"Bengaluru, Karnataka",Lenskart,None,Organic,"Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.


B.E / B.Tech / M.E / M.Tech / M.S in Computer Science.
Experience in technologies like SQL and NoSQL data stores
Hands-on experience in languages like Java/Python. Knowing R is plus.
Experience : 1- 3 years"
Research Analyst / Data Analyst,"Bengaluru, Karnataka",Ifim Business School,None,Organic,"Job Requirements: Looking for a Research/Data Analyst who can work with large volumes of data in the form of numbers, Corporate information in the form of News, Company briefings, Analyst reports etc. Collate, clean the data, Transform the data to a format for further analysis.
Key Skills:
Advanced knowledge of EXCEL
Comfortable in using statistical tools and techniques
Knowledge of one Computer Programming language like R, PYTHON, JAVA
Willingness to learn and explore new techniques
Educational Qualifications: Bachelor’s degree in Computer Science / Engineering OR master’s in computer applications/Statistics / Mathematics.
Experience: Between 1-2 years in Industry/Academic/Research organization after acquiring the minimum qualification. Enough scope is there for carrier growth.
Remuneration: On par with industry standards.
To apply: Email your latest resume along with a cover letter to hr@ifim.edu.in OR recruitment@ifim.edu.in"
Data Scientist,"Bengaluru, Karnataka",Maximus Human Resources,None,Organic,"About Us :
At Maximus, we understand the significance of blending business processes and technology with human values. Started in 2007, we recruited for Sales and Marketing and Advertising Industries. Over the period, we have entered into IT, ITES and ERP sectors, across all levels. And now we recruit across various industries for multinational corporations. We spend time and effort in meeting and understanding our Clients, their requirements, and job specifications. On the other hand we recognize the core competencies of the aspirants, counsel them into making the right career move. Our support goes beyond the stated minimum guidelines and our approach is end to end.
About Company :
The company is a world leader in Precision Medicine and the global pioneer of Therapy Response Index (TRI). We help physicians and payers navigate to the most efficacious, cost-effective treatments for patients in a transparent and timely manner. Companys’ key therapeutic areas are oncology, immunology, dermatology and infectious diseases. Its’ unique biosimulation platform is a unified representation of biological knowledge, curated from heterogeneous datasets, capable of accurately modeling the response of patients to drug therapies. Founded in 2005 and backed by Artiman Ventures and Sequoia Capital, Company has the world’s strongest trans-disciplinary team of molecular biologists, cellular pathway modelers, and internet software technologists working towards a common goal – attacking serious diseases to improve the lives of patients.
Roles and Responsibility :
Data Scientist
Requirements and Qualification:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software
architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch)
and libraries (like scikit-learn). Understanding of algorithms like KNN,
Naive Bayes , SVM , Decision Forests etc
Experience with data visualization tools like D3.js , Ggplot etc is
desired .
Knowledge of databases like MYSQL , NOSQL is desired .
Excellent communication skills
Ability to work in a team with data oriented personality
Outstanding analytical and problem-solving skills
B.Tech/B.E in Computer Science or similar field; Master?s degree is a
plus
Duties and Responsibilities:
Study and transform data science prototypes . Selecting features ,
building and optimizing classifiers using machine learning
techniques .
Data mining using state of art methods
Research and implement appropriate ML algorithms and tools
Select appropriate data sets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field

Recruiter Name : Madhuri
Recruiter Number : 9113636092
Recruiter Email Id : Madhuri@maximusindia.co.in"
Data Scientist,"Jamshedpur, Jharkhand",Imurgence,None,Organic,"Educational qualifications
B Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.

Relevant experience (Type/ Nature and years of relevant experience required to execute the role)
Min. 2-4 years of experience

Locations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai

Experience related to advanced analytics
Machine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.
Programming and process trouble-shooting experience will be preferred.
Exposure to mathematical modelling will be preferred.
Understanding of statistics and statistical modelling will be required.
Good process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.
Programming skills using a high level language (preferably in .net environment) will be necessary.
Knowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.
Sound concepts on Big data analytics will be helpful.

Technical Competencies
Statistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.
Coding in R/ Python language is Compulsory.

Behavioral Competencies
Learning inclination, Collaboration, Achievement orientation, change orientation"
"SRE - Data Analytics Engineer Pune, Maharashtra","Pune, Maharashtra",Carbon Black,None,Organic,"Carbon Black is now part of VMware. As a standalone company, Carbon Black established itself as a leader in the endpoint security space. The product portfolio includes the rapidly growing Carbon Black Cloud platform that delivers next-generation endpoint protection capabilities from the cloud. Now with the full resources of VMware, you have the opportunity to make an impact and build upon Carbon Black’s success.

Our Engineering team is moving at lightning speed on the breaking edge of technology. You’ll be pulling things apart and tinkering, building new platforms, or playing in the cloud. Here, the engineering opportunities are endless. With this fast-paced, synergetic group, you’ll be working together and across the organization to ensure customer success all while continuing to build a product that protects their dearest assets.

What You’ll Do
Architect, implement, support, and enhance a data platform that supports KPI reporting and analytics for Carbon Black Cloud, with a primary focus on AWS cloud costs, infrastructure utilization, and health.
Build and maintain data pipelines to ingest and refresh AWS cost data and operational performance metrics from a variety of data sources.
Create automated dashboards and reports, for consumers ranging from engineering managers to executives, showing Carbon Black Cloud cost performance and other key performance metrics.
Enable self-service reporting and analytics while ensuring proper access controls are in place and enforced.
Develop and implement tests to ensure data quality across all integrated data sources.
Support the Production Engineering teams by participating in ad-hoc projects and providing data analysis as needed.

What You’ll Bring
Bachelor’s degree in Computer Science, Engineering, MIS or other quantitative fields.
Expert level programming experience with SQL; some experience with other languages such as Python, R, Spark, etc.
4+ years working with relational databases and some knowledge of non-relational databases.
2+ years working with AWS services (S3, Lambda, Redshift, Athena)
Ability to work with minimal supervision, making decisions based upon priorities, schedules and an understanding of business initiatives.
Ability to apply critical thinking to all aspects of the position.
Detail oriented with excellent documentation skills/methodologies, who can successfully manage multiple priorities.
Bonus Points For
Some knowledge of other AWS services (DynamoDB, Kinesis, EMR, Cloudformation, Step Functions
Familiarity with AWS billing and reporting practices and cost analysis tools (i.e. Cost Explorer)
Experience analyzing data for data quality and supporting the use of data in an enterprise setting.
Some knowledge of Infrastructure As Code tooling such as Terraform
JoinCarbonBlackPune referral campaign

Category : Engineering and Technology
Subcategory: Software Engineering
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2020-08-14

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law."
Python Data Engineer,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Engineering expert to come and work on our growing Data pipeline and AI applications. You will be working with a team of highly skilled and motivated engineers and professionals. If you are a polyglot programmer who likes to build AI and data applications, AppZen is the right place for you to apply and grow your skills.
Must Haves:
Solid understanding of data fundamentals and tools
Excellent knowledge of Python fundamentals and application
Built applications for containerized deployment
AI/ ML frameworks and toolkits viz. TensorFlow, Scikit learn, xgBoost is an advantage
Expertise in Elasticsearch setup, development and maintenance is a must
Expertise required in other database like Postgres, Redis
Familiar with AWS services, especially S3, big data services and DevOps tools
B.E. or B.Tech in Computer Science, Engineering, or other relevant technical field.
Must have 5-7 years of industry experience.
Must Have:
Able to work onsite in Pune, IN

Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
"Software Development Engineer, Amazon Machine Learning, AWS...","Chennai, Tamil Nadu",ADCI - Tamil Nadu,None,Organic,"2+ years of non-internship professional software development experience
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
Bachelor’s degree in Computer Science, Computer Engineering or related field
Solid Computer Science fundamentals: data structures, object-oriented design, algorithm, problem solving, and complexity analysis

Interested in machine learning, and empowering the world to do more and better machine learning? Amazon SageMaker (https://aws.amazon.com/sagemaker/), Amazon Web Service's (AWS) fully managed Machine Learning (ML) platform team is building customer-facing services to catalyze data scientists and developers in their machine learning endeavors. SageMaker takes away the heavy-lifting normally associated with large-scale Machine Learning implementations, so that developers and scientists can focus on the truly creative work of solving the business problem at hand.

We are looking for software development engineers who take pride in tackling hardest challenges, excel at working in an agile environment, and are excited about our mission. You will work in a diverse team to build out the foundational technology for a next-generation ML workflow platform. Your work will enable customers to build and run entire ML pipelines within Amazon SageMaker without the need to provision or manage servers. You will design, implement, test, document, and support cross-cutting services of this new product. With the goal of providing a world-class user experience, our product offers a blend of web APIs, IDE, and open source libraries that make it easier to build machine learning on SageMaker (for example: https://github.com/aws/sagemaker-python-sdk).

At SageMaker, there are immense learning as well as growth opportunities. This is a great team to come to have a huge impact on AWS and the world's customers we serve!

Experience building software systems that have been successfully delivered to customers
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
Experience defining system architectures and exploring technical tradeoffs
Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs
Hands-on expertise in building and operating complex distributed systems
Master's degree in Computer Science or related field
Experience building and operating mission critical, highly available (24x7) systems
Experience with Machine Learning, data mining, and/or statistical analysis tools such as R and MATLAB is a plus
Experience with deep learning framework such as TensorFlow, MXNet, PyTorch, Chainer is a plus

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status."
Senior Data Scientist,"Chennai, Tamil Nadu",Boston Consulting Group,None,Organic,"Location:
Chennai, Mumbai, New Delhi
Geography:
Asia Pacific
Capabilities:
Big data & advanced analytics
Industries:
Technology industries
Who We Are
Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.

To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.
Practice Area Profile
BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you’ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology.
What You'll Do
POSITION PROFILE:

We are seeking a strong candidate with advanced analytics experience to fill an exciting Senior Data
Scientist (SDS) position within BCG Gamma. The SDS is a valuable expert in Data Science and Analytics
and will design and build analytics methodologies, solutions, and products to deliver value to BCG's clients
in collaboration with case teams. Exceptional candidates will also show an analytical curiosity, going
beyond the immediate requirements of the project to find deep insights that others have missed. They will
ask questions about outliers, seek to understand the fundamental drivers of advantage and look for clues
that may change the basis of competition.

As a Senior Data Scientist you design and build analytics solutions for our clients where data and
analytics are at the heart of the question. The team interaction centers on use of statistical programs and
others tools to conduct intensive analysis of objective data and open discussion, complemented by
objective research into the competitive environment. Responsibilities / duties to include: understand
problems from the client’s point of view, build and execute solid analytics work plans, gather and organize
large and complex data assets, perform relevant analyses (data exploration and statistical modeling),
manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client
counterparts, and communicate hypotheses and findings in a structured way.

As the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on
leading-edge business applications, tools and approaches, proactively working with the Analytics
Leadership to enhance offerings that deliver competitive advantage to BCG.
What You'll Bring (Experience & Qualifications)
JOB REQUIREMENTS:
PhD and 1-2 years of relevant industry work experience or a Masters Degree with significant relevant experience providing advanced analytics solutions is required. The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric field.
Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.
Strong record of professional accomplishment and leadership.
Date Posted:
13-Feb-2019
Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.
BCG is an E-Verify Employer."
Global Data Lead – Supply,"Bengaluru, Karnataka",Alcon,None,Organic,"Tactical PlannerResponsible for driving and managing the Master Production Schedule for the tactical horizon (3 to 24 months) ensuring capacity & resources are in place to support agreed demand plan to satisfy the Customer requirements and to keep the inventory at the next handover point of the supply chain at the agreed target level.Customer Service CoordinatorInterface between the site and its customers acting as the primary contact providing visibility of the supply plan to the customers and maintains the Service Level Agreements (SLAs).Responsible for ensuring a timely implementation of all Life Cycle projects as launches/ changes/ transfers/divestment by coordination of involved stakeholders from different functions. Ensures compliance with Regulatory and GMP, law, SOPs, HSE and Code ofConduct.

-Tactical Planner: -Establishes optimal master production schedule for the tactical horizon from month 3 / 4 to 24 months, including Production volumes based on demand, rough cut capacity analysis and resources allocation resulting in anticipated operational costs and inventory levels -Aligns Master Production Schedule (MPS) to the production plan approved in S&OP -Coordinates action plans to remediate to resources constraints and manages supply KPI reporting and analysis. -Ensures right level of SKU Inventories at the next point of the supply chain. -Owns planning parameters in ERP System. -Confirms supply orders, firmed production orders at the entry point of the time fence. -Leads action plans to achieve supply performance target and drives for continuous improvement. -Facilitate Supply Review Meeting and actively support the entire S&OP processCustomer Service Coordinator: -Ensures that the customers have clear visibility of the current valid supply plan and monitor the delivery commitments in terms of quantities and timelines, in accordance to the Service Level Agreements (SLAs). -Acts as the point of contact for the GOCA process and all order-related topics. -Manages backlog and backorders between the Site and customers/ next supply points and ensures direct communication with Customer and internal and external stakeholders. -Is responsible for creating and maintaining SLAs with related Planning Parameter setup in alignment with the customers. -Is responsible for Monthly Demand Review Meeting (midterm horizon 3 to 24 months) incl. demand assumptions, recognizing trends, showing variances to last demand submissions, as input to Supply Review meeting and Monthly Business Review (MBR) meeting within Sales & Operations (S&OP) process. -Manages demand control activities (short term -3/4 months, within the time fence) and pro-ides inputs to Master Planning Schedule (MPS) and detailed scheduling. -Leads the implementation of LC projects, in order to ensure compliant drug supplies, on time and in right quality and deliver and maintains a detailed Change Over Plan (COP) for LC projects regarding implementation dates, according to the overall strategic project/ program plan, in order to allow for early local Master Data set-up and planning at site and in countries. -Is responsible for the up-to-date assortment at SKU level of the assigned brands. • Execute setup and maintenance of new material master setup and change requests in Alcon ERP systems to support manufacturing and supply chain product launch activities. Requires heavy interaction and coordination across manufacturing and supply chain stakeholders. • Perform daily Material Master Maintenance operations consisting of both global and local manufacturing and supply chain extensions, including process improvements, business rules development, managing ticketing systems and generation of metrics. Ensure that the Alcon business rules defined in the GDM Data Dictionary are applied. • Leverage technology to promote Active and Passive Governance using industry best practices by generating applicable metrics to demonstrate improvemnt of data quality KPIs. • Work closely with other business teams like Supply Chain Planning, Finance, Quality, Regulatory Affairs and Manufacturing to address and resolve master data issues in a timely manner. • Lead process reenginnering and simlificatin efforts to mitigate points of failure, and implement new business processes by documenting revisions to exising or development of new SOPs. • Analyze large amounts of data to support ERP data validation / cleansing activities, operational and project-oriented, and contribute to governance process enhancement. • Maintain compliance with internal, and external controls standards and SOPs (i.e. Alcon Finance Controls Management, Alcan Profit Margin Reporting standards, and Alcon’s Global

-Inventory Management -Gap Analysis -Cost Efficiency and efficiency of supply processes

Operational Excellence Organizational Savvy Stakeholder Engagement Project Excellence Interpersonal Savvy Breakthrough Analysis
Minimum requirements
Operations Management and Execution Project Management Collaborating across boundaries Functional Breadth English Customer Relationship Management Product Life Cycle Management Inventory Management Supply Planning Demand Planning Knowledge of all relevant policies and practices Supplier Relationship Management

• Bachelors Degree in Business, Supply Chain, or Science/Engineering. Masters Degree preferred • 7 years in Master Data Management; Medical Device industry and SAP Master Data Management experience preferred. • Good working skills with MS Office suite; Advance experience in advance MS Excel, MS Access and MS Visio preferred. • 7 years developing solutions to complex problems which may require some ingenuity and innovation. Ensures solutions are consistent with organization precedents and policies. • 7 years interacting with senior internal and external personnel on significant matters often requiring coordination between organizations.
Division
ALCON
Business Unit
NON-NVS AL MFG-TECH OPERATIONS
Country
India
Work Location
Bangalore
Company/Legal Entity
Alcon Ind
Functional Area
Technical Operations
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
consultant,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
ob Overview
Under guidance, provides support in applying statistical methodologies to assigned research projects.
Essential Functions
Candidates must have experience in Advanced Analytics Projects like
Work across projects such as promotional return (ROI analysis), Resource and price optimization analysis, Physician / patient profiling, Survival Analysis, linear and logistic regression, decision tree, segmentation
Develop a good understanding of consumer offerings, proprietary databases, and analytical approaches to effectively guide and support client-facing stakeholders across globe mainly in Europe and US
Handle small and large datasets on projects efficiently and figure out the right technology for processing the data (e.g. Excel, SAS, R Python etc.,). Be a champion on analytics technologies within the team
Present findings and recommendations to stakeholders in business point of view
Qualifications
Bachelor's Degree Statistics, Mathematics or related field Req Or
Master's Degree Statistics, Mathematics or related field Pref
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Big Data,"Mohali, Punjab",XenonStack,None,Organic,"Job Summary
Our Big Data capability team needs hands-on developers who can produce beautiful & functional code to solve complex analytics problems. If you are an exceptional developer with an aptitude to learn and implement using new technologies, and who loves to push the boundaries to solve complex business problems innovatively, then we would like to talk with you.
Responsibilities
You would be responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects
The role would involve big data pre-processing & reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights
The role would also involve testing various machine learning models on Big Data, and deploying learned models for ongoing scoring and prediction. An appreciation of the mechanics of complex machine learning algorithms would be a strong advantage.
Experience
6 Months to 3 Years of demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions. Ideally, This Would Include Work On The Following Technologies
Expert-level proficiency in at-least one of Java/ Python/Scala
Strong understanding and experience in distributed computing frameworks, particularly Apache Hadoop
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage.
Strong knowledge of Databases - SQL/NoSQL Databases and Graph Databases
Building Big Data Solutions for High Volume of Transaction Data and Unstructured Data
Strong Knowledge of Algorithms and Data structures
Experience with Test-Driven development
Skills required (Hands-on)
Experience in one or more languages but not limited to: Java/C/C++/C#/ Python/JavaScript /Go.
Interest and ability to learn other coding languages as needed.
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
In addition, the ideal candidate would have great problem-solving skills, and the ability & confidence to hack their way out of tight corners.
REST API/ BIG DATA/CORE DEVELOPMENT
Education
B.E/B.Tech in Computer Science or related technical degree
Keywords
SQL
Data Analytics
Data Warehouse
Data Ingestion
Database
Data Structure
Data Governance
Data Processing"
Clinical Data Specilaist - R,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
Should have study start up exp, develop test cases. Exp: 2.6-4 yrs of relevant exp in CDM with RAVE
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Programmer Analyst,"Chennai, Tamil Nadu",Cognizant,None,Organic,"Technical Lead
Qualification:
Bachelors in science , engineering or equivalent
Responsibility:
Requirement Understanding and Analysis:
Understand the functional/ nonfunctional requirements.
Participate in client calls and prepare the clarification list to seek clarifications.
Prepare the list of requirements and seek review inputs from the key stakeholders.
Update requirements traceability matrix.
Create impact analysis document (for simple change) to understand the impact on the existing functionality, as required.
Design:
Provide inputs to create the low level design for the module based on the understanding of the requirement and HLD.
Identify the list of reusable assets that can be used and share inputs.
Share the list of components with the Senior Developer/ other relevant stakeholders and seek inputs.
Coding:
Based on LLD , identify the component that needs to be created.
Set up the environment for creating the component.
Replicate the existing code to the environment.
Establish connection to the databases.
Conduct coding as per finalized technical specification document.
Follow coding standards and best practices to check code quality.
Generate code quality document for the code review through various tools (Informatica, Aqua).
Share the developed code for review.
Rework on the code based on inputs shared by the Sr Developer and Module Lead if required.
Identify unit test case scenarios based on the design.
Prepare unit test cases and test data under guidance.
Merge code in the build environment and seek inputs from the Senior Developer.
Conduct peer review for the other team members.
Conduct technical troubleshooting if required.
Testing Management:
Conduct unit testing based on the identified test scenarios.
Fix simple defects identified during unit testing.
Prepare unit test document based on the test results and share the same for review.
Integrate and conduct system integration testing.
Address queries raised by QA team within defined timelines.
Analyze and fix the defects identified during functional / non functional testing.
Understand the impact/ criticality and priority of the defect.
Conduct regression testing for QA testing.
Report defect status as per project standard process within agreed timelines.
Track the status of defects using the test management tool (ALM, QC ).
Close the defect in test management tool once resolved.
Configuration Management:
Branch off the existing code in the version control tool (VSS, CSV).
Identify configurable items.
Maintain version control across different configurable items (documents component, data mapping clarification document etc).
Deployment:
Share the environment set up details with the deployment team.
Provide inputs on instructions (in case standard).
Create a deployment package under guidance of senior members in the team.
Raise deployment request to deployment team to deploy the code in the integrated environment.
Review the deployed component in the environment.
Load the test data.
Conduct smoke testing under guidance.
Share notification with QA team post completion of testing.
Service Support and Maintenance:
Specific to production and maintenance support:
Prioritize incidents based on criticality.
Route the defects logged to the right stakeholder if required.
Attend user calls, and capture required information and incident details for logging.
Coordinate with the different stakeholders to resolve as per SLA.
Run appropriate tests, once the defect is resolved.
Track the status in the test management tool (QC, Alma etc).
In case of any recurring incidents, prepare a learning document capturing the known errors.
Provide inputs to module lead in creation of transition plan (project steps and milestones).
Knowledge Management:
Create specific artifacts for tasks allocated by Lead.
Share artifact with supervisor for review.
Upload article in the knowledge management repository.
Search the knowledge repository for information to resolve problems.
Apply best practices/ learning during the code development.
Create reusable assets and their documentation.
Create value addition documents (value added by team to the client) and share it with the team.
People Management:
Provide inputs in creation of training courses and supporting artifacts on the training server such as demo, presentation.
Conduct training or knowledge sharing sessions (in case of niche technology).
Must Have Skills
Informatica MDM
informatica Data Quality
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Aug 14 2020
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world."
Data Analytics Specialist - Microsoft Azure,"Mumbai, Maharashtra",Lloyds Register,None,Organic,"Date: 20-Jul-2020
Location: Mumbai, IN
Company: Lloyds Register
Job ID:31135
Location:Mumbai : India Management Office (LR_L000156)
Position Category:Information Technology
Department:IN710032 : Group IS Mumbai (IN710032)
Position Type:Employee Regular
Role Purpose:

We are seeking an experienced Microsoft Azure Analytics Developer to work with key business stakeholders to identify and deliver BI reports. We are building a Data Analytics Platform using Azure technologies – Azure Data Lake, Azure Data Warehouse / Synapse, Power BI etc. This platform will ingest, transform, prepare and train data from disparate source systems including SAP, Oracle, Salesforce.com etc.
We are looking for an individual with strong skills in Power BI, Azure Analysis Services and Azure Data Warehouse / Synapse. The Azure Analytics Specialist will be responsible for role-based and data-level security of reports including managing platform access for external data exchange with customers and regulatory bodies.
The Azure Analytics Specialist will develop reports for users, during which time he / she will gain understanding of the business and existing data structures and processes, expanding their skills as required with the platforms used by the company. The individual will work collaboratively with business stakeholders in developing new and refining existing data models / reports / processes.

Key Responsibilities:

Build and enhance existing data models in Analysis Services, Azure Datawarehouse / Synapse to meet reporting requirements
Design and build reports and dashboards and assist in development of complex ad hoc queries and analyses in Power BI
Design and build reports role-based and data-level security models for both internal and external clients
Manage security-based data exchanges with external clients and regulatory bodies
Own the release management process and deployments to all environments
Support user community on Power BI technology and functionality
Work with infrastructure team and Microsoft to ensure system reliability
Conduct activities in line with internal procedures, legislation and industry standards.
To pursue Continuous Professional Development and maintain a high degree of discipline knowledge and awareness.
To mentor/coach other specialist employees to achieve effective specialist knowledge transfer and application.
Ensures documentation/data/information and tasks relevant to the section are planned, evaluated and processed in accordance with local business requirements and agreed deadlines.
Review & analyse data to provide management information/statistics, including the identification and reporting of process failures, to support the overall delivery of processes.

Technical / Professional Qualifications / Requirements:

Sound knowledge and experience of building Power BI based reports and dashboards
Good understanding of data warehouse principles and data modelling for reporting
Strong experience of SQL, Power Query, DAX, MDX and other query processing languages
Data Science experience using Python, Scala, R would be desirable
Experience in Machine Learning and Artificial Intelligence for Predictive Analytics would be an advantage

The Lloyd's Register Group comprises charities and non-charitable companies, with the latter supporting the charities in their main goal of enhancing the safety of life and property, at sea, on land and in the air - for the benefit of the public and the environment. (Group entities)


Job Segment: Database, ERP, Oracle, SAP, SQL, Technology"
Staff Data Scientist,"Bengaluru, Karnataka",Infoblox,None,Organic,"Infoblox is seeking a Staff Data Scientist for the Cybersecurity team in Bangalore. In this role, we are looking for professionals who are well versed in scalable data mining, machine learning techniques, and love to build analytics models. The successful candidate enjoys working in a fast-paced, geographically diverse, multidisciplinary environment. This team designs and builds complex models that learn from Infoblox networks and DNS data to provide security solutions. This role reports to Manager, Data Science-based in Tacoma, WA.
Joining our team in Bangalore, India, will be an opportunity to grow your career in data science, innovate, and contribute thought leadership. You will have the chance to work with experts in next-generation technology and help drive the project and product portfolio to achieve departmental and corporate goals.
Responsibilities:
Apply data mining and machine learning techniques for a variety of modeling problems involving DNS and networking data
Build complex statistical models that learn from and scale to petabytes of data
Develop deployment architecture and scripts for automated system deployment in AWS
Create software to extract, clean and manipulate large datasets both structured and unstructured
Construct data staging layers and fast real-time systems to feed machine learning algorithms
Work with architects and product managers to develop efficient and reliable algorithms
Work collaboratively across multi-disciplinary teams throughout the company as a subject matter expert in analytics with a focus on security solutions and implementation
Requirements:
10+ years of experience with 2+ years in a practical Machine Learning experience with demonstrated experience in feature engineering and data analysis
4+ years of experience in analytic design and implementation
4+ years experience in Big Data with Spark/Hadoop tech stack
4+ years in the hands-on analytic environment, with the ability to articulate analytic needs and translate them into research and development requirements
Demonstrated ability to quickly learn new tools and paradigms to deploy cutting-edge solutions.
Expertise in automating and deploying models in production systems
Familiar with best practices for engineering in an enterprise environment
Proficient in Python, with specific expertise in Python’s data science and machine learning libraries
Strong written and spoken communication skills
Experience with Amazon Web Services
Experience with one or more of, Keras, and TensorFlow
Proficiency in Java or Scala, particularly in a big data spark/hadoop environment
Expertise in streaming analytics frameworks such as Apache Spark, Storm, MOA and WekA
Knowledge of Hadoop architecture, HDFS, Map-Reduce Algorithms and Elastic Search
Network security background, familiarity with botnets, DDoS, and other threat types
Education:
Masters or Ph.D. in Computer Science, Mathematics, CE, EE or related
It’s an exciting time to be at Infoblox. We are the market leader in technology for network control. Our success depends on bright, energetic, talented people who share a passion for excellence in building the next generation of networking technologies—and having fun along the way. Infoblox offers a fast-paced, action-oriented environment. We promote a culture that embraces innovation, change, teamwork, and strong partnerships. Join the winning Infoblox team—our future looks bright, and so will yours. To check out what it’s like to be a Bloxer click here.

#LI-NY1"
Reporting & Data Analyst,"Bengaluru, Karnataka",Koch Technology Center,None,Organic,"Description
This position is a key position with responsibility for analyzing and improving the Profitability Analytics (PA) solution at Molex.This role will manage / track input data used for the solution as well as analyze logic and calculations applied to arrive at the final PA results. This role will be the key point of contact and support for the PA solution as well as ancillary analysis / tools (e.g., Excel, Tableau based) and responsible for functional implementations of future enhancements
What You Will Do In Your Role
Support Executive, Finance and Divisional/BU leadership in establishing a vision for profitability analytics for the organization
Interpret data to develop recommendations to improve quality and capabilities of profitability analytics
Develop reports to support and measure improvement in profitability analytics and business results
Determine key drivers of profitability within key BUs, products, markets, and customers
Collaborate with Finance, BU, and the commercial organization to establish opportunities for profitability optimization.
Support the technical aspects of PA, including capturing, maintaining and analyzing data to support business in decision making.
Provide support across the organization on adoption and use of PA tools and datasets
Partner with finance and BU stakeholders to refine profitability analytics training for organizational growth and development.
Support the implementation of best practices in profitability analytics and administration through effective analysis of internal data used to support decision making
Identify opportunities to streamline the Profitability Analytics processes to support consistency across the BUs
Proactively optimize analytical tools and supporting processes.
Develop technology-driven processes to automate PA process and more accurately track business impact realization.
Integrate PA into existing business processes that consume profitability
Develop functional methodologies to improve the capabilities of the PA solution to assign more costs through activity-based drivers
Collaborate with various data source owners to improve capture of activity-based data, which is used to assign specific costs to products and customers
Functionally master the data, systems and data models used in PA solution and provide continuous PA support to organization
Build and maintain analytics dashboards, standard and ad-hoc reports, and clean data sets to maintain / improve the accuracy of the solution
Coordinate with stakeholder teams in developing reports and tools related to profitability
Conduct ongoing solution maintenance and monitoring.
Provide internal and external data and analysis to support decision-making around PA
The Experience You Will Bring
Minimum of 5 years of experience with data analysis in B2B / B2C environment
Advanced experience managing data systems, data repositories and visualization tools from a complex business environment
Proven ability to manage direct and indirect teams in managing, cleansing and consolidating large data sets from various sources
Core finance and profitability knowledge with minimum 5 years profitability analysis and financial analytics experience
Strong analytical and problem-solving skills; strategic thinker
Solid understanding of ecosystem required for strategic uses for profitability
Demonstrated ability to drive results and measure business impact
Ability to produce, manipulate and refine transactional, customer and product databases in SQL
Advanced Microsoft Excel skills with proven experiences with large data sets
Modeling capabilities, including experience developing, defending and refining models
Familiarity with SQL, including writing queries
SAP Enterprise HANA experience is a plus
Familiar with SAP data elements Experienced Tableau user; able to create dashboards and resolve data issues
Education
Bachelor/Master Degree in commerce, Science or similar or MBA"
Senior Data Scientist,"Bengaluru, Karnataka",Arcadis,None,Organic,"Description
Introducing Arcadis Gen
Are you interested in joining a start up with bold global ambitions, that already has the backing of, a €3+ billion revenue, 27000+ person organisation operating in over 70 countries, that has deep market sector insights in collective design, consultancy, engineering, project and management services?
We are creating a new entity focused upon accelerating the investment and development of digital solutions which support the asset lifecycle and will position Arcadis as a digital front runner in the fields of digitized asset management, cities and mobility. Our focus is upon accelerating our ability to bring highly scalable digital propositions quickly and seamlessly to both existing and new Arcadis clients across the globe.

We have a clear vision that will enable us to rapidly scale our existing digital capabilities and innovate based on the identified underserved demand in the market, by creating industry leading products, platforms and solutions. Our strategy to become more digitally focused has already seen the acquisition of two digital asset management companies to build on our existing digital capabilities from the Arcadis technology division, all of which will form the foundations of this new digital entity.
Qualifications
1. The Opportunity

The Senior Consultant will work in collaboration with the analytics team in India and the UK to deliver advanced analytics projects, and play a key role in creating data-driven, digital products and solutions that generate profitability in the market.
They will help in identifying where and how the client business can be enhanced by using predictive, prescriptive, and other sophisticated data manipulation techniques, and effectively create innovative offerings across existing sectors and beyond.
2. Key Deliverables

Deliver specific analytics solutions ensuring assigned projects are delivered on time, to high quality and in accordance with project scope.
Work as part of a ‘virtual team’ through the project comprising of other colleagues in Arcadis at the GEC in Bangalore as well as Gen in the UK, ensuring that the scope elements within the given remit are delivered to the expected standard.
Identify opportunities to transfer best practice from one sector to another, and opportunities to bring in best practice approaches applied outside Gen/Arcadis to ensure delivered solutions always represent the best approach.
Manage outputs and quality throughout delivery of a project ensuring all work packages align to the project scope.
In association with the Analysts undertake the analytical activities associated in delivering projects including:
o Collecting, assessing, and transforming client data as required to support the project including ensuring data is validated for completeness and analysed for ‘cleanliness’.
o Derive predictive models using appropriate statistical techniques.
o Design and populate models within Gen’s prescriptive analytics software (Enterprise Decision Analytics [EDA]), execute and report on investment scenario analyses, including investment triggers, advanced prioritisation and optimisation.
o Configure Gen’s EDA software and any third-party solutions required to generate optimised investment plans or other advanced analytics solutions.
Production of client reports, technical notes & model documentation.
Peer review of reports produced by colleagues.
Ensure the products and services delivered fully meets client expectations and delivers value in terms of realisation of business benefits.
Ensure all project management process & quality requirements are followed.
Monitor, manage and resolve project risks and issues and escalate serious project risks to the line manager.

3. Key Relationships, Collaborations and Connections

This role will report to: Principal Consultant in Bangalore.
It will collaborate closely with:
o Consultants that run and own projects and who specialise in specific sectors.
o Specialists who are experts in the delivery of certain types of analytics/ data science or in the application of specific analytics tools across any sector
o Analysts that undertake the analytical and modelling tasks required of the projects supporting the work of both the Consultants and the Specialists.

Key relationships will include:
Colleagues in the Arcadis GEC in Bangalore and in region specific analytics roles.
Colleagues within the Analytics Team i.e. other analysts, analytics specialists, and consultants.
The Product Development team who are responsible for the heavy lifting and backend work done on Gen products.

4. What We Are Looking For

Requirements
Excellent communication (verbal and written) and organisational skills.
Educated to degree level as a minimum in a Data Science, Mathematics, Physics, Engineering, or other financial/numeric field (Most of the team members are educated to MSc level or equivalent).
Significant experience (5 + years) of delivery of analytical projects in a consultancy environment.
Having worked as part of a ‘virtual’ team environment.
An effective communicator who is credible, confident, and articulate. Able to communicate complex technical detail to non-technical audiences.
Exceptional skills in data collection and interpretation.
Predictive and / or prescriptive analytics.
Understanding of investment models, assets, and systems of assets, understanding of Optimisation (linear & non-linear), Prioritisation and Monte Carlo analysis.
Specialism in at least one specific area of Data Science/ Analytics. Track record of presenting papers etc. in this area is desirable.
Extensive use of MS Access or SQL to collate data and perform complex queries
Extensive use of MS Excel, R, Python, Matlab, SAS, SPSS or similar or other statistical packages to process data and carry out advanced analytics techniques.
Experience in advanced data visualisation techniques along with tools such as Qlik, Power BI etc.
Sensitivity and scenario analysis of analytical models.
Mathematical and statistical analysis and modelling skills.
Proven ability in presenting methodologies and results to all levels in a business environment.
Understanding and creating end user outputs for different types of engagements (e.g. investment scenarios from prescriptive models) and visualisations including GIS and other.
Overview: understand client needs, capability to build stuff, continuous learning, collaborate effectively, understand end user

Desirable Experience and Qualifications
Experience of building robust, user friendly apps using R Shiny
Exposure to UI/UX design for applications.
Experience with collaboration tools including Azure DevOps and GitLab.
Experience of working with environments for product onboarding, packaging, dockerisation.
Exposure of agile methodology: SCRUM.
Exposure of using project collaboration tools such as Atlassian Confluence & JIRA

5. Who Are We?

Our Mantra
At Gen we have a mantra which is to be Bold, Agile and to deliver Accelerated Growth, this focuses our efforts and defines the way in which we will deliver to the market.
Our Spirit
Our spirit, makes us unique, binds us together and sits at the very essence of who we are and how we ‘show’ up.
Our fear of failure is mitigated by a thirst for positive disruption.
We demonstrate intellectual humility – we can admit we are wrong and may change our options often when new information or insights come to hand.
We value talent, skill & knowledge but prize agility and adaptability above all else.
We are optimists believing that we can and we will always find a way…..mindset matters.

Our Drivers
We are motivated and driven by:
An entrepreneurial spirit and desire to be inventive and free from tight organizational constraints.
A desire to learn and grow, to push and challenge ourselves and to test the limits of our potential.
To attempt the extraordinary, motivated to achieve even in the face of set back or obstacle.
To collaborate, pursuing shared rather than individual goals, believing that we do our best work when we default to ‘open’ rather than ‘closed’.
Playing a role on the global stage, leading, and influencing the future of our industry and sector and by deeply understanding the needs of our clients.

Leadership at Gen
Leadership at Gen is not based on principles of power and control but rather on encouraging self-determination, experimentation, and creativity. Our leaders actively:
Encourage experimentation: The role of a leader is not to reduce risks or prevent failures, but to create an environment resilient enough to take these risks and handle the missteps.
Instill trust: Silos are the enemy of agility, to be truly agile requires foundations built on trust, discipline and single-minded focus, collaboration and transparency are essential to success.
Cultivate diversity of thought: Believe that different views, healthy debate and respectful conflict are good things, they are the catalysts for creativity & will fuel our innovation

Who is Arcadis
ARCADIS is the leading global natural and built asset design and consultancy firm working in partnership with our clients to deliver exceptional and sustainable outcomes through the application of design, consultancy, engineering, project and management services. ARCADIS differentiates through its talented and passionate people and its unique combination of capabilities covering the whole asset life cycle, its deep market sector insights and its ability to integrate health & safety and sustainability into the design and delivery of solutions across the globe. We are a multi-billion business that employees 27,000+ people globally. We support UN-Habitat with knowledge and expertise to improve the quality of life in rapidly growing cities around the world. Please visit: www.arcadis.com.

Equal Opportunity Statement
The community of the future is a place for everyone, and Arcadis is proud to be an equal opportunity employer. All employment is based on merit and business need."
Software Engineer Analytics,"Bengaluru, Karnataka",S-Square Spenta Technologies,None,Organic,"Positions Bangalore
Experience required 3-4 years
Educational qualification B.Tech /MCA/MSC – Comp Science /B.E or equivalent
Skills required 1. Good development skills in any one language ( R , Scala , Python etc).
2. Assess and work with interfaces with Databases for data extraction and aggregation.
3. Knowledge of SQL .
4. Knowledge of Data Models for Analytics and Machine learning techniques.
5. Cloud based systems working knowledge would be essential.
Job Description This role would be a key resource for the organization for development of information systems in the areas of reporting , data analytics and machine learning techniques.
Roles & Responsibilities
Primary role will be responsible for development of Online dashboards, reports.
Would be responsible for Analytic ( statistical ) models and innovative methods of reporting.
Work with application interfaces and Web services .
Would work with a team of Architects and System Engineers , Data Base Administrators of various applications apps and platforms."
Senior Machine Learning Engineer,"Bengaluru, Karnataka",Ushur,None,Organic,"Ushur is transforming the way businesses communicate, with cutting-edge AI and automation technologies. Previously using outdated emails and phone calls, businesses are now automating their conversations with automated text-messaging using Ushur’s platform. We are creating breakthrough experiences for our enterprise customers by deploying the best of web, mobile and data analytics technologies. We focus on fast, iterative development with an emphasis on design-right philosophy. Currently, at Ushur, we are experiencing unprecedented & exciting growth with endless opportunities to innovate!

The Role

Ushur seeks a Senior Engineer with Machine Learning Expertise to join a high-impact team to enhance the Language Intelligence framework that is at the core of industry’s leading Micro-Engagement Platform from Ushur.

What you’ll be doing…

As one of the key members of of the Language Intelligence team, your responsibilities will include:
Design, develop and support machine learning and deep learning models involving
Ushur’s Language Intelligence that encompasses the spectrum of NLP and NLU to support information processing as well as drive the Ushur micro-engagements with users.
Responsible for designing and/or adapting various algorithms, undertaking experiments and impacting the Ushur Micro-engagement Platform.
Construct comprehensive knowledge graphs to support various applications that are delivered over the Ushur Platform.
Research and employ modern algorithms into the Ushur Platform to keep innovating with efficiency, impacting the feature-base of Ushur’s Platform.

Collaborating with engineers from AI & other teams on data analysis and feature design efforts

Qualifications

MS/PhD in Computer Science or related field
At least 3 years hands-on working experience in the AI/ML Area
Demonstrable experience with NLP/NLU techniques, language data
Strong knowledge of NLP tasks and techniques, NER, training machine learning models, neural networks
Strong programming skills in Python or Java and fluency in data manipulation (SQL/Spark/Pandas) and machine learning kits like scikit-learn, Keras/Tensorflow, XGBoost, Gensim
Excellent verbal & written communication, strong organizational skills and attention to detail

Why Join us?

We are passionate about Ushur, our product, and helping our employees grow and develop in their career in a caring, collaborative environment. We offer a very competitive compensation plan & stock options for the ideal candidates."
Validation Engineer,"Bengaluru, Karnataka",Qualcomm India Private Limited,None,Organic,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Hardware Engineering
Job Overview:
Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.
General Summary Plans, designs, and develops electronic systems, circuits, components, integrated circuitry, mechanical systems, equipment and packaging, optical systems, and/or DSP systems. Conducts simulations and analyses of designs. Develops emulation solutions. Evaluates, characterizes, and develops the manufacturing solution for leading-edge products in the most advanced processes. Interfaces with various cross-functional teams (e.g. Designers, Software/System Engineering, Architecture Development, Business Groups, Customers, Customer Engineering) to drive and incorporate the latest test solutions in the production program to improve the yield, test time, and quality. Evaluates reliability of materials, properties, and techniques used in production. The responsibilities of this role include:
Working under close supervision.
Taking responsibility for own work and making decisions with limited impact; Impact of decisions is readily apparent; errors made typically only impact timeline (i.e., require additional time to correct).
Using verbal and written communication skills to convey basic, routine factual information about day-to-day activities to others who are fully knowledgeable in the subject area.
Completing most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.
Exercising some creativity to troubleshoot technical problems or deal with novel circumstances.
Using deductive problem solving to solve moderately complex problems; most problems have defined processes of diagnosis/detection; some limited data analysis may be required. The responsibilities of this role do not include:
Financial accountability (e.g., does not involve budgeting responsibility).
Influence over key organizational decisions.
Role in strategic planning.
Principal Duties & Responsibilities
Develops basic features and components of hardware designs in line with product proposals or roadmaps, under the supervision of more experienced engineers.
Applies basic design rules and processes for electronic hardware, equipment, and/or integrated circuitry with minimal supervision from more experienced engineers.
Reads device specification sheets and interprets basic details required to design various hardware features with minimal guidance from more experienced engineers.
Evaluates devices and documents performance over various operating conditions and configurations.
Assists in the assessment of common design features to identify potential flaws (e.g., electrical, mechanical, hardware), compatibility issues, and/or compliance issues under the supervision of more experienced engineers.
Documents basic details about materials, components, chipsets, and assemblies for a device, and records important changes to design with minimal supervision from more experienced engineers.
Troubleshoots basic issues with product designs.
Provides reasonable schedule for own tasks to project lead.
Develops understanding of Qualcomm products.
Seeks basic knowledge of industry trends, competitor products, and advances in various engineering fields from publically available information; requires minimal consultation with more experienced engineers to understand and apply advanced concepts. Additional responsibilities may also include: Develops design implementation, analysis, methodology, flows, and automation for development and validation of System on Chip, electronic parts, components, integrated circuitry, and packaging. Provides design solutions to evaluate, characterize and develop the design implementation solution for leading-edge products in the most advanced processes. Interfaces with various cross functional teams (RF, Analog and Digital IC designers, Software, System Engineering, Test Engineers, Customer Engineering, and Operations) to drive and incorporate the latest design solutions in the production program to improve yield, productivity, and quality.
IT Core Competencies N/A
Required Competencies (All competencies below are required upon entry)
Analytical Skills - The ability to collect information and identify fundamental patterns/trends in data. This includes the ability to gather, integrate, and interpret information from several sources.
Building Trusting Relationships - The ability to build trusting, collaborative relationships and rapport with different types of people and businesses. This includes delivering on commitments and maintaining confidential information, as well as being approachable, showing interest in the other person, and relating well to people regardless of personality or background.
Communication - The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.
Creating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.
Decision Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.
Documentation - The ability to appropriately document software and/or hardware specifications and processes to promote knowledge transfer to other engineers.
Getting Work Done - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.
Hardware Design - Knowledge of and the ability to understand advanced or complex hardware design elements in order to carry out designs, upgrades, and technology roadmaps.
Hardware Infrastructure - The ability to implement and integrate IT hardware for use in business environments and assist in designing its main features according to business needs. This includes the ability to track and report operational problems. This also includes the ability to compare IT hardware across one's own organization and its competitors.
Project Management - The ability to use organizational skills for purposes of planning and decision-making. This includes developing and communicating objectives, timelines, assignments, and goals. This also includes the ability to scope projects, orchestrate multiple activities at once, and use resources efficiently across functional areas within the enterprise.
Additional Competencies N/A
Minimum Qualifications
Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.
Preferred Qualifications
1+ years experience with circuit design (e.g., digital, analog, RF).
1+ years experience utilizing schematic capture and circuit simulation software.
1+ years experience with hardware design and measurement instruments such as oscilloscopes, spectrum analyzers, RF tools, etc.
Physical Requirements
Frequently transports between offices, buildings, and campuses up to ½ mile.
Frequently transports and installs equipment up to 5 lbs.
Performs required tasks at various heights (e.g., standing or sitting).
Monitors and utilizes computers and test equipment for more than 6 hours a day.
Continuous communication which includes the comprehension of information with colleagues, customers, and vendors both in person and remotely.
Applicants : If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport
To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications."
Machine Learning Science Leader,India,CareerXperts,None,Organic,"Passionate about Big Data, Machine Learning and Predictive Software? Interested in leading new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
We are looking for a dynamic Machine Learning science leader to found and head the Data Science function in Bengaluru. As Head of Data Sciences, you will lead a high performing team of scientists and engineers in the development of innovative and rigorous Machine Learning techniques that advance Machine Learning technology for advertising and convert to high impact solutions for the business.
Major responsibilities:
Recruit, coach, and manage a team of scientists and data science engineers, lead cutting-edge research projects, and influence the technical direction of the Ads business.
Innovate and leverage machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Formulate and test hypotheses, extract signals from peta-byte scale, unstructured data sets, and ensure that our display advertising business delivers the highest standards of performance
Collaborate with distributed cross-functional teams on common goals.
Experience
6 + years , Start-up / Entrepreneurial experience preferred.
Qualification
MSc or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field. (PhD preferred).
4+ years of industrial experience in machine learning and predictive modeling, including 2+ years experience in leading junior team members and guiding them on machine learning and data modeling applications.
Proficient in Java, C/C++, or Python (or similar scripting language).
Proficient in R, Matlab, or another statistical software.
Strong communication and data presentation skills.
Preferred Qualifications:
7+ years of industrial experience in predictive modeling and analysis, predictive software development.
Experience handling gigabyte and terabyte size datasets.
Experience working with advertising, retail or e-commerce data.
Experience working with distributed systems and grid computing.
Experience working with distributed teams.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences."
Visualization Analyst - Consumer Analytics,"Bengaluru, Karnataka",Eli Lilly,None,Organic,"At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our 39,000 employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the world.
As Eli Lilly strives to achieve its purpose of making life better for patients, we have been building up our in-house ‘Consumer Experience’ function, which will design and execute next-generation marketing campaigns aimed at informing and educating consumers (or patients) directly.
To support the Consumer marketing teams in their decision-making, a data and analytics team is being set up simultaneously in Indianapolis (HQ) and Bengaluru (LCCI). This team will be responsible for setting up the data warehouses necessary to handle large volumes of digital streaming data, create meaningful analyses, analytics and deliver recommendations to leadership.
As part of the LCCI team, we are excited to offer the role of a BI/visualization analyst who will be an integral part of the Consumer analytics team in 2020 and beyond.
Core Responsibilities:
Model data to create reporting infrastructure/dashboards for descriptive and diagnostic analyses which drive key business decisions for the Consumer marketing teams of Eli Lilly brands in the US
Writing and tuning complex SQL queries and in a highly dynamic environment to map different Consumer Marketing data sources like Google Ad Server, DCM, Double Click, Google Search/Ads. Campaign Metadata, consumer data sources mapping and connectivity through tagging parameters and deidentified ids. Marketing MEASUREMENT expertise highly desirable
Communicate to share knowledge and findings. Presentable to business partners ensuring interpretation, appropriate detail and usability
Perform detailed analysis of source systems and source system data for quality and model
that data in a data visualization tool like Quick Sight, Power BI or Tableau
Ad-hoc queries, reporting, dashboard and views creation, maintenance and automation with drill down visualizations
Continuous learning and experimenting new possibilities for Consumer Marketing Analytics and Analysis. Proactive and enthusiastic to adopt new marketing EDAs
Required

2-4 years of in-depth hands-on experience in data warehousing Redshift or any cloud-based storage like AWS S3 to create and support business/data analytics, business intelligence (Power BI), Quick sight
Proficiency in Joins, aggregations, measurement, create views and stored procedures
Expert level SQL programming skills to create predictive, forecasting and time series models, measurement using Power BI, Quick Sight and Sage maker
Handling large, complex data sets on cloud systems AWS S3 and Redshift.
Strong SQL and Python expertise to access and transform data into insights and visualizations. Automate visualizations and Dashboards
Advanced proficiency in SQL for exploratory data analysis and present findings in visualization, fine tuning code for processing speed with joins aggregation and manipulation of data.
Experience in gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reports and visualizations
Creative problem solving, organization, attention to detail, flexibility and adaptability
Comfort with ambiguity and a willingness to work with a high degree of autonomy
Demonstrated ability to meet deadlines while managing multiple large-scale projects in a fast-paced and rapidly changing environment
Good communication skills (written and verbal) – English
Should be adaptable with changing priorities and open to picking up new technical skills and data processes.

Preferred Qualifications

Experience in Data Engineering for Healthcare/Retail/BFSI/Digital/ Media native companies
Previous experience required in OLTP and OLAP databases like SQL Server/ Oracle
Website pixel tagging, basic HTML
R/Python Development and OOPS preferred
Education:
Bachelor’s degree or master’s degree in technology, Statistics or Computer Science background
Eli Lilly and Company, Lilly USA, LLC and our wholly owned subsidiaries (collectively “Lilly”) are committed to help individuals with disabilities to participate in the workforce and ensure equal opportunity to compete for jobs. If you require an accommodation to submit a resume for positions at Lilly, please email Lilly Human Resources ( Lilly_Recruiting_Compliance@lists.lilly.com ) for further assistance. Please note This email address is intended for use only to request an accommodation as part of the application process. Any other correspondence will not receive a response.
Lilly does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status."
Senior Product Analyst-Glance,"Bengaluru, Karnataka",Glance,None,Organic,"Senior Product Analyst- Glance
Who are we and What do we do?
Glance – An InMobi Group Company:
Glance is an AI-first Screen Zero content discovery platform, and it's scaled massively in the last few months to one of the largest platforms in India. Glance is a lock-screen first mobile content platform set up within InMobi. The average mobile phone user unlocks her phone >150 times a day. Glance aims to be there, providing visually rich, easy to consume content to entertain and inform mobile users - one unlock at a time. Glance is live on more than 100 millions of mobile phones in India already, and we are only getting started on this journey! We are now into phase 2 of the Glance story - we are going global!
What's the Glance family like?
Consistently featured among the ""Great Places to Work"" in India since 2017, our culture is our true north, enabling us to think big, solve complex challenges and grow with new opportunities. Glanciers are passionate and driven, creative and fun-loving, take ownership and are results-focused. We invite you to free yourself, dream big and chase your passion.
What can we promise?
We offer an opportunity to have an immediate impact on the company and our products. The work that you shall do will be mission critical for Glance and will be critical for optimizing tech operations, working with highly capable and ambitious peer groups. At Glance, you get food for your body, soul, and mind with daily meals, gym, and yoga classes, cutting-edge training and tools, cocktails at drink cart Thursdays and fun at work on Funky Fridays. We even promise to let you bring your kids and pets to work.
What will you be doing?
Interact, collaborate and connect with technical, business and product members as well as external partners to foster bottom-up innovation
Work with product managers to ask questions of data and probe deeper with minimal guidance
You will be working on one of India's largest visual content discovery products. Some problems you might focus on:
Launching newer offering content offerings: For example, showcasing live content on the app, or launching vertical video content on the app
Personalization: Working with data sciences & engineering teams to build content personalization
Content Strategy: Working with content teams to refine content strategies basis analytics and user feedback
What do we expect from you?
A strong bias for action. Willingness to dot the i's and cross the t's to make the product successful.
You are expected to have a strong analytical bent and be comfortable with putting the necessary tooling to use to uncover insights.
You should be energetic and willing to learn and excel in a fast paced, cross functional, global environment.
Ability to multi-task and work with a diverse set of stakeholders
Education: Bachelors or Masters in an analytical or technical field; computer science preferred
Functional Area: Product team
Experience: 3+ years of product analyst experience in consumer products and having driven meaningful outcomes using analytics
Skills: Working knowledge of scripting (Perl, Python), databases (SQL, MySQL)"
Java Application Developer - Product Organization,"Pune, Maharashtra","Avocado Systems, LLP",None,Organic,"Job Summary
As a Senior Backend Developer at Avocado Systems, you will be responsible for architecting and building backend Java applications to support our groundbreaking cyber security platform.
Responsibilities and Duties
Design, architect, and build complex Java applications to digest information from large datasets
Lead engineering discussions, technical evaluations, design reviews, and other project discussions
Work with other engineers, Architecture, Product Management, and QA teams to develop innovative solutions that meet business needs with respect to functionality, performance, scalability, reliability, realistic implementation schedules and alignment to development principles and product goals
Qualifications and Skills
5+ years of experience in software design and development, solid foundation in computer science with strong competencies in data structures, algorithms, and software design
5+ years of hands-on experience in Java, Spring Boot, JSON, REST Web Services
Strong experience with relational databases (MySQL, Oracle DB) a major plus.
Experience working in a Product Development a plus.
Experience in using source control systems such as Git or SVN, issue tracking systems like JIRA
Ability to adapt to changing business priorities and to thrive under pressure
BS or equivalent in Computer Science, Computer Engineering, or related field. Masters' a major plus.
Experience in Agile & Lean product development
Job Type: Full-time
Experience:
Java: 5 years (Preferred)
Education:
Bachelor's (Required)
Benefits:
Paid leaves / Leave encashment
Flexible work hours
Industry:
Software Development"
"Manager, Data Science","Bengaluru, Karnataka",Epsilon,None,Organic,"Company Description
Positioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Through a connected suite of products and services, Epsilon combines leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes. For more information, visit us at https://india.epsilon.com/
Follow us on social: LinkedIn, Facebook, Instagram, and Twitter

Job Description
PeopleCloud Customer is a world-class cloud-based Customer Data Platform (CDP) fully enabled with a complete Marketing Automated Operating System (MAOS). The PeopleCloud Customer platform provides out-of-the-box SaaS and PaaS products that are fully integrated, including Customer Identity services, Deterministic and Probabilistic Customer Record stitching services and Marketing Machine Learning algorithms and models trained to deliver personalized activation at scale.
The PeopleCloud Customer team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group.
You will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the COSMOS Cognitive Marketing Intelligence Cloud Platform team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects.
Provide guidance to the team of Data Scientist and manage Machine learning and Deep Learning based projects. Work with the team who analyze complex data structure, manipulate, cleanse data and perform statistical analysis
Design and guide machine learning models using Spark ML, Python, HDFS, Spring.
Design and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python
Develop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory
Own end to end implementations of multiple Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.

Qualifications
Experience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks
Strong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Proven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results.
Expertise in predictive analytics/statistical modeling/data mining/machine learning algorithms and techniques (classification, clustering, regression, multivariate testing)
Excellent communication & interpersonal skills with an ability to communicate ideas.
MS in Computer Science, Math, Physics, or equivalent education/professional experience is required.
10-12 years of total IT experience with 5+ years of managing and leading data science teams with demonstrable experience
Deep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services.
Azure Cloud experience required. Azure Data Factory experience preferred.
Strong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch
Experience with sequence modeling using RNNs/LSTMs is must
Strong experience in at least one database technology (i.e. Hive, PrestoDb etc.)
Experience with one or more web analytics tools (Google Analytics, etc.)
Strong experience in at least one programming language (i.e. Python, R, C, C++ is plus)
Experience working with different query languages (i.e. PL-SQL, T-SQL)
Understanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred.
Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)
Strong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Excellent communication & interpersonal skills with an ability to communicate ideas, insights and complicated analysis effectively at all organizational levels, include engineering leadership

Additional Information

null"
Data Engineer,"Jadavpur, Kolkata, West Bengal",KPC Medical College & Hospital,None,Organic,"Qualification-Bachelor degree or equivalent professional experience can be accepted in lieu of education. Specifications: Education & Experience Requirements: BA/BS from a College or university and/or related experience and/or training or equivalent combination of education and experience in Computer Science, Data Engineering and Analysis Hands on experience with Microsoft Stack- SQL SSIS, SSAS, SSRS etc. Preferred experience with Agile development process and SDLC Preferred experience with large scale data lake or warehouse implementation and support Preferred experience in hybrid cloud (On prem, AWS/Azure) environment Desire to provide outstanding customer service.
Job Summary-Provides the business knowledge and technical skills to implement technical strategies, evaluate products and provide a superior level of technical support. Data Engineer will be responsible for implementing ETL solutions that deal with various types of challenging data and should also possess knowledge of SQL, PL/SQL (procedures, functions) and scripting languages. The ideal candidate should have outstanding analytical and problem-solving skills and a good grasp of the technical side of business intelligence and always keep up to date with the latest BI tools and technologies. 4+ years of IT and business/industry work experience developing data or software applications including: analysis, design, coding, testing, deploying and supporting of applications Research and deploy new technologies to assist data access, integrity and availability Proven experience (minimum 2 years) with one or more of the following database systems and tools in a Windows environment is required: MS SQL Server (T-SQL, SSIS), Oracle, SSRS, SSRS, Tableau or any visualization tool experiences are a plus. Integrate data from multiple disparate systems - using SQL Server, Oracle, PL/SQL, SFTP process, scripting etc. Develop and optimize complex scripts in MS SQL to meet organizational requirements for reporting, BI and analytics Documental requests from business system owners for data access, integrations and reporting According to Company’s SDLC and Change Management. Collaborate with App/Dev, Habit IT and business system owners on resolution to complex/challenging issues that arise out of data access, integrity, availability and transformation Work collaboratively across the organization to address and predict data performance bottlenecks Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format. Utilize a combination of open source and in house developed software to meet company goals. Possess a sound understanding of areas of Computer Science such as algorithms, data structures, object-oriented design, and databases. Familiarities with Shell, Batch, PERL, Python/R and Machine learning concepts are a plus.
Send your resume to [email protected]"
Python Developer,Maharashtra,Globus Technologies,None,Organic,"Are you seeking an environment where you can apply state-of-the-art computer science techniques, data-driven decision making, and problem solving skills in a real world setting? Do you want to build large-scale reliable, fault-tolerant distributed systems and write interactive tools that directly impacts quality of work and productivity of tens of thousands of people processing billions of dollars' worth of inventory every year?
In this role, you will have an opportunity to own, design, and develop software services that interacts with ERP, Web Application, Mobile Application technologies. You will have influence on subsystem design and help build a team culture around practices that are critical to a quality product. Your work would be cross-functional with other teams in Globus TechTree, including Cloud, Web, Mobile Apps etc.
We are looking for someone with a go-getter attitude who is ready to own a problem and passionately drive successful implementation. We want someone who is a quick learner and ready to adopt latest computer science technologies.
Solid experience in Python and dJango
Solid experience in C++ or Java (expert in at least one)
Solid UNIX or Linux experience.
Experience with scaling and performance of large systems
Proven technical leadership experience
1+ years of solid industry experience
Good knowledge of HTML5, CSS3 and JavaScript
Bachelor's or Master's Degree in Computer Science or related field
Computer Science fundamentals in object-oriented design
Computer Science fundamentals in algorithm design, problem solving, and complexity analysis
Outstanding interpersonal and communication skills
Obsession with quality and customer experience Attention to detail coupled with ability to think abstractly"
AI NLP ENGINEER,"Pune, Maharashtra",NLPBOTS,None,Organic,"Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.
To succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.
What we look for: -
Advanced proficiency in the following:
1. Python
2. Natural Language Processing
3. Deep Learning
4. Machine Learning
5. Numpy, Scipy, Pandas
6. Data Science
7. MongoDB
8. NoSQL
9. SQL
10. Big Data
Experience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)
Self driven individual with a drive to learn the latest in the technology.
Exceptional team player.
Ability to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.
Good understanding and knowledge of enterprise PDLC.
Research mindset with the courage to try things and learn from them."
AI Developer,"Pune, Maharashtra",GrayRipples.com,"₹40,000 - ₹50,000 a year",Organic,"Job Description
Develop custom reports and analytics, dashboards for the various business requirements.
Work with data ETL and data analysis packages and workflows.
Create frameworks using ML models, using symbolic reasoners, and populating knowledge bases or graphs.
Ability to meet the timelines set.
Prepare Unit test scripts and execute as required. Provide maintenance and support for the system and execute any change requests as required.
Deliver design and development of the enhancements raised by the business.
Design test cases and test scripts under own direction, mapping back to pre-determined criteria, recording and reporting outcomes.
Expected Profile
Bachelor’s degree in Computer Science or a similar technical field, or equivalent practical experience.
1 year of work experience.
Experience in JavaScript, and one or more programming languages including but not limited to: Java, C/C++, Python or Go.
Experience in working with front end technologies and/or front end frameworks.
Demonstrated commitment to learning about AI through your own initiatives through courses, books, or side projects.
Good problem-solving skills and logical reasoning skills is required.
You will bring a passion for Artificial Intelligence and an eagerness to be a part of a global Artificial Intelligence initiative.
The ideal candidate must have proven expertise in Artificial Intelligence(including deep learning algorithms),Machine Learning and/or NLP
Job Types: Full-time, Temporary
Salary: ₹40,000.00 - ₹50,000.00 per year
Experience:
software development: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
java: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Business Analytics Specialist,"Hyderabad, Telangana",Microsoft,None,Organic,"Organization Summary:
The AnswersHub team is part of the Shared Business Operations (SBO) team, who’s mission is to continuously modernize our operational capabilities, enabling Microsoft to accelerate Customer value.
Our role within the organisation is critical to enabling the transformation to modern operations, through solving issues, identifying systemic problems and driving improvements related to role experiences within the Connected Customer Experience ecosystem.
Our team works with SBO and key stakeholders in the Microsoft Consulting Services and the Customer Support organisations to prepare for transformational changes, to work in collaboration with change management teams and ultimately to support the field through change and out the other side, by finding and orchestrating the awareness, prioritization and fix of problems. We gather feedback to help shape the future.
In short, AnswersHub helps to ensure that our field roles can maximize their focus on our customers.
Position Description:
We are looking for a strong Operations minded, Business Analytics Specialist to join our team who will enable and empower our Services Answers through insights. Doing so by creating a mature data driven culture, aligned across the 5 motions of work (described below) and drive effective integration into partner and stakeholder ROBs.
You would be an experienced leader, who can understand the work we do, create a vision for how we use data aligned to the Objectives and Key Results and create and execute a plan to achieve that vision. On the journey you would be expected to be an initiator of action where our insights highlight opportunity. Additionally you will put in place and govern data quality controls and develop our data strategy and relationship with peer groups for AI/ML.

Our culture is built around attributes that drive our every decision and our every action:
Customer Obsession - we exist for and because of the customer. We need people who share that passion and drive to make our customers experiences easy, insightful and trusted.
Growth Mindset - we value all perspectives and reward individuals that poke at the edges of what they know to be true. We are seeking people that think differently and are biased toward action to accomplish great things.
Diverse & Inclusive - we enable people who bring a contemporary view to shape our internal teams and encourage all to feel included.
One Microsoft - we collaborate and value the work of others, combining their learnings with our own to make a better outcome for our customers.

Responsibilities
Responsibilities:
General
Act as an evangelist and catalyst for the generation of actionable BI & Analytics
Build and develop operational analytical models working alongside key roles in our end to end ecosystem, who will leverage the solutions you build in their day to day roles.
Engage broadly with our partner insights team to leverage their ML/AI best practices where there is opportunity to apply to accelerate or increase our impact
Manage the data and insight portfolio of work for the AnswersHub team and apply necessary data governance controls and ROB.
Enable the AnswersHub Motions of work
Readiness
Insights assessments – support planning processes to determine taxonomy and onboarding of new work into our operational suite of data.
Preproduction – ensure that debug and testing is completed end to end such that accurate and agile insights are available on day 1 of a new transformation support motion.
Automation
Integrate insights – bring in telemetry and field data from our automation engines including our self-help bot / processors and where applicable feed automation to optimize the user experience.
Efficiency
Baseline Measurements – Enable us to identify, quantify and measure improvements in our operating model to reduce time, skill and what we pay for a given set of activities.
Delivery
Data integrity & agility - Ensure we have a taxonomy strategy / framework to bring together insights from multiple input streams, identify problems and collect field feedback & context by role and organisation.
Controls - Enable operations to self-monitor for manual data entry errors and perform timely correction.
Shift Left – Implement reporting that helps prioritize where work can be either automated or moved down to self-help.
Knowledge management- Implement insights that help us predict and find gaps or deficiencies in our knowledge assets, all the way from self-help in our support BOT, to agent based assets who are triaging new issues.
Partner Integration – establish integration where appropriate to exchange operational data and insights with our partner ecosystem.
Problem management
Predictive insights – Ensure insights enable us to find and quantify problems fast and to track them through to resolution.
One backlog – enable a single backlog, that can be tracked to the necessary grain in order to understand the accountable team / organisation and status.
Enable our Rhythm Of Business (ROB)
Performance Management – Create and maintain our scorecards so that we can track against our committed Objectives & Key Results (OKSs)
Manage the portfolio of work including monthly governance with stakeholders
Team enablement – enable each role in our team to have the insights and tracking needed for them to achieve the core components of their role.
Governance – Partner to apply advanced analytics concepts towards rich and bold AI based insights.
Communications – Enable us to tell a data driven story using insight assets. Automate reports that allow the field to know what problems we are aware of and the actions we are doing to address these.

What Do You Need to Succeed?
You appreciate and are an advocate of diversity and inclusion in a company workplace.
You have a clear understanding of financial and operational risk and mitigation.
You are a critical thinker, who can relate effective risk management to business and operations objectives.
You have the ability to manage complex projects or programs across a company with a truly global footprint.
You have a desire to build actionable insights and monitoring structures that have a direct positive impact on enabling our organisation to meet key company goals and strategies.
You like to use data to drive decisions, yet are comfortable giving direction and provide clarity where ambiguity exists.
You appreciate how through a ‘Growth-Mindset’ we can drive excellence in risk management to allow Microsoft colleagues and partners to ‘Achieve More.’
You thrive in a fast-pace environment where you can multi-task a variety of initiatives, always working effectively to deadlines.
Routine bores you. You are inquisitive, like new challenges and are an agent of change
Qualifications
Basic Qualifications:
10+ years of analytical hands on experience in an operational
Other Qualifications:
Statistics - Basic probability distributions, estimation techniques, confidence intervals, hypothesis testing (z-test, t-test, ANOVA etc.). Understanding of Maximum Likelihood Estimation is a plus
Programming - Hands-on in R/Python and experience in using different Statistics/ML libraries available
Data Visualization - Experience in one or more Data Visualization tools (MS Power BI, Tableau etc.)
Data engineering - Hands-on in SQL and experienced in working with RDBMS for data extraction and data read/write. Understanding of Data Warehouse fundamentals (architectural layers & schema types) is a plus. Familiarity with big data technologies (COSMOS, Hadoop, MapReduce)
Masters in Statistics/Econometrics or PhD in Statistics/Economics/Computer Science or related discipline is preferable, but a candidate with MS combined with strong analytical background in problems relating to Big Data and Analytics is also acceptable.
PERSONAL ATTRIBUTES/INTERPERSONAL SKILLS:
Excellent written and oral communication skills, particularly the ability to synthesize complex issues/scenarios into easy-to-understand concepts.
An attention to detail with self-discipline and a drive for results.
Demonstrated ability to work in ambiguous situations and across organizational boundaries."
Senior Expert Data Scientist,"Hyderabad, Telangana",Novartis,None,Organic,"Your responsibilities include, but are not limited to:

Responsible for all data science tasks on the assigned clinical or non-clinical projects, and perform these tasks for mid- to high- complexity projects with a good level of independence. Responsible for implementing data science planning, data provisioning, analytical activities including exploratory analyses, reporting and communication of methods and results, ensuring reproducible and agile ways of working.
Contribute to planning and execution of exploratory analyses, and/or PK, PK/PD analyses, exploratory biomarker and diagnostic analyses, and data science consultation. Initiate, drive and implement novel and innovative methods in alignment with other quantitative team members.
Explain data science methodology and interpret analysis results. Provide data science expertise to support submission activities, meetings with and responses to Health Authorities and other drug development activities, as required.
Contribute to interactions with external review boards/ethics committees, external consultants and other external parties with oversight as appropriate. Represent Novartis in data science discussions at external congresses, conferences, scientific meetings.
Represent the Analytics Line Function on cross-functional teams for the assigned projects. Responsible for functional alignment and ensuring line function awareness throughout the assigned projects.
Collaborate with other line functions. Explain methods and results in a manner easily understood by non-analytical folks, and provide adequate justifications, sensitivity analyses for actions/decisions/statements, when required.
Establish and maintain sound working relationships and effective communication with the Clinical Colleagues and Biostatistics & Pharmacometrics team.
Understand complex and critical business problems, formulates integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. High agility to be able to work across various business domains. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact.

Minimum requirements
MS (in Statistics or equivalent) with 4+ years relevant work experience or PhD (in Statistics or equivalent) with relevant work experience (including internship)
Good communication and presentation skills.
Experience/Professional Requirement, Influences decisions that directly impact the assigned clinical trial and team ability to deliver objectives.
Proven knowledge and expertise in data science and its application to clinical trials. Depending on the assignment, may require proven expertise in pharmacokinetics, exposure-response modelling, exploratory biomarker, diagnostic analyses, applied Bayesian statistics, or data exploration skills. Proficiency in use of software packages (e.g. Python, R).
Knowledge of drug development and Health Authority guidelines. Able to work on a multidisciplinary team to achieve team objectives.
Experience in Franchise/Therapeutic Area and/or regulatory activities would be advantageous

Why consider Novartis?

799 million. That’s how many lives our products touch. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

We are Novartis. Join us and help us reimagine medicine.

Novartis are an equal opportunities employer and welcome applications from all suitably qualified persons.
Division
Global Drug Development
Business Unit
CD&A GDD
Country
India
Work Location
Hyderabad, AP
Company/Legal Entity
Nov Hltcr Shared Services Ind
Functional Area
Data & Digital
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
Data Scientist / Research Analyst,Andhra Pradesh,Franklin Templeton Investments,None,Organic,"Data Scientist / Research Analyst-834654

At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Research Analyst / Data Scientist in Investment Management team responsible for?
Partner with investment teams to provide machine learning / AI / Data Analysis expertise to enhance investment decisions and returns. Engage Chief Investment Officer (CIO) and Portfolio Managers in investment team meetings; present and share investment ideas, insights and results
What are the ongoing responsibilities of the Data Scientist?
Engaging Portfolio Managers in investment team meetings; present and share investment ideas, insights and results
Selecting/creating features from raw data, and building/optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending the data used in modeling with third party sources of information
Processing, cleaning, and verifying the integrity of data used for analysis
Conducting ad-hoc analysis and presenting results in a clear manner
Creating automated data consistency checks (e.g. between live/historical data) and unit testing techniques to ensure ongoing model performance
Building, deploying, and maintaining ML models in cloud environment

What ideal qualifications, skills & experience would help someone to be successful?
Bachelors or Master’s with 4+ years of coding and data science experience
Experience in US CLO Research is a big plus
Prior experience in Investment Management / Financial Services / FinTech is a must
Experience in Fixed Income Modeling/Quant (or) Research Experience in US Securitized Products or Corporate Credit is a plus
Professional certifications such as Certified Financial Analyst (CFA), Financial Risk Manager (FRM), or Chartered Alternative Investment Analyst (CAIA) are preferred
Requires advanced skills in Python- especially Pandas
Must be able to produce code in Python at a rapid rate
Experience with supervised/unsupervised machine learning techniques, especially tree-based algorithms, and k-means clustering. Neural networks experience is a plus, especially with RNNs and CNNs
Experience modeling and making sense of complex systems
Must have at least 4+ years of coding experience
The applicant must have a strong underlying coding ability
Must have strong applied statistics skills, such as understanding of distributions, hypothesis testing, and probability
Great communication skills and experience with data visualization tools in Python
Proficiency in SQL is a plus. Must be able to write basic queries at minimum
Experience with high performance computing is a plus (e.g. cluster computing on Azure with Spark/Hadoop)
Masters/PhD in a quantitative discipline is a plus, but is not required
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.
Highlights of our benefits include:
Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.
JOB FUNCTION: Data Science and Analytics
PRIMARY LOCATION: India-Andhra Pradesh-Hyderabad
SCHEDULE: Full-time
JOB POSTING DATE: Aug 2, 2020, 11:37:27 PM"
PYTHON/DATA ANALYSIS,"Kochi, Kerala",UVJ Technologies,None,Organic,"PYTHON/DATA ANALYSIS – Job Code(PYD – 04)
Experience with Python to implement data analysis workflows in a Linux environment.
Experience evaluating and improving the efficiency of programs in a Linux environment.
Experience with command line compilation and debugging.
Experience with makefiles, coverage analysis and other forms of runtime profiling.
Experience with all phases of the Software Development Life Cycle.
Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
Working knowledge of MS Office suite of applications.
Working knowledge of Bioinformatics, Genomics, or Life Sciences
Good verbal and written communication skills.
Ability / willingness to learn bioinformatics / genomics

If you are interested in any of the positions mentioned above, Please attach your updated resume to resume@calpinetech.com with an email explaining the position you are looking for, your career goals and your expected salary. Please indicate the job code in the subject line of your email."
Data Engineering,"Chennai, Tamil Nadu",Blackstraw,None,Organic,"Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups, synchronization, and policy access.
Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their usability for the client’s data scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate an effective team
relations.
Essential Qualifications:
Bachelor’s degree in computer engineering.
Demonstrated experience and knowledge in Big Data and NoSQL databases.
Demonstrated experience and knowledge in Object-Oriented Programming.
Demonstrated experience and knowledge in distributed systems.
Proficient in programming languages: Python.
Experience designing and implementing data warehouses.
Experience developing ETL pipelines.
Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
Good Problem-solving capabilities.
Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
Proactive attitude, resolutive, used to work in a team and manage deadlines.
Ability to learn quickly.
Be familiar with agile methodologies development (SCRUM/KANBAN).
Ability to communicate effectively in English both written and spoken.
Preferred Qualifications:
Master’s degree in data engineering or related.
Experience managing deep learning datasets.
Experience managing Cassandra.
Experience working with Spark.
Experience implementing CICD pipelines for automation.
Company Profile:
Conceptualized as far back as 2015, and commencing full-time operations in 2018, Blackstraw LLc. is a software products and services company specializing in Artificial Intelligence (AI) and Machine Learning solutions for various industries. We support businesses around the world, including North America, Europe and Asia, working to simplify AI implementation through our platform that expedites data labelling, AI model-training, and, cloud or on-premise deployments.
With more than 100 years of combined work-experience, the 100+-strong Blackstraw team comprises various experts in the AI value chain. We are a fast-moving team that prides ourselves in rapidly identifying different use-cases and fine-tuning our products to suit specific business needs.
We are focused on providing solutions related to computer vision, natural language processing, Data annotation tool for deep learning models, etc. To stay competitive in business, it is key for organizations to adopt and implement smart AI solutions and service offerings. However, most companies are unable to implement AI rapidly due to the complexity of existing solutions, inadequate data and cost implications.
Our mission is to enable enterprises to adopt AI in an easier, cost-effective and time-efficient manner with a plug-and-play approach to their data.
Blackstraw operations are based out of Mumbai, Pune and Chennai in India."
Data Visualization,"Chennai, Tamil Nadu",Bloom Consulting Services,None,Organic,"Looking for a person who is good at visually communicating the Story !!
A good end to end Experience in Data Visualisation tools like Tableau, QlikView, Microstrategy, Superset, imply, etc
Hands-on Experience in SQL, Data Analysis Skills
Hands-on experience with Big Data Tools and skills (Spark Streaming, Kafka, Druid, Hive, HBase, etc..)
Web UI Design with JAVA would be nice to have
Use of AWS Stack knowledge would be good to have
Proficiency of relational and dimensional data modeling and core reporting
Self Starter with an attitude to try new things and do POC's

DATA SCIENCE:

Must to have:
Python
Data and Statistical modeling
AWS SageMaker (Machine learning)
SAS
What You Need for this Position
You should have knowledge of:
Python
Data and Statistical modelling
AWS SageMaker
SAS
Aditional
No. of Positions
Education level
Career level
Experienced"
Software Engineer,"Bengaluru, Karnataka",PhonePe,None,Organic,"Software Engineer

Job description About PhonePe : Our goal is to make digital payments so easy, safe and universally accepted that people never feel the need to carry cash or cards again. We believe India is at the cusp of a new mobile revolution, which will change the way we manage our money on the go. We see ourselves facilitating this change, through technology and dogged customer centricity. At PhonePe, we take extra care to make sure you give your best at work, Everyday! And creating the right environment for you is just one of the things we do. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one.Being enthusiastic about tech is a big part of being at PhonePe. If you like building technology that impacts millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us! Role
As a software engineer,
You will translate high level business problems into scalable design and code.
You will write performant, unit-tested code, develop object-oriented models and design data structure for new software projects taking systems aspects into account
Responsible for End-to-end service design including API definitions and implementation for large services
Driving discussions to improve product across teams where ever there are inter dependencies across products
Proactive communication to team lead and stakeholders As a software engineer, you must have
Deep expertise in at least one programming language (e.g. Java, C, C++) & tech stack to write maintainable, scalable, unit-tested code.
Understanding of object oriented design skills, knowledge of design patterns, and huge passion and ability to design intuitive module and class-level interfaces
Ability to channel high-level guidance to direct the building of large and complex business applications and platforms.
Go-getter attitude that reflects in energy and intent behind assigned tasks
Experience with full life cycle development in any programming language on a Linux platform
Deep understanding of design patterns, optimizations, deployments and tuning
Knowledge of Test Driven Development
Basic understanding of databases (e.g. MySQL) and NoSQL (e.g. HBase, Elasticsearch, Aerospike etc)
BTech, MTech, or PhD in Computer Science or related technical discipline (or equivalent).
Experience of having been a software engineer for at least 2+ years. As a software engineer, good to have
Drive problem solving skills for high-level business and technical problems.
Multi-perspective approach to developing object-oriented models, designing data structure and building applications and platforms that can scale.
Prior experience in working with Agile software methodologies (XP, Scrum) Job location Bangalore"
Data Scientist,"Bengaluru, Karnataka",Bottomline Technologies,None,Organic,"Bottomline is at the forefront of digital transformation. We are a growing global market leader uniquely equipped to address the changing needs of how businesses pay and get paid. Our culture of Working with and for each other enables us to delight our customers. We empower our teams to think like owners driving customer delight, helping them grow their business and win in their markets.
We are looking for Data Scientist to innovate, win, and grow with us in Bangalore, India.
As a member of Central Data & Analytics Team, you will be developing software to be used for a range of machine learning and data mining techniques, including predictive modeling, anomaly detection, customer profiling and segmentation, recommendations, text analytics, and big data analytics in solving our business problems. You will take an idea from conception and experimentation to design and implementation to deployment and production. In this role, you will interact with a team of experts in Machine Learning and Data Mining.
How you'll contribute:
Exposure to the sate-of-the-art of data analytics products and solutions.
Ability to prototype statistical analysis algorithms
Experience in coding structures for storing and processing complex, high volume, and multi-dimensional data
Experience in optimizing space/time tradeoffs for computationally expensive processes
Exposure to different Machine Learning techniques
Familiar with Agile software development process.
What will make you successful:
At least 2 years' professional experience in with major programming languages such as Java, Python, Scala
A completed graduate degree in Computer Science, Engineering or any other heavily numerate subject
Understanding of the full software development lifecycle (conduct data analysis and build large-scale machine-learning models/pipelines)
Experience in Big Data technologies (Hadoop, Spark), large relational and NoSQL databases
Experience in data pre-processing, Machine Learning, and data visualization
Experience in quantitative analysis and translation of findings into actionable insights
Outstanding communication and presentational skills
You'll love Botttomline because in everything we do we seek to delight our customers and we are passionate about building a company of which we can all be proud, and this starts with building amazing teams filled with team members that challenge you every day.
Start your #LifeAtBT
Public cloud AWS, ML, DL, NPL, Python, Java, Scala, Hadoop, Spark, Docker, Kubernetes, Agile, Scrum"
Senior Data Scientist,"Bengaluru, Karnataka",Myntra.com,None,Organic,"Myntra’s Engineering team builds the technology platform that empowers our customers’ shopping experience and enables the smooth flow of products from suppliers to our customers’ doorsteps. We work on areas such as building massive-scale web-applications, engaging user-interfaces, big-data analytics, mobile apps, workflow systems, inventory-management etc. We are a small technology team where each individual has a huge impact. You will have the opportunity to be part of a rapidly growing organization and gain exposure to all the parts of a comprehensive ecommerce platform.
You will be part of: Data Science

Data Sciences team at Myntra uses data and algorithms to build large scale systems to enable better decision making for the business as well as render better customer experience. Some of the areas of our focus are Personalisation, Pricing, Demand Sensing, Recommendation Systems,
Search etc. Some of the cool things we are working on !
Decoding Fashion Contexts using Word Embeddings. Building novel algorithms for fashion Personalization & Recommendations. Building dynamic pricing models and novel metrics to evaluate to improve the experience. Building prediction models to improve delivery promise times. Building optimization models to improve supply chain cost
Your Responsibilities:

Technical Guidance : As a data scientist, you will have the opportunity to leverage Myntra’s rich data to develop data products that are used by millions of users and propel the growth of our business. You will collaborate with a strong team of engineers, product managers and fellow
data scientists in defining the frontier of data products. Data scientists will work on how to evaluate potential approaches, build features,statistical/machine learning models and determine metrics. You will communicate insights/recommendations to a wide spectrum of
stakeholders across the company.
Execution and Delivery : You will be expected to instill and follow good software development practices and ensure timely delivery of high-quality products. You should be familiar with agile practices as well as be able to adapt these to the needs of the business, with a constant focus on product quality.

Desired Skills and Experience:
Must have a Phd or a related field. Strong understanding of object-oriented programming, concurrency and fundamentals of computer-science.
2 years industry experience developing machine learning models sat scale from inception to business impact.
Deep understanding of modern machine learning techniques and their mathematical underpinnings such as classification, recommendation systems , and natural language processing.
Proven ability to tailor machine learning solutions to business problems in a cross-functional team.
Experience with distributed machine learning and computing framework (Spark, Hadoop, Mahout or equivalent) . Applied experience preferred.
Strong programming skill (Python, R, or Scala preferred).
Experience productionizing machine learning models is a plus.
High proficiency in at least one of the following broad areas:, Machine learning, Computer vision, Statistical modeling/inference, Information retrieval, Data mining or NLP

Requirements

Technical depth : You have the strong technical competence required to gain credibility. Ability to architect, design and code yourself. Technical experience in building and operating web-based applications. Deep understanding of all layers of the web-stack work (from the client
interface to the database. ) Knowledge of multiple technology stacks/languages/tools and their pros/cons.
Execution ability : Focus on delivering products in a timely manner with high quality. Familiarity with multiple software development practices and tools, and the proven ability to adapt, champion and institute good practices and tools."
Data Engineer,"Bengaluru, Karnataka",Huron Consulting Group Inc.,None,Organic,"Huron is redefining what a global consulting organization can be. Advancing new ideas every day to build even stronger clients, individuals and communities. We’re helping our clients find new ways to drive growth, enhance business performance and sustain leadership in the markets they serve. And, we’re developing strategies and implementing solutions that enable the transformative change they need to own their future.

As a member of the Huron corporate team, you’ll help to evolve our business model to stay ahead of market forces, industry trends and client needs. Our accounting, finance, human resources, IT, legal, marketing and facilities management professionals work collaboratively to support Huron’s collective strategies and enable real transformation to produce sustainable business results.

Join our team and create your future
Position Summary:
4 to 7 years of hands on experience as a data lake, data warehouse, /analytics developer
Experience with Data Modeling and data mapping methodologies
Good technical abilities in AWS (S3, lambda, kinesis), Python and SQL : problem solving, coding and debugging skills
Hands on experience with Database (such as Oracle, MS SQL Server, MySQL, PostgreSQL), NoSQL (such as HBase, MongoDB, Cassandra, Cosmos, Arango, Orient) and Data Warehousing (such as Microsoft Azure DW, Redshift, Teradata, Vertica) and data migration, ETL (AWS Glue, Azure Data Factory, Informatica, SSIS, etc.) and integration
Building highly scalable, robust & fault-tolerant systems and capabilities
Experienced in creating large data pipelines (via tools and code level- Python R | Spark)
Creating a complete solution by integrating a variety of programming languages & tools together.
Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external partners/virtual teams.
Qualifications:
Experience with Big Data, Basic Data Science, Statistics, Machine Learning & Modeling is a plus
Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps 3.
About Huron:
At Huron, we’re redefining what a consulting organization can be. We go beyond advice to deliver results that last. We inherit our client’s challenges as if they were our own. We help them transform for the future. We advocate. We make a difference. And we intelligently, passionately, relentlessly do great work…together.
Are you the kind of person who stands ready to jump in, roll up your sleeves and transform ideas into action? Then come discover Huron.
Whether you have years of experience or come right out of college, we invite you to explore our many opportunities. Find out how you can use your talents and develop your skills to make an impact immediately. Learn about how our culture and values provide you with the kind of environment that invites new ideas and innovation. Come see how we collaborate with each other in a culture of learning, coaching, diversity and inclusion. And hear about our unwavering commitment to make a difference in partnership with our clients, shareholders, communities and colleagues.
We offer a competitive compensation/benefits package. Huron is an equal opportunity employer. We recruit, employ, compensate, transfer, promote and train without regard to race, color, creed, religion, national origin, sex, marital status, pregnancy, disability, sexual orientation, veteran status, age, FMLA status or any other basis protected by law.
LI:"
Senior Software Engineer – Big Data,"Chennai, Tamil Nadu",Sysvine Technologies,None,Organic,"Responsible for delivering high-value next-generation products to write high-quality, highly optimized/high-performance and maintainable code
The position is for a project for a multinational client of ours who builds platforms for retail analytics using big data
The project is long-term, probably 3-5 years
Desired Candidate Profile
Experience with Python or Scala in HDFS, Big Data Technologies
Apache Spark with Python or Scala, preferable with AZURE HDInsight
Hands on experience with RDBMS Design, preferable with Hbase, Hive, or Cosmos
Good knowledge of Data architecture, Big Data architecture, and ETL processes
Design and development of data ingestions, reporting, analytics and visualization
Education/Specific Knowledge
B.S. or M.S in Computer Science or relevant discipline
PG: ME/M.Tech – Computers or Any Specialization
Doctorate: Doctorate not required
Key Skills
Big Data, HDFS, Cosmos, Reporting, Analytics, HBase, Big Data Architect, Hive, Software Engineering"
Software Engineer - Equity Derivatives,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
GLOBAL MARKETS
Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.
Your Impact:
The Equity Derivatives Engineering team is a front-office business facing team responsible for development of critical applications and infrastructure for the Equity Derivatives business. We work closely with trading, quants, structuring, ops and other teams in a dynamic and fast-paced environment. The team is involved in the full project lifecycle (analysis, design, development, release, support) across a wide variety of projects including new business initiatives, automation, efficiency, analytics and controls.

RESPONSIBILITIES AND QUALIFICATIONS:
Responsibilities

This is an exciting opportunity to join an expanding team leveraging technology to transform the way we conduct derivatives business and to deliver the most complex transactions for our clients. The role will be suited to a strong technologist with a keen interest in business workflows, derivative products and financial markets.
The successful candidate will need to:
Develop an in-depth understanding of Equity Derivatives front office business, flows and systems, with particular focus on Exotics, Fund Products and Structured Transactions
Form strong partnerships with trading, operations, quants, and other engineering teams
Drive commercially impactful engineering projects to deliver key desk initiatives
Strive for continuous improvement in the effectiveness and stability of the front office stack
Maintain a strong risk and control mindset to mitigate operational & technology risks
Become proficient in Goldman Sachs’ proprietary database and scripting language (SecDB and Slang) and other languages as necessary
Basic Qualifications
Bachelor’s or Master’s degree in Computer Science, Computer Engineering or related field
Strong technical, analytical and problem-solving skills
Strong programming skills in at least one OO/scripting language (e.g. Java, Python, C++)
Experience working with databases and datasets (modelling, querying)
Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
Excellent verbal/written communication skills and ability to work across teams
Ability to work in a fast paced environment whilst maintaining strong attention to detail
Highly motivated with a strong sense of ownership and desire for impact
Preferred Qualifications
Previous experience in a business-facing, front office engineering role in the finance industry
Knowledge of equities markets and experience with derivatives products such as options, swaps or exotics
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Python/Data Analysis-Job Code(PYDAT-14),"Kochi, Kerala",Calpine Group,None,Organic,"Looking for candidates with 4-6 years of experience working in Python development with Data Analytics.
The development team should have the following expertise as mentioned below:
Experience with Python to implement data analysis workflows in a Linux environment.Experience evaluating and improving the efficiency of programs in a Linux environment.Experience with command line compilation and debugging. Experience with make files, coverage analysis and other forms of runtime profiling.Experience with all phases of the Software Development Life Cycle.Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail. Working knowledge of MS Office suite of applications.Working knowledge of Bioinformatics, Genomics, or Life Sciences.Good verbal and written communication skills.Ability / willingness to learn bioinformatics / genomics.
Extra Credit: Experience designing relational databases and working knowledge of SQL.Experience with the Common Workflow Language (CWL). Experience with Arvados.Experience with PERL. Experience with JAVA. Extra credit: Experience with C++. Experience working with AWS. Experience working with docker. Candidates with adequate qualification such as BE, BTech,MCA may only apply to this position.
Job Type: Full-time
COVID-19 considerations:
Scheduling of initial rounds of interviews via Skype/Phone.
Experience:
python: 4 years (Required)
Data Analytics: 3 years (Preferred)
total work: 4 years (Required)
Education:
Bachelor's (Required)"
Data Visualization,"Chennai, Tamil Nadu",Bloom Consulting Services,None,Organic,"Looking for a person who is good at visually communicating the Story !!
A good end to end Experience in Data Visualisation tools like Tableau, QlikView, Microstrategy, Superset, imply, etc
Hands-on Experience in SQL, Data Analysis Skills
Hands-on experience with Big Data Tools and skills (Spark Streaming, Kafka, Druid, Hive, HBase, etc..)
Web UI Design with JAVA would be nice to have
Use of AWS Stack knowledge would be good to have
Proficiency of relational and dimensional data modeling and core reporting
Self Starter with an attitude to try new things and do POC's

DATA SCIENCE:

Must to have:
Python
Data and Statistical modeling
AWS SageMaker (Machine learning)
SAS
What You Need for this Position
You should have knowledge of:
Python
Data and Statistical modelling
AWS SageMaker
SAS
Aditional
No. of Positions
Education level
Career level
Experienced"
Risk Analytics - Machine Learning Engineer,"Chennai, Tamil Nadu",DTCC,None,Organic,"About this Opportunity
The incumbent will be responsible for studying data, discovering the information hidden and help making smarter and better decisions for the Business. The primary focus of the role will be on applying text and data mining techniques, doing statistical analysis and building high quality and high-performance prediction systems integrated with the Risk applications. They will also have proven experience in data analysis, modeling and implementing solutions along with sound understanding of capital markets and financial risk domain to be able to recommend the best-fit model and solution approach.
Business Unit: Global Chief Risk Office
Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems.
What You'll Do
Collaborate with cross functional teams to collate data
Enhancing data collection procedures to include information that is relevant for building analytical solutions
Analyze, extract and understand meaningful patterns from the large volumes / dimensions of historical data by utilizing analytics techniques and SMEs’ inputs
Design, develop, evaluate and implement high quality innovative predictive/prescriptive models using open source tools such as R, Python, or similar scripting within Apache Spark/AWS cloud based big data environment
Support the team in creating/executing novel approaches to solve challenging problems by leveraging AI/ ML/NLP and Big Data/Cloud technologies
Collaborate closely with Business Partners/Analysts, Data Analysts, Application Development and other Data Scientists to integrate innovations and algorithms into useable data products
Doing ad-hoc analysis and presenting results in a clear manner
Aligns risk and control processes into day to day responsibilities to monitor and mitigate risk; escalates appropriately
Sound Like You?
Minimum of 6 years of related experience
Bachelor's degree preferred with Masters or equivalent experience
Additional Qualifications
Minimum of 3-5 years of related experience in Data analysis, Data Science, Modeling
Experience with SQL, Python, Big Data and Machine Learning Algorithms
Strong analytical and problem-solving skills
Great communication skills
Experience in Financial industry with focus on Risk Management is preferred
Experience in Data Visualization tools and AWS is a plus

About DTCC

DTCC safeguards the financial markets and helps them run efficiently, in times of prosperity and crisis. We are uniquely positioned at the center of global trading activity, processing over 100 million financial transactions every day, pioneering industry-wide, post-trade solutions and maintaining multiple data and operating centers worldwide. From where we stand, we can anticipate the industry’s needs and we’re working to continually improve the world’s most resilient, secure and efficient market infrastructure. Our employees are driven to deliver innovative technologies that improve efficiency, lower cost and bring stability and certainty to the post-trade lifecycle.

Our work environment favors openness and gives people freedom to do their jobs well, by encouraging diverse opinions and emphasizing teamwork. When you join our team, you’ll have an opportunity to make meaningful contributions at a company that is recognized as a thought leader in both the financial services and technology industries. A DTCC career is more than a good way to earn a living. It’s the chance to make a difference at a company that’s truly one of a kind.

Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems."
Research Engineers – Complex Problems -Tech Innovation,India,CareerXperts,None,Organic,"We are looking for Research engineers who are comfortable digging into complex system, tweak into algorithms and develop solutions to optimize systems. You will be part of a real-time highly distributed platform running mission-critical smart software applications / robots (replace or augment procedurally defined human work) optimizing the server pushing the envelope of computer science.
Just to give you a sense, our servers are designed to scale to the largest volumes of granular data, the most disparate and varied data sets, and the most complex advanced analytics. We build solutions to challenging data problems at large scale, including areas like real-time bidding, yield optimization, path prediction.
Experience
Research and Development in any of these Areas - Machine Learning, Pattern Recognition, Natural Language Processing, Text Mining, Information Extraction, Recommender Systems, Text Classification, Computer Vision, Reinforcement Learning, Neural Networks, Distributed Systems, Large Scale Systems, Distributed Algorithms, Kernel Distributed Storage, File Systems, Distributed Databases, Parallel Computing.
Qualification
Computer Science or equivalent background (MS or BS) with strong coding ability and familiarity with Java, C++ or other OOP language.
1+ years of academic and/or industry work building systems of data sizes greater than 100 million rows.
Self-starter attitude (It requires a lot of false starts and constant testing before things begin to work. Must be willing to tolerate failures.)
Experience with data from Ad Tech, Online Media or E-Commerce a strong plus.
Research-minded, ability to run experiments independently and present results to leadership.
Responsibilities
As a Research Engineer, you will:
Research, optimize, develop and integrate software in a loosely coupled system for scale.
Scale production systems, develop new features, and fix bugs on massive distributed frameworks.
Provide reliable, performance tuned and scalable Distributed computer system.
Build the core components of our system.
Create Algorithm design for Systems scalability of Parallel and Distributed Systems."
Delivery Manager - Data Science,"Hyderabad, Telangana",Aptagrim Consulting,None,Organic,"Required Skills:
Provide technical and thought leadership to the team
Working knowledge of Deep Learning Architectures/Convolutional Neural Networks
Working knowledge of Supervised Learning, Adversarial Learning
Working knowledge of Image Processing and Computer Vision algorithms
Excellent Python & R language coding skills
Working Knowledge with deep learning frameworks (like Tensorflow or PyTorch)
Working Knowledge with GPU/CUDA programming
Deep knowledge of Mathematics, Probability, Statistics and Algorithms
Understanding of data structures, data modeling, and software architecture
Excellent communication skills
Outstanding analytical and problem-solving skills
Presentation skills with a high degree of comfort with both large and small audiences
Good to have:
Demonstrate previous experience/references in developing data science solutions at scale for production systems"
Consultant Data Scientist-(H/F),"Bengaluru, Karnataka",Société Générale,None,Organic,"Vos missions au quotidien
Le Data Scientist exploite des données pour détecter de nouveaux leviers de création de valeur et aider à la prise de décision pour l’Entreprise, et ce dans le respect de la réglementation en vigueur sur les données :

Il comprend les enjeux du Métier et échange en permanence avec le Métier afin de s’assurer que le modèle réponde au besoin de l’utilisateur

Il identifie les besoins du Métier au regard d’une problématique ciblée et dans divers domaines de la Banque : fraude, marketing (appétence produits, moments de vie, attrition, parcours client…), gestion des risques (octroi de crédit, tarification, probabilité de défaut…) , etc.

Il élabore, en lien avec les Data Engineer, les outils nécessaires à la collecte des données dans l’exhaustivité, dans l’historique, dans la fréquence et dans la qualité suffisantes, en amont de la modélisation

Il modélise les données via les algorithmes mathématiques (machine learning, NLP, Intelligence Artificielle, …)

Il synthétise et communique les résultats des analyses de données de masse pour en extraire une connaissance décisionnelle facilement interprétable et manipulable par les bénéficiaires du dispositif qu’il conçoit, en s’appuyant sur des techniques et des expertises de visualisation


Et si c’était vous ?
Bac +5 en école d’ingénieur, master Data Science

Bon niveau d’anglais

Compétences métier :
Expertise en statistiques et mathématiques appliquées : Connaissance machine Learning, analyse prédictive à partir de différentes bases de données
Programmation informatique : Python, R, C++
Algorithmie et gestion des bases de données : SQL, noSQL, MapReduce, Hadoop
Forte curiosité intellectuelle : intérêt pour le secteur bancaire, vision sur les enjeux stratégiques
Sens du résultat, pragmatisme
Capacité à communiquer ses analyses notamment en utilisant des outils de visualisation de manière claire avec une orientation décision
Autonomie / esprit d’initiative
Esprit d’équipe / capacité d’écoute / sens des responsabilités


Plus qu’un poste, un tremplin
“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.
Pourquoi nous choisir ?
Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.

SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.


Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise.
Le groupe s’engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité sexuelle ou de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l’objet d’une discrimination.
Référence: 200003NS
Entité: SG Global Solution Centre
Date de début: Immédiat
Date de publication: 04/08/2020"
Python Developer/Selenium Testing,"Chennai, Tamil Nadu",Yours Efficiently,"₹96,000 - ₹1,56,000 a year",Organic,"Job Description:
1. Hands-on coding experience in Selenium with Python
2. Design, implement and maintain test scripts with good quality in a python based automated test framework (Atom IDE) for testing web based user interface
3. Able to work independently and with the team to deliver test plans and test cases successfully with best practices
4. Experience in building test scripts for test automation framework using Page Object Model
5. Good to have hands-on experience in PyTest, Unittest automation with Python
6. Proficient in Python as an Object Oriented programming language and community standards for Python programming and related concept
7. Execute and report on planned tests, report and manage defects, regress software fixes for new and existing products, assist development with replicating and debugging problems and develop new test automation solutions as needed
8. Develop test reports and metrics
9. Experience in Test Automation Frameworks like Data Driven, Keyword Driven and Hybrid
10. Deep understanding of Test Case Development with prior experience in Test Case Automation
Educational Qualification:
Graduate or Post Graduate in Engineering, Science, Technology, (Preferably BE or MCA graduate) with Related Experience.
Experience Required:
0-3 Years Experience in Python Development & Selenium Testing.
Job Type: Full-time
Pay: ₹96,000.00 - ₹156,000.00 per year
Work Remotely:
Temporarily due to COVID-19"
Senior Data Scientist,"Bengaluru, Karnataka",Nanobi,None,Organic,"Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience
Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.
Responsibilities
The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work."
Business Analytics/Software Engineering Internship,"Noida, Uttar Pradesh",Code5,"₹3,000 - ₹6,000 a month",Organic,"About the company:
We are a company with innovation in artificial intelligence and gamification, having 3 offices in Noida and Delhi.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working closely with the product team, development team and testers for analyzing the requirements 2. Understanding the requirements and writing requirement documents 3. Preparing data for functional analysis basis the domain 4. Verifying and correcting the technical documentation by developers 5. Preparing documents for projects developed Requirements: 1. The suitable candidate would be a B.Tech/MCA/BSC/MBA in IT 2. Good oral and written English communication 3. Eye of detail 4. Ability to coordinate with the team for meeting goals on given timelines 5. Ability to work under pressure and deliver the results
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 13th Aug'20 and 17th Sep'20
are available for duration of 3 months
have already graduated or are currently in any year of study
are from Noida and neighboring cities
Females willing to start/restart their career may also apply
Other requirements:
Are from Noida/NCR- can travel to the office daily
Number of internships/jobs available: 6
Categories: Analytics,Software Development,Data Science,Computer Science,Engineering"
Data Engineers,"Pune, Maharashtra",SG Analytics,None,Organic,"Writing clean, fully-tested and well-documented code in Python 3.5+ with pandas, NumPy,Dask, TensorFlow, scikit-learn and Django
Creating complex data processing pipelines including optimization and user experience
Design, develop, test, deploy, support, enhance data integration solutions seamlessly to connect and integrate enterprise systems in an Enterprise Data Platform
Working directly with clients to identify pain points and opportunities in pre-existing data pipelines and build or improve clients analytics processes
Developing and testing models using appropriate tools and technologies and deploying the same in the production environment using continuous delivery practices
Working directly with the stakeholders on analytics framework model building, database design and deployment strategies
Advising clients on the usage of different distributed storage and computing technologies from the plethora of options available in the ecosystem
Skills Required
5+ years of overall industry experience specifically in data engineering
3+ years of experience building and deploying large scale data processing pipelines in a production environment
Strong experience in building data pipelines and analysis tools using Python and PySpark
3+ years experience in business analytics, forecasting or business planning with emphasis on analytical modeling, quantitative reasoning and metrics reporting
Experience in SQL Databases: SQL server, Mysql, Redshift, Access etc. Experience with REST APIs, GIT, AWS & DevOps skill-set is highly desired Strong communication and client-facing skills with the ability to work in a consulting environment is essential
Interest to learn and improve all rounded skill set all the time
Python(Expert level)
PySpark
SQL(Intermediate level)
APIs(Look for terms like REST or SOAP)
GIT or BitBucket or SVN
Machine learning (classification, clustering, regression, statistical inference, collaborative filtering, and natural language processing, experimental design, social networking analysis, feature engineering etc) Excellent modeling skills
Qualification
BE/B.Tech./Masters in computer science or with a quantitative discipline, e.g. Mathematics, Statistics, Economics, Artificial Intelligence"
Data Scientist,"Hyderabad, Telangana",thoughtgreen technologies pvt ltd,"₹3,00,000 a year",Organic,"The role of a DATA SCIENTIST / Computer Vision engineer would require the following skills:
To build models using different image processing techniques
To work on a number of computer vision projects in the area of image segmentation, optical character recognition, object recognition and deep learning.
Run experiments using computer vision algorithms and models to evaluate their performance with regards to accuracy, processing time and maintainability.
Develop image processing pipelines that leverage a variety of data engineering techniques and machine learned models to solve problems.
Required Experience, Skills and Qualifications
Enjoys problem solving in an environment that has a high degree of uncertainty
Must be worked on computer vision projects in the area of image segmentation, optical character recognition, object recognition, deep learning and machine learning.
Experience with developing software in Python.
Have experience with a machine learning or a computer vision project
Strong communication skills
Have a Masters or PhD in Software Engineering, Computer Science, Electrical Engineering or similar degree
Experience
Min 2 - 5 Years of experience is required
Benefits
Health Insurance
Job Type: Full-time
Salary: From ₹300,000.00 per year
Experience:
model building : 2 years (Required)
data science in deep learning: 3 years (Required)
Work Remotely:
Temporarily due to COVID-19"
Member of Technical Staff (Python/Golang),"Pune, Maharashtra",Nutanix,None,Organic,"Nutanix Prism Pro improves the quality and efficiency in IT operations for the modern datacenter. Powered by machine learning and task automation, Prism Pro intelligently optimizes capacity, proactively detects performance anomalies, and enables the IT team to automate operations tasks with ease and confidence. Traditional IT operations management (ITOM) tools were built for static infrastructure. They often overwhelm IT teams with complex and noisy alerts that the teams can’t do anything about. In dynamic and scalable modern data centers with high performance and diverse workloads, IT teams need simplicity and accuracy to achieve high productivity in operations.

Overview of the role
MTS, Developer is responsible for building the monitoring, collections & analytics layer in the control plane (management layer) of the Nutanix platform. An important part of prism-pro is building the capability to gather configuration and metrics from parts of Nutanix Platform, Applications running on Nutanix Infrastructure, as well as other entities running in the datacenter and cloud. The developer is also expected to write services that leverage these configurations and metrics to provide monitoring, automation and troubleshooting capabilities to the end user.
The individual needs to have a keen interest in building impactful end to end features (architecture, design, thinking through workflows / use cases / experience and development of scalable solutions for the same) for customers. The solution would be like a platform so as to be usable by a variety of applications as well as Nutanix services.
Responsibilities
Core development:
Develop scalable and performant Analytics and Monitoring Platform software
Contribute as a strong, hands-on technical member in product development activities to develop clean, refactored and tested code that is extensible and highly reusable.
Develop innovative products through all phases of software development including conception, design, implementation, and deployment.
Work in an Agile environment where Quality is everyone’s responsibility.
Collaboration:
Collaborate closely with teams engaged in building the frontend and driving the user experience of the product
Collaborate with the Product Management team to translate requirements into high-quality, timely deliverables to wow our users.
Collaborate with other engineers in the team to develop and use effective mechanisms to ensure code quality.
Collaborate with teams which could be potential stakeholders of the product
Get feedback on the product and incorporate it into the product in innovative ways
Skills Required
2-5 years of development experience using Golang/Python/C++
Experience in building scalable performant distributed systems. This includes experience and knowledge of
Sync/async programming design
Multithreading/concurrency
Object oriented design
Fault tolerant systems
Working knowledge of Linux or *UX environment
Experience in virtualization and containers
Experience with design, development and data modeling of RESTful web services
Basic understanding of web technologies and transport mechanisms (HTTP/S, Javascript, JSON, gRPC, protobuf, etc).
Good knowledge of RDBMS, NOSQL & database design
Familiarity with version control systems such as GIT, build management tools and Continuous Integration tools such as Jenkins & CircleCI
Familiarity with Unit testing frameworks
Ability to write scripts and tools for development and debugging.
Memory/CPU Profiling of applications
Experience building end-to-end solutions is a plus
Qualifications
2-5 years of experience developing applications.
Bachelor Degree in Computer Science or equivalent"
Software Developer 3 - Java/C/C++/Python Engineer,"Bengaluru, Karnataka",Oracle,None,Organic,"Software Developer 3 - Java/C/C++/Python Engineer-20000KB7

Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications
About Oracle GBUCS

Oracle GBU Cloud Service (GBUCS) is responsible for managing cloud infrastructure for hundreds of SAAS products developed internally in Oracle. In particular, our team is responsible to build, maintain, and operate the Monitoring-as-a-Service portfolio of monitoring solutions for the entire GBU organization. Our solutions monitor several million entities, at high frequency, that span all layers of the GBUCS stack that includes Storage, Network, Server and the Application services. The monitoring platform is a highly distributed, 24*7 system that collects, transports, processes time-series and log events and provides utilities to alert and visualize massive telemetry data accurately and reliably.

About The Job
Do you want the challenge of working in a cutting-edge environment, solving technical problems, building talented engineering teams and delivering solutions that underpin Oracle’s GBUCS solutions?

About The Job

Do you want the challenge of working in a cutting-edge environment, solving technical problems, identifying improvements, and implementing your recommendations?

This role lets you design, develop, troubleshoot, debug software for controlling and managing distributed services, multi-level abstractions, end-end automation, monitoring and telemetry, asset management.



What You Need to Have
You need to have the following knowledge, skills, and experience:

Education and Work Experience
Bachelor’s/Master’s degree in Computer Science or a similar field.
6+ years of experience working with mission-critical production environments
Expertise in building highly-scalable distributed solutions, exposing services as APIs (SOAP and REST), understanding of data models using relational databases
Experience implementing a continuous integration (CI) and continuous deployment (CD) pipeline with working knowledge of container management and orchestration tools.
Track record of delivering software on time with high quality, using Agile, DevOps, and SRE practices and toolsets.
Good understanding of network, storage, server and web application design and concepts

Technical Qualifications
Preference for demonstrated practical experience with the following technologies:
Expert level programming skills in Java and/or Python, experience with Object Oriented Programming and Design.
Experience with managing network configuration with code
Experience with scripting/automation languages (PERL, Python, Bash etc.)
Experience with infrastructure or network automation tools and protocols e.g. chef, ansible, netconf.

Soft Skill Qualifications
Good written and oral communication skills. Should be able to clearly convey your thoughts and ideas to others.
Committed self-starter who enjoys working in a collaborative environment with personnel at all levels in the organization
Detailed Description and Job Requirements
Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience."
Python Developer,"Bengaluru, Karnataka","Kaleidoscope Business Solutions, Inc","₹12,000 - ₹18,000 a month",Organic,"Job Summary
Kaleidoscope Business Solutions is a 2-Year-Old StartUp and it is a technology company working in AI, machine learning, deep learning and big data space. With a rapidly growing team of 10+ employees working from US, and India, we are looking for passionate individuals who wish to make a great career in the hi-tech industry.
Job Description
You Must Have:
2+ years of hands-on experience with Python
Working experience of Django, Flask, etc based applications
Understands scaling aspects of these frameworks and how to deploy and maintain them
Understands the micro-services design paradigm and architecture
Good understanding of object-oriented programming and Object-oriented design in Python
Has worked on Python 2.x and 3.x
Knowledge of object-relational mapping (ORM)
Good problem-solving skills and communication
Produce clean and efficient code with proper comments based on the specifications
Ubuntu / Linux based work environment exposure
Used Git, Bitbucket, and as part of the day-to-day work cycle
Good to have:
AWS/Azure/GCP clouds exposure and have worked or used cloud-based services
Familiarity with front-end technologies like JavaScript, ReactJS, HTML5 would be a plus
Qualifications
Ability to join under 15 days
Hands-on Experience in Python & Django
Startup experience or interested to work with Start Up
Additional Information
5 Days Working
Located anywhere in India - We encourage our employees to work from home t
No Bar for the right candidate
Responsibilities and Duties
Responsibilities
Write “clean”, well-designed code
Produce detailed specifications
Troubleshoot, test and maintain the core product software and databases to ensure strong optimization and functionality
Contribute in all phases of the development lifecycle
Follow industry best practices
Develop and deploy new features to facilitate related procedures and tools if necessary
Good knowledge of relational databases, version control tools and of developing web services
Passion for best design and coding practices and a desire to develop new bold ideas
Degree in Computer Science, Engineering or a related subject
Key Skills
python, django, mongodb, machine learning, deep learning, jquery, javascript, , AWS
Required Experience and Qualifications
Required Experience and Qualifications
Experience Required: 1 years or more
Good communications and analytic skills.
Willingness to learn new technologies & update themselves.
Academic Qualification: Graduation in any discipline/ Diploma in Engineering, Computer Science
Must be conversant with AJAX, JSON, REST, SOAP
Must be good at JQuery, Ext JS, Javascript
Cross platform / technology adaptability
Experience with Facebook / Twitter / LinkedIn APIs, a plus
Good communication (written and oral) and interpersonal skills
Experience in Rails or and mobile web programming will be an added advantage
Should be ready to work in Kochi, during GMT hours. ( 12 PM to 9 PM IST)
Compensation: Not a barrier for the right candidate.
Must be passionate about work.
Benefits
About Kaleidoscope Business Solutions Benefits:
Give you the newest MacBook Pro with accessories and best equipment / work setup to make you feel productive and empowered to do your best work once you complete one full year with Kaleidoscope Business Solutions.
We care about your professional development and give you Personal Innovation Fund (education reimbursement)
Offer you opportunities for international travel
Provide a modern office environment
Offer competitive salary and bonuses
Contribute to open source software
We're a AI software consulting firm headquartered in San Francisco with offices in India. We are a growing 10+ team of engineers, designers and project managers working with a client roster of leading organizations from around the world. Our clients are a mix of venture-backed start-ups, Fortune 500 brands, and innovative NGOs.
View our website for more details. www.kb.solutions
Still not sure about applying to us?
If you're interested in applying for this job, we need three important things from you after you click the ""Apply for this job"" button below:
- a short cover letter (paragraph) describing why this seems like a good fit to you- a link to your GitHub profile (if any)- your LinkedIn profile (if any)
Also, if you put the words ""Can't wait for Python!"" in your cover letter, it will please us to know that you took the time to read this post and have good attention to detail.
We're looking forward to hearing from you!
Job Types: Full-time, Temporary, Internship, Contract
Salary: ₹12,000.00 - ₹18,000.00 per month
Experience:
django: 1 year (Preferred)
Python: 1 year (Required)
Education:
Diploma (Preferred)
Location:
Bengaluru, Karnataka (Preferred)
Industry:
Software Development
Work Remotely:
Yes"
Data Scientist - Advanced Analytics,Bihar,IBM,None,Organic,"Introduction
As a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
Combines deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Responsibilities include working with business leaders to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Skills include mathematical optimization, discrete-event simulation, rules programming and predictive analytics. Expected to have knowledge and/or experience in the following skills with focus on data science: Data Science, Apache Ambari, MapReduce, Spark, Labmda, Resilient Distributed Dataset, Java, Zookeeper, Knox, Big Data, IBM BigInsights, Apache Hadoop, SQL, RDBMS, Python, Big SQL, BigSheets+E5Big R, Text Analytics, GPFS, HDFS, Platform Symphony, Structured And Unstructured Data, Open Source, R, POSIX, Yarn, Sqoop, Flume, JSON, XML, NoSQL, HBase, Pig, Hive, Oozie, Apache Solr, JSqsh, Data Server Manager, AQL, Data Security, Data Governance, Networking, Neural Net.



Required Technical and Professional Expertise
Domain about Watson Explorer and other Watson Analytics products
Domain in text mining (characterization, summarization, aggregation)
NoSQL Database Domain
Mastery in natural language processing algorithms, machine learning, information retrieval / retrieval and advanced analytics
Cloud platform knowledge
""Twelve Factor""
Desirable specialization in one of the following areas: Natural Language Processing, Image Processing, Video Processing, Voice Processing and Watson technologies | WEX, WDC, WEA, Big Data analytics-R, Python, Spark, Weka, Mahout, Hadoop, Hive and HBase

***All positions are eligible for people with disabilities or rehabilitated.***

Preferred Technical and Professional Expertise
N/A

About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Software Engineer- Data Model Engineering,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
What We Do
At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.

Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.

Who We Look For
Goldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.
Working in a global team of developers on integrating BI products into GS infrastructure. Developing automation, governance and reporting solutions to provide firm and regulatory mandated controls. Working with stakeholder form firm wide business unites on defining and driving GS BI strategy and governance. Working close with the rest of Data Intelligence team to provide holistic data management solution for GS. Data Model Engineering provides the platform that unlocks the firm’s data by providing the means to describe, access and manipulate it. It is the heart of a data-centric approach to application development. We engineer modelling languages, Software Deverlopment Lifecycle tools, large-scale operational services and portals for access and analysis to achieve this. Data Model Engineering is part of the Data Intelligence platform whose purpose is to extract the maximum value from the firm’s data at all stages of its life.
RESPONSIBILITIES AND QUALIFICATIONS:
HOW YOU WILL FULFILL YOUR POTENTIAL
Drive, shape and champion data modelling standards within the engineering organization
Define analytics and tools to manage the metadata and extract lineage and other useful information from our data graph
Design discussion and review to shape the evolution of the platform.
Leverage technologies and standards to automate and improve all aspects of the platform.
Support and educate clients in their use of the platform

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
Degree qualification in Computer Science or related field
Java or related JVM development experience
Strong technical ability, willing to learn and evolve your skills with advances in Technology
Strong Data Modeling experience with ability to collaborate effectively across global teams and communicate complex ideas in a simple manner
Team player, eager to work in a global organization

Preferred Qualifications
Experience of data modelling and SQL
Experience with Model Driven Architecture
Programming Language design and implementation
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Data & Analytics – Analytics Translator,"Bengaluru, Karnataka",Kimberly-Clark,None,Organic,"Job Description
Key Areas of Expertise and Accountabilities
Domain knowledge: Expertise in CPG and ability to identify the value for Artificial Intelligence and Machine Learning in the business context. Must understand key operational CPG metrics and their impact on profit and loss, revenue, customer retention, etc.
General technical fluency: Strong acumen in quantitative analytics and structured problem solving. Must be able to interpret model results and identify potential model errors. Ability to communicate data science features and capabilities to internal and external stakeholders in order to identify business needs and uncover areas in need of deeper data exploration.
An entrepreneurial spirit and Agile mind-set : Enthusiasm, commitment and business savviness to help remove technical roadblocks that might emerge and ability to anticipate them. Ability to build and iterate through prototypes when building out solutions and act as a trusted advisor.
Acting as a trusted advisor for business partners and business teams, the Analytics Translator will answer new questions and provide leadership and direction in building out K-C’s journey to take information to insights that drive business results.
Accountable for the development of Advanced Analytics on existing data sets and capabilities for Kimberly Clark and for building out capabilities that will provide K-C with competitive edge around prescriptive, predictive and alert-based analytics.
Drive opportunities to reuse the same reporting environment across multiple solutions and regions that are imbedded.
Work collaboratively with business clients, business partners and across the IT organization to define, prototype, and implement new technologies to enable business objectives.
Deliver innovative, efficient and cost-effective solutions to meet enterprise needs and to drive business growth and profitability.
Provide thought leadership in emerging data and analytic technologies (i.e., Microsoft Azure, R, Python, Analytics Cloud, Power BI, Tableau, Natural Language Query, etc.) and ability to leverage the Big Data and Analytics into viable use cases and ultimately into successful data-driven products and services.

Key Qualifications and Experiences:
B.S., B. A. degree. A master’s degree in a related field is preferred but not required.
10+ years of equivalent experience in information technology influencing large, remote, global teams and a minimum of 5 years’ experience in the Advanced Analytics space
Strong experience in IT (or equivalent) influencing large, remote, global teams and a minimum of 5 years’ experience in the Advanced Analytics space and broad knowledge in Data Wrangling, Data Engineering and Data Science.
Strong knowledge of front-end tools including Tableau and Power BI as well as SAP Business Objects.
Strong background in SAP HANA, Microsoft Azure and Python preferred.
Strong functional background to have solid understanding of CPG business along with detailed technical knowledge to generate insights from data. Understands the range of and potential measurements & models needed in a large CPG business.
Demonstrated skills in analytics delivery, client relationship management, keen sense of urgency in delivering results, business knowledge, intuition and judgment, high cross-cultural awareness and sensitivity, effective communication/collaboration.
Excellent visual & design skills in data representation.
Extensive experience bringing data together from multiple platforms and showcase in easy-to-understand visualizations. Skills in turning data into insights.
Experience leading IT projects and/or programs with strong SDLC experience including Agile/Waterfall methodologies. Exposure to Agile fundamentals.
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time"
Associate - Projects,"Hyderabad, Telangana",Cognizant,None,Organic,"Senior Developer
Qualification:
Science / Engineering Graduate
Responsibility:
Requirements Gathering:
Understand, interpret and clarify functional requirements as well as technical requirements and requirement standards for the project.
Design and Analysis:
Study assigned functional specifications.
analyze and identify impact of specifications.
raise queries and seek resolution from different stakeholders.
Provide required support to develop the proof of concept.
Coding:
Develop coding (business layer coding, interface development, service development, creation of stored procedures etc) as required in the project.
Raise clarifications / issues / concerns regarding work output to the lead on time.
seek review from peer / Senior Developer periodically.
rework on the code based on code review / defects raised in unit testing or any other relevant testing phases.
participate in code peer review, as required.
Highlight any potential risks to the Leads and seek inputs to resolve issues identified.
support integration of components, as required.
Update traceability matrix for the work package developed.
provide support on process audit activities.
Adhere to process and tools (usage of cognizant 20, awareness of Quality Management System).
follow the SCM policies set for project.
Testing: Write unit test cases for the specific unit.
seek review from peer / Senior Developer for the test cases written.
Execute the test cases.
Capture and fix defects as and when found, and retest the areas during testing and warranty phase.
Review work to ensure adherence to SCM policies set for project.
Follow up on integration of the component developed with the application.
Understand and execute automation tools for testing.
Defect Management:
Rework on the code based on review comments from code review / defects raised in unit testing, peer testing, SIT, UAT testing or any other relevant testing phases.
Process Improvements and Adherence:
Provide ideas for process optimization or valueadds that can be provided and share them with the relevant stakeholders.
adhere to process and tools (usage of cognizant 20, awareness of Quality Management System, IDE etc).
Knowledge Management:
Contribute towards updating knowledge assets, user manual, online help document, installation manual / scripts.
contribute / search / reuse all types of assets from repository.
Must Have Skills
Model N-BI
Model N-Data model
Order to Cash Order Management
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Aug 12 2020
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world."
Big Data Engineer,"Bengaluru, Karnataka",Zinnov,None,Organic,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
1. B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
2. Experience of 2-6 Years working with Big Data technologies.
3. Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.

Responsibilities:
1. Develop, maintain, test and evaluate big data solutions within the organisation.
2. Build scalable architectures for data storage, transformation and analysis.
3. Design and develop solutions which are scalable, generic and reusable.
4. Build and execute data warehousing, mining and modelling activities using agile development techniques.
5. Leading big data projects successfully from scratch to production.
6. Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
7. Solve problems in robust and creative ways.
8. Collaborate and work with Machine learning and harvesting teams.

Skills:
1. Proficient understanding of distributed computing principles.
2. Must have good programming experience in Python.
3. Proficiency in Apache Spark (PySpark) is a must.
4. Experience with integration of data from multiple data sources.
5. Experience in technologies like SQL and NoSQL data stores such as Mongodb.
6. Good working Knowledge of MapReduce, HDFS, Amazon S3.
7. Knowledge of Scala would be preferable.
8. Should be able to think in a functional-programming style.
9. Should have hands-on experience in tuning software for maximum performance.
10. Ability to communicate complex technical concepts to both technical and non-technical audiences
11. Takes ownership of all technical aspects of software development for assigned projects.

Benefits:
1. Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
2. Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
3. Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
4. Strong knowledge of data structures and algorithms.
5. Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
6. Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred."
Python Lead – Distinguished Founders – Mission Critical,"Bengaluru, Karnataka",CareerXperts,None,Organic,"Are you passionate about Python? You are known for your views on “how to build scalable Internet Products” and “Engineering Excellence”. You have deep Interest to work on Core Platforms? Then, we are looking for you!!
We have a topnotch role of a Tech Lead who is passionate about writing clean code and is vivid about leading and mentoring a team of young engineers to solve hard Computer Science Problems (Distributed Systems, Machine Learning, NLP, and Computer Vision).
Experience
6+ years
Qualification
6+ years of core experience in writing clean production level Python code.
Proven Ability to build large enterprise-grade systems.
Strong mathematics background.
Experience and/or desire to work in a fast paced start-up environment.
Compensation – Better than the best in the industry.
Responsibilities
On being a Python Developer with us!
At the heart of the design and integration of automated vision and serialization systems, you will thrive in an agile and multidisciplinary team.
Leverage our platform and our open source projects to perform distributed information extraction, retrieval and data processing.
Identify and resolve performance and scalability issues with distributed crawling at scale.
Write to deepa.m@careerxperts.com to get connected!
Job Location
Bengaluru"
AI/ML DEVELOPER,"Gurgaon, Haryana",Ushyaku Software Solutions,None,Organic,"Job Description
Creating Scalable Machine Learning systems that are highly performant
Identifying patterns in data streams and generating actionable insights
Customizing Machine Learning (ML) algorithms for in-house use
Writing production quality code and libraries that can be packaged, installed and deployed
Maintain and improve existing in-house tools and code. Optimize for speed and efficiency
Skillset:
Experience of handling various data types and structures: structured and unstructured data, extensive prior experience in integrating data, profiling, validating
Candidate should have good background in Python, Linear Algebra, statistics and have some experience in Machine Learning Frameworks
Algorithms Geek and researcher in field of data science with a strong experience in statistical & analytics packages/tools (R, Alteryx etc.)
Expertise on Machine Learning/Information Retrieval/Artificial Intelligence/Text Mining problems.
Deep understanding & familiarity with Predictive modeling concepts, Recommendation & optimizing algorithms, clustering & classification techniques
High level of proficiency in statistical tools, relational databases & expertise in programming languages like Python/SQL is desired
Strong analytical, troubleshooting and problem-solving skills
Ability to work independently as well as collaboratively within a team
Candidate should open to learn new open source technologies and languages
Must be able to thrive in a fast paced, customer-focused, collaborative environment. Must be able to work hands-on with minimal supervision or assistance
Desired Qualification:
Masters- degree in operations research, applied statistics, data mining, machine learning & related quantitative discipline (Preferably M.Sc /M. Tech. in Statistics/Mathematics)

To apply, email: careers@ushyaku.com"
Data Science AI ML NLP Consultant,"Gurgaon, Haryana",ChampionsIT,None,Organic,"“AI-ML-NLP-0519”
For one of our prestigious multinational clients, we are looking for AI/ML/NLP Professionals for immediate hiring. Our client is an established name in the space of software development and consultancy. This position is based at Gurgaon – Delhi NCR, India.
WHAT IS IN IT FOR YOU?

The company is known for software consulting services and is a respected name in the software industry. You will get to work in a very energetic environment with lot of dynamism. They cater to mainly US customers, and provide their services through onsite/offshore model. The work environment is conducive to innovation, and provides continuous growth opportunities.
JOB DESCRIPTION

Work on Data Science projects in the area of NLP, ML, and Cognitive analysis.
Key Responsibilities:
Understand Customer Problem and Data Requirements.
Translate Customer requirements into a Data Science Problem.
Propose a Data Science solution which may involve use of Machine Learning (Supervised & Unsupervised) and other algorithmic models
Prepare Data followed by Model development
Model Testing and Deployment
Qualifications and skills:
Engineering Degree is a MUST
2 to 4 years experience in AI/ML/NLP/Cognitive Analysis
Coding of Machine Learning models in R and/or Python language
Experience in extracting data from a variety of data sources
Proven expertise in analyzing & visualizing data
-Experience in deploying on AWS, Google Cloud Platform or - Microsoft Azure will be preferred.
Quick learner of newer models, libraries and modeling techniques
Excellent communication and presentation skills
About the client
Our client is an established Software development and consultancy organization with its headquarters in US. They are a respected name in Insurance and Healthcare software and services. They have a large spectrum of customers all over US, and have development centers in India. They believe in hiring smart people and giving them a chance to grow at a rapid pace.
Come, be part of a winning team."
BI & Data Visualization Developer,"Chennai, Tamil Nadu",PayPal,None,Organic,"Specific Responsibilities
Perform detailed analysis of source systems and source system data and model that data in Qlik Sense
Design, develop, and test Qlik Sense scripts to import data from source systems and test Qlik Sense dashboards to meet customer requirements
Interpret written business requirements and technical specification documents
Create and maintain technical design documentation
Perform quality coding to business and technical specifications
Ensure that the Qlik Sense server process continues to run and operate in the most efficient manner
Perform Qlik Sense system administration and testing of releases and patches
Work directly with business units to define and prototype Qlik Sense Applications
Extracting, transforming and loading data from multiple sources into Qlik Sense applications
Provide input on proposing, evaluating and selecting appropriate design alternatives which meet client requirements and are consistent with client's current standards and processes
Ability to develop and manage BI solutions using Java and/or Java Script
Functional Skills & Behaviors
Experience in sourcing data from disparate systems with a good understanding of their Data Models and ETL procedures
Hands-on professional with thorough knowledge of scripting, data source integration and development in Qlik Sense including Publisher/QMC, and Qlik NPrinting, Qlik Alerting
Hands-on professional experience developing and deploying business intelligence solutions using Java and or Java Script languages
Experience building end to end multi-layered Qlik data architectures & applications (e.g. extract, transform, load, Front End/UI) where shared QVDs, business rules, and data validations are applied and loaded into Qlik data model(s)
Full understanding of the processes of data quality, data cleansing and data transformation
Ability to write complicated yet efficient SQL queries and stored procedures
Strong knowledge on Qlik Sense server architecture and applying business rules and data validations
Ability to tune data loads, data models, and front-end design of Qlik applications for efficient performance
Experience in end-to-end implementation of Business Intelligence (BI) projects, especially in scorecards, KPIs, reports & dashboards
Knowledge of formal database architecture and design
Qualifications
Candidate must have 4+ years development experience with Qlik Sense creating visuals, building dashboards, rapid prototyping and customization to meet needs of end-user
Development experience with Java and Java Script to build visualizations, dashboards, and reporting solutions to meet user needs
Familiarity with data engineering, data management, data modeling, standard ETL techniques including extract, de-duping, cleansing, integration, and aggregation
Demonstrated ability to influence critical business outcomes in a matrix based, global environment
Excellent verbal and written communication and collaboration skills to effectively communicate with both business and technical development teams
At a minimum, candidate must have a bachelor’s degrees in a quantitative discipline (e.g. statistics, data science, computer science, engineering, operations research, or mathematics); preferably an advance degree.
Job_Description_Summary: The Risk Intelligence Automation team requires Qlik Sense developers to deliver compelling business intelligence solutions to the leadership of PayPal Credit. The day to day job involves helping inform leadership with data-driven decisions based on analysis of huge data sets in a complex, fast-paced, dynamic environment. Ideal candidates are problem solvers with experience in Qlik Sense development, equipped with strong analytical skills suited to approach varied challenges in complex big data environments. As a Business Intelligence professional, you will be required to drive projects and solutions from start to finish. Having a strong sense of accountability coupled with a passion for delivering crisp data insights and the ability to tell stories through data are essential.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Machine Learning Science Leader,India,CareerXperts,None,Organic,"Passionate about Big Data, Machine Learning and Predictive Software? Interested in leading new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
We are looking for a dynamic Machine Learning science leader to found and head the Data Science function in Bengaluru. As Head of Data Sciences, you will lead a high performing team of scientists and engineers in the development of innovative and rigorous Machine Learning techniques that advance Machine Learning technology for advertising and convert to high impact solutions for the business.
Major responsibilities:
Recruit, coach, and manage a team of scientists and data science engineers, lead cutting-edge research projects, and influence the technical direction of the Ads business.
Innovate and leverage machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Formulate and test hypotheses, extract signals from peta-byte scale, unstructured data sets, and ensure that our display advertising business delivers the highest standards of performance
Collaborate with distributed cross-functional teams on common goals.
Experience
6 + years , Start-up / Entrepreneurial experience preferred.
Qualification
MSc or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field. (PhD preferred).
4+ years of industrial experience in machine learning and predictive modeling, including 2+ years experience in leading junior team members and guiding them on machine learning and data modeling applications.
Proficient in Java, C/C++, or Python (or similar scripting language).
Proficient in R, Matlab, or another statistical software.
Strong communication and data presentation skills.
Preferred Qualifications:
7+ years of industrial experience in predictive modeling and analysis, predictive software development.
Experience handling gigabyte and terabyte size datasets.
Experience working with advertising, retail or e-commerce data.
Experience working with distributed systems and grid computing.
Experience working with distributed teams.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences."
Software Engineer - Equity Derivatives,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
GLOBAL MARKETS
Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.
Your Impact:
The Equity Derivatives Engineering team is a front-office business facing team responsible for development of critical applications and infrastructure for the Equity Derivatives business. We work closely with trading, quants, structuring, ops and other teams in a dynamic and fast-paced environment. The team is involved in the full project lifecycle (analysis, design, development, release, support) across a wide variety of projects including new business initiatives, automation, efficiency, analytics and controls.

RESPONSIBILITIES AND QUALIFICATIONS:
Responsibilities

This is an exciting opportunity to join an expanding team leveraging technology to transform the way we conduct derivatives business and to deliver the most complex transactions for our clients. The role will be suited to a strong technologist with a keen interest in business workflows, derivative products and financial markets.
The successful candidate will need to:
Develop an in-depth understanding of Equity Derivatives front office business, flows and systems, with particular focus on Exotics, Fund Products and Structured Transactions
Form strong partnerships with trading, operations, quants, and other engineering teams
Drive commercially impactful engineering projects to deliver key desk initiatives
Strive for continuous improvement in the effectiveness and stability of the front office stack
Maintain a strong risk and control mindset to mitigate operational & technology risks
Become proficient in Goldman Sachs’ proprietary database and scripting language (SecDB and Slang) and other languages as necessary
Basic Qualifications
Bachelor’s or Master’s degree in Computer Science, Computer Engineering or related field
Strong technical, analytical and problem-solving skills
Strong programming skills in at least one OO/scripting language (e.g. Java, Python, C++)
Experience working with databases and datasets (modelling, querying)
Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
Excellent verbal/written communication skills and ability to work across teams
Ability to work in a fast paced environment whilst maintaining strong attention to detail
Highly motivated with a strong sense of ownership and desire for impact
Preferred Qualifications
Previous experience in a business-facing, front office engineering role in the finance industry
Knowledge of equities markets and experience with derivatives products such as options, swaps or exotics
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Business Intelligence Analyst,"Bengaluru, Karnataka",Cerner Corporation,None,Organic,"Cerner India is expanding and we are pleased to hire Business Intelligence Analysts for our growing Support Operations business unit. As a Business Intelligence Analyst, you are responsible to define, implement and standardize metrics, reports and dashboards leveraging data visualization tools. In this role you are also responsible to find innovative ways to search for meaningful patterns, trends, and relationships amongst large amounts of data and to identify the success measures, analyses and reporting processes that lead to actionable findings. Additionally, your responsibility is to synthesize complex qualitative and quantitative data to form clear, well-supported, data-driven recommendations for non-technical audiences and present results to internal stakeholders.
Back to Description
Cerner Jobs and Careers

Engineering & Technology
Innovation occurs everywhere but maybe you are also looking for a purpose. Nothing is more impactful than improving the health of others. Develop cutting edge technologies that have real meaning.
Qualifications
Basic Qualifications:
Bachelor's or Master's degree in Computer Science or any other related field

At least 3 year of experience in Business Intelligence and Reporting Analytics domain

At least 2 year of experience working on the data analytics and business intelligence visualization tools like Tableau and Power BI

• Good Knowledge on Advanced excel• Basic programming skills with Python and SQ
Additional Information
All employees must be legally authorized to work in the country where the position is located. Work visa sponsorship is not available for this position.
Relocation Assistance Available for this Job:
Yes - Domestic/Regional
Virtual Eligible Job
No
Cerner is a place where people are encouraged to innovate with confidence and focus on what is important – people’s health and the care they receive. We are transforming health care by developing tools and technologies that make it more efficient for care providers and patients to navigate the complexity of our health. From single offices to entire countries, Cerner solutions are licensed at more than 25,000 facilities in over 35 countries.

Cerner’s policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. Cerner is proud to be a drug-free workplace.
If you are an individual with a disability who is unable to use our online tools to search and apply for jobs, and need assistance or an accommodation in the recruiting process, please contact us by calling 866-434-1543 or by emailing CernerCareers@cerner.com."
Bioinformatics Analyst,"Chennai, Tamil Nadu",PerkinElmer,None,Organic,"PerkinElmer is a global technology leader driving growth and initiative in the Environmental and Human Health Science markets. The company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world.
PerkinElmer Genomics is one of the world’s largest providers of newborn screening services, and offers comprehensive genetic testing solutions that help provide insight into the complex nature of rare and inherited diseases. The PerkinElmer DNA Sequencing Services business provides state of the art DNA/RNA measurement services. We are looking for an innovative Bioinformatics Analyst to utilize bioinformatics tools to analyze clinical data generated in our highly advanced DNA sequencing center.
This person will work closely with our bioinformaticians in the United States to process and manage Next Generation Sequencing (NGS) data, as well as other molecular testing data such as Sanger and MLPA. There are also opportunities for the Bioinformatics Analyst to develop new data processing pipelines, software applications, databases and custom scripts. Additional responsibilities include exploring and/or evaluating state of the art bioinformatics tools, maintaining sample tracking logs and delivering results to customers.
Required Skills:
Bachelor or Master degree in bioinformatics, biostatistics, computer sciences or equivalent in Life Sciences discipline.
Programming skills and proficient in programming languages including Perl/Python, R, SQL and shell scripting.
Preferred Qualifications:
Experience in building and delivering NGS data analysis pipelines and software applications is a plus.
Strong programming skills and proficient in programming languages including Perl/Python, R, SQL and shell scripting.
Strong oral and written communication and interpersonal skills required.
Ability to work independently as well as work with others in a team.
Experience in working in a clinical laboratory environment."
Data Engineer,"Bengaluru, Karnataka",HealthifyMe Wellness Private Limited,None,Organic,"About Us:
HealthifyMe was founded in 2012 by Tushar Vashisht and Sachin Shenoy, and incubated by Microsoft Accelerator. Today, we are India and South East Asia's largest and most loved health & fitness app, with over 16 Million users from 300+ cities in India+SEA and rated over 4.6/5. The HealthifyMe mobile app has been rated as the top Health/Fitness app on Play Store by Google for the last 3 years, and has received the prestigious 'Editor's Choice' badge by Google.Our coaching services are delivered by a world class team of over 500 coaches including nutritionists, trainers and yoga instructors. We combine the power of artificial intelligence and human empathy to deliver measurable impact in the lives of our consumers. We launched the world's first AI nutritionist 'Ria' with learnings developed from billions of data points on consumer lifestyles, coupled with 400 man-years of nutritionist/fitness intelligence.

HealthifyMe has raised over $25 Million in funding from marquee investors such as Sistema, IDG, Inventus, Blume and Samsung Next. HealthifyMe works with over 75 corporates across the country to deliver employee wellness solutions. We aspire to be a leading health and fitness platform across the globe.

Data Engineer Responsibilities:
Design, construct, install, test and maintain data pipeline and data management systems.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Collaborate with members of your team (eg, Data Architects, the Software team, Data Scientists) on the project’s goals.
Recommend different ways to constantly improve data reliability and quality.
Data Engineer Requirements:
Experience in a related field with real-world skills and testimonials from former employees.
Familiar with data warehouses like Redshift, Bigquery and Athena.
Familiar with data processing systems like flink, spark and storm.Develop set
Proficiency in Python and SQL.Possible work experience and proof of technical expertise.
You may also consider a Master’s degree in computer engineering or science in order to fine-tune your skills while on the job. (Although a Master’s isn’t required, it is always appreciated).
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.
Minimal data science knowledge is a Must,should understand a bit of analytics.
Look forward to:
Working with a world-class team.
Fun & work at the same place with an amazing work culture and flexible timings.
Get ready to transform yourself into a health junkie
Join HealthifyMe and Make History!"
Data Analyst,"Bengaluru, Karnataka",Liventus,None,Organic,"We’re looking for a Data Analyst who will be responsible for assisting in the efficient planning, collection, and maintenance of data sources to join our analytics team. If you meet the following requirements, wish to enter a creative, collaborative, and fun environment, and work alongside people dedicated to the success of our company, please apply online at careers.liventus.com
Apply Online
Job Responsibilities:
Build Tableau reporting
Identify, clean, and combine data to solve relevant business problems
Research and troubleshoot data related questions, tickets, and issues
Monitor and maintain our existing data to ensure it remains clean, accurate, consistent, and impactful
Transform data into meaningful insight and recommendations for business partners from various areas and companies, including but not limited to the Executive and Sales teams
Work with other members of Data Analytics team to develop business workflows that will help us make better decisions and be more efficient in our daily work
Coordinate development of test data, system testing, and documentation for all phases of our data migration processes (ETL)
Stay up-to-date on emerging technologies
Occasionally perform ad hoc reporting to answer specific business questions from upper management
Support users by developing thorough and complete documentation
Job Requirements:
Candidate must have the following:
3 - 6 years of experience in data analysis using query tools required
Strong Tableau report building skills
Strong SQL skills with the ability to perform advanced queries and create stored procedures
Experience with dashboard reporting, scorecards, and executive presentations focused on analytics
Understanding of CRM reporting capabilities
Ability to gather business requirements and translate to technical specifications
Bachelor’s degree in Management of Information Systems (MIS), Mathematics, Statistics, Computer Science, or Business with an analytics focus
Data manipulation skills within Excel, such as VLOOKUP, Pivot Tables, VBA, etc.
An understanding of statistical and predictive modeling techniques and concepts
Strong analytic/problem-solving, documentation, and prioritization skills
A desire to learn new things and an ability to adapt to change and innovation
Ability to work on a team and manage individual prioritized workload
Candidate must be able to effectively communicate in English (written & verbal)
Knowledge of any scripting language e.g. Shell script, JavaScript, etc.
Knowledge of any ETL Tool e.g. SSIS
Benefits:
Group Mediclaim policy
Accident policy
Parental Health Insurance
Retirement benefits (Provident Fund)
Gratuity"
Data Process Associate_ Clinical Data Management Team,"Bengaluru, Karnataka",Quanticate,None,Organic,"Overview:
We have an exiting opportunity for Fresher's(0-2 year's experience) with knowledge in CDM to join our dynamic Clinical Data Management team.
Responsibilities:
Core Accountabilities: Activities required of a Junior Data Process Associate (however not restricted to) are as below:

To enter data from CRF’s into study database
To follow applicable data entry guidelines.
To scan CRF’s as requested
To assist in the testing of databases prior to activation.
To assist in the preparation of study specific documentation as appropriate.
To assist with the processing of clinical data for projects.
To perform the Quality Control of Data Entry and CRF/database as appropriate.
To be aware of and to work to the standards appropriate to the study (CRO or customer).
To advise on possible improvements to procedures and standards.
To perform other reasonable tasks as requested by management.
To perform other reasonable tasks as requested by management.
Qualifications:
Education

Qualified to an appropriate standard, preferably to degree level in a life sciences subject.

Desired Candidate Profile

Fresher's(0-2 year experience) with knowledge in CDM
PC skills, including some knowledge of Excel and Word.
Basic knowledge of Clinical Data Management Analytical skills and attention to detail.
Good communication skills (oral and written) and good analytical skills.
Basic knowledge of ICH Guidelines and GCP including regulatory requirements for the conduct of clinical development programs, especially as related to data handling and processing.
Ability to manage competing priorities in a changeable environment.
Ability to inspire effective teamwork and motivate staff"
Data Engineer,India,Syngenta,None,Organic,"About the Job Role
Opportunity to be at the forefront of a new data capability for multi-national agribusiness corporation focused on business outcomes
Support data centric innovation projects including building the common data layer of Syngenta to enable Advance analytic and data science
Drive business enabling data integration services
Collaborate with leading technical experts internally as well as externally
Directly impacts Syngenta’s ability to integrate and utilize new and complex data sources
Purpose of the job
Along with collaborations and partnerships deliver the next generation data platform for Syngenta. The role will lead a team enabling integration of data sources with next generation technologies across functional boundaries and enable insight-based decision that impact business outcomes. Work with analysts, project teams, and other leaders within Syngenta to translate data-driven insights into actions and decisions. Implement next generation technologies and capabilities.
Implement a high-performance, next generation data platform
Work with a team to identify, design and build appropriate dataset and linkages for complex data
Refactor legacy data platforms to integrate with the next generation data platform.
Implement data quality infrastructure and processes.
Implement data infrastructure for emerging data classes.
Contribute to the team’s growing set of development platforms, tools, processes and promote industry standard best practices

Qualifications

Experience required for the job
3-5 year experience running Scrum/Agile development practice (Ideally as product owner or scrum master)
5-10 years of experience with large scale data technologies such as AWS ETL environment, S3, Glue, RedShift, Hadoop, Spark, machine learning, etc.
Knowledge of informatics, analytics, computational science, service management, delivery
Knowledge of toolsets and capabilities utilized by expert data scientists and modelers
Knowledge of Python and Unix scripting
SQL, NoSQL and RDBMS databases
Hadoop-based tools (Hive, Hbase, MapReduce, MongoDB, Cassandra)
Data modeling and ELT / ETL
Data analytics and visualization
Solid communication skills and team player

Qualification and critical knowledge required
Bachelor’s or Master’s degree in informatics, computer science, or related fields
Experience in Cloud based ELT, Big Data tools, infrastructure, analytics and visualization
Leading cross-functional / organizational / geography people and teams
Have cultural awareness

Primary Location: India
Job: IS & Business Architecture - Operations"
Senior Consultant - Data Engineer,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Senior Consultant - Data Engineer
Location:TRIL GTC Chennai
GCL: D1
Job description:
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZ’s global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.
We are looking for a passionate Data engineer who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.
Roles & Responsibilities:
Provide data engineering (ETL, ODS, Marts, Reports) support to R&D IT portfolio
Deliver cost-effective solutions to support data engineering activities, for example, data ETL workflows
Test and quality assess new D&A solutions, to ensure they are fit for release: code assurance, Unit and System Integration Testing, Data testing, release management control and support of UAT processes
Ensure that business data and information assets are made available as data services and artefacts for consumption by the wider AZ enterprise
Mandatory skills:
Experience of working with a range of data analytics architectures. These may include: traditional warehousing, distributed computing, visualization analytics
Experience with & knowledge of Talend including:
Use of enterprise version of Talend Software preferably in a virtualized environment like AWS
Development of both standard ETL jobs deployed on JobServers and services (REST, SOAP) deployed on Talend ESB infrastructure
Familiar with using version control (branching, merging etc), ideally Git
Knowledge of working with Talend project branches, merging them and publishing and deploying code to runtime environments
Knowledge of techniques for optimising Talend code
Experience in Talend best practices for error handling, optimization, job layout, job design and naming conventions
Experience and familiarity with data models and artefacts
Any DB experience like Redshift, Netezza, Teradata, etc
Interpret data, process data, analyze results and provide ongoing support of productionized applications
Strong analytical skills with the ability to resolve production issues
Understanding of business area/process in scope
Willing to work in a cross-cultural environment. Ability to work effectively independently or as part of a team to achieve objectives
Eager to learn and develop new tech skills as required
Good written and verbal skills, fluent English
Desired skills:
Domain knowledge (processes & data): Pharma R&D
Experience of working with NoSQL, virtualization, data streaming etc
Amazon Web Services: Connecting, loading and reading data from AWS database technologies like MySQL, Aurora, AWS Redshift, PostgresSQL
Experience with Talend Metadata Manager and Talend Data Preparation an advantage
MS Power BI knowledge or any other reporting tools
Agile/Scrum process
ITIL knowledge

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Robotics Software Engineer II,"Bengaluru, Karnataka",SigTuple Technologies Pvt Ltd,None,Organic,"About SigTuple :
At SigTuple our vision is to make the world of healthcare accessible, affordable and accurate through
data-driven intelligence. We pride ourselves in being the world’s first full-stack healthcare company
having our presence in all the layers of the healthcare fabric – medical devices, diagnostic services and
smart technology platforms to define the healthcare of tomorrow.
We are solving some of the most advanced problems arising out of an unprecedented application of
recent advances in computer science, robotics and AI to the world healthcare. From building robotics
arms, understanding the optics, cameras and operating them through PCB and firmware to capture the
images at micron level accuracy and driving autonomous diagnosis through microscopy and retinal
images and videos, till managing the complex laboratory workflow we are pushing the boundaries of the
latest tools available out there. Research in robotics, core AI, computer vision and extreme platform
engineering are an integral part of our journey. Our indigenous cloud-based AI platform automates routine
tests and empowers pathologists and opthamologists in hospitals and clinics with precision, efficiency,
and speed.
About the role:
SigTuple is looking for a Robotics Software Engineer. In this role, you will be working with the team who
abstracts the hardware from the application developers. Right controls need to be identified by abstracting
out other challenges of the underlying hardware limitations e.g. backlash, optics, motors, etc. Right
metrics need to be captured to understand the underlying health of the physical device.
What you will do:
Play a critical role in software and firmware integration to make the several in-house devices
work.
Build the SDK on Ubuntu so application developers can control the device.
Understand the interaction of various peripheral devices with the kernel.
Debugging core issues at system level ranging from RAM crashes to various race conditions.
Categorize the bugs and handle the errors.
Parse the error logs and system logs.
Interact with other team members to solve the problems.
What you will need:
2-4 years of experience.
B.Tech/M.Tech. (Computer Science, ECE, EEE)
Expertise in C, Python programming.
Expertise in Data-Structures, Algorithms.
Good at system programming, computer architecture.
Understanding of Linux kernel (Specific to IO subsystem, USB, BIOS/UEFI), device drivers.
Ability to debug kernel dumps.
Keywords
Must have: Python, Understanding of Linux Kernel, Device Drivers
Job Type: Full-time
Experience:
Software Engineering: 3 years (Preferred)
work: 5 years (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
No"
Senior Machine Learning Engineer,"Bengaluru, Karnataka",Ushur,None,Organic,"Ushur is transforming the way businesses communicate, with cutting-edge AI and automation technologies. Previously using outdated emails and phone calls, businesses are now automating their conversations with automated text-messaging using Ushur’s platform. We are creating breakthrough experiences for our enterprise customers by deploying the best of web, mobile and data analytics technologies. We focus on fast, iterative development with an emphasis on design-right philosophy. Currently, at Ushur, we are experiencing unprecedented & exciting growth with endless opportunities to innovate!

The Role

Ushur seeks a Senior Engineer with Machine Learning Expertise to join a high-impact team to enhance the Language Intelligence framework that is at the core of industry’s leading Micro-Engagement Platform from Ushur.

What you’ll be doing…

As one of the key members of of the Language Intelligence team, your responsibilities will include:
Design, develop and support machine learning and deep learning models involving
Ushur’s Language Intelligence that encompasses the spectrum of NLP and NLU to support information processing as well as drive the Ushur micro-engagements with users.
Responsible for designing and/or adapting various algorithms, undertaking experiments and impacting the Ushur Micro-engagement Platform.
Construct comprehensive knowledge graphs to support various applications that are delivered over the Ushur Platform.
Research and employ modern algorithms into the Ushur Platform to keep innovating with efficiency, impacting the feature-base of Ushur’s Platform.

Collaborating with engineers from AI & other teams on data analysis and feature design efforts

Qualifications

MS/PhD in Computer Science or related field
At least 3 years hands-on working experience in the AI/ML Area
Demonstrable experience with NLP/NLU techniques, language data
Strong knowledge of NLP tasks and techniques, NER, training machine learning models, neural networks
Strong programming skills in Python or Java and fluency in data manipulation (SQL/Spark/Pandas) and machine learning kits like scikit-learn, Keras/Tensorflow, XGBoost, Gensim
Excellent verbal & written communication, strong organizational skills and attention to detail

Why Join us?

We are passionate about Ushur, our product, and helping our employees grow and develop in their career in a caring, collaborative environment. We offer a very competitive compensation plan & stock options for the ideal candidates."
Data Scientist,"Andheri, Mumbai, Maharashtra",Angel broking,None,Organic,"Expertise or extensive experience with Python/ R -programming
A thorough understanding of SQL databases
Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data
Experience Range:
4 - 8 years
Educational Qualifications:
Any graduation,
Skills Required :
data scientist, data analyst,
Candidate Attributes :
Should be good at R Python and Big Data"
Software Engineer- Data Model Engineering,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
What We Do
At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.

Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.

Who We Look For
Goldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.
Working in a global team of developers on integrating BI products into GS infrastructure. Developing automation, governance and reporting solutions to provide firm and regulatory mandated controls. Working with stakeholder form firm wide business unites on defining and driving GS BI strategy and governance. Working close with the rest of Data Intelligence team to provide holistic data management solution for GS. Data Model Engineering provides the platform that unlocks the firm’s data by providing the means to describe, access and manipulate it. It is the heart of a data-centric approach to application development. We engineer modelling languages, Software Deverlopment Lifecycle tools, large-scale operational services and portals for access and analysis to achieve this. Data Model Engineering is part of the Data Intelligence platform whose purpose is to extract the maximum value from the firm’s data at all stages of its life.
RESPONSIBILITIES AND QUALIFICATIONS:
HOW YOU WILL FULFILL YOUR POTENTIAL
Drive, shape and champion data modelling standards within the engineering organization
Define analytics and tools to manage the metadata and extract lineage and other useful information from our data graph
Design discussion and review to shape the evolution of the platform.
Leverage technologies and standards to automate and improve all aspects of the platform.
Support and educate clients in their use of the platform

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
Degree qualification in Computer Science or related field
Java or related JVM development experience
Strong technical ability, willing to learn and evolve your skills with advances in Technology
Strong Data Modeling experience with ability to collaborate effectively across global teams and communicate complex ideas in a simple manner
Team player, eager to work in a global organization

Preferred Qualifications
Experience of data modelling and SQL
Experience with Model Driven Architecture
Programming Language design and implementation
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
"Senior Consultant, Advanced Analytics Python/R","Bengaluru, Karnataka",Fractal.ai,None,Organic,"Role Brief:
6-9 years of Advanced analytics/Predictive Modeling using Python/R, SQL and Machine Learning.
Brief about the Team & Fractal:
Fractal Analytics is Leading Fortune 500 companies leverage Big Data, analytics and technology to drive smarter, faster and more accurate decisions in every aspect of their business.
Fortune 500 companies recognize analytics is a competitive advantage to understand customers and make better decisions. We deliver insight, innovation and impact to them through predictive analytics and visual story-telling.e.
Technical and domain expertise-
Expertise in Python/R plus SQL & advanced analytics/Statistics Techniques such as general linear model, ANOVA, decision trees, linear regression, Bayesian etc
Execution excellence -
Lead at least one client engagement independently. Execute end to end client engagements. Ensure regular client updates & meetings, stakeholder management, any failure or risk analysis of the project, data sources, tracking execution & success metrics is done effectively & efficiently.
Job Responsibilities:
Solve business problems & develop a business solution: Use problem-solving methodologies to propose creative solutions to solve a business problem. Recommend design and develop state-of-the-art data-driven analysis using statistical & advanced analytics methodologies to solve business problems. Develop models & recommend insights. Form hypothesis and run experiments to gain empirical insights and validate the hypothesis. Identify and eliminate possible obstacles and identify an alternative creative solution.
Project management: Lead at least one client engagement independently. Execute end to end client engagements. Ensure regular client updates & meetings, stakeholder management, any failure or risk analysis of the project, data sources, tracking execution & success metrics is done effectively & efficiently.
Client relationship management: Build deep client relationship, network & be a thought partner. Anticipate business problems & deliver par excellence.
Sales Support & account growth: Actively focus on opportunities to grow the client along with the senior engagement manager. Support the sales team as required for RFPs and regular sales pitches
Firm building: Contribute to firm growth by participating and conducting training sessions.
Coaching & grooming: Coach & groom the team on gaining knowledge & skills on first principles of analytics techniques, problem-solving, project management, client relationship management
The Person:
Experience:
The overall experience of Minimum 6 to 9 years with at least 4 to 9 years of hands-on experience in running Advanced analytics projects
High proficiency in concepts and algorithms used in design of experiments.
Expert-level proficiency in statistical/ML predictive techniques such as regression, Bayesian methods, tree-based learners, SVM etc.
Good to have working experience in one or more of Probabilistic graphical models, Reinforcement learning, NLP and related areas
Expertise in Python/R plus SQL & advanced analytics/Statistics Techniques such as general linear model, ANOVA, decision trees, linear regression, Bayesian etc
Problem-solving, Project management, and communication skills & Creative thinking
Knowledge of data conversion strategy, capturing data, creating source to target definitions for ETL/ data flow process, data quality, and database management
Education:
B.E/B.Tech/M.Tech in Computer Science or related technical degree OR Equivalent
Location: Bangalore/Mumbai/Gurgaon"
Data Scientist,"Bengaluru, Karnataka",Alphonso,None,Organic,"Data Scientist
Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.
Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.
We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.
Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data
Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus"
Tech Quantitative developer,"Mumbai, Maharashtra",MSCI Inc,None,Organic,"About MSCI
For more than 40 years, MSCI’s research-based indexes and analytics have helped the world’s leading investors build and manage better portfolios. Clients rely on our offerings for deeper insights into the drivers of performance and risk in their portfolios, broad asset class coverage and innovative research. Our line of products and services includes indexes, analytical models, data, real estate benchmarks and ESG research. MSCI has $15 Billion of software and content-based products and services. MSCI serves 98 of the top 100 largest money managers, according to the most recent P&I ranking.

For more information, visit us at www.msci.com.

Position Overview


We are searching for talented back-end quantitative analytics software developer. As a member of the quantitative development practice of the MSCI Analytics Platform development group, the quantitative developer extends, maintains and markets a rich collection of analytical software capabilities. Every Quantitative developer individual owns the delivery of analytics to the MSCI analytics platform community of users. The latter consists in demanding analytics practitioners, from and external to MSCI. They have high expectations about the accuracy and performance of the analytics they use. Being able to not only understand the specifics of the analytics to develop, but also how they integrate into an investment workflow is critical to being successful in the offered position.
The Quantitative developer operates within the framework of the MSCI Analytics Platform and is expected to contribute to the development of its framework. Through constant interaction with architecture and framework teams he/she is capable of clearly articulating the challenges the analytics must answer to and therefore help guide where the platform needs to develop.

Scope of Responsibility


The quantitative engineer interacts on a very frequent basis with the MSCI research and product management groups; as being able to accurately identify client requirements is critical. Contributions of the quantitative developer are expected to be thoroughly tested and documented. Ultimately the marketing aspects of his/her deliveries are critical to their adoption by the MSCI Analytics Platform users. The performance profile of the analytics is critical and needs to be considered in every aspect of the work.
Quantitative development engineers work in tandem with the visualization team. The latter ensures proper and effective engagement of the analytics client experience and therefore, needs a good level of conceptual understanding the quantitative developer shall provide as part of his mission. The Quantitative developers also operate in close coordination with the application management to get their production released within the expected timeframe and quality metrics.
This position is optimal for individuals effective at operating cross functionally and with geographically distributed teams.

Specific Knowledge/Skills


Advance functional and general programming languages (Scala / Java, C++)
Strong quantitative skills are a must (lineal regressions, machine learning, statistics)
Excellent analytical skills are a must (algorithms, data structures, and statistics)
Committed test-driven/quality oriented SDLC proven experience
Experience in building software for demanding client community is a must
Experience working in Linux environments
Adaptability to change in programming languages and technologies
Attention to detail with commitment to test-driven development approach
Speaks and writes clearly and effectively in English even when relating complex information
Must be comfortable operating in a globalized work environment.

Desired Experience


5+ years of solid software development experience
Experience with Agile methodology preferred
Development experience of quantitative software from within the financial industry would be a strong plus.

Desired Qualifications

Advanced degree in Computer Science or Information Systems
Strong academic background in mathematics, physics and statistics is a plus (e.g. Machine Learning, Financial engineering and Data science)

Due to the great number of applications we receive for each of our open vacancies, we are unable to respond on an individual basis."
"Engineer, Associate","Hyderabad, Telangana",Qualcomm India Private Limited,None,Organic,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Software Engineering
Job Overview:
Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.
General Summary Develops, creates, and modifies general computer applications software or specialized utility programs. Analyzes user needs and develops software solutions. Designs software or customizes software for client use with the aim of optimizing operational efficiency. May analyze and design databases within an application area, working individually or coordinating database development as part of a team. Modifies existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Analyzes user needs and software requirements to determine feasibility of design within time and cost constraints. Confers with systems analysts, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and interfaces. Stores, retrieves, and manipulates data for analysis of system capabilities and requirements. Designs, develops, and modifies software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design. The responsibilities of this role include:
Working under close supervision.
Taking responsibility for own work and making decisions with limited impact; impact of decisions is readily apparent; errors made typically only impact timeline (i.e., require additional time to correct).
Using verbal and written communication skills to convey basic, routine factual information about day-to-day activities to others who are fully knowledgeable in the subject area.
Completing most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.
Exercising some creativity to troubleshoot technical problems or deal with novel circumstances.
Limited problem solving required, generally in the nature of troubleshooting simple processes or technology. The responsibilities of this role do not include:
Financial accountability (e.g., does not involve budgeting responsibility).
Influence over key organizational decisions.
Role in strategic planning.
Principal Duties & Responsibilities
Gathers, integrates, and interprets information specific to a module or sub-block of code from a variety of sources in order to troubleshoot issues.
Makes straightforward decisions based on well-defined task requirements.
Collaborates with others inside project team to accomplish project objectives.
Networks with colleagues within own team to gain insight, ideas, and connections.
Communicates with project lead to provide status and information about impending obstacles.
Stays focused and deals with setbacks in a timely manner.
Prioritizes project deadlines and deliverables with close supervision.
Adapts to changes and setbacks in order to meet deadlines.
Resolves straightforward software issues and bugs within a reasonable amount of time.
Escalates technical issues to an appropriate party (e.g., project lead, colleagues).
Designs small features or approach for a straightforward coding effort.
Writes readable code for small features or minor bug fixes to support collaboration with other engineers.
IT Core Competencies N/A
Required Competencies (All competencies are required upon entry)
Analytical Skills - The ability to collect information and identify fundamental patterns/trends in simple to moderately complex data. This includes the ability to gather, integrate, and interpret information from several sources.
Communication- The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.
Creating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.
Decision Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.
Getting Organized - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.
Software Engineering - Knowledge of the overall process for developing new software. This includes knowledge of the roles and responsibilities of software engineering and other functions, major phases, checkpoints and deliverables. This also includes the ability to identify common issues and considerations for bringing a new product to the marketplace.
Technical Troubleshooting - Knowledge of systematic approaches to solving common technical problems (e.g., hardware, software, application, operational). This includes the ability to identify problems and report and escalate problems according to established procedures. This also includes the ability to identify available resources for troubleshooting.
Additional Competencies N/A
Minimum Qualifications
Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.
Preferred Qualifications N/A
Physical Requirements
Frequently transports between offices, buildings, and campuses up to ½ mile.
Frequently transports and installs equipment up to 5 lbs.
Performs required tasks at various heights (e.g., standing or sitting).
Monitors and utilizes computers and test equipment for more than 6 hours a day.
Continuous communication which includes the comprehension of information with colleagues, customers, and vendors both in person and remotely.
Applicants : If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport
To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications."
Business Intelligence Engineer,"Bengaluru, Karnataka",ADCI - BLR 14 SEZ,None,Organic,"1+ years of experience as an analyst or engineer in the data/BI space
Experience with data visualization using Tableau, Quicksight, or similar tools
Experience with SQL

Industry experience of working in a Business Intelligence Engineer role.
Familiarity with theory and practice of statistics, information retrieval and data mining.
Demonstrated capability of extracting, transforming, and cleaning large (multi-TB) data sets.
Experience in scripting for automation (e.g. Python, Perl, Ruby).
Experience using statistical packages and business intelligence tools such as R, Python etc.
Experience in data mining and optimizing database query performance in SQL.
Experience in building dashboards and reports to surface business intelligence data.
Strong analytical and excellent problem solving skills.
Proven interpersonal, written and verbal skills, capable of presenting your beliefs clearly and compellingly in both verbal and written form to large cross-functional teams of technical and non-technical members.
Strong desire to push your ideas into production, overcoming obstacles, in order to benefit Amazon's customers.
Degree in Computer Science, Information Technology, Business Analytics, Mathematics, Statistics or Economics. In lieu of degree, relevant skills and equivalent experience

Amazon strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce platform.
Job Description

Business intelligence engineer would support the analytical requirements of the Compliance Operations team. Candidate will be responsible for conducting deep dive analyses to solve complex business problems. He/ she will also be responsible for creating robust reporting frameworks to increase visibility into data and enable data driven decision making. Another key aspect of the job is to unearth insights from data to help the operations team in driving process excellence. This position requires excellent statistical and analytical abilities, good knowledge of business intelligence solutions and data engineering practices, and the ability to collaborate with various teams across compliance operations. Candidate should be comfortable with ambiguity, capable of working in a fast-paced environment, possess strong attention to detail, and able to collaborate with customers to understand and transform business problems into requirements and deliverables

Amazon strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce platform.
Job Description

Business intelligence engineer would support the analytical requirements of the Compliance Operations team. Candidate will be responsible for conducting deep dive analyses to solve complex business problems. He/ she will also be responsible for creating robust reporting frameworks to increase visibility into data and enable data driven decision making. Another key aspect of the job is to unearth insights from data to help the operations team in driving process excellence. This position requires excellent statistical and analytical abilities, good knowledge of business intelligence solutions and data engineering practices, and the ability to collaborate with various teams across compliance operations. Candidate should be comfortable with ambiguity, capable of working in a fast-paced environment, possess strong attention to detail, and able to collaborate with customers to understand and transform business problems into requirements and deliverables

Degree in Computer Science, Information Technology, Business Analytics, Mathematics, Statistics or Economics. In lieu of degree, relevant skills and equivalent experience
Familiar with theory and practice of relevance and machine learning."
"LEAD, DATA ANALYTICS","Bengaluru, Karnataka",AT&T,None,Organic,"Description
Role & Responsibilities
Responsibilities include data and reporting infrastructure planning, development and management of data marts, development, production and support of credit and collections operational and portfolio level reports, and ad-hoc query and data analysis. Our team supports key business initiatives by providing the key data and business intelligence that drives decision making. The focus is on all aspects of the customer life cycle from ordering and credit to billing and collections, as well as aspects of customer interactions through calls into collections centers to digital interactions via smartphone apps or the web.
Work Details
large part of the employee responsibilities involves complex data analysis and development projects or requests to develop data engineered solutions to support new or changing business processes. The employee is expected to develop a solution that meets the projects requirements using their technical expertise, knowledge of the systems, data layers and business processes and experience but they have discretion regarding the design as long as business requirements are met. A variety of tools, databases, job query languages and various technologies are used to solution the problem and meet the expectations of the business.
Works with internal clients individually or as part of a larger cross functional team to define and document requirements for data integration, analytics and business intelligence projects in support of business initiatives. Works with other data engineers on the team to collaborate on projects, coordinate data processing work or share code.

Qualifications
Technical Experience
High level of proficiency using data query and handling tools like SQL assistant, QMF, and Oracle SQL Plus and Python is required. Experience with analytic and visualization tools like PowerBI (desired) and Tableau. Proficient in MS Office and Excel.
Education & Qualification: Bachelor’s degree in business, Information Systems, Engineering, Math, or Sciences
Shift Timings: 1:00 PM – 9:00 PM IST over lapping with US time Zone."
Python Data Engineer,"Pune, Maharashtra",AppZen,None,Organic,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Engineering expert to come and work on our growing Data pipeline and AI applications. You will be working with a team of highly skilled and motivated engineers and professionals. If you are a polyglot programmer who likes to build AI and data applications, AppZen is the right place for you to apply and grow your skills.
Must Haves:
Solid understanding of data fundamentals and tools
Excellent knowledge of Python fundamentals and application
Built applications for containerized deployment
AI/ ML frameworks and toolkits viz. TensorFlow, Scikit learn, xgBoost is an advantage
Expertise in Elasticsearch setup, development and maintenance is a must
Expertise required in other database like Postgres, Redis
Familiar with AWS services, especially S3, big data services and DevOps tools
B.E. or B.Tech in Computer Science, Engineering, or other relevant technical field.
Must have 5-7 years of industry experience.
Must Have:
Able to work onsite in Pune, IN

Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base."
"Manager, Data Science","Bengaluru, Karnataka",Epsilon,None,Organic,"Company Description
Positioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Through a connected suite of products and services, Epsilon combines leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes. For more information, visit us at https://india.epsilon.com/
Follow us on social: LinkedIn, Facebook, Instagram, and Twitter

Job Description
PeopleCloud Customer is a world-class cloud-based Customer Data Platform (CDP) fully enabled with a complete Marketing Automated Operating System (MAOS). The PeopleCloud Customer platform provides out-of-the-box SaaS and PaaS products that are fully integrated, including Customer Identity services, Deterministic and Probabilistic Customer Record stitching services and Marketing Machine Learning algorithms and models trained to deliver personalized activation at scale.
The PeopleCloud Customer team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group.
You will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the COSMOS Cognitive Marketing Intelligence Cloud Platform team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects.
Provide guidance to the team of Data Scientist and manage Machine learning and Deep Learning based projects. Work with the team who analyze complex data structure, manipulate, cleanse data and perform statistical analysis
Design and guide machine learning models using Spark ML, Python, HDFS, Spring.
Design and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python
Develop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory
Own end to end implementations of multiple Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.

Qualifications
Experience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks
Strong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Proven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results.
Expertise in predictive analytics/statistical modeling/data mining/machine learning algorithms and techniques (classification, clustering, regression, multivariate testing)
Excellent communication & interpersonal skills with an ability to communicate ideas.
MS in Computer Science, Math, Physics, or equivalent education/professional experience is required.
10-12 years of total IT experience with 5+ years of managing and leading data science teams with demonstrable experience
Deep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services.
Azure Cloud experience required. Azure Data Factory experience preferred.
Strong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch
Experience with sequence modeling using RNNs/LSTMs is must
Strong experience in at least one database technology (i.e. Hive, PrestoDb etc.)
Experience with one or more web analytics tools (Google Analytics, etc.)
Strong experience in at least one programming language (i.e. Python, R, C, C++ is plus)
Experience working with different query languages (i.e. PL-SQL, T-SQL)
Understanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred.
Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)
Strong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Excellent communication & interpersonal skills with an ability to communicate ideas, insights and complicated analysis effectively at all organizational levels, include engineering leadership

Additional Information

null"
Software Engineer-RIO,"Bengaluru, Karnataka",MiQ Digital,None,Organic,"MiQ is the leading marketing intelligence company with technology and people that help businesses win. We are experts at ingesting large amounts of data, modelling data to convert into insights and then actioning these insights through a variety of products and services.
Our People have an endearing and unique quality that sets them apart from the rest and that is why our product inspires. Our People make the difference and our values make the people.
In short, MiQ make data valuable, insightful, and intelligent, which helps clients engage customers, grow sales and generate revenue. MiQ offers its clients products and services across Media (which is their programmatic managed media offering), Analytics (custom engineering and data science solutions for business challenges in digital marketing space) and Technology (technology and analytics capabilities geared for their customers use). We enjoy a 97% client retention rate globally across brands such as Walmart, Barclaycard and Ford.
MiQ was built 9 years ago by Gurman Hundal and Lee Puri, with its original base in London, UK. Remaining a self-funded business, the company has now grown to over 700 employees, with 15 global offices covering 4 continents.
Our business vision is to empower the marketing divisions with the relevant insights so that they can shape the overall business strategy. It is for this reason MiQ has very exciting and realistic growth expectations over the coming years. It’s a great opportunity to work across a global business while becoming a key contributor within a growing, winning organization.
QUICK FACTS
Represent over 450 Client’s Globally
97% Retention Rate of Client’s since Launch
700 Global Employee’s, with a 100% Staff Retention Rate in the first 3 years of the business, currently 93%
Offices in London, Manchester, Hamburg, 10 cities in the US, Toronto, Australia and Bangalore
Award Winning Infrastructure – Recently voted for the ‘Best Use of Data’ as well as ‘Best Trading Team’ in UK and ‘Most Innovative Brand in Mobile’ in North America
Role: The SDE is a key player in the team, and will work on developing software components in front-end (Chrome plugin) and back-end as per the product growth or customer requirements.
The role provides an opportunity to design and develop end to end software components and systems from the ground up and have ownership of them. It requires working closely with the product manager, UI/UX Design team to make sure the features being developed are in accordance with the company standards. Due to the evolving nature of the product, one would get to work with the latest technologies and frameworks like Chrome Plugin, Spring Boot, Websockets, Celery, Spark to name a few.
The team follows Agile methodology and utilizes CI and CD pipelines to speed up the product’s time to market.
Responsibilities:
Design and Develop scalable components in front-end and back-end with end to end ownership.
Promote and adopt good software development practices.
Assist peer developers in coding and troubleshooting.
Participate in design reviews with the Team, Technical Architect and the UI/UX Design team to ensure that quality standards are followed as per company norms
Staying updated on emerging technologies.
Work with business analysts, product team and QA team to identify defects, troubleshoot and track them to resolution.
Required skills and experience:
1+ years of full-time experience as a full stack developer
Proficiency with fundamental front end languages such as HTML, CSS and JavaScript.
Proficiency with object oriented programming in Java and exposure to REST APIs
Strong Design and coding skills in Java and RDBMS(Sql Queries)
Excellent verbal and written communication skills
Excellent analytical and problem-solving skills.
Ability to collaborate across multiple functions.
Extreme attention to detail.
Ability to meet tight deadlines and prioritize workload.
At MiQ, we don’t just accept the differences of our people, it is what builds us as a community. MiQ is very proud to be an equal opportunity workplace."
Robotics Software Engineer II,"Bengaluru, Karnataka",SigTuple Technologies Pvt Ltd,None,Organic,"About SigTuple :
At SigTuple our vision is to make the world of healthcare accessible, affordable and accurate through
data-driven intelligence. We pride ourselves in being the world’s first full-stack healthcare company
having our presence in all the layers of the healthcare fabric – medical devices, diagnostic services and
smart technology platforms to define the healthcare of tomorrow.
We are solving some of the most advanced problems arising out of an unprecedented application of
recent advances in computer science, robotics and AI to the world healthcare. From building robotics
arms, understanding the optics, cameras and operating them through PCB and firmware to capture the
images at micron level accuracy and driving autonomous diagnosis through microscopy and retinal
images and videos, till managing the complex laboratory workflow we are pushing the boundaries of the
latest tools available out there. Research in robotics, core AI, computer vision and extreme platform
engineering are an integral part of our journey. Our indigenous cloud-based AI platform automates routine
tests and empowers pathologists and opthamologists in hospitals and clinics with precision, efficiency,
and speed.
About the role:
SigTuple is looking for a Robotics Software Engineer. In this role, you will be working with the team who
abstracts the hardware from the application developers. Right controls need to be identified by abstracting
out other challenges of the underlying hardware limitations e.g. backlash, optics, motors, etc. Right
metrics need to be captured to understand the underlying health of the physical device.
What you will do:
Play a critical role in software and firmware integration to make the several in-house devices
work.
Build the SDK on Ubuntu so application developers can control the device.
Understand the interaction of various peripheral devices with the kernel.
Debugging core issues at system level ranging from RAM crashes to various race conditions.
Categorize the bugs and handle the errors.
Parse the error logs and system logs.
Interact with other team members to solve the problems.
What you will need:
2-4 years of experience.
B.Tech/M.Tech. (Computer Science, ECE, EEE)
Expertise in C, Python programming.
Expertise in Data-Structures, Algorithms.
Good at system programming, computer architecture.
Understanding of Linux kernel (Specific to IO subsystem, USB, BIOS/UEFI), device drivers.
Ability to debug kernel dumps.
Keywords
Must have: Python, Understanding of Linux Kernel, Device Drivers
Job Type: Full-time
Experience:
Software Engineering: 3 years (Preferred)
work: 5 years (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
No"
Python Developer - Job Code(PY-02),India,UVJ Technologies Private Limited,None,Organic,"Job Description :
Responsibilities:
â€¢Experience with Python to implement data analysis workflows in a Linux environment.
â€¢Experience evaluating and improving the efficiency of programs in a Linux environment.
â€¢Experience with command line compilation and debugging.
â€¢Experience with makefiles, coverage analysis and other forms of runtime profiling.
â€¢Experience with all phases of the Software Development Life Cycle.
â€¢Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
â€¢Working knowledge of MS Office suite of applications.
â€¢Working knowledge of Bioinformatics, Genomics, or Life Sciences
â€¢Good verbal and written communication skills.
â€¢Ability / willingness to learn bioinformatics / genomics
â€¢Extra Credit: Experience designing relational databases and working knowledge of SQL.
â€¢Extra credit: Experience with the Common Workflow Language (CWL)
â€¢Extra credit: Experience with Arvados.
â€¢Extra credit: Experience with PERL
â€¢Extra credit: Experience with JAVA
â€¢Extra credit: Experience with C++.
â€¢Extra credit: Experience working with AWS
â€¢Extra credit: Experience working with Docker

4.00-7.00 Years"
Looking for Python Scripting,"Mumbai, Maharashtra",ICS Consultancy Services,"₹10,00,000 - ₹25,00,000 a year",Organic,"Roles and responsibilities for Looking for Python Scripting
: Role : Digital Data Engineering Practitioner Role Description : Develop analytics based solutions that produce quantitative and qualitative business insights. Work with partners as necessary to integrate systems and data quickly and effectively, regardless of technical challenges or business environments. Must have Skills : Python Scripting Good to Have Skills : R Programming Job Requirements : A-Professional Experience 1-Min 5 years of Data Science exp 2-Overall 6 to 9 years of work exp B-Responsibilities 1-Proficiency in R and Python 2-TensorFlow, Natural Language Processing preferred 3-Should have expertise in advanced analytics and in developing models using advanced analytical tools such as R and Python 4-Proven experience in regression, time series, classification, clustering, text analytics, deep learning and other machine learning artificial intelligence techniques 5-Research oriented mindset with ability to quickly learn new technologies 6-Use artificial intelligence, machine learning, data mining, predictive modelling statistical techniques to create new scalable models for business requirements 7-Perform sophisticated analysis and predictive modeling with minimal supervision 8-Understand complex business challenges, design scientific solutions, and synthesize insights while managing large datasets using machine learning or statistical modeling techniques
Job Details
Job Role
: All Roles
Industry Sector
: IT-Software/Software Services
Functional Area
: All Functions
Desired Profile
Profile Description
:N/A
Experience
: 3 - 10 (Years)
.
.
Education Details
UG Course
: B.Tech/B.E
UG Specialization
: N/A
PG Course
: M.Tech
PG Specialization
: N/A"
Software Engineer,"Hyderabad, Telangana",Shure,None,Organic,"The Software Engineer designs, develops and implements advanced scripts to validate embedded software systems, analyze system performance and resolve issues through collaboration with the systems engineering and development teams. This professional should have a solid knowledge of software languages and architectures in order to recommend and implement an automation architecture and solution across multiple product lines. The Software Engineer will be responsible for automation strategies and scripting to advance our product development.
Representative Duties
Architect, recommend and implement an automation architecture and solution across multiple product lines
Influences the shaping of future products by contributing to the framework (architecture) used across multiple products or systems
Provides technical recommendations for next generation initiatives
Designs, develops, and implements test plans, and test cases/scripts for complete and complex frameworks, systems, and products
Tests advanced software systems to ensure compliance with system specifications and system interoperability
Identifies, analyzes and resolves software issues
Requirements
Bachelor's degree in Computer Science, Electrical Engineering or related discipline
Uses skills as a professional in systems development and testing of software products
Able to work on problems of diverse scope where analysis of data or situations requires evaluation of complex systems
Demonstrates good judgment in selecting methods and techniques for obtaining solutions for difficult assignments and of diverse scope
Experience with C, C++, python, java script, HTML, SQL, and other scripting languages
We offer
We offer a competitive remuneration package to the right candidate.
How to apply
Please send your application with current and expected salary to
Ranjita Pratap , email: Pratap_Ranjita@shure.com"
Sr. Data Scientist,"Hyderabad, Telangana",SoulPage IT Solutions,None,Organic,"Job Description:
We are looking for a strong skilled Sr Data Scientist who has a strong hold on Machine Learning model building, deployment and problem solving skills.
Skills & Responsibilities:
Ideate, conceptualize and formulate Data Science use case of significant impact for the business
Develop and evaluate various Machine Learning models before zero in on the best one and ability to run Machine Learning models on huge amount of data
Drive discussions with Business to ensure the complete understanding with respect to the data science use case; Gain and demonstrate Data and Domain knowledge
Evaluate the Data Quality and Metadata information of Key Data Elements before any modelling effort to ensure minimal surprises in the later part of the project
Design holistic data science solution covering Descriptive, Predictive & Prescriptive analytics
Build reusable ML code for faster turnaround time to business problem solving
Explain the Machine Learning model implementation to business stakeholders in a way that they can understand and appreciate the solution
Build storytelling dashboards to make all insights and model output available to end users in a form which is highly helpful for decision making
Manage relationship with business stakeholders acting as embedded data scientist constantly thinking about data science solutions to make business better
Excellent skills in Deep learning-based algorithms with structured/ unstructured data.
Strong mathematical statistical understanding behind the algorithms
Key Skills Required: Data Science, Machine Learning, Python, Deep Learning, AL/ML, NLP, Big Data
Work Exp: 4 to 6 yrs
Approximate CTC: Industry Standards
Number of Vacancies: 1
Location: Hyderabad
Functional Area: IT Software – System Programming
Qualification: B.Tech/B.E/M.Tech/B.Sc- Any Specialization"
Data Scientist III,"Mumbai, Maharashtra","General Mills Services, Inc.",None,Organic,":
General Mills is reshaping the future of food. We believe food makes us better. It nourishes our bodies, brings us joy and connects us to each other. As one of the world's leading food companies, General Mills operates in more than 100 countries and markets more than 100 consumer brands, including Cheerios, Nature Valley, Betty Crocker, Yoplait, Annie's Homegrown, Old El Paso, Epic Provisions, Blue Buffalo and more. Are you passionate about the future of food? You've come to the right table. We want the very best talent to help lead something big.
:
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
:
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business
:
Qualification: Any Graduate (Preferred Statistical background)
Experience - 6+ yrs

Statistical analysis, modeling, clustering and data mining techniques to identify trends and insights
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning a plus
Experience with data visualization tools
Experience writing complex SQL queries
Experience with Python & R, comfortable working with DataFrames
Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs"
Data Scientist,"Navi Mumbai, Maharashtra",Aptus Health,None,Organic,"Position: Data Scientist

About us: WebMD Health Corp., an Internet Brands Company, is the leading provider of health information services, serving patients, physicians, health care professionals, employers, and health plans through our public and private online portals, mobile platforms, and health-focused publications. The WebMD Health Network includes WebMD Health, Medscape, Jobson Healthcare Information, prIME Oncology, MediQuality, Frontline, QxMD, Vitals Consumer Services, MedicineNet, eMedicineHealth, RxList, OnHealth, Medscape Education, and other owned WebMD sites. WebMD®, Medscape®, CME Circle®, Medpulse®, eMedicine®, MedicineNet®, theheart.org®, and RxList® are among the trademarks of WebMD Health Corp. or its subsidiaries.
Aptus Health is a wholly-owned subsidiary of WebMD. As the analytics arm of Aptus Health, we help our clients and our products realize their potential. Helping understand customer behaviour and traits is at the core of what we do. A team of 8 members, we are analogous to a start-up centre with hands-on responsibility for every member.

Role & Responsibilities:
The selected candidate will work on the following:
Work with real-world case studies in Data Science and a chance to implement various modeling techniques
Get real-life experience of working with big data in the digital marketing sphere.
Opportunity to independently execute and lead analytical projects and assignments
Help solve some challenging Healthcare related digital marketing problems globally. Transform business question into data requirements; collect and merge the data; analyse the data, link it to the business reality and present the results
Develop predictive models and machine learning algorithms to study the change in physician prescribing behaviour as well as WebMD integrated campaign response behaviour. Build analysis to understand user engagement and behaviours across various WebMD products.
Build expertise in data preparation, data visualisations and transformations through SAS, R, Tableau and other analytical tools.
Technical Skills needed:
Experience with data manipulation in SQL environment is a must. Knowledge of Snowflake data warehousing is good to have
• Experience with statistical and data manipulation tools such as SAS or R is a must • Need very good expertise in using Microsoft Excel, and Microsoft PowerPoint. Excellent presentation skills required
Experience developing statistical models like hypothesis testing, regression models, classifications models, forecasting etc is a must
Algorithm designing and implementation skills in R or Python is required
Requirements:
B.Tech/B.E. / MSc Statistics from premier institutes with minimum 80% marks in 10th and 12th grade
1.5-2.5 years of relevant work experience in Analytics field"
Senior Data Scientist,"Bengaluru, Karnataka",Scienaptic Systems,None,Organic,"Scienaptic is the world's leading AI powered Credit Underwriting platform company. Designed by seasoned Chief Risk Officers, its platform is creating industry leading business impact in terms of lifts such as higher approvals (15-40%) and lower credit losses (10-25%) with all the regulatory explainability. Last year alone, we have helped financial institutions evaluate 45 Million consumers and offer credit to over 15 Million. Scienaptic’s clients include Fortune 100 banks, community banks and Fintechs.
The Data Scientist role will enable you to be at the forefront of latest cutting-edge technology and create a significant and visible business impact for Scienaptic. You will be working with some of the best-in-class Coders, AI/ML Scientist and Business Analytics Consultants in an environment which will encourage you to contribute widely to functional and technological aspects without worrying about conventional job silos.
Responsibilities and Duties
Design, build, test and deploy ML models at scale
Experience with modern machine learning techniques including Ensemble Methods, Deep learning
Write production ready code and deploy real time ML models ; expose ML outputs through APIs
Analyse website and apps effectiveness and recommend changes to content, navigation and design
Hypothesis Testing and Design of experiments to analyse and monitor results
Experience in building digital enquiry generation models, product recommendations on website, marketing response models, social media analytics.
Engineer features to improve decision algorithms
Partner with data/ML engineers and vendor partners for input data pipes development and ML models automation
Skills and competencies
Masters in Computer Science, Mathematical / ML related disciplines with 6+ years of experience into core ML
Solid understanding of probability / statistics / data science / ML along with Python + SQL proficiency
Test of hypotheses and analysis of ML models and optimizing models for accuracy
Experience with Spark or other distributed computing systems for large scale training and prediction of ML models
End to end system design: data analysis, feature engineering, technique selection, implementation, debugging, and maintenance in production
Experience with unstructured data and text mining skillset is a plus
Send your CVs to febina@scienaptic.com"
Senior Expert Data Scientist,"Hyderabad, Telangana",Novartis,None,Organic,"Your responsibilities include, but are not limited to:

Responsible for all data science tasks on the assigned clinical or non-clinical projects, and perform these tasks for mid- to high- complexity projects with a good level of independence. Responsible for implementing data science planning, data provisioning, analytical activities including exploratory analyses, reporting and communication of methods and results, ensuring reproducible and agile ways of working.
Contribute to planning and execution of exploratory analyses, and/or PK, PK/PD analyses, exploratory biomarker and diagnostic analyses, and data science consultation. Initiate, drive and implement novel and innovative methods in alignment with other quantitative team members.
Explain data science methodology and interpret analysis results. Provide data science expertise to support submission activities, meetings with and responses to Health Authorities and other drug development activities, as required.
Contribute to interactions with external review boards/ethics committees, external consultants and other external parties with oversight as appropriate. Represent Novartis in data science discussions at external congresses, conferences, scientific meetings.
Represent the Analytics Line Function on cross-functional teams for the assigned projects. Responsible for functional alignment and ensuring line function awareness throughout the assigned projects.
Collaborate with other line functions. Explain methods and results in a manner easily understood by non-analytical folks, and provide adequate justifications, sensitivity analyses for actions/decisions/statements, when required.
Establish and maintain sound working relationships and effective communication with the Clinical Colleagues and Biostatistics & Pharmacometrics team.
Understand complex and critical business problems, formulates integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. High agility to be able to work across various business domains. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact.

Minimum requirements
MS (in Statistics or equivalent) with 4+ years relevant work experience or PhD (in Statistics or equivalent) with relevant work experience (including internship)
Good communication and presentation skills.
Experience/Professional Requirement, Influences decisions that directly impact the assigned clinical trial and team ability to deliver objectives.
Proven knowledge and expertise in data science and its application to clinical trials. Depending on the assignment, may require proven expertise in pharmacokinetics, exposure-response modelling, exploratory biomarker, diagnostic analyses, applied Bayesian statistics, or data exploration skills. Proficiency in use of software packages (e.g. Python, R).
Knowledge of drug development and Health Authority guidelines. Able to work on a multidisciplinary team to achieve team objectives.
Experience in Franchise/Therapeutic Area and/or regulatory activities would be advantageous

Why consider Novartis?

799 million. That’s how many lives our products touch. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

We are Novartis. Join us and help us reimagine medicine.

Novartis are an equal opportunities employer and welcome applications from all suitably qualified persons.
Division
Global Drug Development
Business Unit
CD&A GDD
Country
India
Work Location
Hyderabad, AP
Company/Legal Entity
Nov Hltcr Shared Services Ind
Functional Area
Data & Digital
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
Senior Data Scientist,"Pune, Maharashtra",Innoplexus,None,Organic,"Job Location – Pune, India
Required experience – 6-10 Years
About Innoplexus
Innoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.
Our products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.
We automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.
You are the right person in our team if you can:
Lead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones
Develop scalable customer-facing solutions over real-world, noisy and unstructured data
Develop highly scalable deep learning algorithms to improve our platform
Develop state-of-the-art machine learning and neural network methodologies to improve our intelligence platform
Cross-functional collaboration between data science and engineering teams to support the integration of finished algorithms and prototypes into product
Support sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing an approach for solutions
We need you to have:
Bachelors/Masters/PhD Degree in Computer Science, related Machine Learning field or equivalent from Tier-1 or premier institutes like IIT, IISc, BITS, NIT or globally renowned universities
Knowledge On:
Relevant Hands-on Experience in any of the below groups:
Information Extraction, Text Mining from Unstructured data
Computational Genomics, Bioinformatics
Strong in Python programming
Knowledge commonly used machine learning tools:, pytorch, scikit-learn, gensim, pandas
Experience with major NoSQL products
Experience in the domain of life sciences is a plus
Must have experience in leading teams
Innoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing."
Data Scientist,"Pune, Maharashtra",NICE Actimize,None,Organic,"Position: Data Scientist
Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities

Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.

Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools."
Web Developer,"Mogappair, Chennai, Tamil Nadu",Excrin Think Labs,None,Organic,"PROFILE
JOB PROFILE : WEB DEVELOPER
Proven working experience in web programming
Top-notch programming skills and in-depth knowledge of modern HTML/CSS
Familiarity with at least one of the following programming languages: PHP, ASP.NET, Javascript or Ruby on Rails
A solid understanding of how web applications work including security, session management, and best development practices
Adequate knowledge of relational database systems, Object Oriented Programming and web application development
Hands-on experience with network diagnostics, network analytics tools
Basic knowledge of Search Engine Optimization process
Aggressive problem diagnosis and creative problem solving skills
Strong organizational skills to juggle multiple tasks within the constraints of timelines and budgets with business acumen
Ability to work and thrive in a fast-paced environment, learn rapidly and master diverse web technologies and techniques
BS in computer science or a related field

RESPONSIBILITIES
WHAT YOU'LL DO:
Write well designed, testable, efficient code by using the best software development practices
Create website layout/user interface by using standard HTML/CSS practices
Integrate data from various back-end services and databases
Gather and refine specifications and requirements based on technical needs
Create and maintain software documentation
Be responsible for maintaining, expanding, and scaling our site
Stay plugged into emerging technologies/industry trends and apply them into operations and activities
Cooperate with web designers to match visual design intent"
Data Architect - Bangalore,"Bengaluru, Karnataka",Wabco,None,Organic,"What will you gain working at WABCO
Innovative products and technologies
Challenging and dynamic working environment
Globally minded and multicultural workplace
Variety of opportunities for personal professional growth
International prospects for individual career development
Team-Work world-wide Immerse yourself in a great working atmosphere in international teams
Responsibilities and Requirements of the role:
Primary Responsibilities
Create and maintain an optimal data pipeline architecture
Assemble large, complex data sets that meet the requirements (functional / non-functional) at optimal costs.
Optimize and build the AWS infrastructure for optimal extraction, transformation and loading data from a wide variety of data sources.
Build analytics tools that utilize the data pipeline to provide actionable insights according to Wabco’s needs.
Industrialize data scientist solutions.
Keep and maintain the data secured anc according to legal standards in the AWS cloud platform.
Work closely with data scientists and analytics experts.
Skills & Experience
Computer Science, Statistics, Informatics degree or equivalent.
12+ years of real problems hands-on data engineering experience.
5+ years of experience in AWS Cloud
3+ years of experience in DataBricks
Advanced knowledge and experience in a wide variety of databases and data lakes.
Strong analytic skills related to working with unstructured, big datasets.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets .
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
A successful history of manipulating, processing and extracting value from large disconnected datasets .
Require an outstanding analytical mindset and good organizational skills
Quick learner with an open mindset.
Excellent communication and relationship building skills.
Essential Knowledge
Experience with big data platform & tools: AWS, Databricks, Spark
Expert knowledge with SQL and non-SQL Databases
Strong knowledge of AWS big data tools and platform: EC2, EMR, RDS, Glue, Redshift
Strong experience with object-oriented/object function scripting languages: Python , JavaScript, C++, etc .( ETL Pipelines)
Experience in at least one data visualization tool such as Tableau, Spotfire, PowerBI
Desired Experience
Previous experience working with GIT
Knowledge in stream analytics
Knowledge of object-oriented programming.
Knowledge of R , Knowledge of DeepLearning
Proficiency in at least one of the following programming languages Node.js, Javascript, C# or React (native)
Mastery of development methodologies & lean principles to create world-class software
Experience with REST APIs and Microservices."
Princ Software Engineer,"Chennai, Tamil Nadu",NortonLifeLock,None,Organic,"Team descriptions
The NortonLifeLock Labs team is made up of leading threat and security researchers supported by advanced systems to innovate security technology and threat intelligence to protect our customers against known and new threats. The main locations of the team are Chennai, India – Oslo, Norway – Dublin, Ireland and Culver City, USA. The Labs team is part of the CTO office.
We overlook the portfolio of security technologies that makes for high detection without sacrificing system performance. The portfolio consists of modern and traditional components, like:
Network detection
Reputation and prevalence
Machine Learning
Cloud and Crowd detections
Behavioral analysis
Anti-virus engines and static scanners
About the role
We are looking for a lead engineer for one or more of the areas mentioned above in the Microsoft Windows environment. This principal engineer should have profound low-level experience in the respective area(s). The role includes all aspects of software development including
Get the hands dirty and work in the code Overlook the architecture Guide, train, and collaborate with senior developers on their way to success
Why this role is awesome
Have an impact on world-wide cyber security by rolling out your features to millions of users
Insights into a wide range of security technologies
Join a team with world-leading security experts
Gain in-depth experience of the Windows OS and latest features through cooperation with Microsoft
Insights into all major operating systems by cooperating with other platform teams
Share experience within and across development teams
Apply modern development practices to deliver latest protections to customers several times per day
Desired Skills
10+ years of experience in Windows development
10+ years of experience developing in both C and C++
5+ years experience in user mode or kernel mode driver development using WDF, WDM, UMDF, or KMDF.
Wide experience with Windows internals.
Good understanding of x86/x64 assembly.
Experience using tools like WinDbg and verifier, Visual studio, Perforce, Git, etc.
Solid experience in writing unit tests
Code coverage and code analysis processes
Ability to navigate quickly in existing code base and unafraid to start progressing in such environment
Excellent English skills
Good communicator to technical stakeholders
Ok to work flexible hours (evenings)
The following is a plus but not required
Experience working in international workplace, preferably Europe
Reverse engineering experience
Good Python skills
Low level / system performance
Experience with network technologies (HTTP / TCP/ IP, SSL / TLS)
Cyber security experience from Network protect / detection perspective
Next generation firewalls (NGFW)
Intrusion detection / prevention systems (IPS/IDS)
Cyber security experience in endpoint security technology
Antivirus
On-access
Network filter drivers
HIPS / behavioral detection
Responsibilities
Design, develop, test, document and maintain both kernel level data collection drivers and user mode services running on Windows endpoints.
Follow best practices, secure coding, testing methodologies, effective peer code reviews, and robust architecture patterns.
Use professional concepts in accordance with company objectives to solve complex problems in creative and effective ways.
Provide guidance to other team members and peers without formal authority or supervisory responsibility
Exercise judgment within broadly defined practices and policies in selecting methods, techniques and evaluation criteria for obtaining results
Frequently contributes to the development of new theories and methods
Employ expertise as a subject matter expert
Works on complex problems where analysis of situations or data requires an in-depth evaluation of various factors
Experience
BS in computer science or equivalent related experience
8+ years of experience in software companies/organizations
10+ years of programming experience
NortonLifeLock is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible environment for all employees. All employment decisions are based on merit, experience, and business needs, without regard to race, color, national origin, age, religion, sex, pregnancy (including childbirth or related medical conditions), genetic information, disability (physical or mental), medical condition, marital status, sexual orientation, gender identity or gender expression, military or veteran status, or any other consideration made unlawful by federal, state, or local law. NortonLifeLock strictly prohibits unlawful discrimination based on such protected characteristics and seeks to recruit the most talented candidates from diverse cultures and backgrounds.
We also consider for employment qualified individuals with arrest and conviction records. In addition, NortonLifeLock will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Learn more about pay transparency .
EEO is the law. Applicants and employees of NortonLifeLock Inc. are protected under Federal law from discrimination. See the EEO poster and supplement .

NortonLifeLock Inc. (NASDAQ: NLOCK) is a global leader in consumer Cyber Safety. NortonLifeLock is dedicated to helping secure the devices, identities*, online privacy, and home and family needs of its nearly 50 million consumers, providing them with a trusted ally in a complex digital world.
NortonLifeLock is committed to requests for reasonable accommodations to assist you in applying for positions at NortonLifeLock including resume submissions. If you need to request an accommodation, please contact HR Service Exchange .
LifeLock identity theft protection is not available in all countries."
Big Data Engineer - Data DQMF,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Technology
Primary Location: ASEAN & South Asia-India-Bangalore
Other Locations: ASEAN & South Asia-India-Bangalore
Schedule: Full-time
Employee Status: Permanent
Posting Date: 26/Jun/2020
Unposting Date: Ongoing
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.


The Role Responsibilities


As a Big Data Engineer, you will be responsible for building and expanding our data architecture on Hadoop platforms.
Key Responsibilities
Create and maintain the bank’s data pipeline and platform architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build monitoring/alerting tools & frameworks using OSS technologies for doing key business/technical performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data-center.
Help ‘commercialize’ the data platform by working closely with the Data Science team in exploring opportunities, be it fighting fraud or developing multi-channel cross-sell/up-sell initiatives

Regulatory & Business Conduct
Display exemplary conduct and live by the Group’s Values and Code of Conduct.
Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct.
Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters.


Our Ideal Candidate
Strong analytic skills related to working with unstructured datasets.
Ability to quickly learn and implement newer technologies, particularly on the Big Data side including HIVE, HBase, Kafka, Spark and Nifi
Exposure to data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.
Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Software Engineer with proficiency in Python,"Aundh, Pune, Maharashtra",Capital float,None,Organic,"Roles and Responsibilities

Design, implement, test and maintain software applications for core business functions in the org
Ensure the architecture can support the requirements of the stakeholders
Follow effective and scalable coding practices with focus on unit testing, security.
Develop new and existing backend components for serving the required business functions
Coordinate with internal teams to understand requirements and provide technical solutions
Assess and prioritize feature requests
Partner with other data science teams to build and improve prescriptive analytics and predictive modelling

Requirements

- Have 2 - 5 years’ experience building and maintaining software applications.
Work experience in Python is a must. Proficiency in at least one popular Python framework (like Django, Flask etc)
Knowledge of object-relational mapping (ORM)
Work experience with data modelling and feature engineering is a plus.
Familiarity with AWS cloud services like EC2, RDS, Lambda etc is a plus.
Good understanding of both SQL (MySQL, PostgreSQL) and NoSQL databases (MongoDB)
Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3"
Data Science part time job/internship at Hyderabad,"Hyderabad, Telangana",First Tech Consulting,"₹2,000 a month",Organic,"About the company:
First Tech Consulting is an enterprise solutions provider in the global IT industry, specializing in data analytics, artificial intelligence, IoT, implementation, support, upgrade & enhancement of packaged data & IT solutions.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Work on tasks related to the data science project 2. Learn and work on machine learning techniques
Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 7th Aug'20 and 11th Sep'20
are available for duration of 2 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Other requirements:
Health care & insurance related domain experience highly preferable
Number of internships/jobs available: 4
Categories: Data Science"
Technical Lead - Backend,"Chennai, Tamil Nadu",Aera Technology,None,Organic,"Do you want to shape the future of enterprise software?

At Aera, we deliver the cognitive technology that enables the Self-Driving Enterprise™: a Cognitive Operating System™ that connects you with your business and autonomously orchestrates your operations. Aera's Cognitive OS leverages the best of artificial intelligence, machine learning, natural language processing, big data, and enterprise domain expertise to deliver Cognitive Automation at scale for some of the world's largest companies.

The Lead Software Engineer is a hands-on role that will work closely with our Product Owners to iterate quickly on the features and APIs, interact with one or more engineering teams to define the architecture, and implement features based on precise understanding of the requirements.

As a technical lead in our global engineering organization, the candidate will mentor and lead talented local/remote teams, and collaborate with other teams as well.

In this role you will work remotely, based from your home in Chennai.
Responsibilities
Design, build and maintain efficient, reusable, and reliable code and automation
Strong experience leading design and implementation of robust and highly scalable services
Demonstrated ability to mentor engineers and lead projects
Strong OOD and SOA principles, with the ability to implement them in JavaHas a passion to produce high quality deliverables while working with cross-functional teams
Ability to handle a fast paced environment for iterative project turnarounds on mission critical systems Team/Leadership qualifications
Demonstrated ability or open to working with global teams across time zones
Has a passion to produce high quality deliverables Participate in design and code reviewsMaintain the CI/CD and improve release pipeline
Identify bottlenecks and bugs in applications, and devise solutions to ensure the best possible performance, quality, and responsiveness of the applications
About You
Strong educational background with Bachelors/Masters in Computer Science or a related area
8+ yrs experience in Java, J2EE, Tomcat, multithreading and caching techniques
2+ yrs experience in Java 8 (Streams, Lambda)
Experience with working on Spring/ORM, Microservice frameworks, Dockers, GIT, Gradle and Linux platforms
Experience building secure, complex, and scalable APIs, from design through deployment
Solid understanding of writing and delivering testable quality code, from the ground upExperience with SQL development, data modeling and complex data structures for high-volume and high-velocity data
Solid experience with Kafka, Kafka Streams
Experience in working with NOSQL technologies like REDIS, MongoDB
Solid understanding and experience with OAuth, Logging and Security frameworks
Hands-on experience with frameworks such as JUnit, TestNG, Mockito
Hands-on experience with code quality frameworks/tools such as SonarQube, pmd, checkstyle etc.
Nice to Have
Experience with streaming data and complex event processing systems
Working knowledge in AWS, Kafka, Apache Spark, Elasticsearch
At Aera, we're on a mission to solve the biggest, most intractable challenges in the world of enterprise software. We envision the rise of the Self-Driving Enterprise: a more autonomously functioning business with a central operating system that connects and orchestrates business operations. Our Cognitive Operating System is increasingly used by the world's largest companies to fundamentally transform their organizations and how work is done.

If you share our passion for building the next generation of enterprise software, and deploying it for the most sophisticated customers in the world, you’ve met your match. Headquartered in Mountain View, California, we're growing fast, with teams in Mountain View and San Francisco (California), Bucharest and Cluj-Napoca (Romania), Paris (France), Munich (Germany), London (UK), Pune and Bangalore (India), Sydney (Australia) and Singapore. So join us, and let’s build the future of work together!"
Data Scientist,"Pune, Maharashtra",NICE Actimize,None,Organic,"Position: Data Scientist
Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities

Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.

Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools."
Advanced Analytics - Data Architect,"Bengaluru, Karnataka",Hewlett Packard Enterprise,None,Organic,"Business Environment
Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industry’s most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure.
Learning does not only happen through training. Relationships are among the most powerful ways for people to learn and grow, and this is part of our HPE culture. In addition to working alongside talented colleagues, you will have many opportunities to learn through coaching and stretch assignment opportunities. You’ll be guided by feedback and support to accelerate your learning and maximize your knowledge. We also have a “reverse mentoring” program which allows us to share our knowledge and strengths across our multi-generation workforce. The team has an excellent mix of experienced professionals with strong analytics, business research and consulting background.
Job Description
The candidate would join the HPE Global Operations Advanced Analytics team housed in Bangalore. The candidate will work closely with global HPE Global Operations organization to design, develop and manage Analytics solutions using various tools and technologies. Some work would also involve superior data handling skills to support various aspects of planning and executive decision making.
Understand business requirement to develop and implement solutions that address business needs and adhere to big data architectural guidelines
Develop data-driven solutions to complex business challenges while working with data scientists and business consultants
Architect and create data views from big data store to feed into analytics solutions and visualization layers
Troubleshoot, debug when data is found to be inaccurate.
Root cause analysis of data issues and coming up with stable long terms solutions.
Education & Experience
Master’s degree in IT, Computer Science, Software Engineering, Business Analytics or equivalent
12-15 years’ experience in industry experience working on data warehousing / distributed system (e.g. Hadoop)
Expert in building and optimizing ‘big data’ data pipelines, architectures, and data sets
Excellent experience in data processing using Scala/Python/Java
Proficient in Big data tools and ecosystem (e.g. HIVE, Spark)
Experience working on analytics tools and solutions using Microsoft R
Strong in user requirements gathering, maintenance, and support
Experience working on scheduling tools like Oozie
Strong technical fundamentals to quickly learn next gen tools and start working on the same.
Personal Attributes
Analytical, with ability to think strategically.
Detail oriented – ability to validate, analyze and sort through data.
Good written and numerical skills
Strong interpersonal skills
Works well in cross functional environments with matrix/influence management
Customer orientation
Results oriented, high energy and drive with a winning attitude
Hewlett Packard Enterprise Values:
Partner. Innovate. Act.
We live by three core values that drive our business.
Simplified, we are good partners, great innovators and we make things happen.
Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.
If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers
You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers
#GlobalOpsIN
1067693"
Data Scientist- Face Recognition,"Bengaluru, Karnataka",Eminence core solutions LLP,None,Organic,"Must have Experience in Face Recognition, Python
Experience with Deep Learning frameworks.
Experience of working with facial recognition technology.
Must have Knowledge of NLP,CNN, RNN, LSTM.

2.00-5.00 Years

Bachelor Of Computer Application (B.C.A), Bachelor of Science (B.Sc), Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A)"
Data Scientist,"Mumbai, Maharashtra",Allerin Tech Private Limited,None,Organic,"Job Description :

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products like: automate scoring using machine learning techniques, build recommendation Engines/systems, optimize and extend the features used by our existing classifier, etc

Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Develop hypotheses and test carefully by experience; develop and improve predictive modeling algorithms; understand and work around possible limitations in models.
Analyze large datasets to produce statistical models and prediction tools.
Visualize, interpret, report, and communicate data findings creatively in various formats to various stakeholders.
Conduct critical data analysis and prepare data sources to be analyzed.
Discover patterns, find meaning and produce actionable intelligence. Work both autonomously and collaboratively when necessary in a fast-paced, competitive, multidisciplinary environment.

Desired Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
Proficient at translating unstructured business problems into an abstract mathematical framework.
BE/BTech/MCA/MTech/MSc in Computer Science
Some development experience in at least one scripting language (Julia, Python, R...).
Ability to initiate and drive projects to completion with minimal guidance.
The ability to communicate the results of analyzes in a clear and efficient manner.
Highly collaborative and curious.
Experience with any big data framework would be a plus.
2-7 years experience

Important:

Should be able to appear for personal interview in our office at Navi Mumbai. Do not apply if you can not appear for personal interview. No telephone round will be conducted.

2.00-7.00 Years"
Senior Data Scientist,India,Emerging India Group,None,Organic,"We are looking for a senior Data Scientist with 7+ years of progressive experience in mining large complex data sets, using a variety of advanced quantitative/modelling techniques. Candidate should have a knack to manage and deliver end to end projects with a proficiency to handle and deliver strategic insights to support crucial business decisions.
Candidate should have great analytical skills with an acumen for analysis, math and statistics and should be well versed with the concepts of machine learning. A rich experience in delivering analytics projects including social media analytics and big data is required.
RESPOSIBILITIES
Understanding business objectives and developing models based on structured and unstructured data to derive relevant metrics
Make the most effective use of the available Big Data infrastructure and Data Science techniques to address the business issues
Build effective presentations to communicate complex analysis and findings suitable for a wide array of audiences
Proactively plan and prioritize work according to criticality and shifting priorities/ strategies, while balancing need to drive longer-term initiatives
Mentor and coach junior team members
SKILLS
Proven experience as a Data Scientist or Data Analyst
Preparing and maintaining project, stage and exception plans as required
Identifying and obtaining support and advice required for the management, planning and control of the project
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Presentation of insights using data visualization techniques
Problem-solving aptitude
Excellent communication and presentation skills
TOOLS & TECHNOLOGY
Familiar with statistical modelling tools such as Python, R, SAS etc. with proficiency in Python
Knowledge and experience of working with SQL and NoSQL databases
Experience in story telling with tools like Tableau, Power BI etc.
Experience with unstructured data using Hadoop
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms

Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules"
"Associate, Index Configuration Data","Gurgaon, Haryana",BlackRock,None,Organic,"About BlackRock
BlackRock’s business is investing on behalf of our clients, from large institutions to parents and grandparents, doctors and teachers who entrust their savings to us. We are committed to our clients—period. Our promise is to offer them the clearest thinking about what to do with their money and the products and services they need to secure a better financial future.
That’s why investors of all kinds have made us the world’s largest asset manager, entrusting us with trillions of dollars, and it’s why companies, institutions and global governments come to us for help meeting their biggest financial challenges.

Description
About this role
The Index Implementation team, part of the BlackRock Data & AI organization, is responsible for onboarding new or custom public indices on BlackRock’s proprietary Aladdin® end-to-end investment platform. BlackRock and its BlackRock Solutions (BRS) clients utilize these indices as an integral part of investment and risk management, serving as benchmarks for Mutual Funds, ETFs, and Hedge Funds, Pensions, and other products. Index Implementation works closely with index vendors such as MSCI, S&P, FTSE, and Markit Partners, as well as internal partner teams including Client Analytics, Portfolio Management, Relationship Management and other BlackRock Data & AI groups. Index Implementation is a diverse and distributed team that service clients in all spectrums of the financial markets.
Supply to all aspects of rolling out multiple concurrent new indices, across various asset classes and strategies in Aladdin, including vendor data acquisition, data mapping and normalization, process testing and automation, and quality control.
Provide high quality client service externally and internally. Address inquiries and resolve problems from clients and internal BlackRock partners.
Understand risk analytics of fixed income, equity and alternatives products to analyze index methodologies, collaborate with vendors, and build custom solutions the business.
Initiate and drive Index platform improvements to support new business needs, minimize risk, and improve quality.
Act as Business Analyst and Project Manager responsible for detailing client requirements, assessing potential solutions, and ensuring key achievements are met.
Bachelor’s Degree is required, with preference to business fields such as Finance, Accounting, or Economics, and technical subject areas such as Computer Science, Information Systems, or Engineering.
A “Student of the Markets” mentality: Intellectually curious with a passion for learning about the global financial markets and the investment management business.
Excellent verbal and written communication skills combined with an ability to connect across different functions and levels.
5+ years of experience, preferably in financial services.
Basic knowledge of SQL, UNIX, or Python is a plus.
Travel : No
Direct Reports: No
Licenses: No
About BlackRock
BlackRock’s purpose is to help more and more people experience financial well-being. As a fiduciary to investors and a leading provider of financial technology, our clients turn to us for the solutions they need when planning for their most important goals. As of June 30, 2020, the firm managed approximately $7.32 trillion in assets on behalf of investors worldwide.
BlackRock is proud to be an Equal Opportunity and Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, disability, protected veteran status, and other statuses protected by law.
BlackRock will consider for employment qualified applicants with arrest or conviction records in a manner consistent with the requirements of the law, including any applicable fair chance law.
Job requisition #
R201565"
Data Analyst,"Bengaluru, Karnataka",Outsource Bigdata,None,Organic,"Requirement
B.Tech. / B.E in any Engineering Stream/ MCA / Bachelor’s degree in any science stream.
0-2 years’ experience - Fresher’s are welcome to apply.
Added advantage if you have basic knowledge about Mechanical/Electrical appliances, FMCG products
Added advantage if you have experience of working with API’s used to extract web data - dimensional data from databases and web is an added advantage. Basic programming skills to program custom scrapping tools
Should have excellent computer knowledge - MS Office – Excel, MS Word, etc.
Engineering Product / Data Mining understanding – Product information like Manufacturer / Part Number / Product Description / Energy rating / Energy consumption etc.
Good Analytical & Communication skills (Ability to communicate with clients)
Data management capabilities, attention to detail.
Demonstrates interpersonal skills and team work
Quick learner and flexible to perform multiple jobs
What you've got
If you have the ability to look down at the meaning of data with good analysis and identify trends and patterns of information clubbed with excellent computer skills, then this role is what you are looking for. Expertise in streamlining of data management projects and end to end process flow, ensuring deliverables are prepared to exceed customer expectations, status reporting, developing, documenting, and maintaining data quality goals and standards."
Data Engineer,"Bengaluru, Karnataka",Cervello Inc,None,Organic,"Summary:

You have experience with client projects and in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR
l6pD4LZYK9"
Software Engineer III - News Distribution,"Hyderabad, Telangana",FactSet Research Systems,None,Organic,"The News Distribution team is responsible for designing and maintaining the various APIs, services, and databases needed to support searching and alerting on document-based data across all FactSet applications and workflows. We work closely with Product Developments and other engineering teams to determine the requirements and implement solutions that are both scalable and maintainable.
Highly Desired Skills:
2 – 5 years of industry experience
Industry experience in C++
Experience with C++, Python, Java
Familiarity with OOP concepts
Experience working in a Linux environment
Experience with Linux debugging and profiling tools such as GDB
Experience with service-oriented architectures
A strong interest in distributed systems and in developing highly performant software
Strong communication skills, with both technical and non-technical people
Independent and proactive
Required Skills:
B.Tech or M.Tech in Computer Science or equivalent
Comprehensive understanding of programming principles
Comfortable navigating a large codebase
Experience with Relational or NoSQL databases
Good communication and problem-solving skills
Desire to work in a collaborative team environment
Comfortable working in a real-time, 24/7 production environment"
Programmer Analyst,"Chennai, Tamil Nadu",Cognizant,None,Organic,"Technical Lead
Qualification:
Bachelors in science , engineering or equivalent
Responsibility:
Requirement Understanding and Analysis:
Understand the functional/ nonfunctional requirements.
Participate in client calls and prepare the clarification list to seek clarifications.
Prepare the list of requirements and seek review inputs from the key stakeholders.
Update requirements traceability matrix.
Create impact analysis document (for simple change) to understand the impact on the existing functionality, as required.
Design:
Provide inputs to create the low level design for the module based on the understanding of the requirement and HLD.
Identify the list of reusable assets that can be used and share inputs.
Share the list of components with the Senior Developer/ other relevant stakeholders and seek inputs.
Coding:
Based on LLD , identify the component that needs to be created.
Set up the environment for creating the component.
Replicate the existing code to the environment.
Establish connection to the databases.
Conduct coding as per finalized technical specification document.
Follow coding standards and best practices to check code quality.
Generate code quality document for the code review through various tools (Informatica, Aqua).
Share the developed code for review.
Rework on the code based on inputs shared by the Sr Developer and Module Lead if required.
Identify unit test case scenarios based on the design.
Prepare unit test cases and test data under guidance.
Merge code in the build environment and seek inputs from the Senior Developer.
Conduct peer review for the other team members.
Conduct technical troubleshooting if required.
Testing Management:
Conduct unit testing based on the identified test scenarios.
Fix simple defects identified during unit testing.
Prepare unit test document based on the test results and share the same for review.
Integrate and conduct system integration testing.
Address queries raised by QA team within defined timelines.
Analyze and fix the defects identified during functional / non functional testing.
Understand the impact/ criticality and priority of the defect.
Conduct regression testing for QA testing.
Report defect status as per project standard process within agreed timelines.
Track the status of defects using the test management tool (ALM, QC ).
Close the defect in test management tool once resolved.
Configuration Management:
Branch off the existing code in the version control tool (VSS, CSV).
Identify configurable items.
Maintain version control across different configurable items (documents component, data mapping clarification document etc).
Deployment:
Share the environment set up details with the deployment team.
Provide inputs on instructions (in case standard).
Create a deployment package under guidance of senior members in the team.
Raise deployment request to deployment team to deploy the code in the integrated environment.
Review the deployed component in the environment.
Load the test data.
Conduct smoke testing under guidance.
Share notification with QA team post completion of testing.
Service Support and Maintenance:
Specific to production and maintenance support:
Prioritize incidents based on criticality.
Route the defects logged to the right stakeholder if required.
Attend user calls, and capture required information and incident details for logging.
Coordinate with the different stakeholders to resolve as per SLA.
Run appropriate tests, once the defect is resolved.
Track the status in the test management tool (QC, Alma etc).
In case of any recurring incidents, prepare a learning document capturing the known errors.
Provide inputs to module lead in creation of transition plan (project steps and milestones).
Knowledge Management:
Create specific artifacts for tasks allocated by Lead.
Share artifact with supervisor for review.
Upload article in the knowledge management repository.
Search the knowledge repository for information to resolve problems.
Apply best practices/ learning during the code development.
Create reusable assets and their documentation.
Create value addition documents (value added by team to the client) and share it with the team.
People Management:
Provide inputs in creation of training courses and supporting artifacts on the training server such as demo, presentation.
Conduct training or knowledge sharing sessions (in case of niche technology).
Must Have Skills
Informatica MDM
informatica Data Quality
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Aug 14 2020
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world."
-Developer R programming and ShinyProfessional 2 Information...,"Bengaluru, Karnataka",DXC,None,Organic,"Job Description:
Description
Developer is expected to demonstrate expert competencies in Design and Building shiny web apps using R programming on Azure cloud. The developer should have good technical documentation skill and working knowledge in Agile projects.
In this role the successful candidate will work in an energetic, fast-pace and extremely professional environment to understand customers’ requirements of Enterprise Azure Cloud and find solutions to their business problems.
Qualifications
Bachelor’s in computer science engineering (or equivalent) and having statistics knowledge
5 plus years of IT experience with key focus on Business Intelligence and Analytics on Azure
Good analytical and problem-solving skills
Fluent in Data warehousing concepts
Must be knowledgeable in software development lifecycles/methodologies i.e. Agile & DevOps
Has strong presentation and collaboration skills and can communicate all aspects of the job requirements, including the creation of formal documentation
Strong problem solving, time management and organizational skills
Desired Skills:
Excellent R programing Skills and shiny web app development
Good in simulations, data analyses and data visualizations with the R package
Experience in Azure cloud
Exposure to databases such as SQL Server/SQL DWH
Assist in designing and development of technical architecture, requirements and statistical models
Good in manipulating and analyzing complex, high-volume, high-dimensional data from varying sources
Good to have Python scripting skill
Knowledge in Azure Machine learning"
Software Engineer – Cloud Application Development (New Grad)...,"Bengaluru, Karnataka",Cisco Systems,None,Organic,"Job Description – Software Engineer – Cloud Application Development
In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!
We are Innovators
We drive innovation to propel business transformation while maintaining operational quality.
We are Accelerators
We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.
We are Transformers
As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients. What You’ll Do
Team Description
Cisco CX Engineering & Product Incubation is a global team of 1,200 engineers, designers, researchers and product management experts located in major hubs of Bangalore, Krakow, Raleigh, San Jose and Toronto. They create world-class digital experiences to support services offers and maximize customer value from the Cisco technology portfolio. Their work is part of the larger Cisco transformation from a hardware-centric company to one that is leading the way in meeting customers' changing needs through cloud and As-a-Service offerings.

A key focus for the team is the development of the CX Success Tracks suite of services, which digitally connect customers with the right expertise, insights and learning at the right time, accelerating time to value from their technology investments. These benefits are accessed through the CX Cloud, a single digital interface that provides a personalized, use-case guided approach that speeds achievement of defined business outcomes, across architectures.
You will work as part of a SCRUM team building and developing our Cloud based platforms and applications and applying principles and techniques of software and platform component development. You will be an integral part of the teams building our next generation SaaS applications that have a direct impact on the customers we serve.

You will have the opportunity to work closely with seasoned software engineers and architects developing software and tools in support of technology platform, infrastructure, SaaS applications, databases and others win a cloud-native environment. You will be part of a team that is focused on building a true cloud native SaaS application that is secure, stable, reliable and scalable.

Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists. We provide a great learning experience and also have developed a program to help our University Hires transition to true professionals.
Software Engineer – Cloud Application Development
Solid fundamentals of Data Structures, Algorithms, Object oriented design and programming
Strong knowledge on Unix/Linux systems and Unix scripting
A good understanding of Cloud based application development (using Docker,
Kubernetes, AWS services) and think about security and scalability from group up
Solid understanding of computer science fundamentals and software engineering with
an aptitude for learning new technologies
Strong knowledge of programming and scripting languages like JAVA, python, Scala,
GoLoang etc
Strong testing inclination to ensure programs are comprehensive and well tested for all
use cases
Exposure to debugging application programs along with development and debugging tools
Familiar with more than one development environment, well-versed with at least one
Interest in User experience and User interface design and development
Possess creative problem solving skills and excellent troubleshooting/debugging skills
Familiar with CI/CD tools namely GIT, GitHub, Jenkins, Drone etc Who You Are
Recent graduate or on your final year of studies towards a Bachelor’s or Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering, related majors such as Math, Physics
Minimum of an 8.5 GPA or higher
The requirement is for 2021/22 passout only.
Solid understanding of computer science fundamentals and software engineering with an aptitude for learning new technologies
Strong knowledge of programming and scripting languages
Possess creative problem-solving skills and excellent troubleshooting/debugging skills
Experience in establishing and sustaining excellent relationships with the extended team
Excellent verbal and written skills
Why Cisco
At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!
Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
Associate Data Scientist - MFG,"Bengaluru, Karnataka",Noodle.ai,None,Organic,"Noodle's Data Scientists build advanced AI models that change the way our clients do business by empowering them to make better decisions. Our solutions impact small and large businesses ranging from media, to retail companies, to airlines, to e-commerce, financial services, to government agencies. Members of our Data Science team are passionate about problem solving with applied data science and work with clients to explore, specify, and communicate high-value, AI- based solutions. We geek out about AI technology.

As a Data Scientist at Noodle.ai, you will collaborate with the Noodle Client Service team, Data Engineers, SW Engineers, UX Designers, and industry-specific experts from our client companies to build a deep understanding of our clients' business context and then develop, test, and deploy advanced AI models. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the models, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.
Qualifications:

Must haves
1+ years of experience in applied artificial intelligence technologies including machine learning, predictive data analytics, and/or data science
BE/B.Tech or Advanced degree in a relevant field (Computer Science, Operations Research, Statistics, Mathematics, Electrical Engineering, or other Computational Science)
Proficient in python
Experience with spark
Knowledge of data science/machine learning concepts
Demonstrated ability to iteratively conceptualize, design and build data-driven analytical models
Strong capabilities in modern analytics languages/tools
Collaborative, open, and respectful working style
Passion for learning and a desire to grow – Noodlers are life-long learners!
Nice to haves
Experience applying advanced AI techniques (g., machine learning, predictive analytics. optimization, semantic analysis, time-series analysis, advanced visualization) to real-world problems
Experience with R
Experience manipulating and preparing large, heterogeneous data sets (""Big Data"") to support advanced analytics
Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with
Experience with (and excitement for) interdisciplinary collaboration"
Data Scientist,"Kochi, Kerala",Mindcurv,None,Organic,"About Mindcurv
We help our customers rethink their digital business, experiences, and technology to navigate the new digital reality. We do this by designing sustainable and accountable solutions for humans living in a digital world. Mindcurv holistically covers the market’s need to digitize business processes and customer experiences and take advantage of the cloud following DevOps and agile principles.
Within Digital Platforms & Experiences we design and fully craft tailored solutions for our customers enabling them to get the most out of their business. We design and build a solid foundation in commerce, marketplace, responsive design, DXP and order management to name a few.

Your Role :
Be part of Big Data and Advanced analytics project team’s in the Data Science domain and as a trusted advisor to the VP of Data Science department on technology, configuration and delivery of projects undertaken by Mindcurv. You need to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. Need to have a proven ability to drive business results with your data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. You should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
What you will do :
Identify valuable data sources and collection processes
Supervise preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns for insurance industry.
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Collaborate with engineering and product development teams
Hands-on knowledge of implementing various AI algorithms and best-fit scenarios.
Who you are :
4+ years’ experience in Analytics systems/program delivery. At least 2 Big Data or Advanced Analytics project implementation experience
Experience using statistical computer languages (R, Python, SQL, Pyspark, etc.) to manipulate data and draw insights from large data sets; familiarity with Scala, Java or C++
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Hands on experience in Azure/AWS analytics platform (3+ years).
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Strong math skills (e.g. statistics, algebra)
Excellent communication and presentation skills
Deploying data pipelines in production based on Continuous Delivery practices.
Experience using variations of Databricks or similar analytical applications in AWS/Azure
Fluent in English (verbal and written). German/Dutch language familiarity will be a plus
Interpersonal and Team skills should be top notch
Why join Mindcurv?
We believe that the most important aspect of a job is being excited about it, having growth opportunities and working in a team you really like. We’re always on the lookout for people who know their stuff and want to collaborate on tomorrow’s digital solutions. Our workplaces feel good, because they’re filled with good people.
Join a collaborative environment and work with the latest technologies. We’ll grow your career and provide a great workplace with flexible hours.
If you agree with our philosophy and share our values, we are looking forward to meeting you as soon as possible!"
Software QA Engineer,"Bengaluru, Karnataka",AliveCor,None,Organic,"Software QA Engineer
Making the invisible visible. By harnessing the power of artificial intelligence, we’re advancing the practice of medicine for doctors and society. And we’re just getting warmed up.
AliveCor, the creator of the smartphone ECG, which has now captured over 20 million ECGs from tens of thousands of active users, seeks a SQA Engineer. The Software QA engineer will directly contribute to existing products, testing software for our Web, iOS, and Android products. You will be a key player in developing highly-visible, customer-facing products that are transforming the healthcare industry via big data.

Responsibilities
Be responsible for the testing of all mobile applications.
Report and verify bugs in a timely manner.
Work with developers, product and other team members to develop test plans and cases to mitigate risk.
Document test cases for regulatory purposes.
Promote a culture of quality throughout the organization.
Work with Engineering and Product Management teams to identify high-impact issues.
Use defect tracking tools to log, track and refine issues.
Perform functional testing of new features as they are developed.
Participate in all aspects of QA product lifecycle: understand the product requirements, test case creation, feature, regression, integration, end-to-end test execution.
Prepare and review test plans and cases with extended development and product management teams.

Qualifications and Skills
B.E in Computer Science or a related discipline, or related practical experience.
3-8 years of relevant QA experience.
Proven work experience in Mobile Apps Testing for Android and iOS.
Proven work experience in modern web-based applications testing.
Strong knowledge of software QA methodologies, tools and processes.
Experience in writing clear, concise and comprehensive test plans and test cases.
Hands-on experience with both white box and black box testing.
Knowledge of automated testing tools will be an added advantage.
Excellent programming skills in one of the following - Ruby, Python, Go, Objective C, or Java

About Us
AliveCor is on a mission to define modern healthcare through data, design and disruption. We’ve pioneered the creation of FDA-cleared machine-learning techniques, transformed wearable medtech to put proactive heart care at everyone’s fingertips. Kardia is the most clinically validated mobile EKG technology. AliveCor was named as one of the Top 10 Most Innovative Companies in Health for 2017 by Fast Company as part of the publication’s annual ranking of the world’s Most Innovative Companies. AliveCor was awarded the 2015 Tech Pioneer by the World Economic Forum and one of the 50 Smartest Companies in 2015 by the MIT Technology Review. AliveCor recently announced a collaboration with Mayo Clinic that will result in new machine learning capabilities to unlock previously hidden health indicators in EKG data, potentially improving heart health as well as overall health care for a variety of conditions. AliveCor is a privately held company headquartered in Mountain View, CA.
AliveCor is an equal opportunity employer and will not discriminate against any employee or applicant on the basis of age, colour, disability, gender, national origin, race, religion, sexual orientation, or any other classification protected by federal, state, or local law.
Watch the following video demonstrating our product.
KardiaMobile: How's your heart?
https://www.youtube.com/watch?v=8I9xosgA-Ig"
Project Specialist (Intern) - India UHR,"Bengaluru, Karnataka",Cisco Systems,None,Organic,"PROJECT SPECIALIST

Job Description – Project Specialist
In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!
We are Innovators
We drive innovation to propel business transformation while maintaining operational quality.
We are Accelerators
We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.
We are Transformers
In Supply Chain Operations we have an opportunity and the responsibility to enable Cisco's business now and prepare for the future. Our vision and strategy continue to emphasize the importance of providing our customers an unrivaled customer experience by delivering a flexible, innovative and scalable supply chain while continuing to build upon our strong operational foundation. Cisco is also committed to social and environmental responsibility in our supply chain. We work with our suppliers to maintain a sustainable supply chain that meets our standards for ethics, labor practices, health and safety, and the environment.
We encourage you to become a part of this dynamic organization where on a daily basis we leverage Cisco's aggressive competitive spirit and accelerate time to market by empowering our employees to use their expertise to take good business risks. As Cisco expands into new technologies, and geographies, it's become an exciting time to be part of the Supply Chain Operations team.
There are three sub-roles, you will be assigned a role depending on the team you join.
Project Specialist – Product Ops
Definition: Open Source Software Technology license evaluator and authorization specialist with strong Product Engineering and components integration background
Provide technical guidance to engineers and business decision-makers on architectural and source selection matters including buy vs. build vs. reuse based upon knowledge of software development practices as well as open source licensing.
Review, evaluate, and approve of SW engineering requests for use of Free and Open Source Software (FOSS), primarily evaluating inbound technology licenses for use in Cisco products.
Give approval decisions based on legal and technical criteria for use of FOSS products, as well as outbound contributions and the audit of mandatory redistributions for alignment to our license obligations.
Contribute to the development of project goals, schedules and resource planning.
Evaluate and recommend different ways you can use the component in the product.
Top skills required:
Python (hands-on programming)
Opensource licenses knowledge
Team player with ‘can-do’ attitude
SQL knowledge (Definite plus)
Education Eligibility Criteria (Bachelor):
Desired Degree: (BA/BS /MA/MS)
Desired Major: Business Management, Applied Science, Mathematics, Material
Engineering, Statistics, Manufacturing, Supply Chain Management or equivalent
Minimum CGPA of 3.0
The requirement is for 2021/22 passout only
Project Specialist - Supply Chain Transformation
Who You Are

Help develop, execute and track projects within one or more of the Supply Chain strategic programs
Work cross-functionally to define project scope, execute status reporting, ensure program deliverable completion, manage key risks and issues, create and manage project schedules and timelines
Strengthen the Supply Chain Transformation team’s tight relationship with IT, working closely with cross functional teams to improve handoffs
Ability to work in a cross functional environment; which will require collaboration with teams within and outside Supply Chain
Analyse business processes, find gaps and identify improvement opportunities
Work with large amount of data and having business context to derive meaningful insights from the analysis of the data
Document business requirements and work with IT on solution design, execution and business testing
Present data and insights in a logical, influential manner to drive data driven business decisions
Drive innovation and next gen ideas in Supply Chain: Block Chain, AI, ML
Capture the inventory of Supply Chain data sources, dashboards, measurements and metrics to prepare and manage integrated data architecture
Knowledge of Blockchain, AI and ML is desired
Excellent organizational, MS Office skills are required
Creative and flexible, work effectively within a team, and function with heavy cross-functional engagement
Strong written, oral, interpersonal communications and presentation skills
Education Eligibility Criteria (Bachelor):
Desired Degree: (BA/BS /MA/MS)
Desired Major: Business Management, Applied Science, Mathematics, Material
Engineering, Statistics, Manufacturing, Supply Chain Management or equivalent
Minimum CGPA of 3.0
The requirement is for 2021/22 passout only
Project Specialist - Global Supplier Management
Who You Are

Work as part of a new product development team to develop our products and manufacturing processes.
Assist with creating, analyzing, and releasing product and process documentation
Work with cross-functional product teams to provide mechanical engineering recommendations on product design and manufacturability.
Provide innovative solutions to optimize Supply Chain Operations internal and external processes, policies, and protocols to enable the best cost, quality, and delivery of Cisco products.
Identify, develop, and qualify new electro-mechanical and mechanical components to meet next-generation product and customer needs
Collaborate with Engineering and provide closed-loop feedback regarding forecast trends and accuracy
Opportunity to learn about various manufacturing product development methodologies such as Design for Manufacturing/Cost/Quality/Reliability/Packaging/Assembly.
Work with key mechanical suppliers to develop, optimize, and maintain new and current technologies
Opportunity to learn about mechanical supply chain technical capabilities and industry trends
Interface with Cisco suppliers to support and maintain daily operation health on mechanical product quality and customer delivery
Opportunity to work with cross functional mechanical engineering teams to problem solve and root cause product and process failures.
Collaborate with marketing, finance, sales and the Supply Chain Organization to develop manufacturing strategies and protocols.
Provide quantitative analysis of data to drive decision making and improve processes and tools.
Opportunity to learn about mechanical product functional and reliability testing methodologies and protocols.
Desired Degree: (BA/BS /MA/MS)
Desired Major: Business Management, Applied Science, Mathematics, Material
Engineering, Statistics, Manufacturing, Supply Chain Management or equivalent
Minimum CGPA of 3.0 out of 4
The requirement is for 2021/22 passout only
Why Cisco
At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!
Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
Data Scientist,"Mumbai, Maharashtra",Allerin Tech Private Limited,None,Organic,"Job Description :

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products like: automate scoring using machine learning techniques, build recommendation Engines/systems, optimize and extend the features used by our existing classifier, etc

Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Develop hypotheses and test carefully by experience; develop and improve predictive modeling algorithms; understand and work around possible limitations in models.
Analyze large datasets to produce statistical models and prediction tools.
Visualize, interpret, report, and communicate data findings creatively in various formats to various stakeholders.
Conduct critical data analysis and prepare data sources to be analyzed.
Discover patterns, find meaning and produce actionable intelligence. Work both autonomously and collaboratively when necessary in a fast-paced, competitive, multidisciplinary environment.

Desired Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
Proficient at translating unstructured business problems into an abstract mathematical framework.
BE/BTech/MCA/MTech/MSc in Computer Science
Some development experience in at least one scripting language (Julia, Python, R...).
Ability to initiate and drive projects to completion with minimal guidance.
The ability to communicate the results of analyzes in a clear and efficient manner.
Highly collaborative and curious.
Experience with any big data framework would be a plus.
2-7 years experience

Important:

Should be able to appear for personal interview in our office at Navi Mumbai. Do not apply if you can not appear for personal interview. No telephone round will be conducted.

2.00-7.00 Years"
Software Development Engineer II,"Mumbai, Maharashtra",ADCI - Maharashtra,None,Organic,"2+ years of non-internship professional software development experience
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
Key Responsibilities include:-
Ability to code right solutions starting with broadly defined problems,
Understand basic Algorithm fundamentals
Development of code in object oriented languages like C++ and java and build large scale robust distributed systems
Candidates for this role must have:
A solid grounding in Computer Science fundamentals (based on a BS or MS in CS or related field)
Understanding of the tools of the trade, including an understanding of any of modern programming languages (Java / JavaScript / C/C++).
Proven educational track record with sound data structure and algorithm knowledge

Amazon has come a long way since opening on the World Wide Web in July 1995. Today, we operate retail websites in multiple countries across geographies, offering products in many categories (books, media, digital, electronics etc.) worldwide, and we still like to work hard, have fun and make history! The Amazon.com brand has become synonymous with a superior level of convenience, selection, low prices, and customer service. We are looking for software engineers with experience involving solving complex problems.
Bachelors/Masters in Computer Science or Engineering
Strong, object-oriented design and coding skills (C/C++ and/or Java preferably on a UNIX or Linux platform)
Experience with distributed (multi-tiered) systems, algorithms, and relational databases
Ability to effectively articulate technical challenges and solutions
Deal well with ambiguous/undefined problems; ability to think abstractly
Previous technical internship(s) preferred"
Senior Software Engineer - Data Science and Machine Learning,"Pune, Maharashtra",VSH SOLUTIONS,None,Organic,"Overview
We are looking for creative people with analytical minds and machine learning experience to transform diverse datasets into decisions and value for our customers. Responsibilities:
Design and implement machine learning solutions for recommendation and classification
Use machine learning platforms and services to build solutions and bots, esp. for startups as part of our startup studio
Building and improving data-intensive web services
Developing complex, multi-step data pipelines that unify various data sources into one cohesive platform for data access
Unit, integration, and data integrity test development
Qualifications:
Experience building RESTful APIs & multi-tiered web applications in Python, Java, RoR or Go
Understanding of SQL and data warehousing concepts
Understanding of leading NoSQL solutions such as Cassandra and MongoDB
Experience with Git
Experience with atleast a few of these components: ElasticSearch, Caffe, Pandas, R, Matlab, SciPy
Bachelor’s Degree in Computer Science or Engineering
Location: Pune, India To apply for this job, please write to us at jobs@vshsolutions.com"
Member of Technical Staff (Python/Golang),"Pune, Maharashtra",Nutanix,None,Organic,"Nutanix Prism Pro improves the quality and efficiency in IT operations for the modern datacenter. Powered by machine learning and task automation, Prism Pro intelligently optimizes capacity, proactively detects performance anomalies, and enables the IT team to automate operations tasks with ease and confidence. Traditional IT operations management (ITOM) tools were built for static infrastructure. They often overwhelm IT teams with complex and noisy alerts that the teams can’t do anything about. In dynamic and scalable modern data centers with high performance and diverse workloads, IT teams need simplicity and accuracy to achieve high productivity in operations.

Overview of the role
MTS, Developer is responsible for building the monitoring, collections & analytics layer in the control plane (management layer) of the Nutanix platform. An important part of prism-pro is building the capability to gather configuration and metrics from parts of Nutanix Platform, Applications running on Nutanix Infrastructure, as well as other entities running in the datacenter and cloud. The developer is also expected to write services that leverage these configurations and metrics to provide monitoring, automation and troubleshooting capabilities to the end user.
The individual needs to have a keen interest in building impactful end to end features (architecture, design, thinking through workflows / use cases / experience and development of scalable solutions for the same) for customers. The solution would be like a platform so as to be usable by a variety of applications as well as Nutanix services.
Responsibilities
Core development:
Develop scalable and performant Analytics and Monitoring Platform software
Contribute as a strong, hands-on technical member in product development activities to develop clean, refactored and tested code that is extensible and highly reusable.
Develop innovative products through all phases of software development including conception, design, implementation, and deployment.
Work in an Agile environment where Quality is everyone’s responsibility.
Collaboration:
Collaborate closely with teams engaged in building the frontend and driving the user experience of the product
Collaborate with the Product Management team to translate requirements into high-quality, timely deliverables to wow our users.
Collaborate with other engineers in the team to develop and use effective mechanisms to ensure code quality.
Collaborate with teams which could be potential stakeholders of the product
Get feedback on the product and incorporate it into the product in innovative ways
Skills Required
2-5 years of development experience using Golang/Python/C++
Experience in building scalable performant distributed systems. This includes experience and knowledge of
Sync/async programming design
Multithreading/concurrency
Object oriented design
Fault tolerant systems
Working knowledge of Linux or *UX environment
Experience in virtualization and containers
Experience with design, development and data modeling of RESTful web services
Basic understanding of web technologies and transport mechanisms (HTTP/S, Javascript, JSON, gRPC, protobuf, etc).
Good knowledge of RDBMS, NOSQL & database design
Familiarity with version control systems such as GIT, build management tools and Continuous Integration tools such as Jenkins & CircleCI
Familiarity with Unit testing frameworks
Ability to write scripts and tools for development and debugging.
Memory/CPU Profiling of applications
Experience building end-to-end solutions is a plus
Qualifications
2-5 years of experience developing applications.
Bachelor Degree in Computer Science or equivalent"
Big Data Engineer,"Bengaluru, Karnataka",Zinnov,None,Organic,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
1. B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
2. Experience of 2-6 Years working with Big Data technologies.
3. Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.

Responsibilities:
1. Develop, maintain, test and evaluate big data solutions within the organisation.
2. Build scalable architectures for data storage, transformation and analysis.
3. Design and develop solutions which are scalable, generic and reusable.
4. Build and execute data warehousing, mining and modelling activities using agile development techniques.
5. Leading big data projects successfully from scratch to production.
6. Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
7. Solve problems in robust and creative ways.
8. Collaborate and work with Machine learning and harvesting teams.

Skills:
1. Proficient understanding of distributed computing principles.
2. Must have good programming experience in Python.
3. Proficiency in Apache Spark (PySpark) is a must.
4. Experience with integration of data from multiple data sources.
5. Experience in technologies like SQL and NoSQL data stores such as Mongodb.
6. Good working Knowledge of MapReduce, HDFS, Amazon S3.
7. Knowledge of Scala would be preferable.
8. Should be able to think in a functional-programming style.
9. Should have hands-on experience in tuning software for maximum performance.
10. Ability to communicate complex technical concepts to both technical and non-technical audiences
11. Takes ownership of all technical aspects of software development for assigned projects.

Benefits:
1. Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
2. Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
3. Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
4. Strong knowledge of data structures and algorithms.
5. Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
6. Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred."
Data Analyst,"Mumbai, Maharashtra",Augmenter Consulting,None,Organic,"We are looking for dynamic, energetic and result oriented business / data analyst to be a part of team and work closely and/ or independently on specific projects. You will be an independent operator and will need to deliver the set priorities in timely and most diligent manner. Your analysis will form the basis for making appropriate recommendations to customers to help them achieve the set objectives.
The successful candidate will convert data into information, information into insight and insight into business decision for the assigned project / client.
Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analyst will develop analysis and reporting capabilities. They will also monitor performance and quality control plans for identifies improvement opportunity.
The key goal of the position is to own components of the consulting / implementation projects and drive the maximization of value preposition for the client organization.
Key responsibilities:
Define and carry out the analysis of the data and information to prepare actionable insights.
Build a robust understanding of the customer business focused towards opportunities to improve customers business performance for the assigned areas.
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiencies and quality
Acquire data from primary or secondary data source and maintain them for suitable actionable usage.
Identify, analyze and interpret trends or patterns in complex data sets.
Filter and “clean” data for review reports and key performance indicators, specific to the project or work areas.
Work with company’s management team to prioritize business and information needs.
Locate, define, seek alignment and implement process improvement opportunities.
Requirements:
Proven working experience as a business data analyst.
Technical expertise regarding data models, database design, data mining and segmentation analysis.
Strong knowledge and experience with reporting packages.
Knowledge of statistics and experience using statistical tools and packages for analyzing data.
Proficient level expertise in MS Excel & Power Point.
Strong analytics skills with ability to collect, organize, analyze and disseminate significant amount of information with attention to details and accuracy.
Adept at queries, report writing and presenting finding.
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.
Qualification and experience:
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.
Minimum 2 to 5 years of relevant experience.
Proven track record.
Compensation: in line with the market and commensurate with the relevant experience."
"Technology head Data science, data analytics background","Hyderabad, Telangana",Truedge Software Solutions,None,Organic,"Technology head Data science, data analytics background – Hyderabad
Job Title: Python, Machine Learning/AI – Software Engineer
Location: Hyderabad.
Job Description:
Must have product development experience using full stack
Must have ML hands on expertise using python
Data science, data analytics background preferred
Should be able to lead a strong team of Technologists in the above mentioned tech skills from top engineering schools
Education background from IIT preferred
Salary: Commensurate to experience.
Other details: Start date: ASAP"
Data Scientist,"Mumbai, Maharashtra",Tata Communications,None,Organic,"Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
- 3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions

Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:
Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks
Innovative Solution&Group:
Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders
Stakeholder Management:
Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills"
MSSQL Data Science & R Analytics Programmer,"Bengaluru, Karnataka",Optidesk Solutions,None,Organic,"Job Role: The role is targeted at candidates with 2 to 6years of experience in Database Programming / Data Science role with hands-on experience in MS SQL Server. The Database Programmer will be responsible for developing complex queries, stored procedures, functions and R Programs to designing business logic for the applications. Responsibilities: Work with the product / functional teams on developing business logic through complex queries, stored procedures and functions. Develop R-Code for Machine Learning algorithms in the products Work on client Proof of Concepts on Machine Learning and Analytics applications. Build use cases based on industry relevant Supply Chain problems. Ideal candidate: Holds a degree only from top engineering institutes such as IISC, IITs, NITs, Anna University (CEG only), BITS Pilani, DCE, BEC, ISI. Expertise in writing complex queries, stored procedures, and functions. Experience in writing complex queries using CTE, windows functions, dynamic queries. Experience in Query Performance Fine-Tuning, index management and query plan analysis Expertise in R-Analytics programming and MS SQL R Analysis services. Hands on experience in Machine Learning Techniques such as Naives Bayes, SVM, Random Forests, Decision Trees etc. Good to have experience in handling JSON, SSIS, SSRS and MS Power BI. What we offer? A competitive salary. You grow with us. A non-hierarchical, entrepreneurial and exciting work environment. We focus on the deliverable and not on the hours of work you put. Expand your database skills across areas in Supply Chain and build domain knowledge in enterprise systems such as SAP, Oracle etc. Want to apply for this job, Forward your resume to contact@opti-desk.com Job Features
Job Category
Developer"
Web Developer (FE and BE)/ AI Developer,"Thane, Maharashtra",Siemens AG,None,Organic,"Mode of employment: Full time / Contract

As a Data Scientist in the LDA India, you will be involved in designing, implementing and testing a component of the Minerals projects. You will work closely with our product owner, scrum master and other developers in an agile development team throughout the entire product lifecycle.

What are my responsibilities?
You are proficient in modern technologies and software development for web AI application using Java
o Basic python, tensorflow, regression models, deep learning, neural networks, data science mathematical models and Git
Design, develop and maintain in on premise and cloud environment (Dev, Test and Release)
Implement, test and release bug fixes

What do I need to qualify for this job?
General Experience & Skill Set
Qualification: Degree / BE (Computer Science, Information Technology)
Experience: 3+ years of experience on software development projects, out of which at least 2 year of AI Work experience

Required Skills:
Strong knowledge in software development, build, release.
Knowledge of AI
1. Python, tensorflow, regression models, deep learning, neural networks, data science mathematical models, Git
Knowledge of Java
Strong in OOP concepts

Organization: Portfolio Companies
Company: Siemens Limited
Experience Level: Experienced Professional
Job Type: Full-time"
Computer Scientist - (C++),"Noida, Uttar Pradesh",Adobe,None,Organic,"Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver outstanding digital experiences. We’re passionate about empowering people to craft alluring and powerful images, videos, and apps, and transform how companies interact with customers across every screen.
We’re on a mission to hire the very best and are committed to building outstanding employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
The Challenge
As an Engineer, you will be responsible for owning the technical vision for PDF workflows. You will have significant influence on our overall strategy by helping define these product features, drive the system architecture, and spearhead the best practices that enable a quality product.
The ideal candidate is clearly who is adaptable to an agile environment, passionate about new opportunities in desktop application and has a proven track record of success in delivering new features and products. Creating such reliable, scalable, and high performance products requires exceptional technical expertise, a sound understanding of the fundamentals of Computer Science, desktop technologies and practical experience building customer facing products.
Evolve Acrobat for modern user experience with the objective of delighting the customer
Build the next generation document management based solutions by integrating cloud based services and frameworks in Acrobat/Reader.
Build the best in class document creation tools.
Design and build document processing tools to extract, index and search document content.
Develop advanced document reconstruction algorithms for document editing, PDF Export.
Develop document and image processing algorithms for crafting document scanning and OCR tools.
Develop most intuitive and powerful document reviews, commenting and approval solutions.
Develop security solutions for close to a billion Acrobat free users
What you need to succeed
5-9 years of hands on development experience
Bachelors/master’s in computer science or a related field.
Proficient in C++, HTML, CSS, JS, data structures and algorithms
Experience in Databases like MySQL, Postgres will be added advantage
Excellent software design skills
Strong problem-solving skills.
Able to communicate technical details clearly
Motivated self-starter with the ability to learn and adapt to new technologies
Work closely and seamlessly with various engineering teams, product management, experience design and quality engineering to ensure we deliver great compelling solutions.
At ease with ambiguity and able to adapt and change direction/technologies to leverage new learnings.
Be a mentor and role model for junior engineers.
At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists . You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.
If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, or veteran status."
Python Developer,"Gurgaon, Haryana",ITC Infotech,None,Organic,"Python dev with 4 to 6 years exp
Exp in data science
Exposure to libraries – NumPy, Pandas , Matplotlib
Exp of working with Oracle Databases , strong SQL"
Quantitative Engineer - FICC Mortgage Strats - BCE,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
SECURITIES

Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.

Who We Are
At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.
Engineering, which is comprised of our Technology Division and global Strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.

What We Do
Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.

Your Impact
As a strategist who sits in the Securities Division, you will play an integral role on the trading floor. You may create cutting-edge derivative pricing models and empirical models to provide insight into market behavior, or develop automated trading algorithms for the firm and its clients. You might be involved in analyzing exposures and structuring transactions to meet client needs, or involved in designing and developing complex parallel computing architectures, electronic trading tools, and advanced algorithms. Throughout the Securities Division, strategists are using quantitative and technological techniques to solve complex business problems.

RESPONSIBILITIES AND QUALIFICATIONS:
Who We Look For
For this position, we are looking for an Analyst/Associate to be a part of the BCE team within the Divisional Strats Group. The BCE (Brokerage, Clearance & Exchange) Strats team liaises with trading, engineering, operation and other groups to develop analytics toward BCE expense optimization.

Responsibilities

Work closely with SecDiv senior management, trading desks, engineering & operation teams on BCE project development.
Analyze data; design and build analytics, algorithms and tools to optimize BCE costs across all desks in SecDiv.
Communicate with various internal teams (Traders, Sales, Strats, Engineering, Operations, Controllers, etc.) to onboard new BCE tools and strategies.
External optimization negotiations with brokerages and exchanges.
Understand various secdiv business models, risks and tools used, to suggest solutions to optimize flows and change trading behavior.
Basic Qualifications:
Strong academic background in a relevant STEM field (Computer Science, Engineering, Physics or Mathematics)
Strong interpersonal/communication skills
Strong programming skills (OOP, SQL)
Ability to focus both on details and on the big picture, as requested
Preferred Qualifications:
Derivatives product knowledge in FICC and equities
Knowledge in Financial Mathematics, market microstructure, etc.
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Data Scientist,"Mumbai, Maharashtra",Allerin Tech Private Limited,None,Organic,"Job Description :

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products like: automate scoring using machine learning techniques, build recommendation Engines/systems, optimize and extend the features used by our existing classifier, etc

Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Develop hypotheses and test carefully by experience; develop and improve predictive modeling algorithms; understand and work around possible limitations in models.
Analyze large datasets to produce statistical models and prediction tools.
Visualize, interpret, report, and communicate data findings creatively in various formats to various stakeholders.
Conduct critical data analysis and prepare data sources to be analyzed.
Discover patterns, find meaning and produce actionable intelligence. Work both autonomously and collaboratively when necessary in a fast-paced, competitive, multidisciplinary environment.

Desired Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
Proficient at translating unstructured business problems into an abstract mathematical framework.
BE/BTech/MCA/MTech/MSc in Computer Science
Some development experience in at least one scripting language (Julia, Python, R...).
Ability to initiate and drive projects to completion with minimal guidance.
The ability to communicate the results of analyzes in a clear and efficient manner.
Highly collaborative and curious.
Experience with any big data framework would be a plus.
2-7 years experience

Important:

Should be able to appear for personal interview in our office at Navi Mumbai. Do not apply if you can not appear for personal interview. No telephone round will be conducted.

2.00-7.00 Years"
Field Application Scientist - Pharma Analytics,"Pune, Maharashtra",Thermo Fisher Scientific,None,Organic,"Job Title: Field Application Scientist - Pharma Analytics
Job Location: Bengaluru / Hyderabad / Pune / Mumbai / Ahmedabad
About Company:
Thermo Fisher Scientific Inc. is the world leader in serving science, with revenues of more than $25 billion and approximately 75,000 employees globally. Our Mission is to enable our customers to make the world healthier, cleaner and safer. We help our customers accelerate life sciences research, solve complex analytical challenges, improve patient diagnostics, deliver medicines to market and increase laboratory productivity. Through our premier brands – Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific and Unity Lab Services – we offer an unmatched combination of innovative technologies, purchasing convenience and comprehensive services.
About Team:
Life Sciences Solutions Group - Bioproduction
Role &amp; Responsibilities
Purpose of the Role:
Field Application Scientist (FAS) – Pharma Analytics is a technical role and involves training customers on Thermo Fisher Scientific SEQ rapid molecular methods for pharmaceutical manufacturing to help ensure the quality and safety of pharmaceutical products, especially when accuracy and time-to-results are critical. The SEQ assays are developed for multiple platforms, including but not limited to Q- PCR, thermal cyclers, CE – genetic analyzers, Next Gen sequencing, sample preparation and automation platforms. For their targeted applications using the specific SEQ assays the FAS should be well aware of bioprocessing workflow for vaccine and biosimilar mAbs, r-proteins , Cell and gene therapy as well as regulatory expectations to provide guidance to customers based on regional US-FDA and EU lot release testing guidelines for contamination and impurity testing . FAS is also expected to support the sales team and the customer during the purchase process, to help the customer chose the most appropriate products for their R&amp;D and manufacturing projects. FAS is expected to actively participate in various seminars, scientific discussions (pre &amp; post sale), proof of concept studies and product training for external &amp; internal (commercial team) customers.
Responsibilities
Provide training on site as well as in house lab facilities on SEQ solutions and participate in pre-sales discussions, conferences, meetings.
Drive customer workshop for customers in South Asia (India, Bangladesh, Sri Lanka, Nepal)
Responsible for imparting knowledge transfer to customer related to workflows in DNA / RNA analysis, DNA Sequencing, REAL TIME (Q- PCR) and ancillary procedures.
Troubleshooting and In-depth Analysis -in case of any deviations from normal data are part of the necessary skill set for FAS role.
Provide remote support to users- either by telephonic / chats or email communications.
Provide post sales support to commercial teams.
Provide Customer support on quality issues by resolving customer complaints for SEQ products and escalation to Global BU and manufacturing teams via appropriate channels
Support to internal teams as and when required.
Responsible for delivering revenue targets for business area of responsibility and have budgetary responsibility for marketing spends in the region.
Desired Experience:
Must have 5 – 8 years of experience in working with customers and supporting demos, evaluations and validation studies
Demonstrated experience in driving for continuous improvement of processes
Willingness to be flexible and adaptable in a complex, matrixed environment
Able to adapt quickly to changing needs caused by time, budget, or business constraints
Comfortable working in a fast-paced environment
Strong communication and presentation skills are essential
Experience gathering VOC and utilizing CRM tools
Multidisciplinary background preferred having qPCR experience. NGS, CE, and sample extraction platform experience preferred. Protein detection experience (e.g. ELISA) a plus.
Preferred Skills:
Experience in working with regulated (GMP) customers
Experience in QC lot release testing and assay development
Demonstrated experience communicating and coordinating work across functions, cultures, and time zones
At Thermo Fisher Scientific, each one of our 75,000 extraordinary minds has a unique story to tell. Apply today http://jobs.thermofisher.com.
Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status."
Data Scientist,"Bengaluru, Karnataka",Talent Zone Consultants,"₹1,25,000 - ₹3,25,000 a year",Organic,"Bangalore


Apply technical and analytical expertise to exploring and examining data from multiple disparate sources with the goal of discovering patterns and previously hidden insights that in turn can provide a competitive advantage or address a pressing business problem
Leverage expertise in computer science, software development, and the latest technologies to analyze and implement analysis infrastructure and tools, analytic workflow processes, and complex data visualizations
Use comprehension of mathematical and statistical concepts, computer science, or domain expertise to bridge the gap between technologists and mathematicians, ensuring software solutions meet analytic requirements. Provide work leadership to junior employees, as needed
Experience
4 - 6 Years

Salary
1 Lac 25 Thousand To 3 Lac 25 Thousand P.A.

Industry
Engineering / Technical / R&D

Qualification
Post Graduate Diploma

Key Skills
Expert in R and Python with firm understanding of statistical modelling techniques and should be adept at handling unstructured data 4 plus years of experience of working in the areas related to data science including machine learning and text mining


About Company
Company Name
Talent Zone Consultant


About Company
TALENT ZONE Consultants is known for offering best recruitment solutions in Bangalore includes Outsourcing Services, HR Consultancy in Bangalore, Campus

Contact Person
TZC

Address
Talent Zone Consultant, Sampige Road, Malleshwaram Bangalore

Mobile
8884264343

Email ID
info@talentzoneconsultant.com"
Senior Software Engineer - Data Science and Machine Learning,"Pune, Maharashtra",VSH SOLUTIONS,None,Organic,"Overview
We are looking for creative people with analytical minds and machine learning experience to transform diverse datasets into decisions and value for our customers. Responsibilities:
Design and implement machine learning solutions for recommendation and classification
Use machine learning platforms and services to build solutions and bots, esp. for startups as part of our startup studio
Building and improving data-intensive web services
Developing complex, multi-step data pipelines that unify various data sources into one cohesive platform for data access
Unit, integration, and data integrity test development
Qualifications:
Experience building RESTful APIs & multi-tiered web applications in Python, Java, RoR or Go
Understanding of SQL and data warehousing concepts
Understanding of leading NoSQL solutions such as Cassandra and MongoDB
Experience with Git
Experience with atleast a few of these components: ElasticSearch, Caffe, Pandas, R, Matlab, SciPy
Bachelor’s Degree in Computer Science or Engineering
Location: Pune, India To apply for this job, please write to us at jobs@vshsolutions.com"
Senior Expert Data Scientist,"Hyderabad, Telangana",Novartis,None,Organic,"Your responsibilities include, but are not limited to:

Responsible for all data science tasks on the assigned clinical or non-clinical projects, and perform these tasks for mid- to high- complexity projects with a good level of independence. Responsible for implementing data science planning, data provisioning, analytical activities including exploratory analyses, reporting and communication of methods and results, ensuring reproducible and agile ways of working.
Contribute to planning and execution of exploratory analyses, and/or PK, PK/PD analyses, exploratory biomarker and diagnostic analyses, and data science consultation. Initiate, drive and implement novel and innovative methods in alignment with other quantitative team members.
Explain data science methodology and interpret analysis results. Provide data science expertise to support submission activities, meetings with and responses to Health Authorities and other drug development activities, as required.
Contribute to interactions with external review boards/ethics committees, external consultants and other external parties with oversight as appropriate. Represent Novartis in data science discussions at external congresses, conferences, scientific meetings.
Represent the Analytics Line Function on cross-functional teams for the assigned projects. Responsible for functional alignment and ensuring line function awareness throughout the assigned projects.
Collaborate with other line functions. Explain methods and results in a manner easily understood by non-analytical folks, and provide adequate justifications, sensitivity analyses for actions/decisions/statements, when required.
Establish and maintain sound working relationships and effective communication with the Clinical Colleagues and Biostatistics & Pharmacometrics team.
Understand complex and critical business problems, formulates integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. High agility to be able to work across various business domains. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact.

Minimum requirements
MS (in Statistics or equivalent) with 4+ years relevant work experience or PhD (in Statistics or equivalent) with relevant work experience (including internship)
Good communication and presentation skills.
Experience/Professional Requirement, Influences decisions that directly impact the assigned clinical trial and team ability to deliver objectives.
Proven knowledge and expertise in data science and its application to clinical trials. Depending on the assignment, may require proven expertise in pharmacokinetics, exposure-response modelling, exploratory biomarker, diagnostic analyses, applied Bayesian statistics, or data exploration skills. Proficiency in use of software packages (e.g. Python, R).
Knowledge of drug development and Health Authority guidelines. Able to work on a multidisciplinary team to achieve team objectives.
Experience in Franchise/Therapeutic Area and/or regulatory activities would be advantageous

Why consider Novartis?

799 million. That’s how many lives our products touch. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

We are Novartis. Join us and help us reimagine medicine.

Novartis are an equal opportunities employer and welcome applications from all suitably qualified persons.
Division
Global Drug Development
Business Unit
CD&A GDD
Country
India
Work Location
Hyderabad, AP
Company/Legal Entity
Nov Hltcr Shared Services Ind
Functional Area
Data & Digital
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
Software QA Engineer,"Bengaluru, Karnataka",AliveCor,None,Organic,"Software QA Engineer
Making the invisible visible. By harnessing the power of artificial intelligence, we’re advancing the practice of medicine for doctors and society. And we’re just getting warmed up.
AliveCor, the creator of the smartphone ECG, which has now captured over 20 million ECGs from tens of thousands of active users, seeks a SQA Engineer. The Software QA engineer will directly contribute to existing products, testing software for our Web, iOS, and Android products. You will be a key player in developing highly-visible, customer-facing products that are transforming the healthcare industry via big data.

Responsibilities
Be responsible for the testing of all mobile applications.
Report and verify bugs in a timely manner.
Work with developers, product and other team members to develop test plans and cases to mitigate risk.
Document test cases for regulatory purposes.
Promote a culture of quality throughout the organization.
Work with Engineering and Product Management teams to identify high-impact issues.
Use defect tracking tools to log, track and refine issues.
Perform functional testing of new features as they are developed.
Participate in all aspects of QA product lifecycle: understand the product requirements, test case creation, feature, regression, integration, end-to-end test execution.
Prepare and review test plans and cases with extended development and product management teams.

Qualifications and Skills
B.E in Computer Science or a related discipline, or related practical experience.
3-8 years of relevant QA experience.
Proven work experience in Mobile Apps Testing for Android and iOS.
Proven work experience in modern web-based applications testing.
Strong knowledge of software QA methodologies, tools and processes.
Experience in writing clear, concise and comprehensive test plans and test cases.
Hands-on experience with both white box and black box testing.
Knowledge of automated testing tools will be an added advantage.
Excellent programming skills in one of the following - Ruby, Python, Go, Objective C, or Java

About Us
AliveCor is on a mission to define modern healthcare through data, design and disruption. We’ve pioneered the creation of FDA-cleared machine-learning techniques, transformed wearable medtech to put proactive heart care at everyone’s fingertips. Kardia is the most clinically validated mobile EKG technology. AliveCor was named as one of the Top 10 Most Innovative Companies in Health for 2017 by Fast Company as part of the publication’s annual ranking of the world’s Most Innovative Companies. AliveCor was awarded the 2015 Tech Pioneer by the World Economic Forum and one of the 50 Smartest Companies in 2015 by the MIT Technology Review. AliveCor recently announced a collaboration with Mayo Clinic that will result in new machine learning capabilities to unlock previously hidden health indicators in EKG data, potentially improving heart health as well as overall health care for a variety of conditions. AliveCor is a privately held company headquartered in Mountain View, CA.
AliveCor is an equal opportunity employer and will not discriminate against any employee or applicant on the basis of age, colour, disability, gender, national origin, race, religion, sexual orientation, or any other classification protected by federal, state, or local law.
Watch the following video demonstrating our product.
KardiaMobile: How's your heart?
https://www.youtube.com/watch?v=8I9xosgA-Ig"
"Senior Data Analyst, ED&A ICC","Bengaluru, Karnataka",Nike,None,Organic,"Become a Part of the NIKE, Inc. Team
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.
NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it.
Nike does more than outfit the world's best athletes. We are a place to explore potential, obliterate boundaries, and push out the edges of what can be. We're looking for people who can grow, think, dream and create. We thrive in a culture that embraces diversity and rewards imagination. We seek achievers, leaders and visionaries. At Nike, it's about bringing what you have to a challenging and constantly evolving game.

Now, more than ever, Technology needs to respond quickly to turn market disruptions into opportunities for our world-class brand. To achieve this, we must continue to develop our Enterprise Analytics, Data Science & Machine Learning capabilities and team to ensure we’re maximizing the power of the Nike enterprise in the analytics/machine learning space and managing data as a competitive advantage.

If you’re ready to innovate and be a driving force for building solutions Enterprise Data and Analytics organization, come join us now! You will be part of an organization that is revolutionizing Nike technology platforms and architecting a data and analytics landscape that is simplified, modern, flexible and will ultimately enable Nike on its journey to 2020 and beyond.

Responsibilities:

Build and deploy forecasts and report business key performance indicators (KPIs) for senior leadership and partner with the stakeholders to deliver relevant analysis and insights.
Write, drive, and prioritize thoughtful and detailed functional specifications for real-time operational and performance analytics using opensource streaming technologies
Deploy reporting and analytics within a focused area of the Nike business value stream to enable data driven business decisions that will drive performance and lead to the accomplishment of annual goals
Deploy quantitative research, casual inference and predictive models to understand and optimize drivers of growth and performance
Project manage and deliver large analytics projects with multiple business stakeholders on firm deadlines
Utilize expertise with business partners to collaborate with key partners to understand requirements, drive knowledge into action and support data driven decision making
Document and communicate systems/analytics changes to the business, translating complex functionality into business relevant language
Support and troubleshoot issues (process & system), identify root cause, and proactively recommend sustainable corrective actions
Skills:

Bachelor’s Degree in Computer Science, MIS, other quantitative disciplines, or related fields
7+ years of relevant analytical experiences that can translate into defining strategic vision into requirements and working with the best engineers, product managers, and data scientists
Ability to conduct data analysis, develop and test hypothesis and deliver insights with minimal supervision
Experience identifying and define KPI’s and cohorts for apps, traffic, user retention
Exceptional SQL skills
Experience with modern visualization tool stack, such as: Kibana, Tableau, Power BI, d3js
Hands-on experience working with streaming data sources such as Kafka, Kinesis
Experience with open-source, big data and cloud infrastructure such as AWS
Experience writing detailed technical specifications describing requirements for data movement, transformation, storage, quality checks, and access latency
Incredible attention to detail, with structured problem-solving approach
Excellent communications skills (written and verbal)
Experience with clickstream data
Experience with agile development methodologies
Experience with data transformation and BI tools
Experience with retail or ecommerce domains is a plus
NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.
NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Big Data Engineer - Data DQMF,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Technology
Primary Location: ASEAN & South Asia-India-Bangalore
Other Locations: ASEAN & South Asia-India-Bangalore
Schedule: Full-time
Employee Status: Permanent
Posting Date: 26/Jun/2020
Unposting Date: Ongoing
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.


The Role Responsibilities


As a Big Data Engineer, you will be responsible for building and expanding our data architecture on Hadoop platforms.
Key Responsibilities
Create and maintain the bank’s data pipeline and platform architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build monitoring/alerting tools & frameworks using OSS technologies for doing key business/technical performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data-center.
Help ‘commercialize’ the data platform by working closely with the Data Science team in exploring opportunities, be it fighting fraud or developing multi-channel cross-sell/up-sell initiatives

Regulatory & Business Conduct
Display exemplary conduct and live by the Group’s Values and Code of Conduct.
Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct.
Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters.


Our Ideal Candidate
Strong analytic skills related to working with unstructured datasets.
Ability to quickly learn and implement newer technologies, particularly on the Big Data side including HIVE, HBase, Kafka, Spark and Nifi
Exposure to data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.
Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Software Engineer - Java (Insights),"Bengaluru, Karnataka",Truecaller,None,Organic,"Hey, Truecaller is calling you from Bangalore, India! Ready to pick up?
Truecaller was born in 2009, Stockholm, Sweden, with the mission to provide more safe and efficient communication to everyone's daily life. Today, Truecaller is loved by 180 million daily active users around the world, popular in South Asia, Middle East, Africa! We are the go-to app for Caller ID, spam blocking, messaging, and payments.
We at Insights team The Insights Team is responsible for all the Smart-SMS features (Smart Notifications, InfoCards in conversations, Important tab etc) that you see in the Truecaller app and is fully based out of the Bangalore office.
As a Java Developer in the team, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
What we expect from you:
4 + Years of experience into core java
Strong understanding of core java 8, threading, generics, garbage collection, serialization etc
Strong OOPs, data structure, algorithm knowledge
Strong understanding and hands on experience of some dependency injection framework and writing testable code
hands on experience on build/deploy tools/configuration such as maven, jenkins, etc
Prior experience in resolving performance issues and should know how to go about optimizing APIs via code, configuration, caching or whatever method suitable
Aptitude/experience of analyzing and debugging complex production issues using tools such as splunk, dynatrace and sometimes UNIX commands
Ability & willingness to learn technologies at pace and adapt easily
A bachelor's degree in computer science. If the candidate has strong technical skills and/or great reasoning ability paired with decent coding ability, this will not be a barrier
What will you work on?
This position is for a java developer within the Insights Team.The team owns a patented fully offline text parser which enables all these features. The parse is written in Java and is maintained as a separate project and included within the app. It is tuned for a very small memory footprint and parsing speed compared to other parsers.If you get selected, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
It would be great if you also have:
Since we are working with text parsing, it would be awesome if the candidate has
Experience in compiler design (Undergrad knowledge is good enough)
NLP knowhow and a basic understanding of how text parsers work.
Knowledge of Graph based data structures/algorithms
Some experience with stream processing paradigms
Working experience in Kotlin
More about Truecaller
Truecaller is a Swedish company founded in 2009 in Stockholm, Sweden by Nami Zarringhalam and Alan Mamedi. The app began when our co-founders were just students who wanted to create a service that would easily identify incoming calls from unknown numbers. We have our strongest presence in South Asia, Middle East, Africa, and HQ in Sweden. We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.
Life at Truecaller - Behind the code: instagram.com/truecaller/ https://www.linkedin.com/company/truecaller/
How To Apply
You can also apply with the help of link given
https://boards.greenhouse.io/truecaller/jobs/2247266
This position is based in Bangalore, India. Please contact Talent@truecaller.com if you have any questions.
What we offer:
International teams - 25+ nationalities work together!
Learning & sharing environment
Exciting company parties & team activities – Football Team, Geek lunch, Lab Days!
Flexible working hours
Start the day with delicious breakfast
Stay refreshed: juices, tea, coffee and soft drinks
Gym reimbursement.
Competitive salary
Medical, Accident,Term life insurances
Truecaller is an equal opportunity employer and value diversity company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status."
Data Engineer II / Sr Data Engineer,"Mumbai, Maharashtra",Colgate-Palmolive,None,Organic,"Relocation Assistance Offered Within Country
# 83461 - Mumbai, Maharashtra, India
We are looking for a savvy Data Engineer to join our growing team of analytics experts. Data Engineers will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Roles and Responsibility:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Experience
We are looking for a candidate with minimum 2 years of experience in a Data Engineer role
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc
Experience with cloud services: GCP, AWS, etc
Experience with object-oriented/object function scripting languages: Python, Java, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.

Qualification & Competencies
Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is preferred
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Strong analytic skills related to working with unstructured datasets.
Strong problem solving skills with an emphasis on product development.
Strong experience with test driven development methodologies.
Strong oral & written communication skills with an ability to express complex technical concepts in business terms and business needs in technical specifications
A drive to learn and master new technologies and techniques.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation."
Information Analyst - Bangalore,"Bengaluru, Karnataka",Informatics,None,Organic,"No. of positions: 3
Location: Bangalore
Education: BE computer science or MCA
Required Skills
Good oral & written communication
Basic commercial knowledge, MS Office tools / Excel / numeracy skills.
Roles & Responsibilities
Configuring journals to extract the metadata to Database by using Regular Expressions
Extracting active links for dead links of J-Gate by running SQL queries
Quality check for the extracted content
Classifying the subjects for the allocated articles / Journals and other Data types
Normalization of Data"
Data Scientist,"Mumbai, Maharashtra",Tata Communications,None,Organic,"Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.
He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.
He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
- 3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions

Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:
Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks
Innovative Solution&Group:
Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders
Stakeholder Management:
Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills"
Senior Software Engineer,"Zakhir Nagar, Delhi",Synapse Valuetech,None,Organic,"Requirements
B.Tech./ B.E / MCA degree in Computer Science, Engineering or a related stream.
3+ years of software development experience.
3+ years of Python / Java development projects experience.
Minimum of 4 live project roll outs.
Experience with third-party libraries and APIs.
In depth understanding and experience of either SDLC or PDLC.
Good Communication Skills
Team Player
What we Expect from you?
Design and build applications/ components using open source technology.
Taking complete ownership of the deliveries assigned.
Collaborate with cross-functional teams to define, design, and ship new features.
Work with outside data sources and API's.
Unit-test code for robustness, including edge cases, usability, and general reliability.
Work on bug fixing and improving application performance.
What you've got?
You'll be familiar with agile practices and have a highly technical background, comfortable discussing detailed technical aspects of system design and implementation, whilst remaining business driven. With 5+ years of systems analysis, technical analysis or business analysis experience, you'll have an expansive toolkit of communication techniques to enable shared, deep understanding of financial and technical concepts by diverse stakeholders with varying backgrounds and needs. In addition, you will have exposure to financial systems or accounting knowledge."
CIEL/SEL/14839: Data Science - AI/ML Specialist,"Bengaluru, Karnataka",CIEL HR Services,None,Organic,"About the company -
Our client is one of the world's fastest-growing AI-based contract management solution providers.

Exp -
7+ Years
Location -
Mumbai
Job Role -
Min 7years hands-on experience in Natural Language Processing, Machine Learning, Artificial Intelligence, and IBM Watson"
Data Scientist,"Kochi, Kerala",Mindcurv,None,Organic,"About Mindcurv
We help our customers rethink their digital business, experiences, and technology to navigate the new digital reality. We do this by designing sustainable and accountable solutions for humans living in a digital world. Mindcurv holistically covers the market’s need to digitize business processes and customer experiences and take advantage of the cloud following DevOps and agile principles.
Within Digital Platforms & Experiences we design and fully craft tailored solutions for our customers enabling them to get the most out of their business. We design and build a solid foundation in commerce, marketplace, responsive design, DXP and order management to name a few.

Your Role :
Be part of Big Data and Advanced analytics project team’s in the Data Science domain and as a trusted advisor to the VP of Data Science department on technology, configuration and delivery of projects undertaken by Mindcurv. You need to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. Need to have a proven ability to drive business results with your data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. You should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
What you will do :
Identify valuable data sources and collection processes
Supervise preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns for insurance industry.
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Collaborate with engineering and product development teams
Hands-on knowledge of implementing various AI algorithms and best-fit scenarios.
Who you are :
4+ years’ experience in Analytics systems/program delivery. At least 2 Big Data or Advanced Analytics project implementation experience
Experience using statistical computer languages (R, Python, SQL, Pyspark, etc.) to manipulate data and draw insights from large data sets; familiarity with Scala, Java or C++
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Hands on experience in Azure/AWS analytics platform (3+ years).
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Strong math skills (e.g. statistics, algebra)
Excellent communication and presentation skills
Deploying data pipelines in production based on Continuous Delivery practices.
Experience using variations of Databricks or similar analytical applications in AWS/Azure
Fluent in English (verbal and written). German/Dutch language familiarity will be a plus
Interpersonal and Team skills should be top notch
Why join Mindcurv?
We believe that the most important aspect of a job is being excited about it, having growth opportunities and working in a team you really like. We’re always on the lookout for people who know their stuff and want to collaborate on tomorrow’s digital solutions. Our workplaces feel good, because they’re filled with good people.
Join a collaborative environment and work with the latest technologies. We’ll grow your career and provide a great workplace with flexible hours.
If you agree with our philosophy and share our values, we are looking forward to meeting you as soon as possible!"
Senior Software Engineer - Data Science and Machine Learning,"Pune, Maharashtra",VSH SOLUTIONS,None,Organic,"Overview
We are looking for creative people with analytical minds and machine learning experience to transform diverse datasets into decisions and value for our customers. Responsibilities:
Design and implement machine learning solutions for recommendation and classification
Use machine learning platforms and services to build solutions and bots, esp. for startups as part of our startup studio
Building and improving data-intensive web services
Developing complex, multi-step data pipelines that unify various data sources into one cohesive platform for data access
Unit, integration, and data integrity test development
Qualifications:
Experience building RESTful APIs & multi-tiered web applications in Python, Java, RoR or Go
Understanding of SQL and data warehousing concepts
Understanding of leading NoSQL solutions such as Cassandra and MongoDB
Experience with Git
Experience with atleast a few of these components: ElasticSearch, Caffe, Pandas, R, Matlab, SciPy
Bachelor’s Degree in Computer Science or Engineering
Location: Pune, India To apply for this job, please write to us at jobs@vshsolutions.com"
Software Development Engineer-Java,"Noida, Uttar Pradesh",Ebix Inc.,None,Organic,"Designing and developing high-volume, low-latency web backend
Contribute in all phases of the development lifecycle
Write well designed, testable, efficient code
Ensure designs are in compliance with specifications
Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review

Requirements
BTech/BE/MTech/ME/MCA degree in Computer Science, Engineering or a related subject
Good problem solving and communication skills
Good in data structure/Algorithm and coding skills
Proven working experience in Java development [1-5 years]
Hands on experience in designing and developing applications using Java EE platforms
Object Oriented analysis and design using common design patterns.
Profound insight of Java and JEE internals (Classloading, Memory Management, Transaction management etc)
Excellent knowledge of Relational Databases, SQL and Hibernate
Experience in developing web applications"
Modem LTE,"Hyderabad, Telangana",Qualcomm India Private Limited,None,Organic,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Software Engineering
Job Overview:
Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.
General Summary Develops, creates, and modifies general computer applications software or specialized utility programs. Analyzes user needs and develops software solutions. Designs software or customizes software for client use with the aim of optimizing operational efficiency. May analyze and design databases within an application area, working individually or coordinating database development as part of a team. Modifies existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Analyzes user needs and software requirements to determine feasibility of design within time and cost constraints. Confers with systems analysts, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and interfaces. Stores, retrieves, and manipulates data for analysis of system capabilities and requirements. Designs, develops, and modifies software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design. The responsibilities of this role include:
Working under some supervision.
Making decisions that are moderate in impact; errors may have relatively minor financial impact or effect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.
Using verbal and written communication skills to convey information that may be somewhat complex to others who may have limited knowledge of the subject in question. May require basic negotiation and influence, cooperation, tact, and diplomacy, etc.
Having a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to provide input on key decisions).
Completing tasks with multiple steps that can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.
Exercising creativity to draft original documents, imagery, or work products within established guidelines.
Using deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or incomplete; intermediate data analysis/interpretation skills may be required.
May be solicited during strategic planning period. The responsibilities of this role do not include:
Financial accountability (e.g., does not involve budgeting responsibility).
Principal Duties & Responsibilities
Completes assigned coding tasks to specifications on time without significant errors or bugs.
Adapts to changes and setbacks in order to manage pressure and meet deadlines.
Collaborates with others inside project team to accomplish project objectives.
Communicates with project lead to provide status and information about impending obstacles.
Quickly resolves complex software issues and bugs.
Gathers, integrates, and interprets information specific to a module or sub-block of code from a variety of sources in order to troubleshoot issues and find solutions.
Seeks others' opinions and shares own opinions with others about ways in which a problem can be addressed differently.
Participates in technical conversations with tech leads/managers.
Anticipates and communicates issues with project team to maintain open communication.
Makes decisions based on incomplete or changing specifications and obtains adequate resources needed to complete assigned tasks.
Prioritizes project deadlines and deliverables with minimal supervision.
Resolves straightforward technical issues and escalates more complex technical issues to an appropriate party (e.g., project lead, colleagues).
Writes readable code for large features or significant bug fixes to support collaboration with other engineers.
Determines which work tasks are most important for self and junior engineers, stays focused, and deals with setbacks in a timely manner.
Unit tests own code to verify the stability and functionality of a feature.
IT Core Competencies N/A
Required Competencies (All competencies are required upon entry)
Analytical Skills - The ability to collect information and identify fundamental patterns/trends in data. This includes the ability to gather, integrate, and interpret information from several sources.
Building Trusting Relationships - The ability to build trusting, collaborative relationships and rapport with different types of people and businesses. This includes delivering on commitments and maintaining confidential information, as well as being approachable, showing interest in the other person, and relating well to people regardless of personality or background.
Communication - The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.
Creating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.
Decision-Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.
Demonstrating Personal Flexibility - The ability to demonstrate resourcefulness and resilience in the face of change, obstacles, and adversity. This includes adapting to competing demands and shifting priorities. This also includes improving adaptability, pursuing new skills and knowledge, and regularly seeking feedback from others.
Getting Organized - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.
Software Optimization - Knowledge of techniques and approaches to optimize software for specific hardware platforms. This includes basic practices in software optimization and the interaction between software and the hardware platform.
Taking Initiative - The ability to attack work activities with drive and energy, understanding the impact of work on key metrics, and making decisions that are in the company's best interest. This includes not being afraid to initiate action before all the facts are known, and driving value-added work tasks to completion.
Technical Documentation - Ability to appropriately document software and/or hardware specifications to promote knowledge transfer to other engineers.
Software Engineering - Knowledge of the overall process for developing new software. This includes knowledge of the roles and responsibilities of software engineering and other functions, major phases, checkpoints and deliverables. This also includes the ability to identify common issues and considerations for bringing a new product to the marketplace.
Time Management - The ability to quickly prioritize mission-critical from less important or trivial work activities. This includes sensing what the next most useful thing is to work on, and focusing on the critical few tasks that add value while putting aside or delaying the rest.
Troubleshooting - The ability to detect malfunctions in daily operations, including scheduling issues and process problems, and determining root causes and appropriate solutions for operating errors. This also includes the ability to detect malfunctions or the need for repair and adjustment to various types of equipment and implement corrective actions and track their success.
Additional Competencies N/A
Minimum Qualifications
Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.
2+ years Software Engineering or related work experience.
2+ years experience with Programming Language such as C, C++, Java, Python, etc.
Preferred Qualifications
4+ years Software Engineering or related work experience.
2+ years experience with Database Management Software.
2+ years experience with API.
2+ years experience working in a large matrixed organization.
1+ years of work experience in a role requiring interaction with senior leadership (e.g., Director level and above).
Physical Requirements
Frequently transports between offices, buildings, and campuses up to ½ mile.
Frequently transports and installs equipment up to 5 lbs.
Performs required tasks at various heights (e.g., standing or sitting).
Monitors and utilizes computers and test equipment for more than 6 hours a day.
Continuous communication which includes the comprehension of information with colleagues, customers, and vendors both in person and remotely.
Applicants : If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport
To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications."
Data Scientist,"Pune, Maharashtra",NICE Actimize,None,Organic,"Position: Data Scientist
Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities

Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.

Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools."
Senior Data Scientist,"Bengaluru, Karnataka",Noodle.ai,None,Organic,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.
Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning
Manipulate and prepare large, heterogeneous data sets to support advanced analytics
Iteratively conceptualize, design and build data-driven analytical models
Develop processes and tools to monitor and analyze model performance and data accuracy
Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.
Productionalizing machine learning code and interfacing with industry standardmsoftware systems
Understand and manipulate unstructured data from different platforms.
Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value
Qualifications:
Required:

Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems
Good to have:
4+years of experience applying advanced AI techniques to real-world problems
Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)
Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)
Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, etc...)
Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).
Demonstrable familiarity with code and programming concepts.
Knowledge of Spark and/or Hadoop
Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning
Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau
Strong problem solving skills with an emphasis on product development
Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style
Passion for learning and a desire to grow"
Data Scientist / Analyst,"Mumbai, Maharashtra",Adoro,None,Organic,"Data Scientist / Analyst
If you are someone who always argues that data tells you everything and can speak numbers in your sleep, then you are it.
Requirements
Bachelor of Engineering in Computer Science, Math, Physics, Engineering, Statistics from Tier-1 college.
Development experience in SQL and any scripting language (Shell, Python, etc.)
Basic understanding of statistic and Experience manipulating large data sets through statistical software(ex R, Matlab etc)."
Associate Partner - Data Science Consulting LT00,"New Delhi, Delhi",IBM,None,Organic,"Introduction
As a Strategy Consultant at IBM, you will help reinvent businesses and industries by developing and utilizing specialized knowledge of industry-specific and cross-industry competitive strategies. You'll manage complex components of an engagement, working closely with clients and their customers to understand their pain points. Your strategic recommendations will drive change in a digitally-enabled era and give you the opportunity to collaborate with highly talented IBMers. Are you ready?

Your Role and Responsibilities
Deep data science skills, including the knowledge of statistical and machine learning based predictive model development.
Prior experience of framing and running a comprehensive data science program for a large enterprise.
Driving last mile consumption of models and insights with a variety of stakeholders, including the program sponsor, various Lines of Businesses. Branches/Channels, Field Staff,
Should have led feedback loop from the field back to into program to improve the accuracy, relevance, effectiveness and adoption of models and insights based decision making.
Developing C-Suite relationship and consistently winning client confidence on a range of program objectives.
Ability to collaborate with disparate partes and be able to drive alignment on business objectives, deliverables and has a closure mindset.

kwd1xyabc



Required Technical and Professional Expertise
15+ Years of relevant experience.
Post Graduate in one of the the following quantitative and/or business degrees, mathematics, statistics, computer science, engineering, economics/econometrics, business management with under graduate in quant.



Preferred Technical and Professional Expertise
Should have led a large and diverse skill set team consisting of data scientists, data engineers, business insight generator, AI geeks.
Ability to travel extensively
Extensive experience in third party services and consulting

About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Python Developer,"Kochi, Kerala",Calpine Group,None,Organic,"Experience : 4 - 7 year(s)
Skills required : Python,Java,C++,Bioinformatics,Sql,Linux,Aws
No. of Positions: 1-2
Responsibilities:
Experience with Python to implement data analysis workflows in a Linux environment.
Experience evaluating and improving the efficiency of programs in a Linux environment.
Experience with command line compilation and debugging.
Experience with makefiles, coverage analysis and other forms of runtime profiling.
Experience with all phases of the Software Development Life Cycle.
Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
Working knowledge of MS Office suite of applications.
Working knowledge of Bioinformatics, Genomics, or Life Sciences
Good verbal and written communication skills.
Ability / willingness to learn bioinformatics / genomics
BE/BTech/MCA/MSc graduates only"
Sr Analyst - Global Data Management,"Mumbai, Maharashtra",Colgate-Palmolive,None,Organic,"No Relocation Assistance Offered
# 84623 - Mumbai, Maharashtra, India

The Global Data Management (GDM) Analyst position supports business functions by providing master data expertise and managing the master data governance and maintenance processes. Providing support and liaise with the business and the Global GDM Team with related projects and issue resolution of queries. Identify and implement improvements resulting in increased operational and business efficiency.

Key Responsibilities:
Provides input to Global Data Management in defining strategy for process development and delivery, including operational KPIs
Resolves data integration issues within the process or domain and works with IT organization on having them solved
Ensures the alignment of the business data requirements with the IT systems & solutions
Provides input in development of Corporate Data Policies and supporting guidelines, standards and procedures and ensures they are implemented globally or in the region within responsibility,
Serves as the facilitator of data quality and data management issues that span multiple regions or business units within the process and data domain responsibility,
Implements Data Management strategy globally or in the region within responsibility of the functional area and operated processes,
Collects, evaluates and incorporates, if applicable, global and/or divisional requirements to Data Management processes within area of responsibility,
Ensures operational and project work continuity avoiding negative impact on business
Represents Data Management function in workshops and/or meetings with business functions representatives,
Cooperates with business functions to optimize data collection and maintenance processes, resulting in increased business processes efficiency,
Monitors data management processes to ensure compliance with process cycle times and related performance measures and KPIs,
Investigates and recommends appropriate corrective action when data quality deteriorates,
Identifies root causes of the issues and implements fixes to the processes, procedures and systems,
Recommends adjustments to data policies and procedures as necessary to improve key performance indicators,
Leads Data Management related projects, initiatives or roll-outs to new divisions, business units or sourcing locations,
Plans and executes data cleansing and data quality initiatives,
Supports subsidiaries on internal and external data alignment initiatives,
Uses Change Management Methodology when implementing new or changing existing Data Management process, policy or procedure,
Ensures that SOX compliance requirements are met,
Monitors accesses to the systems to ensure that they are in accordance to the data governance policies and procedures,
Optimizes utilization of resources by implementing changes to existing processes, tools and systems,
Works with direct manager to establish resource plan for the team, monitor workload of subordinates, manage priorities to minimize resources requirements and report in advance potential capacity limits or risks of impacting operational or project work continuity,
Monitors and manages performance and work objectives for subordinates,

Minimum Required Education
Bachelor degree

Required Experience and Qualification
8+ years of Experience in Master Data Management
Experience in Business Function (Procurement and/or Finance for Vendor/Finance Lead, Supply Chain for Product Lead)
Experience implementing new systems/applications, desirable
People Management experience desirable

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation."
"Data Engineer, Bangalore","Bengaluru, Karnataka",Assa Abloy,None,Organic,"Job Title

Staff Data Engineer

Experience & Skills

8+ years of experience in IT industry.
Must have current and deep experience in programming with relational database, preferably SQL Server or Oracle.
Must have experience in working with large relational database using SQL queries to extract, transform and other pre-processing activities on large dataset.
Strong analytic skills related to working with unstructured and structured datasets.
Exposure to cloud technologies using AWS /Azure/ Google Cloud with special emphasis on Database and/or data science related products.
Experience in coding using python or java or C#.
Having a good knowledge or experience in .Net Core/Windows platform is helpful.
Having some experience in UI development (either using javascript or angular) is helpful but not mandatory.
Experience in building data pipeline that feed into analytical / ML jobs is desirable.
Experience in constructing reports and dashboards.
Experience in leading a small team of data engineers and collaborating with other teams within the company as well as with customers.
Demonstrated ability to effectively communicate complex concepts to project teams including business representatives.
Experience working with RESTful Web Services is desirable
A Can-do attitude and mindset to work within a Fast-paced environment


Responsibilities

Position is for a seasoned software engineer responsible for designing & developing HID SAFE - an industry leading, enterprise Physical Identity and Access Management product.

Coding, testing and debugging software according to specifications.
Write code with an eye towards maintainability and performance.
Documenting the key aspects of the software being developed.
Planning and Estimation of assigned work under Agile process
Building prototypes and ""proof of concept"" solutions.
Maintaining code in version control repository
Working with customer teams and other engineering teams to develop long term data platform.


Education

An Advanced Engineering / Computer Science Degree."
Director of Data Science,"Noida, Uttar Pradesh",Deal4loans,None,Organic,"Location:Noida, Uttar Pradesh, India
As a Director of Data Science you will develop problem statements and high quality quantitative models for business insight in the space of Banking, Capital Markets and Insurance.
Strong knowledge and skills in statistics, mathematics and computer science. Design and delivery of leading analytics solutions by applying your deep skills in above mentioned disciplines to solve priority issues and help improve performance using Advanced Analytics. Deep skills in R, SAS or Python, along with strong understanding of all key market leading Analytics techniques, frameworks, methodologies and tools.
Defines analytic strategies to meet the demands of business requirements
Defines the technical requirements of the analytic solutions
Defines the data requirements of the analytic solution
Refine our credit scoring model across various credit products
Integrates advanced analytics into end-to-end business intelligence solutions and operational business processes
Engages in technical problem solving across multiple technologies; often needs to develop new
What kind of person are we looking for:
PHD or M.S. in statistics, economics, mathematics, or related field is required
Should be an expert in Credit scoring models
Looking for someone with atleast 5 years of experience (always happy to relax for exceptional candidate)
Extensive experience solving analytical problems using quantitative approaches using machine learning methods
Competent in R. Bonus points for knowing Matlab, SQL, SAS and Python
High-energy, company first, team first, positive attitude
Problem solver: it a cliche, but this cliche is important for us! You should be able independently research and resolving partner questions or concerns in a timely manner... yes there will be fire, but fighting fire should be fun for you
Team team team: We are very collegial, we collaborate, we help each other, we teach each other, we grow with each other
Develop frameworks to analyze information, situations and data. Separate critical from mundane, using 80/20 principles
Good with numbers: digest numbers/data, analyze it, use this data to make. Share your insights in a crisp and simple-digestable form to your team, colleagues and management
You should be able to develop high-level relationships with partners - you will develop partnerships and work on developing new business as well
Compensation
Compensation will be competitive, in line with best in the industry
ESOPS of one of the most successful fintech companies in India
Opportunity to impact people's lives and be a change agent in the banking services"
ML Engineer,"Chennai, Tamil Nadu",Positivenaick,None,Organic,"As an ML engineer, you need to be strong in Statistical Knowledge, with hands-on experience in Machine Learning Algorithms. You need to be good with Deep learning, Neural models. Coding capabilities in Python is mandatory. You’ll need to be proficient in handling Big Data and have experience in streaming analytics capabilities of Storm and Spark.
Responsibilities
Develop new machine learning, deep learning (RNN or LSTM based) &
ontology-based modeling algorithms to take up unsolved industry challenges
Develop algorithms for multi-lingual support.
Cross-functional collaboration between data science and engineering teams to
support integration of finished algorithms and prototypes into products.
Create an intellectual property for our organization and write patent disclosures.
Support sales and business development teams to fine-tune client requirements, and
perform feasibility testing.
Demonstrate thought leadership by participating in national & international
conferences, represent our organization, publish blogs, white papers, etc.
Skills
High coding capabilities in Python with efficiency in handling Big Data.
Strong statistical knowledge with hands-on in Machine Learning Algorithms
(supervised and unsupervised).
Good experience and understanding with all kinds of Neural models.
Hands-on experience deploying Machine Learning or Deep Learning based
solutions in production with large datasets.
Strong understanding of Python and Machine Learning libraries (NumPy, SciPy,
Scikitlearn, TensorFlow, PyTorch, Keras).
Good writing skills, demonstrated by patents, publications, blogs or personal pages.
Experience
Should have 4 to 6 years of experience."
PYTHON/DATA ANALYSIS,"Kochi, Kerala",UVJ Technologies,None,Organic,"PYTHON/DATA ANALYSIS – Job Code(PYD – 04)
Experience with Python to implement data analysis workflows in a Linux environment.
Experience evaluating and improving the efficiency of programs in a Linux environment.
Experience with command line compilation and debugging.
Experience with makefiles, coverage analysis and other forms of runtime profiling.
Experience with all phases of the Software Development Life Cycle.
Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
Working knowledge of MS Office suite of applications.
Working knowledge of Bioinformatics, Genomics, or Life Sciences
Good verbal and written communication skills.
Ability / willingness to learn bioinformatics / genomics

If you are interested in any of the positions mentioned above, Please attach your updated resume to resume@calpinetech.com with an email explaining the position you are looking for, your career goals and your expected salary. Please indicate the job code in the subject line of your email."
Lead Data Analytics & Reporting,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Business Support and Management
Primary Location: ASEAN & South Asia-India-Bengaluru
Schedule: Full-time
Employee Status: Permanent
Posting Date: 10/Aug/2020
Unposting Date: 10/Sep/2020
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.



Purpose:
The role is at a senior level in the Digital Channels & Data Analytics team of CCIB based in Bangalore. Innovative big data and machine learning solutions are a key priority for the Bank as part of investments in creating value-add services for clients, creating or joining new consortiums and enabling new business models. This role is to contribute to the development of data projects.
Strategic data initiatives in CCIB creates differentiated digital capabilities for clients to access the Bank's transactional services in over 50 markets efficiently and securely. This includes internet and mobile banking for global business clients, direct integration options, as well as services through third parties.
The role would be suited to a candidate having experiences in data science and analytics field – developing models, rules and algorithms from structured and unstructured sources and performing deep-dive analysis to derive data-driven decisions
Proven track records in building and deploying (financial services) analytic solutions that have created significant value for customers and additional revenue based on new business models.
Experience in building dynamic dashboard (eg Tableau, Power BI) for business stakeholders will be an absolute must
Experienced working in an offshore model is required since role will be based in Bangalore with business stakeholders in Singapore and other overseas locations
Strong data defining, structuring, labelling and developing data models to capture, store, process and use this data to generate intelligent outcomes through Data Analytics
The candidate will have a profound knowledge of large data sets, data management, data governance, data science and metadata.
The role requires close partnership with Cash, Trade, and Security Services Product organisation. Other key stakeholders include global Sales and Implementation teams, Technology, and risk owners such as legal and compliance.
This role reports to the Data Analytics lead for Transaction Banking.

Key Accountabilities:
Help built a strategy & roadmap of analytics solutions that will position Standard Chartered as leading in this field
Creating effective dashboards for business stakeholders
Apply and ensure data governance framework.
Develop and implement artificial intelligence algorithms, rules and rapid prototypes from big data sets that will be fed into various business programs.
Behavioural segmentation based on client journey, profiles, transaction patterns, and app activities that will lead to highly personalized client insights.
Design and monitor A/B testing and various engagement activities.
Perform deep-dive analysis to solve various business problems arising from marketing, dynamic incentive programs, and campaign management.
Build and automate intuitive dashboards that help visualize and answer complex business problems.
Managing risks and regulatory issues associated in data analytics solutions.

Qualifications and Skills:
University Degree or equivalent, preferably in computer science, engineering or analytical discipline, e.g. mathematics, statistics, IT, economics, finance, accounting.
Minimum 8 years working experience in data analytics or business intelligence units, preferably in consultancy (eg Mu Sigma, IBM, Accenture) or financial industry.
Relevant experience in using data is a pre-requisite.
Analytical mind with sound business insights. Ability to translate the business problems and requirements into analytics solutions.
Knowledge of a variety of predictive models, machine learning algorithms and statistical techniques, e.g. logistic regression, decision tree, clustering, neural networks, support vector machines, principal component analytics, natural language processing.
Proficiency across the core statistical toolsets (SQL, SAS, R, Python), data visualization tools (Tableau, Qlik, Power BI) and Hadoop ecosystem.
In-depth knowledge of digital banking, banking products and the overall industry a strong plus
Good verbal and written communication skills.
Excellent stakeholder management skills
Self-motivated. Can-do spirit


Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
Analyst-Statistics and Predictive Modelling,"Mumbai, Maharashtra",PMaps,None,Organic,"Job Category : Research
Department/Group : Product Development and Research
ROLE AND RESPONSIBILITIES
You should know the best ways to collect and cleanse the data used in the modeling analysis. You will be required to coordinate with other departments in order to improvise the existing data capture techniques and suggest the new data elements required for modeling.
You should be able to use advanced statistical techniques to identify and interpret correlations using univariate and multivariate analysis to develop new approaches to the existing problems.
You should be able to create valuable analytics using data mining technology, multivariate analysis, regression analysis, and statistical sampling.
You should be able to support the research team to construct or maintain the built models, including data mining/extracting or combining data from multiple sources using languages such as SQL and SAS.
You are required to assist other team members complex work related problems.
QUALIFICATIONS AND EDUCATIONAL REQUIREMENTS
Bachelor’s/Master’s degree in Statistics, Mathematics, Econometrics, Computer Science, or related field required
**Relevant Certification in Data Science, Data Analytics, Data Mining, Artificial Intelligence, Machine Learning preferred
**Equivalent work experience in a similar position may be substituted for educational requirements.
PREFERRED SKILLS
Willing to take challenges associated with the start-up environment
Experience working with large datasets in SAS or similar statistical software
Strong skills in statistical and data mining tools such as R, SPSS or SAS
Excellent oral and written communication and presentation skills
Advanced knowledge of MS Word, Excel, Access, and PowerPoint
Ability to quickly adopt and learn new software and technologies
Ability to effectively handle multiple situations simultaneously"
Python Developer,"Pune, Maharashtra",Merkle Sokrati,None,Organic,"Company Description
About Merkle
Merkle is a global data-driven, technology-enabled performance marketing agency. For over 30 years, Fortune 1,000 companies and leading nonprofit organizations have partnered with us to build and maximize the value of their customer portfolios. We work with world-class brands like Dell, T-Mobile, Samsung, GEICO, Regions, Kimberly-Clark, AARP, Lilly, Sanofi, NBC Universal, DIRECTV, American Cancer Society, Habitat for Humanity, and many others to build and execute customer-centric business strategies. With more than 9,000 smart, dedicated people in more than 50 offices around the world, we are still growing at a rate that outpaces the market, with 2018 net revenue of $846million.
About Dentsu
Dentsu is the world’s largest advertising agency brand, a company with a history of 118 years of innovation, the Dentsu Group provides a comprehensive range of client centric brand, integrated communications, media and digital services through its ten global network brands—Carat, Dentsu, dentsu X, iProspect, Isobar, McGarry Bowen, Merkle, MKTG, Posterscope and Vizeum—as well as through its specialist/multi-market brands. The Dentsu Group has a strong presence in over 145 countries and regions across five continents and employs more than 62,000 dedicated professionals. Dentsu Aegis Network Ltd., its international business headquarters in London, oversees Dentsu’s agency operations outside of Japan. The Group is also active in the production and marketing of sports and entertainment content on a global scale.

Job Description
2-4 years of experience in building successful production software systems
A solid grounding in Computer Science fundamentals (based on a BE/BTech or MS in Computer Science)
Experience developing software services and an understanding of design for scalability, performance and reliability.
Mastery of the tools of the trade, including a variety of modern programming languages (Python ) and open-source technologies (Linux, Spring)
Proven ability to work in a fast-paced, agile and in an ownership and results-oriented culture
If you are excited about:
Having an unmatched startup experience that allows you to work on bleeding-edge technologies.
Making a splash in a multi-billion dollar Digital Advertising industry
Learning & Growing far beyond your current horizon
A place full of like-minded & ridiculously smart folks
A start-up culture that you'd cherish forever in your work life

Qualifications

null

Additional Information
All your information will be kept confidential according to EEO guidelines."
Data Analytics Specialist - Microsoft Azure,"Mumbai, Maharashtra",Lloyds Register,None,Organic,"Date: 20-Jul-2020
Location: Mumbai, IN
Company: Lloyds Register
Job ID:31135
Location:Mumbai : India Management Office (LR_L000156)
Position Category:Information Technology
Department:IN710032 : Group IS Mumbai (IN710032)
Position Type:Employee Regular
Role Purpose:

We are seeking an experienced Microsoft Azure Analytics Developer to work with key business stakeholders to identify and deliver BI reports. We are building a Data Analytics Platform using Azure technologies – Azure Data Lake, Azure Data Warehouse / Synapse, Power BI etc. This platform will ingest, transform, prepare and train data from disparate source systems including SAP, Oracle, Salesforce.com etc.
We are looking for an individual with strong skills in Power BI, Azure Analysis Services and Azure Data Warehouse / Synapse. The Azure Analytics Specialist will be responsible for role-based and data-level security of reports including managing platform access for external data exchange with customers and regulatory bodies.
The Azure Analytics Specialist will develop reports for users, during which time he / she will gain understanding of the business and existing data structures and processes, expanding their skills as required with the platforms used by the company. The individual will work collaboratively with business stakeholders in developing new and refining existing data models / reports / processes.

Key Responsibilities:

Build and enhance existing data models in Analysis Services, Azure Datawarehouse / Synapse to meet reporting requirements
Design and build reports and dashboards and assist in development of complex ad hoc queries and analyses in Power BI
Design and build reports role-based and data-level security models for both internal and external clients
Manage security-based data exchanges with external clients and regulatory bodies
Own the release management process and deployments to all environments
Support user community on Power BI technology and functionality
Work with infrastructure team and Microsoft to ensure system reliability
Conduct activities in line with internal procedures, legislation and industry standards.
To pursue Continuous Professional Development and maintain a high degree of discipline knowledge and awareness.
To mentor/coach other specialist employees to achieve effective specialist knowledge transfer and application.
Ensures documentation/data/information and tasks relevant to the section are planned, evaluated and processed in accordance with local business requirements and agreed deadlines.
Review & analyse data to provide management information/statistics, including the identification and reporting of process failures, to support the overall delivery of processes.

Technical / Professional Qualifications / Requirements:

Sound knowledge and experience of building Power BI based reports and dashboards
Good understanding of data warehouse principles and data modelling for reporting
Strong experience of SQL, Power Query, DAX, MDX and other query processing languages
Data Science experience using Python, Scala, R would be desirable
Experience in Machine Learning and Artificial Intelligence for Predictive Analytics would be an advantage

The Lloyd's Register Group comprises charities and non-charitable companies, with the latter supporting the charities in their main goal of enhancing the safety of life and property, at sea, on land and in the air - for the benefit of the public and the environment. (Group entities)


Job Segment: Database, ERP, Oracle, SAP, SQL, Technology"
Computer Scientist - (C++),"Noida, Uttar Pradesh",Adobe,None,Organic,"Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver outstanding digital experiences. We’re passionate about empowering people to craft alluring and powerful images, videos, and apps, and transform how companies interact with customers across every screen.
We’re on a mission to hire the very best and are committed to building outstanding employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
The Challenge
As an Engineer, you will be responsible for owning the technical vision for PDF workflows. You will have significant influence on our overall strategy by helping define these product features, drive the system architecture, and spearhead the best practices that enable a quality product.
The ideal candidate is clearly who is adaptable to an agile environment, passionate about new opportunities in desktop application and has a proven track record of success in delivering new features and products. Creating such reliable, scalable, and high performance products requires exceptional technical expertise, a sound understanding of the fundamentals of Computer Science, desktop technologies and practical experience building customer facing products.
Evolve Acrobat for modern user experience with the objective of delighting the customer
Build the next generation document management based solutions by integrating cloud based services and frameworks in Acrobat/Reader.
Build the best in class document creation tools.
Design and build document processing tools to extract, index and search document content.
Develop advanced document reconstruction algorithms for document editing, PDF Export.
Develop document and image processing algorithms for crafting document scanning and OCR tools.
Develop most intuitive and powerful document reviews, commenting and approval solutions.
Develop security solutions for close to a billion Acrobat free users
What you need to succeed
5-9 years of hands on development experience
Bachelors/master’s in computer science or a related field.
Proficient in C++, HTML, CSS, JS, data structures and algorithms
Experience in Databases like MySQL, Postgres will be added advantage
Excellent software design skills
Strong problem-solving skills.
Able to communicate technical details clearly
Motivated self-starter with the ability to learn and adapt to new technologies
Work closely and seamlessly with various engineering teams, product management, experience design and quality engineering to ensure we deliver great compelling solutions.
At ease with ambiguity and able to adapt and change direction/technologies to leverage new learnings.
Be a mentor and role model for junior engineers.
At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists . You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.
If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, or veteran status."
Python Developer/Selenium Testing,"Chennai, Tamil Nadu",Yours Efficiently,"₹96,000 - ₹1,56,000 a year",Organic,"Job Description:
1. Hands-on coding experience in Selenium with Python
2. Design, implement and maintain test scripts with good quality in a python based automated test framework (Atom IDE) for testing web based user interface
3. Able to work independently and with the team to deliver test plans and test cases successfully with best practices
4. Experience in building test scripts for test automation framework using Page Object Model
5. Good to have hands-on experience in PyTest, Unittest automation with Python
6. Proficient in Python as an Object Oriented programming language and community standards for Python programming and related concept
7. Execute and report on planned tests, report and manage defects, regress software fixes for new and existing products, assist development with replicating and debugging problems and develop new test automation solutions as needed
8. Develop test reports and metrics
9. Experience in Test Automation Frameworks like Data Driven, Keyword Driven and Hybrid
10. Deep understanding of Test Case Development with prior experience in Test Case Automation
Educational Qualification:
Graduate or Post Graduate in Engineering, Science, Technology, (Preferably BE or MCA graduate) with Related Experience.
Experience Required:
0-3 Years Experience in Python Development & Selenium Testing.
Job Type: Full-time
Pay: ₹96,000.00 - ₹156,000.00 per year
Work Remotely:
Temporarily due to COVID-19"
Consultant - Data Engineer,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Consultant - Data Engineer
Location:TRIL GTC Chennai
GCL: C3
Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.
Department – Data & Analytics, R&D IT
R&D IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.
The Data & Analytics team provides technical support to analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of R&D Science IT and AZ. Data & Analytics is organized into teams specializing in Information Architecture, Data Engineering, Visual Engineering, Knowledge Management, Data Science, Data Analysis and Information Governance.
Role
We are looking for a Data Engineer to help us build intelligent applications that make use of our structured and unstructured data to derive key insights. As part of the R&D Data Foundation engineering group, you will work together with ML engineers and data scientists to build the data foundations supporting R&D.
We are building a global Competitive Intelligence platform that will provide industry-leading competitive intelligence across our R&D and Commercial organizations. As a member of our team, you will be primarily responsible for implementing ETL processes.
You should be well-versed in the design and development of ETL and database developments for large data products, as well as maintaining and supporting production environments.
Key Accountabilities
Part of a DevOps team implementing and supporting ETL workflows. Data sources will be: structured, semi-structured and unstructured.
working with suppliers, data scientists, machine learning engineers, and platform teams to acquire and process data.
analysing data requirements, source data, model the source, and determine the best methods in extracting, transforming and loading the data into the data lake and processing the data through the layers of the lake.
providing technical input around design, architecture, integration and support of the entire data sourcing platform with a focus on high availability, performance, scalability and maintainability.
act as the ETL technical liaison working with technical infrastructure teams to resolve problems and implement solutions to technical issues impacting application performance
managing data administration tasks such as scheduling jobs, troubleshooting job errors, identifying issues with job windows, assisting with backups, rollback and performance tuning.
test, document and quality assess new data solutions, to ensure they are fit for release.
communicate and coordinate with members of the development team to work across multiple projects. Explore, actively support and work on new technology initiatives that may be of interest to the organization.
manage automation of all ETL processes within a job workflow
documentation of data engineering workflows to support downstream use
Testing of data in analytics applications, to ensure data validity and reconciliation to source systems
Development of subject matter expertise in sub-domains of the Science & Enabling Unit portfolio – understanding of the business process, data flows, data provenance, data restrictions and data use.
Highly Desirable Knowledge, Skills and Experience
6 years+ experience on data engineering– ETL workflows
B.Tech/ M.Tech/MSc in Computer Science.
A strong understanding of databases and source systems, including experience with, RDBMS, NoSQL and Graph technologies.
Experience writing ETL pipelines/orchestrations including code (Java, Python, C#).
Good software development skills with demonstrable knowledge of Python and Java, and source control (GIT)
Working knowledge of cloud environments (AWS preferred)
Experience of semi-structured (XML, JSON) and unstructured data handling including extraction and ingestion via web-scraping and FTP/SFTP.
Additional skills and experience sought
In addition, these are the bonus skills (not mandatory) for this position:
Excellent communication and facilitation skills.
Good written and verbal skills, fluent English.
Experience of working with data scientists and their methods: understanding of how data needs to be prepared for use by data scientists.
Experience of delivering solutions within IT projects delivered through Agile and Waterfall methodologies.
Experience of working within a range of data architectures.
Supporting a data-centric application.
Working with APIs (support or development).
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Big Data Engineer,India,CereSight,None,Organic,"Location:: Anywhere in India (remote)
Key skills:: Hadoop technologies, ANSI SQL, Python/R/Scala
Desired Candidate Profile::
We are looking for a Big Data Engineer who will work on the collecting, storing, processing, and analysis of huge datasets from multiple data sources. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.
You must have::
A good understanding of distributed computing principles, management of Hadoop cluster, with all included services;
Proficiency with Hadoop v2.x:: MapReduce, HDFS, Ambari, Zookeeper;
Good knowledge of Big Data querying tools, such as, Hive, Impala, or Big SQL
Experience with Python, R, or Scala;
Experience with integration of data from multiple data sources;
Deep Knowledge of various ETL techniques and frameworks, such as Datastage;
Experience with various messaging systems, such as Kafka; Experience with Cloudera/MapR or Hortonworks
Good understanding of AWS/GCP/Azure
Familiarity with Big Data ML toolkits, such as Tensorflow, SparkML, or H2O
Reach out to us if you have 3+ years experience in selecting and integrating any Big Data tools and frameworks and implementing solid ETL process, monitoring performance, recommending appropriate infrastructure and making required changes, defining data collection, retention and archiving policies, and interested in training and building a team of data engineers
Education:: - Bachelors/ Masters / Phd
We think the knowledge acquired by earning a doctorate or master’s degree in Computer Science with AI as a specialization would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time
Company Profile: This is the right place for you, if want to work in
A Data Science and Big Data technology start-up.
A place where you would want to create value for yourself, and our customers
An environment that supports your personal growth
Group of the best in class professionals who are excited about the work they do
Contact::
Sangeetha: sangpraman@gmail.com, +919655998843"
Data and Geospatial Analyst II,India,Catholic Relief Services,None,Organic,"Data and Geospatial Analyst II - (200000EO)
Description

Job Title: Data and Geospatial Analyst II
Department: Global Knowledge and Information Management (GKIM)
Work Location: Remote
Reports To: Data, Knowledge Management and Communications Manager

Job Summary:
*Remote from India or remote internal staff*

Job Summary:

CRS has prioritized Information and Communications Technology for Development (ICT4D) as a core competency. As part of this core competency, CRS is developing ICT tools and associated skills to support activities across program areas, such as digital monitoring and evaluation and analysis of resulting data.

As a key driver of this core competency, the analyst provides internal data and geospatial analysis consultancy services dedicated to building capacity and supporting the successful and appropriate implementation of data and geospatial solutions. The analyst II will take on the most challenging assignments and create new advanced analytics processes that can be scaled. Additionally, the analyst is a key member of the ICT4D community within CRS and is active in promoting the smart and effective use of data and geospatial analysis to support CRS programming.

The data and geospatial analyst will develop map products, reports and/or dashboard applying data and spatial analysis techniques to multiple humanitarian aid, international development and other projects underway at Catholic Relief Services (CRS). These products serve as valuable communication tools to improve the efficacy of programs. Examples of similar work at CRS include: analysis of malaria knowledge, attitudes and practices to answer questions about where malaria education campaigns would have the greatest impact; and predictive analysis of walking paths to optimize placement of food distribution sites.
Responsibilities:

Build capacity in our team to: run advanced analytics processes including machine learning. automating analytics processes, database architecture, and simplifying processes.
Review, test and implement system changes to formulas and sheets.
Customer service: identify ways we can build efficiencies and automate or offload processes in data or system issues.
Work autonomously and identify needs as they arise, be able to prioritize workflow and identify ways to automate or delegate repetitive tasks
Visualization
Evaluate publicly available data sources and their fitness for use.
Evaluate data that will be collected via mobile devices and identify the best approach to visualize it using ArcGIS suite of tools and/or PowerBI.
Improve the visualization of advanced analytics so that data visuals are easy to interpret and are in line with CRS data visual branding standards.
Spatial Analysis
Utilize machine learning in spatial analysis workflows and satellite imagery analysis.
Build the teams capacity on spatial analysis, including; object-oriented classification, remote sensing, interpolation, and prediction, with the possibility of 3D modeling.
Create automatic workflows to replicate spatial analysis.
Promote the workflows in easily accessible language in webinars, newsletters, and one pagers.


Enterprise GIS
Champion the opportunities that GIS offers to CRS and contribute to the evolution and implementation of the agency’s GIS roadmap.
Incorporate geospatial technology into enterprise systems (examples include SalesForce and ERP) and define common processes for GIS implementation efforts.
Lead GIS system definition efforts including elicitation of business needs, definition of potential solutions to meeting those needs and incorporation of GIS into proposals.
Proactively identify areas for capacity development, develop and curate advanced GIS training curricula/content and deliver trainings both onsite and remotely.
Assess and remain current about emerging trends in the use of spatial data in the relief and development sector.
Data Analytics
Coordinate/lead research engagements with external organizations to create new analytics processes that can be scaled to new country programs.
Coordinate an external analytics support group to bolster CRS analytics ability
Attend meetings with external advisors in data analytics
Coach team members in their external research engagements, assuring clarified expectations and a positive experience for both parties.
Provide consultancy to field projects on best use of data analytics and visualization.
Ensure deployment of
o Integration interface between standard forms and legacy data
o Data Warehouse (wherever applicable)
o Reports and Dashboards
Enable smarter business processes—and implement analytics for meaningful insights.
Work with stakeholders throughout the organization to identify opportunities for leveraging data to drive projects.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Promote and contribute to the data security approach throughout the support process.
Help build a culture of data use and decision making
Key Working Relationships:
CRS’ ICT staff; technical experts across sectors; monitoring & evaluation staff; field project staff; various HQ staff; owners of CRS business systems; and technology vendors.
Qualifications:
Education / Certifications
Master’s degree in data science, Geographic Information Systems related field or equivalent experience.
Certified Analytics Professional (CAP), or Data Science Council of America (DASCA) Principle Data Scientist (PDS) or higher, or Open Certified Data Scientist (Open CDS) preferred.
Esri ArcGIS Desktop Certification (10.1 or higher; Associate or Professional level)
Experience with UML 2.0 highly preferred.
ITIL Foundation Certification desired.
Ability to code in R and Python preferred.
General Experience
Experience delivering training on data analysis to both technical and non-technical audiences; both in person and remotely.
Experience developing work plans (project plans) that address all phases of solution delivery and managing project risk and dependencies.
Good understanding of business analysis and business process mapping (using industry standards); ability to capture as-is and to-be business models.
Experience with vendor selection and management including developing RFPs, SOWs and managing/monitoring vendor work activities
Technologies
Data analysis software
Experience using ArcGIS Online strongly preferred; experience using ArcGIS Pro and Collector for ArcGIS desired
Demonstrable experience applying core concepts of cartography to quality map production
Demonstrable experience applying spatial analysis to solve real-world problems
Strong understanding of relational databases (SQL Server strongly preferred), data modeling and general geodata management technologies.
Ability to code in python, and R preferred
Personal/Professional Qualities:
Ability to communicate technical concepts to non-technical audiences, including briefings with agency leadership.
Ability to represent the agency in external forums.
Excellent interpersonal, presentation and oral and written communication skills.
Ability to thrive as part of a geographically distributed team.
Ability to work independently and be self-driven.
Highly responsive with an attitude of service.
Attention to detail and organized.
Travel:
This position will require 10-20% international travel, including to resource poor locations.
Supervisory Responsibilities:
Supervise TDY and intern staff as needed.
Language Required:
Must be fluent in written and spoken English; French or Spanish fluency desirable.

Qualifications

Basic Qualifications
Bachelor's degree in Cyber or IT related field or equivalent experience
Minimum of 5 years' experience in Information Security administration
Experience with Microsoft Windows operating systems, Office 365, Enterprise Mobility and Security (EMS) and Enterprise Mobility Management (EMM)
Experience with Privilege Access Management solutions, Least privilege Access Management platforms and multi-factor authentication solutions among other technologies
Experience in managing Information Security compliance
In depth knowledge of Information risk concepts / relating business needs to security controls

Agency-wide Competencies (for all CRS Staff)
These are rooted in the mission, values, and guiding principles of CRS and used by each staff member to fulfill his or her responsibilities and achieve the desired results.
Integrity
Continuous Improvement & Innovation
Builds Relationships
Develops Talent
Strategic Mindset
Accountability & Stewardship

***Our Catholic identity is at the heart of our mission and operations. Catholic Relief Services carries out the commitment of the Bishops of the United States to assist the poor and vulnerable overseas. We welcome as a part of our staff people of all faiths and secular traditions who share our values and our commitment to serving those in need. CRS’ processes and policies reflect our commitment to protecting children and vulnerable adults from abuse and exploitation.
Disclaimer: This job description is not an exhaustive list of the skill, effort, duties, and responsibilities associated with the position.

CRS' talent acquisition procedures reflect our commitment to protecting children and vulnerable adults from abuse and exploitation.

EOE/M/F/D/V - CRS is an Equal Opportunity Employer. (For all US and International positions)

Primary Location: ASIA-IN-Uttar Pradesh
Job: ICT
Organization: Catholic Relief Services
Schedule: Regular
Shift: Standard
Employee Status: Individual Contributor
Job Type: Full-time
Job Level: Day Job
Travel: Yes, 20 % of the Time
Job Posting: Jul 6, 2020, 12:40:17 PM"
"Software Engineer, Engineering Productivity","Bengaluru, Karnataka",Google,None,Organic,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.
Minimum qualifications:
Bachelor's Degree in Computer Science, related technical field, or equivalent practical experience.
5 years of coding experience in one or more of the following languages: C, C++, Java, or Python.
Experience in computer science, data structures, algorithms and software design.

Preferred qualifications:
Passion for automation and optimization, as well as to develop tools to help other Engineers.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

As a Software Engineer focusing on Engineering Productivity, you will be at the heart of Google’s engineering process building software that empowers engineering teams to develop and deliver high quality products quickly. We are focused on solving the hardest, most interesting challenges of developing software at scale without sacrificing stability, quality, velocity or code health.


We ensure Google's success by partnering with engineering teams and developing scalable tools and infrastructure that help engineers develop, test, debug and release software quickly. We impact Googlers and users by increasing the pace of product development and ensuring our products are thoroughly tested. We are advocates for code health, testability, performance, maintainability and best practices for development and testing.
Google is and always will be an engineering company. We hire people with a broad set of technical skills who are ready to take on some of technology's greatest challenges and make an impact on millions, if not billions, of users. At Google, engineers not only revolutionize search, they routinely work on massive scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world. From Google Ads to Chrome, Android to YouTube, Social to Local, Google engineers are changing the world one technological achievement after another.
Responsibilities
Lead and contribute to engineering efforts from planning and organization to execution and delivery to solve complex engineering problems in tools and infrastructure.
Design and build tooling and infrastructure to help engineering teams measure and increase their velocity. Develop tools to understand, model, and replicate production traffic patterns in pre-production environments, including some cases in statistical modeling and machine learning techniques.
Analyze and decompose complex software systems and collaborate with and influence others to improve the overall design.
Design and develop mobile tools and infrastructure that help us provide quality apps.
Design and build advanced automated testing frameworks.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
"Technology head Data science, data analytics background","Hyderabad, Telangana",Truedge Software Solutions,None,Organic,"Technology head Data science, data analytics background – Hyderabad
Job Title: Python, Machine Learning/AI – Software Engineer
Location: Hyderabad.
Job Description:
Must have product development experience using full stack
Must have ML hands on expertise using python
Data science, data analytics background preferred
Should be able to lead a strong team of Technologists in the above mentioned tech skills from top engineering schools
Education background from IIT preferred
Salary: Commensurate to experience.
Other details: Start date: ASAP"
Java Application Developer - Product Organization,"Pune, Maharashtra","Avocado Systems, LLP",None,Organic,"Job Summary
As a Senior Backend Developer at Avocado Systems, you will be responsible for architecting and building backend Java applications to support our groundbreaking cyber security platform.
Responsibilities and Duties
Design, architect, and build complex Java applications to digest information from large datasets
Lead engineering discussions, technical evaluations, design reviews, and other project discussions
Work with other engineers, Architecture, Product Management, and QA teams to develop innovative solutions that meet business needs with respect to functionality, performance, scalability, reliability, realistic implementation schedules and alignment to development principles and product goals
Qualifications and Skills
5+ years of experience in software design and development, solid foundation in computer science with strong competencies in data structures, algorithms, and software design
5+ years of hands-on experience in Java, Spring Boot, JSON, REST Web Services
Strong experience with relational databases (MySQL, Oracle DB) a major plus.
Experience working in a Product Development a plus.
Experience in using source control systems such as Git or SVN, issue tracking systems like JIRA
Ability to adapt to changing business priorities and to thrive under pressure
BS or equivalent in Computer Science, Computer Engineering, or related field. Masters' a major plus.
Experience in Agile & Lean product development
Job Type: Full-time
Experience:
Java: 5 years (Preferred)
Education:
Bachelor's (Required)
Benefits:
Paid leaves / Leave encashment
Flexible work hours
Industry:
Software Development"
Data Scientist,"Kandivali, Mumbai, Maharashtra",Exeliq Consulting,None,Organic,"Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.
Responsibilities:
Creating solutions and products for leading representatives of different industries;
Analysing business problems, looking for better technical solutions and their implementation;
Expanding company’s expertise in the field of Computer Vision;
Management of the direction of the company in the future."
Risk Analytics - Machine Learning Engineer,"Chennai, Tamil Nadu",DTCC,None,Organic,"About this Opportunity
The incumbent will be responsible for studying data, discovering the information hidden and help making smarter and better decisions for the Business. The primary focus of the role will be on applying text and data mining techniques, doing statistical analysis and building high quality and high-performance prediction systems integrated with the Risk applications. They will also have proven experience in data analysis, modeling and implementing solutions along with sound understanding of capital markets and financial risk domain to be able to recommend the best-fit model and solution approach.
Business Unit: Global Chief Risk Office
Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems.
What You'll Do
Collaborate with cross functional teams to collate data
Enhancing data collection procedures to include information that is relevant for building analytical solutions
Analyze, extract and understand meaningful patterns from the large volumes / dimensions of historical data by utilizing analytics techniques and SMEs’ inputs
Design, develop, evaluate and implement high quality innovative predictive/prescriptive models using open source tools such as R, Python, or similar scripting within Apache Spark/AWS cloud based big data environment
Support the team in creating/executing novel approaches to solve challenging problems by leveraging AI/ ML/NLP and Big Data/Cloud technologies
Collaborate closely with Business Partners/Analysts, Data Analysts, Application Development and other Data Scientists to integrate innovations and algorithms into useable data products
Doing ad-hoc analysis and presenting results in a clear manner
Aligns risk and control processes into day to day responsibilities to monitor and mitigate risk; escalates appropriately
Sound Like You?
Minimum of 6 years of related experience
Bachelor's degree preferred with Masters or equivalent experience
Additional Qualifications
Minimum of 3-5 years of related experience in Data analysis, Data Science, Modeling
Experience with SQL, Python, Big Data and Machine Learning Algorithms
Strong analytical and problem-solving skills
Great communication skills
Experience in Financial industry with focus on Risk Management is preferred
Experience in Data Visualization tools and AWS is a plus

About DTCC

DTCC safeguards the financial markets and helps them run efficiently, in times of prosperity and crisis. We are uniquely positioned at the center of global trading activity, processing over 100 million financial transactions every day, pioneering industry-wide, post-trade solutions and maintaining multiple data and operating centers worldwide. From where we stand, we can anticipate the industry’s needs and we’re working to continually improve the world’s most resilient, secure and efficient market infrastructure. Our employees are driven to deliver innovative technologies that improve efficiency, lower cost and bring stability and certainty to the post-trade lifecycle.

Our work environment favors openness and gives people freedom to do their jobs well, by encouraging diverse opinions and emphasizing teamwork. When you join our team, you’ll have an opportunity to make meaningful contributions at a company that is recognized as a thought leader in both the financial services and technology industries. A DTCC career is more than a good way to earn a living. It’s the chance to make a difference at a company that’s truly one of a kind.

Our Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems."
Data Engineer,"Bengaluru, Karnataka",ADCI - BLR 14 SEZ,None,Organic,"Experience writing high quality, maintainable SQL on large datasets.
Ability to write code in Python, Ruby, Scala or other platform-related Big data technology.
Expertise in Star Schema data modelling
Exposure/Experience in Big data Technologies (hadoop, spark, etc.).
Strong analytical and problem solving skills
Expertise in the design, creation and management of large datasets/data models
Experience working on building /optimizing logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs
Experience with AWS services including S3, Redshift, EMR and RDS
Excellent verbal and written communication skills
Ability to work with business owners to define key business requirements and convert to technical specifications

Amazon.com operates in a virtual, global e-commerce environment without boundaries, and operates a diverse set of businesses, including retail, third party marketplaces, e-commerce platforms, web services for developers. Amazon's mission is to be earth's most customer-centric company.

Are you interested in delighting customers and are passionate about promoting sustainability? Then Amazon’s Packaging Team is the place for you. We are the Customer Packaging EXperience (CPEX) team within Amazon Robotics Technology organization and we optimize Amazon’s packaging solutions. To do this across billions of shipments, we need data infrastructure, tools, software solutions that support analytics, data science, and machine learning functionalities all of which come together in building packaging decision mechanisms across millions of products.

You'll be responsible for the design, implementation, operation, and support of large-scale, performance-critical data sources that are crucial to the successful operation of our CPEX team. You will work with tenured ML scientists, software developers, business intelligence engineers, and product managers on our team as well as remote data engineering resources. You will be tasked with optimizing, managing, and supporting existing data solutions and identifying and designing our next generation.

You should be an expert in the architecture of DW, ETL solutions using multiple technologies (RDBMS, AWS, and Big Data). You should excel in the design, creation, management, and business use of extremely large datasets. You should be able to write scripts (Python, UNIX, Java etc.) and automate processes. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring data sets together to answer business questions and drive change.

Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
Experience working with other engineers in defining data engineering best practices and leveraging software development life cycle best practices such as agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Knowledge of software engineering best practices across the development life cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations"
"Lead Big Data Engineer, ED&A - ICC, India Capability Center...","Bengaluru, Karnataka",Nike,None,Organic,"Become a Part of the NIKE, Inc. Team
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.
NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At Nike, it’s about each person bringing skills and passion to a challenging and constantly evolving game.

Do you have a passion for digital technology, innovation and problem solving? Are you curious about how to turn billions of events and signals into meaningful information that not only provides insights into the present but also help predict the future? Are you interested in applying Data Streaming and Big Data Technology along with Machine Learning to help deliver personalized experiences? If so, come join the talented team of engineers that are a driving force behind data engineering solutions at Nike.

The following qualifications and technical skills will position you well for this role:


MS/BS in Computer Science, or related technical discipline

7+ years of industry experience, 3+ years of relevant big data experience

Strong programming experience, Scala preferred

Experience working with Big Data streaming services such as Kinesis, Kafka, etc.

Experience working with NoSQL data stores such as HBase, DynamoDB, etc.

Experience building domain-driven Microservices

Experience provisioning RESTful API’s to enable real-time data consumption

Experience in Python or Java

Experience working with Hadoop and Big Data processing frameworks (Spark, Hive, Nifi, Spark-Streaming, Flink, etc.)

Experience with SQL and SQL Analytical functions

Experience participating in key business, architectural and technical decisions

Experience designing, estimating and executing for complex software projects

Experience providing guidance and mentoring junior engineers
These are the characteristics that we strive for in our own work. We would love to hear from candidates who embody the same:


Desire to work collaboratively with your teammates to come up with the best solution to a problem

Demonstrated experience and ability to deliver results on multiple projects in a fast-paced, agile environment

Excellent problem-solving and interpersonal communication skills

Strong desire to learn and share knowledge with others
NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.
NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Machine Learning Engineer,"Bengaluru, Karnataka",Apple,None,Organic,"Summary
Posted: May 15, 2020
Weekly Hours: 40
Role Number:200170315
Imagine what you could do here. At Apple, we believe new ideas have a way of becoming excellent products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just build products — they create the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that encourages the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. It takes deeply dedicated, intelligent and hard-working individuals to maintain and exceed the high expectations for the exciting iPhone brand at Apple. The iPhone Product Operations Data Team is looking for an extraordinary Machine Learning Engineer to join our team. You will help design and implement our machine learning strategy to the massive iPhone supply chain and help build the future of our manufacturing systems. This team will be collaborating and working with multi-functional teams and applying machine learning/data mining algorithms to large-scale data.
Key Qualifications
Minimum three years of hands-on experience applying machine learning techniques to build models coordinated into applications or research.
Strong working knowledge of machine learning/data mining algorithms (deep learning, classification, clustering, etc). Experience with Image Analysis/Computer Vision is a plus.
Understand algorithms (be able to tweak them when needed) as well as infrastructure that enables fast iterations
Strong software development skills with proficiency in Python and R. Experienced user of libraries such as scikit-learn, scipy, R, NetworkX, Spacy, and NLTK.
Good understand of deep learning algorithms and workflows, and experience with Torch, Caffe, MXNet, TensorFlow is a Plus.
Experience in Hadoop, Spark, Hive, Cassandra, Kafka and NoSQL databases a plus
Ability to significantly present results of analyses in a clear and impactful manner
Description
Product Operations partners with a variety of different engineering and operations teams, the ML Data Science team leads development of machine learning solutions for a variety of tasks and projects. This Data Scientist will be responsible for delivering projects from end-to-end: problem statement and conceptualization, proof-of-concept, and participation in final deployment. You will also perform ad-hoc statistical and data science analyses. You will also work closely with data engineers to generate detailed business intelligence solutions. You will be encouraged to conduct presentations of analyses to a wide range of audiences including executives.
Education & Experience
Master of Machine Learning, Data Science, Statistics, Operations Research or related fields with 5+ years’ experience applying machine learning techniques to real business problems."
Data Engineer,"Bengaluru, Karnataka",Menorah Personnel Management India Private,None,Organic,"Keyskills :
Data structures.
Job Description :
Requirements:
Responsible for the design and development of medium to highly complex systems.Skills include system design and analysis as well as business skills.
Works with data and project managers to understand systems and consults with customers to understand needs.
Developments and implements new systems, corrects software errors in existing systems, and works to improve performance through hardware upgrades.
Manages computer systems in a business environment and responsible for resolving technical issues.Knowledgeable in programming, data structures, computer systems, and software engineering.
Bachelor's degree in computer science, software engineering, or other related field.
Ability to manage multiple assignments.Superior written and oral communication skills. 6-10+ years of experience.
Posted On : 2019-12-28 10:03:17"
Software Intern (Algorithms),"Pune, Maharashtra",AdElement,None,Organic,"We are looking for computer science final year students/ fresh graduates that have solid understanding of computer science fundamentals (algorithms, data structures, object oriented programming) and strong java / c++ programming skills. You will get to work on machine learning algorithms as applied to online advertising. You will learn how to collaborate in small, agile teams, do rapid development, testing and get to taste the invigorating feel of a start-up company.
Experience
Solid foundation in computer science, with strong competencies in data structures, algorithms, and software design
Java / C++ programming

Required Skills
Familiarity with online advertising, web technologies
Familiarity with Hadoop, Mahout, R

Optional Skills
UG - B.Tech/B.E. - Computers; PG - M.Tech - Computers"
Data Scientist III,"Mumbai, Maharashtra",General Mills,None,Organic,"General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills

Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business"
Data Analyst,"Hyderabad, Telangana",BuzzBoard,None,Organic,"Description:
We are looking for a passionate experienced & Certified Data Analyst. The Successful candidate will turn data into information, information into insight and insight into business decisions.
Data analyst responsibilities include conducting full life cycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.
Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and ""clean"" data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Be able to develop a clear under stand of user behavior and interpret patterns that can help improve experience
Requirements
Proven working experience as a data analyst or business data analyst.
Should have worked on tracking and analyzing data for web and/or mobile apps.
Experience with Google Data Studio, Mix panel would be highly beneficial.
Technical expertise regarding data models, data base design development, data mining and segmentation techniques.
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Java script, or ETL frameworks).
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc).
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.
BS in Mathematics, Economics, Computer Science, Information Management or Statistics.
Powered by JazzHR
SER0L2RBjt"
"Associate, Index Configuration Data","Gurgaon, Haryana",BlackRock,None,Organic,"About BlackRock
BlackRock’s business is investing on behalf of our clients, from large institutions to parents and grandparents, doctors and teachers who entrust their savings to us. We are committed to our clients—period. Our promise is to offer them the clearest thinking about what to do with their money and the products and services they need to secure a better financial future.
That’s why investors of all kinds have made us the world’s largest asset manager, entrusting us with trillions of dollars, and it’s why companies, institutions and global governments come to us for help meeting their biggest financial challenges.

Description
About this role
The Index Implementation team, part of the BlackRock Data & AI organization, is responsible for onboarding new or custom public indices on BlackRock’s proprietary Aladdin® end-to-end investment platform. BlackRock and its BlackRock Solutions (BRS) clients utilize these indices as an integral part of investment and risk management, serving as benchmarks for Mutual Funds, ETFs, and Hedge Funds, Pensions, and other products. Index Implementation works closely with index vendors such as MSCI, S&P, FTSE, and Markit Partners, as well as internal partner teams including Client Analytics, Portfolio Management, Relationship Management and other BlackRock Data & AI groups. Index Implementation is a diverse and distributed team that service clients in all spectrums of the financial markets.
Supply to all aspects of rolling out multiple concurrent new indices, across various asset classes and strategies in Aladdin, including vendor data acquisition, data mapping and normalization, process testing and automation, and quality control.
Provide high quality client service externally and internally. Address inquiries and resolve problems from clients and internal BlackRock partners.
Understand risk analytics of fixed income, equity and alternatives products to analyze index methodologies, collaborate with vendors, and build custom solutions the business.
Initiate and drive Index platform improvements to support new business needs, minimize risk, and improve quality.
Act as Business Analyst and Project Manager responsible for detailing client requirements, assessing potential solutions, and ensuring key achievements are met.
Bachelor’s Degree is required, with preference to business fields such as Finance, Accounting, or Economics, and technical subject areas such as Computer Science, Information Systems, or Engineering.
A “Student of the Markets” mentality: Intellectually curious with a passion for learning about the global financial markets and the investment management business.
Excellent verbal and written communication skills combined with an ability to connect across different functions and levels.
5+ years of experience, preferably in financial services.
Basic knowledge of SQL, UNIX, or Python is a plus.
Travel : No
Direct Reports: No
Licenses: No
About BlackRock
BlackRock’s purpose is to help more and more people experience financial well-being. As a fiduciary to investors and a leading provider of financial technology, our clients turn to us for the solutions they need when planning for their most important goals. As of June 30, 2020, the firm managed approximately $7.32 trillion in assets on behalf of investors worldwide.
BlackRock is proud to be an Equal Opportunity and Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, disability, protected veteran status, and other statuses protected by law.
BlackRock will consider for employment qualified applicants with arrest or conviction records in a manner consistent with the requirements of the law, including any applicable fair chance law.
Job requisition #
R201565"
Business Analyst,"Bengaluru, Karnataka",PayU,None,Organic,"Job responsibilities:
Design infrastructure for data, especially for but not limited to consumption in machine learning applications
Define database architecture needed to combine and link data, and ensure integrity across different sources
Ensure performance of data systems for machine learning to customer-facing web and mobile applications using cutting-edge open source frameworks, to highly available RESTful services, to back-end Java based systems
Work with large, fast, complex data sets to solve difficult, non-routine analysis problems, applying advanced data handling techniques if needed
Build data pipelines, includes implementing, testing, and maintaining infrastructural components related to the data engineering stack.
Work closely with Data Engineers, ML Engineers and SREs to gather data engineering requirements to prototype, develop, validate and deploy data science and machine learning solutions

Requirements to be successful in this role:
Strong knowledge and experience in Python, Pandas, Data wrangling, ETL processes, statistics, data visualisation, Data Modelling and Informatica.
Strong experience with scalable compute solutions such as in Kafka, Snowflake
Strong experience with workflow management libraries and tools such as Airflow, AWS Step Functions etc.
Strong experience with data engineering practices (i.e. data ingestion pipelines and ETL)
A good understanding of machine learning methods, algorithms, pipelines, testing practices and frameworks
Preferred) MEng/MSc/PhD degree in computer science, engineering, mathematics, physics, or equivalent (preference: DS/ AI)
Experience with designing and implementing tools that support sharing of data, code, practices across organizations at scale"
Product Support Tech Advisor 2,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
We are looking for below technical skills.
4+ years of experience as appian administrator.
Provide level 3 support for internal and external user's for appian applications.
Interact with delivery team, platform team to identify and resolve performance issues with applications and services.
Manage and coordinate implementation for appian based applications and API's.
Good troubleshooting skills on workflow bases appian applications.
Strong PL/SQL knowledge to understand data flow for applications.
Experience working on ITSM tools.
Good communications skills
Flexible in support hrs and shifts.
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Analyst-Statistics and Predictive Modelling,"Mumbai, Maharashtra",PMaps,None,Organic,"Job Category : Research
Department/Group : Product Development and Research
ROLE AND RESPONSIBILITIES
You should know the best ways to collect and cleanse the data used in the modeling analysis. You will be required to coordinate with other departments in order to improvise the existing data capture techniques and suggest the new data elements required for modeling.
You should be able to use advanced statistical techniques to identify and interpret correlations using univariate and multivariate analysis to develop new approaches to the existing problems.
You should be able to create valuable analytics using data mining technology, multivariate analysis, regression analysis, and statistical sampling.
You should be able to support the research team to construct or maintain the built models, including data mining/extracting or combining data from multiple sources using languages such as SQL and SAS.
You are required to assist other team members complex work related problems.
QUALIFICATIONS AND EDUCATIONAL REQUIREMENTS
Bachelor’s/Master’s degree in Statistics, Mathematics, Econometrics, Computer Science, or related field required
**Relevant Certification in Data Science, Data Analytics, Data Mining, Artificial Intelligence, Machine Learning preferred
**Equivalent work experience in a similar position may be substituted for educational requirements.
PREFERRED SKILLS
Willing to take challenges associated with the start-up environment
Experience working with large datasets in SAS or similar statistical software
Strong skills in statistical and data mining tools such as R, SPSS or SAS
Excellent oral and written communication and presentation skills
Advanced knowledge of MS Word, Excel, Access, and PowerPoint
Ability to quickly adopt and learn new software and technologies
Ability to effectively handle multiple situations simultaneously"
Software Engineering Lead - Public Cloud Engineering,"Bengaluru, Karnataka","JPMorgan Chase Bank, N.A.",None,Organic,"Public Cloud Platform-Software Engineer - Vice President
When you work at JPMorgan Chase & Co., you're not just working at a global financial institution. You're an integral part of one of the world's biggest tech companies. In 14 technology hubs worldwide, our team of 40,000+ technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $9.5B+ annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry, but also change the world.
At JPMorgan Chase & Co. we value the unique skills of every employee, and we're building a technology organization that thrives on diversity. We encourage professional growth and career development, and offer competitive benefits and compensation. If you're looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you.
JPMorgan Chase & Co. is an equal opportunity employer.
The Chief Technology Office - Enterprise Architecture and Core Engineering department within JPMorgan Chase & Co. is responsible for the evolution of modern, efficient development practices and tooling for an optimal engineer experience.
This role forms part of the Chief Technology Office Cloud Services Group. This is an opportunity to join JP Morgan's Greenfield Cloud development team building products that will accelerate our journey to Public Cloud. Our team is responsible for making Public Cloud services available within the bank, leveraging native services from multiple cloud service providers to deploy scalable, secure and resilient products.
As an experienced Software Engineer, your mission is to help lead our team of innovators and technologists toward creating next-level solutions that improve the way our business is run. Your deep knowledge of design, analytics, development, coding, testing and application programming will help your team raise their game, meeting your standards, as well as satisfying both business and functional requirements. Your expertise in various technology domains will be counted on to set strategic direction and solve complex and mission critical problems, internally and externally.
You will play a critical role in the evolution of J.P. Morgan's cloud strategy. You are responsible for providing technical solutions, working with technical staff, and enabling our business and technology partners to succeed on the cloud. You love technology, enjoy working with highly technical engineers on complex problems, and value continuous learning. As a technical expert with an entrepreneurial drive and passion for strong collaboration, you are able to balance business, user and security needs with technical constraints.
Responsibilities
Solving the companies most challenging cloud problems by building innovative technical solutions.
Focus on automation as first class operating model to ensure stability and velocity during development.
Implement acceptance tests to ensure the product meets the business goal and specification.
Create efficient integrations between on-premises enterprise systems and cloud provider services.
Work with customers to provide in-depth technology solutions to their business problems.
Lead, coach and mentor the organization with practical examples, hands-on workshops and papers.
Skills & Experience
BS degree in Computer Science or related technical field or equivalent practical experience
10+ Years of significant programming experience in one or more of the following: Java, Python or Go
Technical experience in:
Web Scalability - Highly available architectures - load balancing, scale out
Messaging middleware - application interoperability - ActiveMQ, MQ Series, SQS
Storage technologies - object and block storage
Database - SQL and NoSQL e.g. DynamoDB, Postgres, MySQL, Oracle, SQL Server
CI / CD pipelines and tool sets
Networking - TCP/IP, DNS, Firewalls
OS - Linux (RHEL)
Cyber security fundamentals and working knowledge
Testing - xUnit, FitNesse, Cucumber
Experience designing, developing, or maintaining production-grade cloud solutions in Cloud ecosystems such as Amazon Web Services, Microsoft Azure or Google Cloud Platform
A systems thinker with hands-on experience with Lean and Agile methodologies such as Scrum and Kanban
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."
Data Scientist,India,TCG Digital,None,Organic,"Location
India / US / Europe

Experience
2 Years

Academic Qualification:

B.S, B.E., B.Tech/MBA from top-tier Engineering /B-School OR
Masters in Statistics/Economics from leading University

Overview

Continuous, growth opportunities for career progression and personal development
Professional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate training
Competitive and performance-oriented compensation and employee benefits package
Industry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.

Roles and responsibilities

Will involve teamwork as well as work in which individual contribution will be needed.
Clear, articulate and confident written and verbal communication skills.
Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.
The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.
Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:
Interacting with business stake holders for gathering requirements
Analysing data to develop key insights on business trends and performance
Applying statistical/mathematical algorithms as needed to address specific business problems
Proficiency in using query languages such as SQL(preferable), Hive, Pig, R, SAS, Python

Additional Skills (preferred)

Will involve teamwork as well as work in which individual contribution will be needed.
Intermediate querying and scripting skills in SQL
Experience in relevant field such as Statistics, Computer Science or Applied Math.

SPOC
Buddhadeb Bhattacharjee

Mail to
Buddhadeb.bhattacharjee@tcg-digital.com"
Python Developer/Selenium Testing,"Chennai, Tamil Nadu",Yours Efficiently,"₹96,000 - ₹1,56,000 a year",Organic,"Job Description:
1. Hands-on coding experience in Selenium with Python
2. Design, implement and maintain test scripts with good quality in a python based automated test framework (Atom IDE) for testing web based user interface
3. Able to work independently and with the team to deliver test plans and test cases successfully with best practices
4. Experience in building test scripts for test automation framework using Page Object Model
5. Good to have hands-on experience in PyTest, Unittest automation with Python
6. Proficient in Python as an Object Oriented programming language and community standards for Python programming and related concept
7. Execute and report on planned tests, report and manage defects, regress software fixes for new and existing products, assist development with replicating and debugging problems and develop new test automation solutions as needed
8. Develop test reports and metrics
9. Experience in Test Automation Frameworks like Data Driven, Keyword Driven and Hybrid
10. Deep understanding of Test Case Development with prior experience in Test Case Automation
Educational Qualification:
Graduate or Post Graduate in Engineering, Science, Technology, (Preferably BE or MCA graduate) with Related Experience.
Experience Required:
0-3 Years Experience in Python Development & Selenium Testing.
Job Type: Full-time
Pay: ₹96,000.00 - ₹156,000.00 per year
Work Remotely:
Temporarily due to COVID-19"
Data Analyst,"Bengaluru, Karnataka",Outsource Bigdata,None,Organic,"Requirement
B.Tech. / B.E in any Engineering Stream/ MCA / Bachelor’s degree in any science stream.
0-2 years’ experience - Fresher’s are welcome to apply.
Added advantage if you have basic knowledge about Mechanical/Electrical appliances, FMCG products
Added advantage if you have experience of working with API’s used to extract web data - dimensional data from databases and web is an added advantage. Basic programming skills to program custom scrapping tools
Should have excellent computer knowledge - MS Office – Excel, MS Word, etc.
Engineering Product / Data Mining understanding – Product information like Manufacturer / Part Number / Product Description / Energy rating / Energy consumption etc.
Good Analytical & Communication skills (Ability to communicate with clients)
Data management capabilities, attention to detail.
Demonstrates interpersonal skills and team work
Quick learner and flexible to perform multiple jobs
What you've got
If you have the ability to look down at the meaning of data with good analysis and identify trends and patterns of information clubbed with excellent computer skills, then this role is what you are looking for. Expertise in streamlining of data management projects and end to end process flow, ensuring deliverables are prepared to exceed customer expectations, status reporting, developing, documenting, and maintaining data quality goals and standards."
Senior Data Analyst,"Bengaluru, Karnataka",GSK,None,Organic,"Site Name: India - Karnataka - Bengaluru
Posted Date: Aug 3 2020
If you are ready for an exciting career YOU would be responsible for the following.
This role is accountable for contributing within and across product teams in the technical solution design, implementation & continuous improvement of solutions for large-scale complex products, embedding agile and DevOps principles.
Provides leadership, technical direction and GSK expertise to the Data Analyst team composed of GSK FTEs, strategic partners and software vendors.
Partner with Product Owners and Data Architects to inform product strategy and roadmaps.
Maintain awareness of emerging technology in the market and technical industry trends related to the data and analytics space and use the knowledge to contribute to product strategy.
Lead and provide technical guidance to several product teams at once.
Develop high-level requirements / use cases for analytics to support business justification
Work with the product owners to translate the requirements into a form of data mapping, logical data model for engineering team
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
Take dashboard requirements and transfer into rapidly developed prototypes and working solutions
Implement and document reports, dashboards, and other story-telling insights within the BI platforms consistent with business and technical requirements
Optimize and update semantic data models to support new and existing projects
Develop test scenarios and test cases in collaboration with data test engineer along with acceptance criteria
Identify and drive opportunities to reuse data models in new environments
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Bachelor’s Degree (Computer Science, Engineering, or other STEM-related area preferred)
10+ years of successful experience as a Business And/Or Data Analyst in Data focused products and proven history working on and delivering complex projects in an Analytics environment space
The ideal candidate would be highly experienced in conducting data analysis on multiple projects simultaneously in a distributed global matrix environment.
Familiar with Agile and DevOps processes
The candidate is required to carry strong Business Intelligence tool skills and relevant programming experience to query data.
Extensive experience with at least 1 data visualization platform preferably Power BI
Programming in Python or JavaScript is a plus
Experience working in Azure environments a plus
Strong professional communication skills with both technical & non-technical audiences
Why GSK?
Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.
GSKIndia_DA
LI-GSK
Our goal is to be one of the world’s most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine."
Director of Data Science,"Noida, Uttar Pradesh",Deal4loans,None,Organic,"Location:Noida, Uttar Pradesh, India
As a Director of Data Science you will develop problem statements and high quality quantitative models for business insight in the space of Banking, Capital Markets and Insurance.
Strong knowledge and skills in statistics, mathematics and computer science. Design and delivery of leading analytics solutions by applying your deep skills in above mentioned disciplines to solve priority issues and help improve performance using Advanced Analytics. Deep skills in R, SAS or Python, along with strong understanding of all key market leading Analytics techniques, frameworks, methodologies and tools.
Defines analytic strategies to meet the demands of business requirements
Defines the technical requirements of the analytic solutions
Defines the data requirements of the analytic solution
Refine our credit scoring model across various credit products
Integrates advanced analytics into end-to-end business intelligence solutions and operational business processes
Engages in technical problem solving across multiple technologies; often needs to develop new
What kind of person are we looking for:
PHD or M.S. in statistics, economics, mathematics, or related field is required
Should be an expert in Credit scoring models
Looking for someone with atleast 5 years of experience (always happy to relax for exceptional candidate)
Extensive experience solving analytical problems using quantitative approaches using machine learning methods
Competent in R. Bonus points for knowing Matlab, SQL, SAS and Python
High-energy, company first, team first, positive attitude
Problem solver: it a cliche, but this cliche is important for us! You should be able independently research and resolving partner questions or concerns in a timely manner... yes there will be fire, but fighting fire should be fun for you
Team team team: We are very collegial, we collaborate, we help each other, we teach each other, we grow with each other
Develop frameworks to analyze information, situations and data. Separate critical from mundane, using 80/20 principles
Good with numbers: digest numbers/data, analyze it, use this data to make. Share your insights in a crisp and simple-digestable form to your team, colleagues and management
You should be able to develop high-level relationships with partners - you will develop partnerships and work on developing new business as well
Compensation
Compensation will be competitive, in line with best in the industry
ESOPS of one of the most successful fintech companies in India
Opportunity to impact people's lives and be a change agent in the banking services"
AI NLP ENGINEER,"Pune, Maharashtra",NLPBOTS,None,Organic,"Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.
To succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.
What we look for: -
Advanced proficiency in the following:
1. Python
2. Natural Language Processing
3. Deep Learning
4. Machine Learning
5. Numpy, Scipy, Pandas
6. Data Science
7. MongoDB
8. NoSQL
9. SQL
10. Big Data
Experience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)
Self driven individual with a drive to learn the latest in the technology.
Exceptional team player.
Ability to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.
Good understanding and knowledge of enterprise PDLC.
Research mindset with the courage to try things and learn from them."
Software Engineer,"Bengaluru, Karnataka",GE Healthcare,None,Organic,"Role Summary:
Digital Platforms Engineering develops common software foundation/platform intended mainly for diagnostic imaging modalities like CT, MR, PET, XRay, etc., provides common services for Medical Image (DICOM) management & common acquisition workflows. This position is for a Software Engineer who can work as a developer at IAAS layer for Cloud-native system.
Essential Responsibilities:
Strong on scripting languages (python, bash etc) with emphasis on writing modular, scalable code
Expert in Kubernetes & Docker areas
Troubleshooting capabilities
Experience in Virtualization.
Network and Storage infrastructure setup and configuration
Experience with IP networking constructs (TCP/IP, routing, switching, VLANs, GRE).
Qualifications/Requirements:
Master's or Bachelor's degree in Computer Science (or related field) or equivalent experience.
At least 2 years in programing language such as python alomhg with Kubernetes/docker experience.
Strong OS Concepts : good working knowledge of Unix/Linux
Good designing and debugging skills.
Desired Characteristics:
Experience in deployment and support of Openstack environment & VM environment
Strong expertise in Linux administration troubleshooting.
Good experience of Storage providers & Storage operators such as Rook-Ceph
Openstack Command line and Production environment experience
Experience in Agile methods such as Scrum on a small development team
Experience with IP networking constructs (Open vswitch, Load balancing)
Has the ability to break down problems and estimate time for development tasks
Has the ability to make basic technology choices based on experience
Voices opinions and presents clear rationale. Uses data or factual evidence to influence
Recognizes collaborative behavior and participates in collaborative activities
Learns organization vision statement and decision making framework. Able to understand how
team and personal priorities contribute to the organization vision
Technically leading Opentack development project
Good communication skills: Strong verbal, written communication.
Good Analytical and Log debugging Skills
Must have a customer service focus
Self-starter with the passion to make a difference with the deliverables.
Team player & good interpersonal skills: Should be able to work well in a team.
Good technical aptitude : Should have proven analytical / problem solving ability
Experience in use of open source tools and systems; comfortable with open source community
and collaborative merit-based work where all ideas are heard and the best ones are implemented
About Us:
GE (NYSE:GE) drives the world forward by tackling its biggest challenges. By combining world-class engineering with software and analytics, GE helps the world work more efficiently, reliably, and safely. GE people are global, diverse and dedicated, operating with the highest integrity and passion to fulfill GE’s mission and deliver for our customers. www.ge.com
Additional Locations:
India;Bengaluru;"
Looking for Python Scripting,"Mumbai, Maharashtra",ICS Consultancy Services,"₹10,00,000 - ₹25,00,000 a year",Organic,"Roles and responsibilities for Looking for Python Scripting
: Role : Digital Data Engineering Practitioner Role Description : Develop analytics based solutions that produce quantitative and qualitative business insights. Work with partners as necessary to integrate systems and data quickly and effectively, regardless of technical challenges or business environments. Must have Skills : Python Scripting Good to Have Skills : R Programming Job Requirements : A-Professional Experience 1-Min 5 years of Data Science exp 2-Overall 6 to 9 years of work exp B-Responsibilities 1-Proficiency in R and Python 2-TensorFlow, Natural Language Processing preferred 3-Should have expertise in advanced analytics and in developing models using advanced analytical tools such as R and Python 4-Proven experience in regression, time series, classification, clustering, text analytics, deep learning and other machine learning artificial intelligence techniques 5-Research oriented mindset with ability to quickly learn new technologies 6-Use artificial intelligence, machine learning, data mining, predictive modelling statistical techniques to create new scalable models for business requirements 7-Perform sophisticated analysis and predictive modeling with minimal supervision 8-Understand complex business challenges, design scientific solutions, and synthesize insights while managing large datasets using machine learning or statistical modeling techniques
Job Details
Job Role
: All Roles
Industry Sector
: IT-Software/Software Services
Functional Area
: All Functions
Desired Profile
Profile Description
:N/A
Experience
: 3 - 10 (Years)
.
.
Education Details
UG Course
: B.Tech/B.E
UG Specialization
: N/A
PG Course
: M.Tech
PG Specialization
: N/A"
Data Architect,"Chennai, Tamil Nadu",PipeCandy,None,Organic,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.
About the Role:
We are building a complex data platform that aims to revolutionize sales and marketing by crunching billions of data points and applying sophisticated ML & AI algorithms.
We are looking for a Solution Architect who has worked on large-scale data systems and has a strong understanding of data structures, databases and data pipelines.
The architect will work with our software developers, data analysts and data scientists and will ensure that the platform architecture is robust and scalable to handle our analytical, BI and data science requirements. The ideal candidate will have experience in designing data platforms that use varied databases and incorporate complex data pipelines as part of large analytical systems.
The right candidate will be excited by the prospect of optimizing our existing data architecture and designing and building a platform to support our next generation of ML/AI data initiatives. The candidate must be self-directed and comfortable with learning new concepts and technologies to support emerging data needs.
Key Responsibilities:
Understand product requirements and design solution and data architecture to support and scale with the product roadmap
Create and maintain optimal data architecture, including data models/data structures and data pipelines, to support analytical and data science model deployment
Assemble large, complex data sets that meet functional/non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, NOSQL and AWS ‘big data’ technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into user acquisition, asset utilization, user behavior and other key metrics
Create data tools for analytics and data science team members that enable in building, integrating and optimizing ML/AI features in our product
Work with data and analytics experts to strive for greater AI functionality in our data systems
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Skills Required:
Able to write technical documents such as requirement specs or data standards
Strong analytic skills related to working with unstructured datasets
Advanced knowledge and experience in working with SQL and NoSQL databases as part of BI/ analytical systems. Experience with implementing analytical/ machine learning algorithms is a plus
Working knowledge of message queuing, stream processing, and highly scalable data stores
Strong project management and organizational skills
Knowledge/ experience using one or more of the following software/tools:
Relational SQL and NoSQL databases, including Postgres DB, Mongo DB and Cassandra
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Object-oriented/object function scripting languages: Python, Java, Scala, etc.
Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Big data tools: Hadoop, Spark, Kafka, etc.
Stream-processing systems: Storm, Spark-Streaming, etc.
Detail oriented, results-driven with the ability to manage multiple requirements in a dynamically changing environment
Self-motivated and able to handle tasks with minimal supervision or questions
Qualifications & Competencies Required:
We are looking for a candidate with 3+ years of experience in a data role
Graduate degree in Computer Science, Informatics, Information Systems or another engineering or quantitative field
Experience in building and optimizing data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience supporting and working with cross-functional teams in a dynamic environment
Perks:
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course"
Business Analyst,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"Bachelor’s or Master’s degree in a relevant field
Advanced proficiency in scripting, querying and/or analytics languages and tools: SQL, Tableau, Python, R, SAS, or similar
5+ years of professional experience in analytics, business analysis or comparable consumer analytics position
Demonstrated ability for analytical problem solving and research design skills
Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.
Strong organizational skills, strong attention to detail and experience balancing multiple tasks and deadlines

Are you interested in Amazon Echo and have a passion for language and data? Come join us! We’re building the speech and language solutions behind Amazon Alexa and other Amazon products and services.
We, Alexa's Applied Modeling & Data Science (AMDS) team, are seeking a flexible and detail-oriented Business Analyst with a passion for language data. In this role, you will support a range of analytics efforts, monitor NLU model accuracy and help customers to analyze and solve complex problems. You will be responsible for data-driven evaluation and improvements for our spoken language understanding models.
You will:
Handle unique data analysis requests from a range of data customers, including quantitative and qualitative analyses to elevate the customer experience
Lead and test tooling developments and pilot processes to support expansion to new data areas
Continuously evaluate data analysis tools and processes and offer solutions to ensure they are efficient, high-quality and scalable
Present proposals and results in a clear manner backed by data and coupled with actionable conclusions
Generate actionable insights through the development of dashboards and deep dive analyses
Closely collaborate with colleagues from science, engineering and business backgrounds

A self-starter, who proactively converts gaps into opportunities
Experience working with language, language data, speech recognition and/or natural language processing
Comfortable working in a fast paced, highly collaborative, dynamic work environment
Native or near native fluency (read and write) in one or more Indian regional languages"
Lead Statistician,"Bengaluru, Karnataka",Profectus,None,Organic,"What we are looking for:
Proficiency in most areas of mathematical and statistical analyses, machine learning, statistical modeling, and data visualization. (Hypothesis Testing, Regression analysis, econometric modeling, forecasting technique, ARIMA modeling, optimization, deep learning, etc.)
Must have worked on large datasets as the consultant will be responsible for manipulating, extracting, transforming, and analyzing the large data to develop solutions and insights.
Excellent problem-solving skills as well as critical thinking and conceptual thinking abilities.
Expert in at least one coding language – preferably python.
Knowledge on deep learning and AI tools, and their application in the Retail domain will be preferred.
Experience in client facing roles will an added advantage.
Team management experience.
Responsibilities:
Conceptualize statistical modeling framework, define data requirement, create variables for model development and implementation.
Manage end to end delivery including requirement gathering, solution design and business recommendation. Work closely with statisticians & other data science team members to develop solution framework – Identify statistical techniques, implementation mechanism.
Analyze big data using statistics, econometrics, mathematics, operations research, and text mining techniques. Provide analytical architecture analysis, design, development, and enhancements.
Building dynamic regression models, econometric models, elasticity modeling, forecasting techniques such as time-series modeling, building ARIMA models, and optimization are a few statistical techniques which will be worked on extensively.
Finalize the list of variables for modeling based on business and technical aspects. Validate the model outcomes and align it with the business needs and implementation plan.
Develop business insights based on the output of model relevant to business needs.
Prepare the benchmarking report (technical report) to analyze and compare the results of different models/variables.
Presentation of results to the management and discuss further opportunities within/outside the project.
You must be:
A team player who likes to work hard and play harder, have excellent interpersonal, organizational and time-management skills
Able to think strategically and analytically to effectively complete assigned work within given timelines
Someone who possesses excellent written and oral communication skills and have an attention to detail
A person with an ability to multi-task on multiple projects and tasks at the same time
A person who gives importance to attention to detail and be highly organized
Positive and upbeat with the ability to learn quickly
Be able to laugh. At others and most importantly at yourself. Need a sense of humor
You can expect:
A fast-paced, high-growth startup environment where you will gain a career and not just a job
The company to invest in your personal and professional development. We support your ongoing education and training by reimbursing you for relevant educational courses
An open office culture, no cabins or cubicles and a place that is looking for your input to help us grow
The support of your teammates to always do better. Own it and win together!
Exposure of International Retail market. Learn about a high growth industry and build critical skill-set
Excellent employee referral program. Refer your friends, work with your friends and be awarded for it
Work along with the smart, creative and energetic team who truly believe in ‘working hard and partying harder!’
Educational Requirement:
Masters/Ph.D in statistics"
Python Developer,"Kochi, Kerala",Calpine Group,None,Organic,"Experience : 4 - 7 year(s)
Skills required : Python,Java,C++,Bioinformatics,Sql,Linux,Aws
No. of Positions: 1-2
Responsibilities:
Experience with Python to implement data analysis workflows in a Linux environment.
Experience evaluating and improving the efficiency of programs in a Linux environment.
Experience with command line compilation and debugging.
Experience with makefiles, coverage analysis and other forms of runtime profiling.
Experience with all phases of the Software Development Life Cycle.
Ability to effectively handle multiple tasks with a high level of accuracy and attention to detail.
Working knowledge of MS Office suite of applications.
Working knowledge of Bioinformatics, Genomics, or Life Sciences
Good verbal and written communication skills.
Ability / willingness to learn bioinformatics / genomics
BE/BTech/MCA/MSc graduates only"
Full Stack Engineer,"Bengaluru, Karnataka",PayPal,None,Organic,"BSEE, CS + 10 yrs or a Master's in Computer Science
Mentor a team of engineers, contribute to and influence technical discussions and decisions.
Have strong foundational knowledge in Object-Oriented Design Principles, Data Structures, Algorithms, SQL/NoSQL, Operating Systems, and Software Engineering.
Be ready to adapt to a fast changing environment and be willing to learn multiple technologies like Java, SQL, node.js, Javascript and many more.
Understand or be keen to learn about Web Services, REST API development and design, GraphQL etc.
Build new experiences, improve existing products, and develop distributed systems powering the world’s largest e-commerce and payments websites at a scale few companies can match.
Should be open to travel to San Jose (and maybe other locations)
Job_Description_Summary: Identity Platform team is at the forefront of changing the fabric of modern authentication by delivering a modern, secure, extensible authentication platform which allows PayPal users to securely authenticate to any application, using any authentication method and on any device. This platform processes millions of login requests each day, enabling PayPal and its partners to rapidly innovate on new payment scenarios and enable new experiences. There are several opportunities in the fast growing and highly energetic engineering team. As an Identity Engineer in our development team, you will be responsible for the design, development and quality delivery of the platform web services and infrastructure.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Senior Software Engineer - Data Science and Machine Learning,"Pune, Maharashtra",VSH SOLUTIONS,None,Organic,"Overview
We are looking for creative people with analytical minds and machine learning experience to transform diverse datasets into decisions and value for our customers. Responsibilities:
Design and implement machine learning solutions for recommendation and classification
Use machine learning platforms and services to build solutions and bots, esp. for startups as part of our startup studio
Building and improving data-intensive web services
Developing complex, multi-step data pipelines that unify various data sources into one cohesive platform for data access
Unit, integration, and data integrity test development
Qualifications:
Experience building RESTful APIs & multi-tiered web applications in Python, Java, RoR or Go
Understanding of SQL and data warehousing concepts
Understanding of leading NoSQL solutions such as Cassandra and MongoDB
Experience with Git
Experience with atleast a few of these components: ElasticSearch, Caffe, Pandas, R, Matlab, SciPy
Bachelor’s Degree in Computer Science or Engineering
Location: Pune, India To apply for this job, please write to us at jobs@vshsolutions.com"
Software Engineer - Java (Insights),"Bengaluru, Karnataka",Truecaller,None,Organic,"Hey, Truecaller is calling you from Bangalore, India! Ready to pick up?
Truecaller was born in 2009, Stockholm, Sweden, with the mission to provide more safe and efficient communication to everyone's daily life. Today, Truecaller is loved by 180 million daily active users around the world, popular in South Asia, Middle East, Africa! We are the go-to app for Caller ID, spam blocking, messaging, and payments.
We at Insights team The Insights Team is responsible for all the Smart-SMS features (Smart Notifications, InfoCards in conversations, Important tab etc) that you see in the Truecaller app and is fully based out of the Bangalore office.
As a Java Developer in the team, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
What we expect from you:
4 + Years of experience into core java
Strong understanding of core java 8, threading, generics, garbage collection, serialization etc
Strong OOPs, data structure, algorithm knowledge
Strong understanding and hands on experience of some dependency injection framework and writing testable code
hands on experience on build/deploy tools/configuration such as maven, jenkins, etc
Prior experience in resolving performance issues and should know how to go about optimizing APIs via code, configuration, caching or whatever method suitable
Aptitude/experience of analyzing and debugging complex production issues using tools such as splunk, dynatrace and sometimes UNIX commands
Ability & willingness to learn technologies at pace and adapt easily
A bachelor's degree in computer science. If the candidate has strong technical skills and/or great reasoning ability paired with decent coding ability, this will not be a barrier
What will you work on?
This position is for a java developer within the Insights Team.The team owns a patented fully offline text parser which enables all these features. The parse is written in Java and is maintained as a separate project and included within the app. It is tuned for a very small memory footprint and parsing speed compared to other parsers.If you get selected, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
It would be great if you also have:
Since we are working with text parsing, it would be awesome if the candidate has
Experience in compiler design (Undergrad knowledge is good enough)
NLP knowhow and a basic understanding of how text parsers work.
Knowledge of Graph based data structures/algorithms
Some experience with stream processing paradigms
Working experience in Kotlin
More about Truecaller
Truecaller is a Swedish company founded in 2009 in Stockholm, Sweden by Nami Zarringhalam and Alan Mamedi. The app began when our co-founders were just students who wanted to create a service that would easily identify incoming calls from unknown numbers. We have our strongest presence in South Asia, Middle East, Africa, and HQ in Sweden. We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.
Life at Truecaller - Behind the code: instagram.com/truecaller/ https://www.linkedin.com/company/truecaller/
How To Apply
You can also apply with the help of link given
https://boards.greenhouse.io/truecaller/jobs/2247266
This position is based in Bangalore, India. Please contact Talent@truecaller.com if you have any questions.
What we offer:
International teams - 25+ nationalities work together!
Learning & sharing environment
Exciting company parties & team activities – Football Team, Geek lunch, Lab Days!
Flexible working hours
Start the day with delicious breakfast
Stay refreshed: juices, tea, coffee and soft drinks
Gym reimbursement.
Competitive salary
Medical, Accident,Term life insurances
Truecaller is an equal opportunity employer and value diversity company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status."
Returnies - Returnship (Engineering),"Bengaluru, Karnataka",Aleron,None,Organic,"ID: 16978
Posted: 7/3/2020
Location: Bangalore, KA
Category: Classified
Job Type: Contract


Description
Responsibilities:
Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance
Job Requirements
Skill set required:
Bachelor’s degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
Comfortable with multi-tasking, managing multiple stakeholders and working as part of a team
Excellent communication skills including experience speaking to technical and business audiences and working globally
Can apply an entrepreneurial approach and passion to problem solving and product development"
CIEL/SEL/14839: Data Science - AI/ML Specialist,"Bengaluru, Karnataka",CIEL HR Services,None,Organic,"About the company -
Our client is one of the world's fastest-growing AI-based contract management solution providers.

Exp -
7+ Years
Location -
Mumbai
Job Role -
Min 7years hands-on experience in Natural Language Processing, Machine Learning, Artificial Intelligence, and IBM Watson"
Data Engineer,"Bengaluru, Karnataka",Whatfix,None,Organic,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.
We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.
Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements
Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have
Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status"
Senior Data Analyst,"Bengaluru, Karnataka",GSK,None,Organic,"Site Name: India - Karnataka - Bengaluru
Posted Date: Aug 3 2020
If you are ready for an exciting career YOU would be responsible for the following.
This role is accountable for contributing within and across product teams in the technical solution design, implementation & continuous improvement of solutions for large-scale complex products, embedding agile and DevOps principles.
Provides leadership, technical direction and GSK expertise to the Data Analyst team composed of GSK FTEs, strategic partners and software vendors.
Partner with Product Owners and Data Architects to inform product strategy and roadmaps.
Maintain awareness of emerging technology in the market and technical industry trends related to the data and analytics space and use the knowledge to contribute to product strategy.
Lead and provide technical guidance to several product teams at once.
Develop high-level requirements / use cases for analytics to support business justification
Work with the product owners to translate the requirements into a form of data mapping, logical data model for engineering team
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
Take dashboard requirements and transfer into rapidly developed prototypes and working solutions
Implement and document reports, dashboards, and other story-telling insights within the BI platforms consistent with business and technical requirements
Optimize and update semantic data models to support new and existing projects
Develop test scenarios and test cases in collaboration with data test engineer along with acceptance criteria
Identify and drive opportunities to reuse data models in new environments
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Bachelor’s Degree (Computer Science, Engineering, or other STEM-related area preferred)
10+ years of successful experience as a Business And/Or Data Analyst in Data focused products and proven history working on and delivering complex projects in an Analytics environment space
The ideal candidate would be highly experienced in conducting data analysis on multiple projects simultaneously in a distributed global matrix environment.
Familiar with Agile and DevOps processes
The candidate is required to carry strong Business Intelligence tool skills and relevant programming experience to query data.
Extensive experience with at least 1 data visualization platform preferably Power BI
Programming in Python or JavaScript is a plus
Experience working in Azure environments a plus
Strong professional communication skills with both technical & non-technical audiences
Why GSK?
Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.
GSKIndia_DA
LI-GSK
Our goal is to be one of the world’s most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine."
Data Engineer II / Sr Data Engineer,"Mumbai, Maharashtra",Colgate-Palmolive,None,Organic,"Relocation Assistance Offered Within Country
# 83461 - Mumbai, Maharashtra, India
We are looking for a savvy Data Engineer to join our growing team of analytics experts. Data Engineers will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Roles and Responsibility:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Experience
We are looking for a candidate with minimum 2 years of experience in a Data Engineer role
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc
Experience with cloud services: GCP, AWS, etc
Experience with object-oriented/object function scripting languages: Python, Java, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.

Qualification & Competencies
Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is preferred
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Strong analytic skills related to working with unstructured datasets.
Strong problem solving skills with an emphasis on product development.
Strong experience with test driven development methodologies.
Strong oral & written communication skills with an ability to express complex technical concepts in business terms and business needs in technical specifications
A drive to learn and master new technologies and techniques.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation."
Senior Data Analyst,"Bengaluru, Karnataka",GSK,None,Organic,"Site Name: India - Karnataka - Bengaluru
Posted Date: Aug 3 2020
If you are ready for an exciting career YOU would be responsible for the following.
This role is accountable for contributing within and across product teams in the technical solution design, implementation & continuous improvement of solutions for large-scale complex products, embedding agile and DevOps principles.
Provides leadership, technical direction and GSK expertise to the Data Analyst team composed of GSK FTEs, strategic partners and software vendors.
Partner with Product Owners and Data Architects to inform product strategy and roadmaps.
Maintain awareness of emerging technology in the market and technical industry trends related to the data and analytics space and use the knowledge to contribute to product strategy.
Lead and provide technical guidance to several product teams at once.
Develop high-level requirements / use cases for analytics to support business justification
Work with the product owners to translate the requirements into a form of data mapping, logical data model for engineering team
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
Take dashboard requirements and transfer into rapidly developed prototypes and working solutions
Implement and document reports, dashboards, and other story-telling insights within the BI platforms consistent with business and technical requirements
Optimize and update semantic data models to support new and existing projects
Develop test scenarios and test cases in collaboration with data test engineer along with acceptance criteria
Identify and drive opportunities to reuse data models in new environments
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Bachelor’s Degree (Computer Science, Engineering, or other STEM-related area preferred)
10+ years of successful experience as a Business And/Or Data Analyst in Data focused products and proven history working on and delivering complex projects in an Analytics environment space
The ideal candidate would be highly experienced in conducting data analysis on multiple projects simultaneously in a distributed global matrix environment.
Familiar with Agile and DevOps processes
The candidate is required to carry strong Business Intelligence tool skills and relevant programming experience to query data.
Extensive experience with at least 1 data visualization platform preferably Power BI
Programming in Python or JavaScript is a plus
Experience working in Azure environments a plus
Strong professional communication skills with both technical & non-technical audiences
Why GSK?
Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.
GSKIndia_DA
LI-GSK
Our goal is to be one of the world’s most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine."
Junior Data Analyst,"Gurgaon, Haryana",GroundTruth,None,Organic,"Role: Junior Data Analyst
Location: Gurgaon, India
GroundTruth is the leading global location platform that leverages data and insights to drive business performance. Using its proprietary Blueprints technology, GroundTruth is able to learn about mobile users and reach them at the right place and right time, ultimately helping companies make smarter marketing decisions, increase sales, and grow their businesses. Since its foundation in 2009, GroundTruth has launched several innovative products and won numerous awards, including Inc. 5000’s Fast Growing Private Companies and Deloitte's Fast 500 Technology companies. Today, we're proud to employ over 400 employees across three continents and serve millions of marketers across 21 countries. Learn more: www.groundtruth.com

This will be an exciting and challenging role that will enable you to work with very large data sets, expose you to cutting edge analysis techniques, work with the latest components in cloud architecture and gain experience in the usage of location data to drive businesses. As an early member you will have significant opportunities for growth within the organization. A successful applicant will be passionate about technology and developing a deep understanding of human behavior in the real world. They would also have excellent communication skills, be able to synthesize and present complex information and be a fast learner.
You will:
Learn about location-driven marketing and how companies are using location signals to drive their business
Work closely with marketing, growth strategy and sales teams based out of our offices in USA, Germany
Develop re-usable tools and templates to quickly create data driven narratives
Gather requirements, design analyses, identify data sources and define measurement metrics to present insights and recommendations for ready consumption
Be responsible for managing your work pipeline and creating re-usable analysis and documentation
You have:
BA/BSc/B.E./BTech degree in Computer Science, Statistics, Mathematics, Economics, Physics or related fields from Tier 1/Tier 2 colleges
6 months - 2 years of experience in working with data and conducting statistical and/or numerical analysis
Strong understanding of how data can be stored and accessed in different structures
Experience with writing computer programs to solve problems
Strong understanding of data operations such as sub-setting, sorting, merging, aggregating and CRUD operations
Ability to write SQL code and familiarity with R/Python, Linux shell commands
Be willing and able to quickly learn about new businesses, database technologies and analysis techniques
Ability to tell a good story and support it with numbers and visuals
Strong oral and written communication
How you can impress us:
Experience working with large datasets
Experience with AWS analytics infrastructure (Redshift, S3, Athena, Boto3)
Experience building analytics applications leveraging R, Python, Tableau, Looker or other • Experience in geo-spatial analysis with POSTGIS, QGIS
We operate in a fast paced, dynamic environment where everyone on the team is committed to the success and growth of GroundTruth. Our culture is highly entrepreneurial and our success comes from our employees who voice their opinions and ideas to facilitate growth to our bottom line. We reward hard work, support career development, offer comprehensive benefits, and foster a fun and friendly work environment.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status"
Data Engineer,"Gurgaon, Haryana",ADCI - Haryana,None,Organic,"Bachelors in Computer Science or Engineering, or equivalent experience.
Minimum of 5+ years of experience as a DBA, Database Engineer, or similar role is required.
Broad and deep knowledge of atleast 2 relational databases including Oracle, PostgreSQL & MySQL.
Proficient in SQL optimization.
Experience with non-relational database technologies as well.
Excellent problem-solving skills.
Familiarity with Amazon Web Services such as RDS, Redshift, DynamoDB, IAM, EC2, S3, CLI, SDK or equivalent cloud services.
Proficiency coding in UNIX shell, and at least one procedural language such as Python, Ruby, Java, Perl, C++.
Excellent speaking-listening-writing skills, attention to details, proactive self-starter.

Can you work at the scale of the biggest Internet companies?
The solutions that you will deploy must scale to accommodate rapid processing and integration with large enterprise customers. However, to add to the challenge, the solutions must also support integration with highly scaled systems.

Are you ready to create best in class taxation systems to expand one of the world’s largest e-commerce engines?
If so, come be a member of Amazon’s Taskless Tax Technology team. Taskless Tax Tech builds software systems that ensure compliance for Amazon businesses and its subsidiaries and makes it easy for millions of Amazon vendors including publishers, app developers, game developers, marketplace sellers, associates and others to comply for hundreds of billions of dollars in transactions. We're constantly looking for opportunities to expand capabilities in new geographies and new lines of business.

Is your next project defining enough challenges for you conquer in an highly entrepreneurial environment?
Enabling Amazon’s explosive growth requires top talent in our Taskless Tax Technology organization. We are seeking an Data Engineer to be a part of this growth story. Our team owns data warehouse and software platforms that are among the largest in the world by volume and complexity, and a successful candidate will be able to dive deep and execute technical and functional assignments with their team. As a data engineer, you will drive architectural and design choices, invent new features, optimize programs and build a scalable, performance-driven solutions in maintaining, migrating and creating Data Lake and Data Warehouse on native AWS stack. We have a team culture that encourages innovation and we expect developers to take a high level of ownership, technical architecture and project delivery.

Position Responsibilities:
Design and build new Data Lake and Data Warehouse solutions on native AWS stack. Extend current Data Warehouse systems. Develop technical specifications and data pipelines integrating with external teams. Develop interfaces in and out with other applications. Build, configure and modify reporting modules on this data. End user support for multiple applications in multiple geographies. Collaboratively work with the integrated applications.

Join our development team to work hard, have fun and make history. You will join a highly technical and entrepreneurial culture defining and building a taxation experience to complement Amazon’s world-class eCommerce domains. Amazon is a premier place to build, deploy and operate internet-scale services.

Amazon’s Taskless Tax Technology team operates software platforms that are among the largest in the world by volume and complexity. We interact upstream with all of Amazon’s businesses globally and the majority of our projects are cross-functional. Much of our work enables Amazon’s new market or business model launches and happens as part of these enterprise programs. We partner integrally with the CFO organization worldwide, including the central finance functions and line of business leadership.

We’re looking for strong and talented data engineers who will drive architectural and design choices, invent new features, integrate with distributed services, and build a scalable platform for our cutomers. We have a team culture that encourages innovation and we expect engineers and management alike to take a high level of ownership for the product vision, technical architecture and project delivery.

As a DataEngineer, you will drive next generation of Data Lake and Warehousing technologies for growing compliance needs of the organization as unlocking expansion in multiple countries and new businesses. You will build ability to build integrated solutions enhancing your influence across teams. You will build highly scalable and secure software. You will develop and maintain algorithms for efficient and error free transactions as well as ensuring tractability of every transaction in real-time. You will build processes that drive accountability within your team, where people assume and take responsibility for actions and decisions. You will solve problems at their root, stepping back to understand the broader context.

· · 5+ years of experience managing and supporting large and complex mission-critical production databases.
Working knowledge of all phases of the software development life cycle, from initial requirements through operational support.
Experience working using Agile development a plus.
Experience in 24x7 on-call support for high-severity problem resolution.
Experience working directly with internal and/or external customers in database software development and support.
Experience in root cause analysis, remediation, and problem resolution for complex systems.
Working knowledge in database systems architecture, including networking, security, scaling, and fault-tolerance.
Working knowledge of database internals such as locking, wait events, consistency, logging, recovery.
Proficiency tuning databases for performance, availability and scalability.
Ability to deliver initiatives from conception through completion."
"Manager, Data Science","Bengaluru, Karnataka",Epsilon,None,Organic,"Company Description
Positioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Through a connected suite of products and services, Epsilon combines leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes. For more information, visit us at https://india.epsilon.com/
Follow us on social: LinkedIn, Facebook, Instagram, and Twitter

Job Description
PeopleCloud Customer is a world-class cloud-based Customer Data Platform (CDP) fully enabled with a complete Marketing Automated Operating System (MAOS). The PeopleCloud Customer platform provides out-of-the-box SaaS and PaaS products that are fully integrated, including Customer Identity services, Deterministic and Probabilistic Customer Record stitching services and Marketing Machine Learning algorithms and models trained to deliver personalized activation at scale.
The PeopleCloud Customer team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group.
You will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the COSMOS Cognitive Marketing Intelligence Cloud Platform team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects.
Provide guidance to the team of Data Scientist and manage Machine learning and Deep Learning based projects. Work with the team who analyze complex data structure, manipulate, cleanse data and perform statistical analysis
Design and guide machine learning models using Spark ML, Python, HDFS, Spring.
Design and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python
Develop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory
Own end to end implementations of multiple Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.

Qualifications
Experience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks
Strong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Proven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results.
Expertise in predictive analytics/statistical modeling/data mining/machine learning algorithms and techniques (classification, clustering, regression, multivariate testing)
Excellent communication & interpersonal skills with an ability to communicate ideas.
MS in Computer Science, Math, Physics, or equivalent education/professional experience is required.
10-12 years of total IT experience with 5+ years of managing and leading data science teams with demonstrable experience
Deep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services.
Azure Cloud experience required. Azure Data Factory experience preferred.
Strong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch
Experience with sequence modeling using RNNs/LSTMs is must
Strong experience in at least one database technology (i.e. Hive, PrestoDb etc.)
Experience with one or more web analytics tools (Google Analytics, etc.)
Strong experience in at least one programming language (i.e. Python, R, C, C++ is plus)
Experience working with different query languages (i.e. PL-SQL, T-SQL)
Understanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred.
Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)
Strong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Excellent communication & interpersonal skills with an ability to communicate ideas, insights and complicated analysis effectively at all organizational levels, include engineering leadership

Additional Information

null"
"Architect,Master Data Management","Hyderabad, Telangana",PepsiCo,None,Organic,"Auto req ID: 214161BR
Job Description
Main Purpose:
Role will focus on PepsiCo data governance support of MDM check table and cross reference functions. Role will support data governance activities to ensure alignment of key attributes across local, sector, and globally defined attributes.

Accountabilities:
• Oversee coordination and partnerships with Business Teams, Business Relationship Managers, Architecture and IT services teams to develop and maintain data governance best practices and standards along with appropriate policies and procedures
Support core governance activities for assigned projects
Ensure on time and on budget delivery which satisfies project requirements, while adhering to enterprise data governance standards.
Manage work intake, prioritization and release timing; balancing demand and available resources. Ensure tactical initiatives are aligned with the strategic vision and business needs
Qualifications/Requirements
Years of Experience:
9+ years of Master data management

Technical Skills required:
• Bachelors Degree in Business, Computer Science, or Min 7 years related business experience
Minimum 3-5 years experience in project management in a IT related role
More than 2 years experience in data governance and/or data catalog an metadata management
Proven experience in managing Data, BI or Analytics projects

Non-Technical Skills required:
• Exceptional written and verbal communication skills along with collaboration and listening skills
Good understanding of PepsiCo business processes, data, and EDW/MDM environments
Ability to work with agile delivery methodologies
Ability to ideate requirements & design iteratively with business partners without formal requirements documentation
Ability to budget resources and funding to meet project deliverables

Competencies required:
• Proactively analyze data to increase quality as it relates to accuracy, completeness, consistency, integrity, timeliness, conformity, and validity; Verify accuracy of data in functional area and for integration/project activities.
Able to conduct root cause analysis.
Contribute to the ongoing metadata maintenance and content updates. Understanding importance of metadata and reinforcing benefits and usage to team.
Cooperates with others and responds to customers and team members.
Proactively collaborates with end users and team members in supporting existing business processes and applications. Identify and recommend process improvements.
Interface with business partners as an expert in explaining and relating how data impacts their business function
Relocation Eligible: Eligible for Standard Relocation
Job Type: Regular"
Senior Data Scientist and Machine Learning Engineer,"Bengaluru, Karnataka",McAfee,None,Organic,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:
McAfee is looking for an experienced data scientist to work on our next-gen threat assessment platform. You will work with experienced developers, security researchers and data scientists to understand and implement solutions to the problems found in today’s fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.

Company Overview
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.
About the role:
You will collect and analyse data to spot trends and help us face the challenges of an evolving security landscape.
Design, debug and test complex software in the field of data science.
Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with team members (developers and malware researchers) to develop and review designs and requirements to analyse data and build ML models.
Knowledge of security practises, procedures and capabilities to perform non-repetitive, work. You will report to the Engineering Manager.
About You:
You have the following required skills:
Display understanding of and ability to use programming languages: C++, Python, C#, and SQL. Have a knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Have ability to think and research creatively. Create“stories” told by the data and presents them to other scientists.
5+ years’ experience working in security research, data mining or natural language processing. Use predictive modelling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect and explore insights from structure and unstructured data .
Develop software, algorithms and applications to apply mathematics to data, perform large-scale experimentation and build data-driven apps to translate data, solve a variety of business problems and ensure strategy. Assist business with casual inferences & observations with finding patterns , relationships in data.
Have understanding of internal business segment (partners).
Typically requires expertise in relational database structures, research methods, machine learning, Cloud-based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL).
Typically have advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.
Company Benefits and Perks:
We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.
Job Type:
Experienced Hire
Primary Location:
India, Bangalore

Additional Locations:"
Senior Data Analyst,"Hyderabad, Telangana",UnitedHealth Group,None,Organic,"Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm)

Positions in this function are responsible for the management and manipulation of mostly structured data, with a focus on building business intelligence tools, conducting analysis to distinguish patterns and recognize trends, performing normalization operations and assuring data quality. Depending on the specific role and business line, example responsibilities in this function could include creating specifications to bring data into a common structure, creating product specifications and models, developing data solutions to support analyses, performing analysis, interpreting results, developing actionable insights and presenting recommendations for use across the company.
Roles in this function could partner with stakeholders to understand data requirements and develop tools and models such as segmentation, dashboards, data visualizations, decision aids and business case analysis to support the organization. Other roles involved could include producing and managing the delivery of activity and value analytics to external stakeholders and clients. Team members will typically use business intelligence, data visualization, query, analytic and statistical software to build solutions, perform analysis and interpret data. Positions in this function work on predominately descriptive and regression-based analytics and tend to leverage subject matter expert views in the design of their analytics and algorithms. This function is not intended for employees performing the following work: production of standard or self-service operational reporting, casual inference led (healthcare analytics) or data pattern recognition (data science) analysis; and/or image or unstructured data analysis using sophisticated theoretical frame works. Generally work is self-directed and not prescribed

Required Qualifications:
Undergraduate degree or equivalent experience
10+ years of experience in data analytics, statistics and data science

Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make the health system work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)"
Senior/ Software Engineer - Data Engineering,"Bengaluru, Karnataka",zeotap,None,Organic,"Zeotap is a Customer Intelligence Platform (CIP) that helps companies better understand their customers and predict behaviors, to invest in more meaningful experiences. We enable brands to build on a nucleus of first-party data to win new customers and grow their loyal base. Our independent but seamlessly integrated modules include customer data unification, identity resolution, enrichment, analytics/modeling (including in data clean rooms), and activation to 100+ partners in the marketing ecosystem.

Recognized by Gartner as a ""Cool Vendor"" (2020) and by AdExchanger as the “Best Data-Enabling Technology” (2019), our platform meets the highest enterprise data privacy and security standards, including GDPR, ISO 27001 and CSA STAR. We serve the world's top brands, agencies and publishers across a dozen countries in Europe, North and Latin America, and APAC. Zeotap is also the founding member of ID+, a universal marketing ID initiative.

Responsibilities
You design, develop and implement products and modules considering aspects of performance, scalability and fault tolerance
You explore and operationalize new scalable technology in zeotap
You handle escalations and customer issues from time to time
You behave as a consultant to internal stakeholders and help design a creative solution for our customers
You are able to work on diverse technologies in Bigdata and Event Processing.
You are able to adapt and use emerging technology
You take complete responsibility for the feature/module
You need to mentor junior developers
You adhere to zeotap’s company, privacy and information security policies and procedures
You complete all the awareness trainings assigned on time

Requirements
4+ years of experience in building and deploying high scale solutions
Must have very good problem-solving skills and clear fundamentals of DS and algorithms
Expert coding skills in Java or Scala
Expert coding skills in Go or Python is a huge plus
Apache Spark or other Bigdata stack experience is a mandatory
High level and low-level design skills.
Deep understanding of any OLTP, OLAP, NoSQL or Graph databases is a huge plus.
Deep knowledge of distributed systems and design is a huge plus
Hands-on with Streaming technologies like Kafka, Flink, Samza etc is a huge plus
Good knowledge of scalable technologies involving Bigdata technologies
Bachelor or Master’s degree in information systems, computer science or other related fields is preferred

What we offer
Become part of a friendly, diverse team that values trustworthiness, agility, and a pioneer spirit
Join the company founded by successful entrepreneurs with a distinguished track record
Make an impact: at zeotap, your voice is heard, your opinion matters, your ideas change things
Work with cutting edge technologies and on-demand equipment
Your health is important to us: we offer a great health insurance (for you and your family)
Enjoy great work atmosphere, an awesome office, regular team events and much more
Get free lunches in the office, snacks and drinks in the evening, and other tax free benefits
We are family-friendly, respect your work-life balance and offer flexible office hours
Zeotap welcomes all – we are equal employment opportunity & affirmative action employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.
Interested in joining us?
We look forward to hearing from you!"
Senior Consultant - Deep Learning Engineer,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Senior Consultant - Deep Learning Engineer
Location: TRIL GTC
GCL: D1
Company
AstraZeneca is a global, innovation-driven bio-pharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.
Role
We are looking for a Deep Learning Engineer to join our AI Engineering team in Chennai. The ideal candidate will have industry experience working on a range of different Deep Learning fields, e.g. creating data preparation pipelines, modelling and training state of the art deep neural networks (CNNs/RNNs/LSTMs/Transformers) as well as deploying inference pipelines to process unseen data at scale. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery. You will work as part of a global team of deeply technical data scientists, knowledge engineers & machine learning engineers and have the chance to create tools that will advance the standard of healthcare improving the lives of millions of patients across the globe.
We are working in collaboration with our scientists to help develop better drugs faster, choose the right treatment for a patient and run safer clinical trials. Our team empowers our scientists from early development to the late stages in drug development, driving innovation and acting as a catalyst for the adoption of the latest advances in Artificial Intelligence and Data Science. You will work closely with scientists & product teams and learn to deliver DL solutions at scale within the AstraZeneca tech stack, whilst encouraging standard methodologies for DL across the company.
We are looking for deep learning engineers capable of building robust and accurate DL-based systems, tools, and services that serve as infrastructure for practically everyone in AstraZeneca. As a strong software leader and a specialist in building complex systems, you will be responsible for inventing how we use technology, Deep Learning and data to enable the productivity of AstraZeneca.
You will help envision, build, deploy and develop our next generation of data engines and tools at scale.
Key Accountabilities
Understand, develop and optimize highly scalable classifiers and regression models and tools demonstrating machine learning and statistics
Work collaboratively with other DL engineers globally on scientific problems such as audio analytics and image segmentation & classification.
Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)
Deploying machine learning solutions into production.
Optimizing solutions for performance and scalability.
Data engineering, i.e. ensuring a good data flow between database and backend systems with high performance data pipelines.
Implementing custom machine learning code.
Explain analyses and machine learning solutions to technical audiences
Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
Being an active member of the AI Engineering team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure. You will get involved in testing and assessing the quality of new tools. It’s also likely you’ll get involved in team recruitment, training provision and coaching
Candidate Knowledge, Skills and Experience
Essential
MS in Computer Science or related quantitative field or Ph.D degree in Computer Science or related quantitative field
2+ years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
1+ year of experience with one or more DL frameworks such as Tensorflow or PyTorch.
Experience with scientific and machine learning libraries e.g., SciPy, SciKit-learn, numPy.
Strong software development skills, with proficiency in Python or Scala preferred
Experience building large scale data processing pipelines
Experience with Cloud computing, Hadoop/Spark, SQL
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Creative, collaborative, & product focused
Desirable
Ability to work with loosely defined objectives and turning these into concrete machine learning problems
Experience training and deploying machine learning models at scale on distributed cloud environments
Experience with reinforcement learning is a plus
Other
The role will have no direct line reports, but task management responsibilities within project or services may occur
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Product Development Team Lead,"Madhapur, Hyderabad, Telangana",Signant Health,None,Organic,"Role Overview:
Signant Health innovates at the leading-edge of clinical research data, one exceptional service at a time. From the advanced technology of our eCOA electronic Clinical Outcomes Assessments flexible platform, to the efficiency of our scalable and configurable Randomization and Trial Supply Management (RTSM) Clinical IRT solution, to our science-focused Rater Training and Quality Assurance programs, Signant does it faster, better and with an eye on the future of our industry.

If you’re looking for a growing company with delighted customers, a dedication to superb products designed with the patient in mind, and a management team that allows you to make your mark on how the company evolves, we want to hear from you.

We are:
A company that offers a unique suite of solutions, with a unique perspective on clinical research development
Focused on bringing together best-in-class science, technology and service to drive superior clinical outcome results for our clients and for their patients
At the leading-edge of clinical research data, one exceptional service at a time
Experienced and have implemented over 250 studies in more than 80 countries
A company that takes great care to maintain our culture and ensure that each new team member enhances that culture
You are:
Ready to work in an inspiring team environment with an open communication culture
Creative and innovative
A detail-oriented problem solver who delights in adding value to products and their roadmap
Eager to stay abreast of emerging new software technologies, frameworks, and libraries, and identify where these could improve existing or new projects
Able to design, develop, and maintain front-end systems and back-end systems
Providing technical input to project-related decisions
Ready to use unit testing, integration testing, code coverage, and other tools to ensure correctness of software.
Drawn to Development because you like contributing to solid, well-made products
Eager to use your skills in a company with products that helps people
Key Accountabilities/Decision Making & Influence:
We are seeking an exceptional candidate to lead and produce software for our team.

This role will require an experienced Team Lead ready to play a key part in our software development efforts, interfacing directly with the engineering, product testing and product management teams to ensure superb-quality development and deployments of software enhancements. As the key lead on our software development, you will learn our innovative software suite from the inside out. You will help developers grow both technically and increasing their product knowledge. At a medium sized company, you will see the impact of your work daily as part of our rapid release schedule.

We pride ourselves on the quality of our systems and our ability to evolve products to anticipate client needs. As a Team Lead, you’ll combine organizational skills, expertise with software development, and a keen detail orientation to help ensure we settle for nothing less than the highest standards.

As a Team Lead, you will be contributing to team and software development needs:

Inspire and motivate teamwork for achieving goals
Help facilitate the day to day activities of a team of Product Developers
Be open to new ideas from the team
Provide oversight and ownership to a vertical area of one or more products
Contribute to a technical product roadmap
Provide technical leadership to drive the successful completion of development projects.
Create and/or approve technical design documentation
Evaluate and implement new technologies into the current development process
Assist in the creation and maintenance of technical standards
Act as a mentor to your team
Contribute to the creation of departmental procedure documents and working instructions
Work with Remote teams involving Product Management, Solution architects and peer development teams.
Provide regular update on progress of the Release
Knowledge, Skills & Attributes:
Required Skills/Experience
Eight+ years’ experience professionally developing software
Three+ years managing development teams in the range of 5 to 10 developers
Experience with Agile SDLC and DevOps concepts
Ability to build cloud native solutions in Azure leveraging Serverless architecture and PaaS services
Able to setup CI/CD pipelines for automated build/deploy with Azure DevOps or Jenkins
Expert in C#, and .NET Core
Solid work experience leveraging JavaScript and React
Proficient with Microsoft SQL Server
Experience with Containerization, leveraging Docker and Kubernetes
Fluency in English, both written and verbal.
B.Tech/M.Tech in any engineering preferably Computer science or MCA
INDHP1"
Data Engineer,"Bengaluru, Karnataka",IHS Markit,None,Organic,"Position: Data Engineer

Description of Duties
The Automotive Supply Chain and Technology team at IHS Markit is in search of a Data Engineer to support its global team's ongoing research and analysis efforts. The research team produces granular forecast dataset and written analyses on the supply chain of parts supplied to automakers with technology, supplier and logistic information. The team generate forecasts on technology trends through multiple research channels and by using many connected and disconnected data sources to drive the forecast.

The position covers an array of critical data-centric activities aimed at enhancing the efficiency of our 70+ strong research team, sustaining the increasing data complexity and most importantly supporting new product development at one of IHS Markit's fastest growing product lines. The position is based in Gurgaon or Bangalore, India and reports to our U.K.-based Data and Platform operations lead.

Responsibilities and duties
Understanding business requirements to create maintainable workflows e.g. inbound/input data from analysts and external sources to feed a set of interconnected data sets and calculations
ETL process design, implementation, maintenance and documentation for large inter-connected data sets
Data cleaning and manipulation of raw data to provide to Data Science team
Creation of logical and physical data models
Utilise existing database infrastructures as well as building new DB infrastructures as required
Data acquisition exploration
Create and maintain detailed documentation of workflows

Qualifications and skills
3+ years’ experience as a data engineer with data science touchpoints
At minimum, a degree in computer science, computer engineering or a related quantitative field with proven work experience in the data engineering/scientist field
Proven experience with SQL and NoSQL databases like Oracle DB, SQL Server, Cassandra, MongoDB, MySQL, Hadoop, Spark, AWS (EC2 and S3)
Proven experience with one or more programming/scripting languages (e.g. Python, R) is highly desirable
Knowledge of OLAP and ETL processes
Familiarity with data science platforms such as KNIME is a bonus
Knowledge of API creation and maintenance
Familiar with techniques to manage large databases, including partitioning, compression and indexes as well as data mining
Ability to build models (e.g. Linear regression, logistic, Markov models) a plus
Established MS Office skills, O365 desirable
Good communication skills, collaborative team spirit, curiosity to constantly keep thinking of unique approaches and solutions.
Ability to work independently.
Experience committing to deadlines whilst multi-tasking
-
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.
We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.
IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.
For information please click on the following links:
IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement
-
Current Colleagues
If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site."
Software Engineering Architect - Data Services,Remote,Data Direct Networks,None,Organic,"Overview:
DataDirect Networks (DDN.com) is a world leader in massively scalable storage. We are the leading provider of data storage and processing solutions and professional services that enable content-rich and high-growth IT environments to achieve the highest levels of systems scalability, efficiency and simplicity. DDN enables enterprises to extract value and deliver results from their information. Our customers include the world's leading online content and social networking providers, high performance cloud and grid computing, life sciences, media production organizations and security & intelligence organizations.
Job Description:
We are currently seeking a Data Services Software Architect
Job Summary:
Data Direct Networks provides multi-protocal access (Data Services) over its EXAScaler parallel file system. We are searching for a highly-skilled senior software engineer/architect to design the integration of open source protocol services to provide NFS, SMB, S3, HDFS, and other protocol access to this parallel file system and other advanced file systems. This engineer understands big data, issues with performance and scale, the specific technologies of CTDB/Samba/Ganesha, enterprise authentication and authorization through Active Directory, LDAP, and Kerberos, and Docker/containers. This role includes designing how to deploy CTDB/Samba/Ganesha in containers in such a way that deployment is simple and well-integrated into the product. This takes into consideration the full deployment and configuration experience of the end user, which includes integration with existing authentication/authorization services. This engineer will prototype/demonstrate technical solutions and communicate the high-level design to other engineers and participate in the implementation of the solution. This engineer will also describe various integration use cases and work with QA engineers to develop test plans that verify that our product meets the customer need. This engineer will make recommendations regarding what equipment is needed to verify the product.

Responsibilities for this role include but are not limited to:
High-level system product design
Technology demonstration / prototyping of key design components
Understanding end user use cases and communicating them to development and QA engineers
Evaluating, identifying, and prototyping new technologies focusing around high performance data I/O in a multi-node environment.
Designing, coding, prototyping, implementing and debugging the data services products.
Passion for technology outside the workplace with an interest in the latest open source framework/libraries/tools.
Team building, helping hiring talented individuals and promoting collaborative environment.

Qualifications for this role are:
12+ years of software development experience
Experience with at scale, high performance, highly available data systems.
Experience working in Linux, with In-depth knowledge of Linux operating systems internals, Kernel Development.
Experience with Samba, Ganesha, or equivalent implementation of SMB/NFS protocols
Strong experience of working in multi-threaded and distributed environment.
Proficient in data structures and algorithm.
Proven experience dealing with File System, I/O performance, operating system tuning is a plus.
Strong knowledge of Networking Concepts TCP/IP v4 and v6 and protocols such as CIFS, NFS, FTP, REST or S3.
Knowledge of the major computer languages is a must, including Java or C, C++, Python, Shell scripting, Perl, Ruby, PHP, MySQL, Linux, Redhat Linux, AJAX.
Ability to innovate, prioritize and multi-task.
BS or MS in Computer Science, or comparable experience (graduate degree is preferred).
DDN Core Characteristics:
DDN has a very strong orientation towards these 4 characteristics and any successful employee will demonstrate these capabilities:

Self-Starter - Takes independent action to identify and solve problems. Seeks out relevant information needed to make decisions. Gets involved with new initiatives.
Success/Achievement Orientation - Delivers quality results consistently. Targets, achieves (or exceeds) measurable results. Sets challenging goals, focuses on critical priorities, and is accountable.
Problem Solving - Recognizes problems and responds with a systematic assessment that identifies and addresses cause of issue. Practical, realistic, and resourceful.
Innovative - Builds and improves key business processes that enhance the effectiveness of DDN. Generates new ideas, challenges the status quo, and solves problems creatively.

DataDirect Networks, Inc. is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, gender expression, transgender, sex stereotyping, sexual orientation, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law."
Machine Learning Engineering Internship,"Bengaluru, Karnataka",Vumonic Datalabs,"₹10,000 - ₹15,000 a month",Organic,"About the company:
Vumonic Datalabs is a data intelligence company that is in the business of furnishing competitive insights and consumer behaviour data to online businesses.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Perform statistical analysis 2. Fine-tuning test results 3. Train and retrain systems 4. Work on frameworks 5. Develop deep learning systems to various use cases based on the business needs 6. Undertake machine learning experiments and tests
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 23rd Jul'20 and 28th Aug'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply
Number of internships/jobs available: 2
Categories: Engineering,Machine Learning,Data Science"
"Application Engineer, Corporate Engineering","Hyderabad, Telangana",Google,None,Organic,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.
Minimum qualifications:
Bachelor's degree in Computer Science, Engineering, related field, or equivalent practical experience.
Programming experience in Java, Python, Web Services (RESTful, SOAP), SQL.
Experience developing business application, system integration and/or IT development.

Preferred qualifications:
Master's degree in Computer Science, or related field.
12 years of relevant work experience in business application development/implementation.
Experience implementing, customizing and/or integrating third-party applications within business enterprise software.
Understanding of software implementation lifecycle (e.g., analyze, design, build, test, implement, support).
Excellent interpersonal, communication and analytical skills and a demonstrable bias toward action.
About the job
At Google, we work at lightning speed. So when things get in the way of progress, the Business Systems Integration team steps in to remove those roadblocks. The team identifies time-consuming internal processes and then builds solutions that are reliable and scalable enough to work within the size and scope of the company. You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation. Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently.
As an Application Engineer, you will develop business applications for Googlers that manage all aspects of Google's growth. You'll work in a dynamic environment that provides opportunity for you to learn new Google and third party technologies allowing you to solve impactful problems at scale.
The team identifies time-consuming internal processes and then builds solutions that are reliable and scalable enough to work within the size and scope of Google. You will listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation. Whether working on system processes or leveraging Google products for Googlers themselves, you'll help Googlers work faster and more efficiently.
Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
Responsibilities
Design, build, and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Build internal solutions, with custom front ends (web, mobile) and backend services that automate business processes.
Maintain highest levels of development practices (e.g. technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution) writing clean, modular and self-sustaining code, with repeatable quality and predictability.
Partner with product area business, engineering, privacy, security and legal to provide an easy on-ramp (or off-ramp) for the business application systems of acquisitions/spinouts and non-Google Alphabet entities.
Work with the program managers and analysts to create/lead the design and development of tools to support transition to end-state applications for various functional groups including engineering, HR, finance, supply chain, and business management.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
"Associate, Index Configuration Data","Gurgaon, Haryana",BlackRock,None,Organic,"About BlackRock
BlackRock’s business is investing on behalf of our clients, from large institutions to parents and grandparents, doctors and teachers who entrust their savings to us. We are committed to our clients—period. Our promise is to offer them the clearest thinking about what to do with their money and the products and services they need to secure a better financial future.
That’s why investors of all kinds have made us the world’s largest asset manager, entrusting us with trillions of dollars, and it’s why companies, institutions and global governments come to us for help meeting their biggest financial challenges.

Description
About this role
The Index Implementation team, part of the BlackRock Data & AI organization, is responsible for onboarding new or custom public indices on BlackRock’s proprietary Aladdin® end-to-end investment platform. BlackRock and its BlackRock Solutions (BRS) clients utilize these indices as an integral part of investment and risk management, serving as benchmarks for Mutual Funds, ETFs, and Hedge Funds, Pensions, and other products. Index Implementation works closely with index vendors such as MSCI, S&P, FTSE, and Markit Partners, as well as internal partner teams including Client Analytics, Portfolio Management, Relationship Management and other BlackRock Data & AI groups. Index Implementation is a diverse and distributed team that service clients in all spectrums of the financial markets.
Supply to all aspects of rolling out multiple concurrent new indices, across various asset classes and strategies in Aladdin, including vendor data acquisition, data mapping and normalization, process testing and automation, and quality control.
Provide high quality client service externally and internally. Address inquiries and resolve problems from clients and internal BlackRock partners.
Understand risk analytics of fixed income, equity and alternatives products to analyze index methodologies, collaborate with vendors, and build custom solutions the business.
Initiate and drive Index platform improvements to support new business needs, minimize risk, and improve quality.
Act as Business Analyst and Project Manager responsible for detailing client requirements, assessing potential solutions, and ensuring key achievements are met.
Bachelor’s Degree is required, with preference to business fields such as Finance, Accounting, or Economics, and technical subject areas such as Computer Science, Information Systems, or Engineering.
A “Student of the Markets” mentality: Intellectually curious with a passion for learning about the global financial markets and the investment management business.
Excellent verbal and written communication skills combined with an ability to connect across different functions and levels.
5+ years of experience, preferably in financial services.
Basic knowledge of SQL, UNIX, or Python is a plus.
Travel : No
Direct Reports: No
Licenses: No
About BlackRock
BlackRock’s purpose is to help more and more people experience financial well-being. As a fiduciary to investors and a leading provider of financial technology, our clients turn to us for the solutions they need when planning for their most important goals. As of June 30, 2020, the firm managed approximately $7.32 trillion in assets on behalf of investors worldwide.
BlackRock is proud to be an Equal Opportunity and Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, disability, protected veteran status, and other statuses protected by law.
BlackRock will consider for employment qualified applicants with arrest or conviction records in a manner consistent with the requirements of the law, including any applicable fair chance law.
Job requisition #
R201565"
"Analyst, Essential Medicines","Bhopal, Madhya Pradesh",Clinton Health Access Initiative,None,Organic,"Overview:
The Clinton Health Access Initiative, Inc. (CHAI) is a global health organization committed to saving lives and reducing the burden of disease in low-and middle-income countries, while strengthening the capabilities of governments and the private sector in those countries to create and sustain high-quality health systems that can succeed without our assistance. For more information, please visit: http://www.clintonhealthaccess.org

CHAI, in partnership with its India affiliate William J Clinton Foundation (WJCF), works in close partnership with and under the guidance of the Ministry of Health and Family Welfare (MoHFW) at the Central and States’ levels on an array of high priority initiatives aimed at improving health outcomes. Currently CHAI/WJCF works across projects to expand access to quality care and treatment for HIV/AIDS, Hepatitis-C, tuberculosis, cancer and immunization.

Background on Essential Medicines Program:

CHAI’s Essential Medicines program is an effort to scale-up access to treatment for Pneumonia & Diarrhea, which combined, kills over 1.5 million children every year. Working with the governments of five-high-burden countries (India, Kenya, Uganda, Ethiopia and Nigeria) and leading global institutions, CHAI is supporting intensified efforts at both global and country levels to plan, resource, and implement effective interventions for scaling-up access to treatment for these conditions. This is achieved by supporting Governments’ effort in improving access to oxygen and anti-biotics for pneumonia, and, zinc and ORS for diarrhoea.

In India, CHAI, in partnership with its affiliate William J Clinton Foundation, is building on its work on supporting efforts to reduce mortality among children below 5 years of age in Madhya Pradesh (MP), which accounts for approximately one eighth of total pneumonia mortality in the country.[1] Appropriate pneumonia treatment and care is constrained by primary dependence in rural areas on informal providers, who lack appropriate training and knowledge as also supply chain inefficiencies that hamper availability of essential medicines and commodities. Further, knowledge and skills gaps at mid-tier public health facilities lead to inconsistent and inaccurate pneumonia classification and higher burden on higher level healthcare facilities.

To overcome these challenges, CHAI/WJCF has been working with government to draft a comprehensive strategy to significantly improve treatment and care and, therefore, outcomes for children suffering from pneumonia. To that end, the program imparts skill-based training for providers at public health facilities, supports measures to improve quantification, procurement and distribution of essential medicines, helps mentor staff at various aspects of oxygen administration and supports improvements in availability of pulse-oximeters for increased hypoxemia screening. At the national level, the program has supported efforts in launching the revised Pneumonia Operational Guidelines and has supported the “Social Awareness and Action plan to Neutralise Pneumonia from Society” (SAANS) campaign to intensify action for reducing mortality due to childhood pneumonia.

Position:

The Essential Medicines program is looking for a highly motivated professional for the position of Analyst who will work closely with the Program Manager on project strategy and execution. The role entails working with an entrepreneurial mind-set and self-motivation. The candidate must be able to function independently, be flexible, and have strong commitment to excellence. We are looking for dynamic and exceptional talent looking to work in challenging environment. Demonstrated application of analytical skills and problem solving in complex environments would be essential. Previous exposure to strategy projects and working on outputs for senior leadership, especially with the government, would help bolster the application. This position will report to the Program Manager, Essential Medicines (EM) program.
Responsibilities:
Manage the overall analytics, data-systems and insight generation. Coordinate with internal stakeholders/team members to ensure timely delivery of the same
Work with state teams to monitor project achievements and address any issues/impediments earnestly.
Closely coordinate within the state and country teams to monitor and review the performance of the public sector field force.
Develop a dashboard framework for monitoring the overall performance of the project
Develop reports and presentation decks for sensitizing internal and external stakeholders about the projects/ programs
Effectively coordinate with the internal and external stakeholders to ensure timely delivery and progress on project Operational Plan
Support the Monitoring and evaluation team (M&E) internal and global team on the planning, implementation and evaluation of midline/end line surveys
Support CHAI's strategy for increased access by identifying areas with significant market and policy impact
Work with various stakeholders towards identifying potential opportunities in piloting innovative programs and global best practices in India
Undertake any other duties as requested by the Program Manager or Country/State Director
Qualifications:
Master’s/Bachelor’s degree in management, economics, engineering, computer science, statistics, operations research economics or allied areas
Minimum of 2 years of experience in private or public sector enterprise; in consulting, investment banking or insurance analytics
Excellent quantitative, problem solving, analytical and statistical analysis skills and experience of handling big datasets through use of software such as SQL, Oracle
Exposure to data visualisation tools such as TABLEAU/POWER BI, etc. will be an added advantage
Excellent knowledge of program implementation, trainings, monitoring and evaluation methods (qualitative and quantitative), including experience of developing trainings and monitoring and evaluation plans, tools, training materials, reports and summary forms
Ability to develop new and manage existing relationships with multiple stakeholders
Ability to work independently and effectively in high-pressure, fast-paced environment and handle multiple tasks simultaneously
Experience structuring and leading evidence-based decision-making processes
Excellent structured oral and written communication ability
#jobreference1"
Data and Geospatial Analyst II,India,Catholic Relief Services,None,Organic,"Data and Geospatial Analyst II - (200000EO)
Description

Job Title: Data and Geospatial Analyst II
Department: Global Knowledge and Information Management (GKIM)
Work Location: Remote
Reports To: Data, Knowledge Management and Communications Manager

Job Summary:
*Remote from India or remote internal staff*

Job Summary:

CRS has prioritized Information and Communications Technology for Development (ICT4D) as a core competency. As part of this core competency, CRS is developing ICT tools and associated skills to support activities across program areas, such as digital monitoring and evaluation and analysis of resulting data.

As a key driver of this core competency, the analyst provides internal data and geospatial analysis consultancy services dedicated to building capacity and supporting the successful and appropriate implementation of data and geospatial solutions. The analyst II will take on the most challenging assignments and create new advanced analytics processes that can be scaled. Additionally, the analyst is a key member of the ICT4D community within CRS and is active in promoting the smart and effective use of data and geospatial analysis to support CRS programming.

The data and geospatial analyst will develop map products, reports and/or dashboard applying data and spatial analysis techniques to multiple humanitarian aid, international development and other projects underway at Catholic Relief Services (CRS). These products serve as valuable communication tools to improve the efficacy of programs. Examples of similar work at CRS include: analysis of malaria knowledge, attitudes and practices to answer questions about where malaria education campaigns would have the greatest impact; and predictive analysis of walking paths to optimize placement of food distribution sites.
Responsibilities:

Build capacity in our team to: run advanced analytics processes including machine learning. automating analytics processes, database architecture, and simplifying processes.
Review, test and implement system changes to formulas and sheets.
Customer service: identify ways we can build efficiencies and automate or offload processes in data or system issues.
Work autonomously and identify needs as they arise, be able to prioritize workflow and identify ways to automate or delegate repetitive tasks
Visualization
Evaluate publicly available data sources and their fitness for use.
Evaluate data that will be collected via mobile devices and identify the best approach to visualize it using ArcGIS suite of tools and/or PowerBI.
Improve the visualization of advanced analytics so that data visuals are easy to interpret and are in line with CRS data visual branding standards.
Spatial Analysis
Utilize machine learning in spatial analysis workflows and satellite imagery analysis.
Build the teams capacity on spatial analysis, including; object-oriented classification, remote sensing, interpolation, and prediction, with the possibility of 3D modeling.
Create automatic workflows to replicate spatial analysis.
Promote the workflows in easily accessible language in webinars, newsletters, and one pagers.


Enterprise GIS
Champion the opportunities that GIS offers to CRS and contribute to the evolution and implementation of the agency’s GIS roadmap.
Incorporate geospatial technology into enterprise systems (examples include SalesForce and ERP) and define common processes for GIS implementation efforts.
Lead GIS system definition efforts including elicitation of business needs, definition of potential solutions to meeting those needs and incorporation of GIS into proposals.
Proactively identify areas for capacity development, develop and curate advanced GIS training curricula/content and deliver trainings both onsite and remotely.
Assess and remain current about emerging trends in the use of spatial data in the relief and development sector.
Data Analytics
Coordinate/lead research engagements with external organizations to create new analytics processes that can be scaled to new country programs.
Coordinate an external analytics support group to bolster CRS analytics ability
Attend meetings with external advisors in data analytics
Coach team members in their external research engagements, assuring clarified expectations and a positive experience for both parties.
Provide consultancy to field projects on best use of data analytics and visualization.
Ensure deployment of
o Integration interface between standard forms and legacy data
o Data Warehouse (wherever applicable)
o Reports and Dashboards
Enable smarter business processes—and implement analytics for meaningful insights.
Work with stakeholders throughout the organization to identify opportunities for leveraging data to drive projects.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Promote and contribute to the data security approach throughout the support process.
Help build a culture of data use and decision making
Key Working Relationships:
CRS’ ICT staff; technical experts across sectors; monitoring & evaluation staff; field project staff; various HQ staff; owners of CRS business systems; and technology vendors.
Qualifications:
Education / Certifications
Master’s degree in data science, Geographic Information Systems related field or equivalent experience.
Certified Analytics Professional (CAP), or Data Science Council of America (DASCA) Principle Data Scientist (PDS) or higher, or Open Certified Data Scientist (Open CDS) preferred.
Esri ArcGIS Desktop Certification (10.1 or higher; Associate or Professional level)
Experience with UML 2.0 highly preferred.
ITIL Foundation Certification desired.
Ability to code in R and Python preferred.
General Experience
Experience delivering training on data analysis to both technical and non-technical audiences; both in person and remotely.
Experience developing work plans (project plans) that address all phases of solution delivery and managing project risk and dependencies.
Good understanding of business analysis and business process mapping (using industry standards); ability to capture as-is and to-be business models.
Experience with vendor selection and management including developing RFPs, SOWs and managing/monitoring vendor work activities
Technologies
Data analysis software
Experience using ArcGIS Online strongly preferred; experience using ArcGIS Pro and Collector for ArcGIS desired
Demonstrable experience applying core concepts of cartography to quality map production
Demonstrable experience applying spatial analysis to solve real-world problems
Strong understanding of relational databases (SQL Server strongly preferred), data modeling and general geodata management technologies.
Ability to code in python, and R preferred
Personal/Professional Qualities:
Ability to communicate technical concepts to non-technical audiences, including briefings with agency leadership.
Ability to represent the agency in external forums.
Excellent interpersonal, presentation and oral and written communication skills.
Ability to thrive as part of a geographically distributed team.
Ability to work independently and be self-driven.
Highly responsive with an attitude of service.
Attention to detail and organized.
Travel:
This position will require 10-20% international travel, including to resource poor locations.
Supervisory Responsibilities:
Supervise TDY and intern staff as needed.
Language Required:
Must be fluent in written and spoken English; French or Spanish fluency desirable.

Qualifications

Basic Qualifications
Bachelor's degree in Cyber or IT related field or equivalent experience
Minimum of 5 years' experience in Information Security administration
Experience with Microsoft Windows operating systems, Office 365, Enterprise Mobility and Security (EMS) and Enterprise Mobility Management (EMM)
Experience with Privilege Access Management solutions, Least privilege Access Management platforms and multi-factor authentication solutions among other technologies
Experience in managing Information Security compliance
In depth knowledge of Information risk concepts / relating business needs to security controls

Agency-wide Competencies (for all CRS Staff)
These are rooted in the mission, values, and guiding principles of CRS and used by each staff member to fulfill his or her responsibilities and achieve the desired results.
Integrity
Continuous Improvement & Innovation
Builds Relationships
Develops Talent
Strategic Mindset
Accountability & Stewardship

***Our Catholic identity is at the heart of our mission and operations. Catholic Relief Services carries out the commitment of the Bishops of the United States to assist the poor and vulnerable overseas. We welcome as a part of our staff people of all faiths and secular traditions who share our values and our commitment to serving those in need. CRS’ processes and policies reflect our commitment to protecting children and vulnerable adults from abuse and exploitation.
Disclaimer: This job description is not an exhaustive list of the skill, effort, duties, and responsibilities associated with the position.

CRS' talent acquisition procedures reflect our commitment to protecting children and vulnerable adults from abuse and exploitation.

EOE/M/F/D/V - CRS is an Equal Opportunity Employer. (For all US and International positions)

Primary Location: ASIA-IN-Uttar Pradesh
Job: ICT
Organization: Catholic Relief Services
Schedule: Regular
Shift: Standard
Employee Status: Individual Contributor
Job Type: Full-time
Job Level: Day Job
Travel: Yes, 20 % of the Time
Job Posting: Jul 6, 2020, 12:40:17 PM"
Global Incident Analyst,"Hyderabad, Telangana",Pinkerton,None,Organic,"We are as invested in your career as you are.
As you navigate through these uncertain times, know that Pinkerton has been a stable, thriving corporation for over 170 years. As recognized leaders around the globe in the corporate risk management industry, you can rest assured that joining us now means moving to a future-looking company. We are here today, will be here tomorrow, and are a thriving community of over 2,000 risk management professionals.
This is just one of the several exciting career opportunities that are currently available.
JOB SUMMARY: The Global Incident Analyst will utilize internal processes and external tools to identify real or potential risks related to the safety and security of the client personnel and assets. The Analyst accurately synthesizes emerging and developing information, communicates actionable intelligence, contributes to travel risk and threat assessment products, and intakes emergency phone calls and provides support during crisis situations.
Details
Essential Functions
The functions listed describe the business purpose of this job. Specific duties or tasks may vary and be documented separately. The employee might not be required to perform all functions listed. Additional duties may be assigned, and functions may be modified, according to business necessity.
All assigned duties or tasks are deemed to be part of the essential functions, unless such duties or tasks are unrelated to the functions listed, in which case they are deemed to be other (non-essential) functions.
Employees are held accountable for successful job performance. Job performance standards may be documented separately, and may include functions, objectives, duties or tasks not specifically listed herein.
In performing functions, duties or tasks, employees are required to know and follow safe work practices, and to be aware of company policies and procedures related to job safety, including safety rules and regulations. Employees are required to notify superiors upon becoming aware of unsafe working conditions.
All functions, duties or tasks are to be carried out in an honest, ethical and professional manner, and to be performed in conformance with applicable company policies and procedures. In the event of uncertainty or lack of knowledge of company policies and procedures, employees are required to request clarification or explanations from superiors or authorized company representatives.
The Essential Functions Include:
Represent Pinkerton's core values of integrity, vigilance, and excellence.
Continuously monitor worldwide events in real-time through internal and external tools and platforms to identify developing real or potential safety and security incidents.
Evaluate and assess identified incidents for real or potential impact to company personnel and assets.
Synthesize data and compose accurate and timely communications, according to established procedures and templates, to notify relevant stakeholders (leadership, Regional Security Managers, employees, travelers, etc.).
Support security managers as instructed, including in crisis situations.
Analyze daily developments to identify trends and patterns, forecast future behavior, and make recommendations.
Compile regular bulletins.
Contribute to tactical and/or strategic threat assessments for locations or events.
Assist company personnel in identifying and meeting requirements, and obtaining proper permissions, for proposed travel to high-risk locations.
Serve as the main point of contact for the intake and escalation of safety and security incidents as reported by company personnel and assets.
All other duties, as assigned.
Minimum Hiring Standards
Additional qualifications may be specified and receive preference, depending upon the nature of the position.
Must have a High School Diploma or GED.
Must be willing to participate in the Company's pre-employment screening process, which may include drug screen and background investigation.
Must be at least 18 years of age.
Must have a reliable means of communication (i.e., email, cell phone).
Must have a reliable means of transportation (public or private).
Must have the legal right to work in India.
Must have the ability to speak, read, and write English.
Education/Experience
Bachelor's degree preferably in international affairs or political science. In lieu of degree, three to five years of military intelligence or corporate security intelligence experience.
Competencies
Security, safety, or emergency operations center experience.
Intelligence analyst experience within a corporate set-up.
Traveler tracking software experience.
Familiar with open-source intelligence and monitoring tools.
Knowledge of and active interest in global geopolitical and security developments.
Able to quickly adapt priorities.
Client and results orientated.
Able to effectively comprehend large amounts of emerging and evolving data.
Strong attention to detail.
Critical thinking skills.
Able to make informed and sound decisions.
Serve as a positive and effective team member.
Able to effectively manage multiple projects simultaneously in a demanding and fast paced environment with varying deadlines and time constraints.
Effective verbal and written skills for a global audience.
Computer knowledge; Microsoft Office.
Working Conditions
With or without reasonable accommodation, requires the physical and mental capacity to perform effectively all essential functions. In addition to other demands, the demands of the job include:
Must undergo and meet company standards for background and reference checks, drug testing, and behavioral selection survey.
Maintain composure in dealing with authorities, executives, clients, staff, and the public occasionally under conditions of urgency and in pressure situations.
Exposure to sensitive and confidential information.
Regular computer usage.
Ability to handle multiple tasks concurrently.
Must be able to see, hear, speak, and write clearly in order to communicate with employees and/or customers.
Manual dexterity required for occasional reaching and lifting of small objects and operating office equipment.
Close and distance vision and ability to adjust focus.
Must be able to work rotating shifts including nights, weekends, and holidays for a 24/7/365 security operation.
Pinkerton is an equal opportunity employer and provides equal opportunity to all applicants for all positions without regard to race/ethnicity, color, national origin, ancestry, sex/gender, gender identity/expression, sexual orientation, marital/prenatal status, pregnancy/childbirth or related conditions, religion, creed, age, disability, genetic information, veteran status or any protected status by local, state, federal or country-specific law."
Data Scientist – 2 Positions,"Aundh, Pune, Maharashtra",TeamPlus Staffing Solution Pvt Ltd,None,Organic,"Gender : Male/Female
Industry : IT – Software
Job Role & Responsibilities:
2-4 years of experience in the field of Data Science / Machine Learning.
Should have built and deployed models at scale.
In-depth knowledge of Time Series Modelling, LSTMs, Regression techniques, Decision
trees. Classification algorithms like Neural Nets, SVMs. Clustering algorithms like KNNs,
Expectation Maximising algorithms, Fuzzy models – FCM.
Experience writing SQL queries and handling large amounts of data.
Experience bringing models in production.
Experience with AWS Athena, AWS Sagemaker, and other AWS services like EC2, S3, Lambda
(or other equivalent services from another Cloud platform)
Good written and oral communication skills.
Skills:
Knowledge of Data Engineering
Good to have knowledge of deep learning algorithms like RNNs, CNNs etc.
Good to have knowledge of TensorFlow, PyTorch, PySpark, MXNET etc
Joining : At the earliest"
Scientist Toxicology,"Mumbai, Maharashtra",Johnson & Johnson Family of Companies,None,Organic,"Caring for the world, one person at a time has inspired and united the people of Johnson & Johnson for over 125 years. We embrace research and science - bringing creative ideas, products and services to advance the health and well-being of people. Every day, our more than 130,000 employees across the world are blending heart, science and ingenuity to profoundly change the trajectory of health for humanity.
Our Consumer Business touches a billion lives around the world and works with the vision of 'Bringing science to the art of healthy living'. In India, the company touches the lives of consumers through businesses spanning baby care, women's health, beauty, oral & wound care and over-the-counter-products which are endorsed by healthcare professionals around the world. In India, the company touches the lives of consumers through Baby Care, Women’s Health, Beauty, Oral & Wound Care and OTC. Some of our key brands include Johnson's® Baby, Stayfree®, Clean & Clear™, Band-Aid®, Listerine®, ORSL and Benadryl®.
Job Responsibilities:
Literature search & safety data (preclinical and clinical) collection for ingredient and consumer products safety assessment.
Literature review for hazard assessment of ingredients intended to be used in consumer products.
Assessment of fragrances and flavors used in consumer products.
Toxicology risk assessment for formulations for cosmetic applications including Margin of safety calculation.
Assessment of skin tolerance of cosmetic ingredients and products from preclinical and clinical perspectives.
Review and Interpretation of clinical skin safety studies (patch test, phototoxicity, irritation and sensitization studies)
Review of products at different stages of development cycle.
Assessment of OTC products and impurity qualification.
Preparation of technical justification reports for regulatory submission.

Qualifications
Minimum required Qualification / Experience / Exposures:
Master’s degree/ Ph.D. in toxicology, pharmacology or relevant science discipline.
Masters with 2-3 years of experience in the field of consumer product risk assessment or other relevant Toxicology and/or Clinical safety (skin tolerance) experience. For candidates with Ph.D. in Toxicology, fresh candidates would also be considered.
Diploma in clinical sciences preferred.
Knowledge of in silico tools for toxicity prediction, databases for literature search.
Desirable: Knowledge of regulatory requirements for product safety submissions and experience in medical writing.
requirements may limit your candidate pool, thus impacting diversity and inclusion.]
Are you ready to impact the world?
Johnson & Johnson offers an unusual experience to professionals looking for an opportunity to work with hardworking people who share your real passion for caring in an environment that empowers you to drive your own career.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
This description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job.

Primary Location
India-Maharashtra-Greater Mumbai-
Organization
Johnson & Johnson Private Limited (8080)
Job Function
R&D
Requisition ID
2005840451W"
Software Engineer – Internal Applications (Intern) - India U...,"Bengaluru, Karnataka",Cisco Systems,None,Organic,"Bachelor’s or Master’s Job Description – Software Engineer – Internal Applications
In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!
We are Innovators
We drive innovation to propel business transformation while maintaining operational quality.
We are Accelerators
We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.
We are Transformers
As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients.
What You’ll Do
Team Description
Apply principles and techniques of engineering, mathematics, and computer science to the design, development, and testing of business software applications. May work as a member of a scrum team across the entire software development lifecycle.
Designs, develops, and improves software applications / platforms. Multi-facet role that may provide the opportunity to work in any part of the development stack across diverse software languages.
Develops software and tools in support of design, infrastructure and technology platforms, including applications, operating systems, compilers, routers, networks, utilities, databases, cloud-based and Internet-related tools. Scales systems sustainably through mechanisms like automation, and evolves systems to improve reliability, supportability and velocity.
Build high performance, horizontally scalable, low latency service using the latest tech nologies and handle information at massive scale.
Evaluate and leverage new technologies in the product architecture
Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists.
Software Engineer – Internal Applications
Problem solving instincts / abilities
Passion about technology and building software applications, with object-oriented design, test driven development and Continuous Integration / Delivery
Ability to work efficiently as part of a collaborative team
Ability to work cross-functionally is solving complex problems
Proficient in general purpose programming languages (GoLang, Java, JavaScript, C/C++, Python, NodeJS) and development technologies (GIT, JIRA). and database technologies such as relational (e.g. Oracle), NOSQL (e.g. Mongo), Big data (e.g. Hadoop, SnowFlake).
Proficient in Cloud, Cloud Connector, and Container technologies such as AWS, GCP, Azure, CloudRun, Knative, Kubernetes, and APIs.
Proficiency of CI/CD tools, security mindset and orchestration/config mgmt/IaC tools such as terraform, ansible, puppet, etc.
Familiar with business/ERP applications such as Salesforce, Oracle and SAP and integration with other internal applications.
Grasp of distributed systems and micro services
Solid programming background in an object-oriented development and Design Patterns
Understanding of threads, synchronization, locks, concurrent programming and load balancing
Who You Are Currently pursuing a Bachelor’s or Master’s of Engineering degree in Computer Science or Information Science CGPA of 8.0 (out of 10) and above The requirement is for 2021/22 passout only Excellent written and verbal communication skills. Must be fluent in English. Comfortable in fast-paced and dynamic environments
Why Cisco
At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!
Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
Data curator and Analyst,"Bengaluru, Karnataka",Genbios,None,Organic,"Please email your resume only to info@genbios.in

Data curator and Analyst
Qualification: Graduate/ Post-graduate/ Diploma in Bioinformatics
The job profile includes
Literature survey
Collection and curation biological data
Bioinformatics analysis of data
Database creation and management
Skill set:
Bioinformatics: A complete knowledge of the most commonly used bioinformatics databases and tools
Information Science: Good knowledge in application of various programming languages such as Perl, Perl-CGI, Java, MySQL, PHP and related technologies for Bioinformatics. Experience in Linux environment is an advantage
Life sciences: A very sound basic knowledge of biology is necessary.
Good communication skills, fluent in reading and writing English, ability to work in teams, independent and innovative thinking, enthusiasm at work and an open mindedness for learning."
Software Engineer – Cloud Application Development (New Grad)...,"Bengaluru, Karnataka",Cisco Systems,None,Organic,"Job Description – Software Engineer – Cloud Application Development
In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!
We are Innovators
We drive innovation to propel business transformation while maintaining operational quality.
We are Accelerators
We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.
We are Transformers
As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients. What You’ll Do
Team Description
Cisco CX Engineering & Product Incubation is a global team of 1,200 engineers, designers, researchers and product management experts located in major hubs of Bangalore, Krakow, Raleigh, San Jose and Toronto. They create world-class digital experiences to support services offers and maximize customer value from the Cisco technology portfolio. Their work is part of the larger Cisco transformation from a hardware-centric company to one that is leading the way in meeting customers' changing needs through cloud and As-a-Service offerings.

A key focus for the team is the development of the CX Success Tracks suite of services, which digitally connect customers with the right expertise, insights and learning at the right time, accelerating time to value from their technology investments. These benefits are accessed through the CX Cloud, a single digital interface that provides a personalized, use-case guided approach that speeds achievement of defined business outcomes, across architectures.
You will work as part of a SCRUM team building and developing our Cloud based platforms and applications and applying principles and techniques of software and platform component development. You will be an integral part of the teams building our next generation SaaS applications that have a direct impact on the customers we serve.

You will have the opportunity to work closely with seasoned software engineers and architects developing software and tools in support of technology platform, infrastructure, SaaS applications, databases and others win a cloud-native environment. You will be part of a team that is focused on building a true cloud native SaaS application that is secure, stable, reliable and scalable.

Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists. We provide a great learning experience and also have developed a program to help our University Hires transition to true professionals.
Software Engineer – Cloud Application Development
Solid fundamentals of Data Structures, Algorithms, Object oriented design and programming
Strong knowledge on Unix/Linux systems and Unix scripting
A good understanding of Cloud based application development (using Docker,
Kubernetes, AWS services) and think about security and scalability from group up
Solid understanding of computer science fundamentals and software engineering with
an aptitude for learning new technologies
Strong knowledge of programming and scripting languages like JAVA, python, Scala,
GoLoang etc
Strong testing inclination to ensure programs are comprehensive and well tested for all
use cases
Exposure to debugging application programs along with development and debugging tools
Familiar with more than one development environment, well-versed with at least one
Interest in User experience and User interface design and development
Possess creative problem solving skills and excellent troubleshooting/debugging skills
Familiar with CI/CD tools namely GIT, GitHub, Jenkins, Drone etc Who You Are
Recent graduate or on your final year of studies towards a Bachelor’s or Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering, related majors such as Math, Physics
Minimum of an 8.5 GPA or higher
The requirement is for 2021/22 passout only.
Solid understanding of computer science fundamentals and software engineering with an aptitude for learning new technologies
Strong knowledge of programming and scripting languages
Possess creative problem-solving skills and excellent troubleshooting/debugging skills
Experience in establishing and sustaining excellent relationships with the extended team
Excellent verbal and written skills
Why Cisco
At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!
Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
Mobile AI Engineer - NLP & Speech Tech,"Chandigarh, Chandigarh",DataToBiz,"₹6,00,000 - ₹10,00,000 a year",Organic,"DataToBiz is an AI and Data Analytics Services startup. We are a team of young and dynamic professionals looking for an exceptional Mobile AI Engineer to join our team in Chandigarh. We are trying to solve some very exciting business challenges by applying cutting-edge Machine Learning and Deep Learning Technology.
Being a consulting and services startup we are looking for quick learners who can work in a cross-functional team of Consultants, SMEs from various domains, UX architects, and Application development experts, to deliver compelling solutions through the application of Data Science and Machine Learning. The desired candidate will have a passion for finding patterns in large datasets, an ability to quickly understand the underlying domain and expertise to apply Machine Learning tools and techniques to create insights from the data.
Responsibilities:
* As a Mobile AI engineer on our team, you will be responsible for solving complex data problems for various clients using deep learning techniques.
* Work with the team to extract and transform natural language data from audio and text on the mobile native application.
* Develop and implement a framework for mobile processing of language syntax and semantics as well as contextualization of audio and textual data using python
* Develop strategies and implement methods to pass NLP techniques to classification algorithms.
* Execute project plan to meet requirements and timelines.
* Identify success metrics and monitor them to ensure high-quality output for the client.
* Deliver production-ready models that can be deployed in the production system.
* Understand and identify appropriate data sources required for solving the business problem at hand.
Requirements
* 2+ years of working with Python, Machine learning with exposure to one or more DL frameworks like Tensorflow, Keras, Caffe, MXNet etc
* Minimum 2 years experience in text representation techniques and NLP algorithms to succeed in this role along with hands on Speech Analytics
* Exposure to Deep Learning algrithm implementation in either speech analytics or NLP domain
* Exposure to ML/DL techniques and algorithms to work with different data formats including voice and text unstructured data
* Strong verbal and written communication skills with other developers and business client
* Android or iOS experience will be advantageous
* Exposure to DL Model optimization & transfer learning techniques
Job Type: Full-time
Salary: ₹600,000.00 - ₹1,000,000.00 per year
Experience:
Full time Work: 2 years (Required)
NLP or Speech Tech: 1 year (Required)
Deep Learning: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19"
Associate Engineer,"Pune, Maharashtra",TIBCO Software,None,Organic,"In this role you will be working in the design, development in the following areas
Rest API
Analytics using technologies like Airflow, S3, Redshift
Product feature development using .net stack
UI development
Realtime transaction engine
What You'll Do
Technical design and development to make Reward features the best
Coding and code review for peers and do your own QA
Develop and present proof of concept in newer technologies to validate the stack of products we intend to use
Bug fixes as required for releases
Follow the development processes as required
Self-motivated and able to work independently as well as collaboratively in team environments
Who You Are
1-3 years overall experience
Microsoft technologies (C#, ASP.Net)
Good knowledge in Data Science, Statistics.
Development experience in Analytics using Python or R
Experience in database tools: Microsoft SQL Server, AWS Redshift, Hadoop, Airflow
Design and implement data transfer framework using tools like Airflow, ETL experience
AWS services knowledge - Console login, S3 (importing and exporting data)
Knowledge in Data warehouse
Exposure to realtime and predictive analytics"
Principal Data Scientist,India,CereSight,None,Organic,"Location:: Anywhere in India (remote)
Key skills:: Machine Learning Algorithms
Desired Candidate Profile::
We are looking for AI engineers who are as passionate as we are about artificial intelligence, advancing science, and inventing the next generation of intelligent machines.
We are hiring for candidates with 4+ years hands on development in experience in ML/AI.
Knowledge in a broad range of machine learning areas, including: Deep learning, including novel architectures with attention and memory, supervised learning, semi-supervised and unsupervised learning, including generative models, Reinforcement learning, Meta-learning, Multi-task learning, transfer learning, few-shot learning, continual/lifelong learning, Interpretability, fairness, accountability of machine learning models, Brain-inspired machine learning algorithms, Optimization for AI/ML, Bayesian learning, graphical models, and causal models. Familiarity with Big Data ML toolkits, such as Tensorflow, Spark ML, or H2O
You will work on the most cutting-edge, exciting projects that have immediate use in the industry. Your creativity and innovative problem solving will be essential to the success of our team and the company.
Reach out to us if you have solved real-life problems at scale utilizing message queueing (Apache Kafka, MS EventHub, or equivalent) and streaming event processing technologies (Apache Storm, Apache Spark, or equivalent), applied machine learning and AI algorithms to very large datasets at scale.
Education:: - Bachelors/ Masters / Phd
We think the knowledge acquired by earning a doctorate or master’s degree in Computer Science with AI as a specialization would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time
Company Profile: This is the right place for you, if want to work in
A Data Science and Big Data technology start-up.
A place where you would want to create value for yourself, and our customers
An environment that supports your personal growth
Culture that believes the greater priorities in life are family, health and integrity
Group of the best in class professionals who are excited about the work they do
Contact::
Sangeetha: sangpraman@gmail.com, +919655998843"
Data Engineer,"Jadavpur, Kolkata, West Bengal",KPC Medical College & Hospital,None,Organic,"Qualification-Bachelor degree or equivalent professional experience can be accepted in lieu of education. Specifications: Education & Experience Requirements: BA/BS from a College or university and/or related experience and/or training or equivalent combination of education and experience in Computer Science, Data Engineering and Analysis Hands on experience with Microsoft Stack- SQL SSIS, SSAS, SSRS etc. Preferred experience with Agile development process and SDLC Preferred experience with large scale data lake or warehouse implementation and support Preferred experience in hybrid cloud (On prem, AWS/Azure) environment Desire to provide outstanding customer service.
Job Summary-Provides the business knowledge and technical skills to implement technical strategies, evaluate products and provide a superior level of technical support. Data Engineer will be responsible for implementing ETL solutions that deal with various types of challenging data and should also possess knowledge of SQL, PL/SQL (procedures, functions) and scripting languages. The ideal candidate should have outstanding analytical and problem-solving skills and a good grasp of the technical side of business intelligence and always keep up to date with the latest BI tools and technologies. 4+ years of IT and business/industry work experience developing data or software applications including: analysis, design, coding, testing, deploying and supporting of applications Research and deploy new technologies to assist data access, integrity and availability Proven experience (minimum 2 years) with one or more of the following database systems and tools in a Windows environment is required: MS SQL Server (T-SQL, SSIS), Oracle, SSRS, SSRS, Tableau or any visualization tool experiences are a plus. Integrate data from multiple disparate systems - using SQL Server, Oracle, PL/SQL, SFTP process, scripting etc. Develop and optimize complex scripts in MS SQL to meet organizational requirements for reporting, BI and analytics Documental requests from business system owners for data access, integrations and reporting According to Company’s SDLC and Change Management. Collaborate with App/Dev, Habit IT and business system owners on resolution to complex/challenging issues that arise out of data access, integrity, availability and transformation Work collaboratively across the organization to address and predict data performance bottlenecks Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format. Utilize a combination of open source and in house developed software to meet company goals. Possess a sound understanding of areas of Computer Science such as algorithms, data structures, object-oriented design, and databases. Familiarities with Shell, Batch, PERL, Python/R and Machine learning concepts are a plus.
Send your resume to [email protected]"
Data Scientist (Machine Learning)/Artificial Intelligence,"Lucknow, Uttar Pradesh",MNL GLUCK SERVICES PVT. LTD,"₹30,000 - ₹60,000 a month",Organic,"This is an individual contributor role in areas of AI (ML, DL and NLP). This is a hands-on experience role for developing large scale B2C applications.
You will be responsible for:
- Developing large scale B2C systems/modules
- Developing prototype for various new business use cases
- Taking end-to-end ownership of business use cases – Define, POC, Develop, Deploy and Maintain
- Building Machine learning models for Predictions, Image processing, Natural Language Processing and other related areas.
- Building Large scale system for Video, Audio, Image and Text analysis AI system
- Implement and experiment with different features and architectures for Deep-Learning models for NLP
Minimum Skills Required:
- B.E, B.Tech, M.Tech in Computer Science, EC, Mech, IT or equivalent work experience
- 3+ years of data science / mining experience;
- Knowledgeable in one or more of the following : Machine Learning / Information Retrieval / Deep Learning / NLP
- Excellent knowledge of at least two coding languages like Python, Java, Scala, R
- Language, SQL, ETL Tools, Perl and Pig;
- Should have worked on different tools like Java, SQL, Python, etc.;
- Good experience with SQL, Linux shell scripts, Perl, and AWK;
- Domain knowledge in at least two industries
- Overall knowledge of Business Intelligence; in particular, data modeling, ETL, and reporting tools;
- Extensive hands on experience working with very large data sets, including statistical analyses, data visualisation, data mining, and data cleansing/transformation;
Under-the-hood knowledge of many of these machine learning concepts:
- Supervised/unsupervised learning, loss functions, regularisation, feature selection, regression/ classification,
- Cross-validation, bagging, kernel methods, sampling, probability distributions;
- Experience prototyping and developing data mining solutions using statistical software packages (R, H2O);
- Excellent verbal and written communication;
- Good analytical and interpersonal skills;
- Strong ability to communicate deep analytical results in forms that resonate with scientific and/or business collaborators, highlighting actionable insights;
Job Type: Full-time
Salary: ₹30,000.00 - ₹60,000.00 per month"
Full Stack Developer,"Chennai, Tamil Nadu",Cache digital,"₹12,000 - ₹30,000 a month",Organic,"Job Description
The Full Stack Web Developer (FSD) will be responsible for designing and developing a web-based biomechanics analysis platform tailored specifically for the company’s markerless motion capture and video data. The aim of this project is to develop a web-based platform, accessed through the company’s website, to aid front office personnel, coaching staff, and players in the analysis, visualization, and reporting of KinaTrax’s data. Additionally, the FSD will support future web development initiatives of the company.
Essential Job Responsibilities
The FSD performs the major functions listed below. The position may require additional duties/responsibilities that may not be outlined below, and specific functions are subject to change.
Designing and developing a web-based biomechanical analysis platform tailored specifically for use with the company’s markerless motion capture and video data.
Developing front end website architectures.
Designing user interactions on web pages.
Developing back end website applications.
Creating servers and databases for functionality.
Ensuring cross-platform optimization for mobile devices.
Ensuring responsiveness of applications.
Working alongside biomechanists and data scientists for core functionality.
Working alongside graphic designers for web design features.
Designing and developing APIs.
Troubleshooting, debugging, and upgrading software.
Designing and developing security and data protection measures.
Seeing through a project from conception to finished product.
Meeting both technical and consumer needs.
Writing technical documentation.
Staying abreast of developments in web technology.
Supporting the company’s future web development initiatives.
Designing and developing unit tests.
Participating in code reviews.
Qualifications & Requirements
The following qualifications are the minimum requirements necessary to successfully perform this role. However, any equivalent combination of experience, education and training, which provides the necessary knowledge, skills and abilities, would be acceptable, subject to any legal and/or regulatory requirements.
Degree in Computer Engineering, Computer Science or equivalent disciplines.
Proficiency with fundamental front-end languages such as HTML, CSS and JavaScript.
Proficiency with Angular JS and familiarity with other JavaScript frameworks such as React.
Proficiency with ASP.NET Core and familiarity with other server-side languages such as Python, Ruby, Java, and PHP.
Proficiency with MySQL and familiarity with other database technologies such as MSSQL, Oracle and MongoDB.
Proficiency with Microsoft Visual Studio.
Proficiency with web servers, such as IIS and Apache, and UI/UX design.
Experience in software engineering practices, including but not limited to software design and implementation, unit testing, code reviews, continuous integration, source control, and coding standards compliance.
Experience with Git is preferred.
Experience interfacing with both internal team members and external customers as part of a solution-based service process.
Experience troubleshooting and responding to customer concerns.
Proven record of being reliable and accountable for all aspects of their job.
Excellent analytical, interpersonal and communication skills with the ability to communicate complex technical issues in an easy to understand manner.
Ability to work in a fast-paced, self-directed, entrepreneurial environment.
Resourceful, with the ability to work independently.
Strong time management skills.
Ability to adapt to changing circumstances.
Decision-making, problem resolution and creative thinking skills.
Attention to detail.
Ability to multi-task activities with shifting priorities. Able to work productively in a pressurized environment.
Ethical and trustworthy.
Working Conditions
Extended periods of computer usage.
Occasional travel to meet with clients.
Relocation
None required. Remote work.
Job Type: Full-time
Salary: ₹12,000.00 - ₹30,000.00 per month
Experience:
Web Development: 3 years (Preferred)
SEO: 1 year (Preferred)
PHP: 1 year (Preferred)
Angular / Node JS: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
"Chatbot, Machine Learning and Artificial Intelligence","Mumbai, Maharashtra",Tata Insights and Quants,None,Organic,"COMPANY OVERVIEW
Tata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.
Tata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.

BACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.

Tata Insights and Quants – Journey to Date
Company: Tata - Insights and Quants – A Newly started division by Tata Industries.
http://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html
Employer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)
Top 10 most desirable Analytics Indian Firms to work for in 2016:
http://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/
Generating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place
http://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html
Contributing to Community through big data:
In line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.
Okhai partners with Tata iQ to deliver big impact through big data

Company : Tata Insights and Quants
Role :Chatbot, Machine Learning and Artificial Intelligence
Role Type : Analyst – Associate - Senior Associate
Role Description : Individual Contributor
Location : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open

Job Description
Understanding the end user’s requirement and translating the requirement into a business requirement document for the Chatbot development or implementation.
Developing chatbot queries and responses model based on the uses input in the form of chatbot consumable format.
Transforming the user requirement into the Chabot flow and design appropriate module for training and integration to user interface.
Create NLP modules to enhance the chatbot development process and improve the accuracy of the Chatbot.
Developing and fine-tuning machine learning algorithm to improve chatbot engine accuracy and speed.
Creation of test plan, test cases and testing chatbot responses using various tools such as selenium.

Requirements/Skill sets
Must-have technical skills
o Must be proficient in using python 3.x platform.
o Have worked on chatbot development or implementation in a real business scenario.
o Must have proficiency in Natural Language processing packages such as NLTK, Spacy, Gensim etc.
o Must have pro-efficient in Deep Learning algorithm using Keras, Pytorch etc
o Knowledge of Social platforms (Facebook, Twitter, LinkedIn, Google, WhatsApp etc.) and their APIs preferred.
o Hand-on knowledge of Database, Excel, Powerpoint

• Must-have soft skills
o Excellent written and oral communication skills
o Good interpersonal, problem solving, reasoning and analytical skills
o Ability to interact with clients with ease

• Good-to-have skills
o Working knowledge of HTML, JavaScript
o Worked on chatbot platform such as Alexa, Watson, Luis, Rasa
o Must have experience working with unstructured data related to text, voice, video and image analytics.

Education and Experience
Bachelors (+2-4 years) or Masters (2 years) in Computer Science or MBA with Bachelor in technical.
Experience in Chatbot implementation / development is a must

Reach us on careers@tataiq.com"
Data Engineer,"Jadavpur, Kolkata, West Bengal",KPC Medical College & Hospital,None,Organic,"Qualification-Bachelor degree or equivalent professional experience can be accepted in lieu of education. Specifications: Education & Experience Requirements: BA/BS from a College or university and/or related experience and/or training or equivalent combination of education and experience in Computer Science, Data Engineering and Analysis Hands on experience with Microsoft Stack- SQL SSIS, SSAS, SSRS etc. Preferred experience with Agile development process and SDLC Preferred experience with large scale data lake or warehouse implementation and support Preferred experience in hybrid cloud (On prem, AWS/Azure) environment Desire to provide outstanding customer service.
Job Summary-Provides the business knowledge and technical skills to implement technical strategies, evaluate products and provide a superior level of technical support. Data Engineer will be responsible for implementing ETL solutions that deal with various types of challenging data and should also possess knowledge of SQL, PL/SQL (procedures, functions) and scripting languages. The ideal candidate should have outstanding analytical and problem-solving skills and a good grasp of the technical side of business intelligence and always keep up to date with the latest BI tools and technologies. 4+ years of IT and business/industry work experience developing data or software applications including: analysis, design, coding, testing, deploying and supporting of applications Research and deploy new technologies to assist data access, integrity and availability Proven experience (minimum 2 years) with one or more of the following database systems and tools in a Windows environment is required: MS SQL Server (T-SQL, SSIS), Oracle, SSRS, SSRS, Tableau or any visualization tool experiences are a plus. Integrate data from multiple disparate systems - using SQL Server, Oracle, PL/SQL, SFTP process, scripting etc. Develop and optimize complex scripts in MS SQL to meet organizational requirements for reporting, BI and analytics Documental requests from business system owners for data access, integrations and reporting According to Company’s SDLC and Change Management. Collaborate with App/Dev, Habit IT and business system owners on resolution to complex/challenging issues that arise out of data access, integrity, availability and transformation Work collaboratively across the organization to address and predict data performance bottlenecks Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format. Utilize a combination of open source and in house developed software to meet company goals. Possess a sound understanding of areas of Computer Science such as algorithms, data structures, object-oriented design, and databases. Familiarities with Shell, Batch, PERL, Python/R and Machine learning concepts are a plus.
Send your resume to [email protected]"
Mobile AI Engineer (NLP),"Chandigarh, Chandigarh",DataToBiz,None,Organic,"Being a consulting and services startup we are looking for quick learners who can work in a cross-functional team of Consultants, SMEs from various domains, UX architects, and Application development experts, to deliver compelling solutions through the application of Data Science and Machine Learning. The desired candidate will have a passion for finding patterns in large datasets, an ability to quickly understand the underlying domain and expertise to apply Machine Learning tools and techniques to create insights from the data.
Key responsibilities:
As a Mobile AI engineer on our team, you will be responsible for solving complex data problems for various clients using deep learning techniques.
Work with the team to extract and transform natural language data from text on the mobile native application.
Develop and implement a framework for mobile processing of language syntax and semantics as well as contextualization of textual data using python
Develop strategies and implement methods to pass NLP techniques to classification algorithms.
Execute project plan to meet requirements and timelines.
Identify success metrics and monitor them to ensure high-quality output for the client.
Deliver production-ready models that can be deployed in the production system.
Understand and identify appropriate data sources required for solving the business problem at hand.
Key Skills:
2+ years of working with Python, Machine learning with exposure to one or more DL frameworks like Tensorflow, Keras, Caffe, MXNet etc (Mandatory)
Minimum 2 years experience in text representation techniques and NLP algorithms to succeed in this role (Mandatory)
Strong Exposure to at least 1-2 state of the art NLP algorithms e.g GPT, BERT, T5,RoBERTa, ERNIE, huggingfaces etc
Exposure to DL Model optimisation and transfer learning techniques
Strong verbal and written communication skills with other developers and business client
Android or iOS experience will be advantageous
Hands on experience in voice technology will be advantageous
Interested Candidates please share their resume at careers@datatobiz.com"
Data Integration / ETL Developer,"Hyderabad, Telangana",ServiceNow,None,Organic,"Description:
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.
We’re disruptive. We work hard but try not to take ourselves too seriously. We are highly adaptable and constantly evolving. We are passionate about our product, and we live for our customers. We have high expectations and a career at ServiceNow means challenging yourself to always be better.

What you get to do in this role:
Serve as the subject matter expert, mastering existing API based ETL tool capabilities as well as future enhancements as they become available, in order to continually improve our business intelligence offerings.
Collaborate with Lead Analyst to implement and maintain security of the business intelligence environment both in terms of access and data.
Responsible for troubleshooting data issues and conducting root cause analysis when reporting data is in question.
Maintain an in-depth understanding of the functionality of all system hardware and software
Perform assistance in maintenance and updates as required on server software, applications, and hardware environments.
Lead and/or participate in various projects intended to continually improve/upgrade BI infrastructure, including evaluation of new software and hardware required, to meet organizational business needs or to make processes more efficient and cost-effective.
Design, develop and test ETL Code.

In order to be successful in this role, we need someone who has:

Bachelor’s degree or equivalent in Computer Science, Computer Engineering, Information Systems or similar. Master’s degree preferred
6+ years of documented experience as a ETL developer in both data warehouse and BI technologies
4+ years of experience in any ETL tool (SAP BODS/Informatica/Datastage)
2+ years API based (Mulesoft/Dell Boomi etc) ETL experience is a must
Experience in Big Data is a plus
Scripting experience in Powershell, Python will be a plus point
Expertise in database design & development & SQL on Oracle, SQL Server,SAP HANA is a plus
Experience in ad-hoc data analysis, solution design, reporting & dashboard development
Prior ServiceNow platform experience is a huge plus
Excellent communication skills, ability to work individually and in a broader geographically disperse team
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business"
Software Development Engineer III (Backend),"Bengaluru, Karnataka","Zendrive, Inc.",None,Organic,"“Perfection is achieved not when there is nothing more to add, but rather when there is nothing more to take away.” – Antoine de Saint-Exupery

While there may be no such thing as a perfect world, we are working towards making it a safer place to drive by building products that support the evolution of transportation. We are writing code that processes terabytes of data in real time collected through smartphone applications that speak to millions of vehicles. Imagine the best-in-class infrastructure that makes it possible to analyse and monetize this data.

If you have 5+ years of programming experience with Java / Python, and are passionate about achieving perfection in coding, you may be what Zendrive needs for its back-end team.

What we need you to do:

Understand and analyse project requirements and translate it into specifications and programming deliverables
Work closely with analysts, designers and clients to enhance existing applications and build new ones
Test and debug the backend infrastructure in controlled situations
Maintain systems and update as per requirement

What you need to have:

BE/BTech or MTech / Dual degree in Computer Science from a Tier-1 institute
Strong understanding of data structures, algorithms and their application
Hands-on experience of coding in Python and Java among other programming languages
Good understanding of building scalable systems which are easy to operate and cost effective

What we offer you:
Apart from a competitive salary, we offer you the option of working from a location of your choice until we determine that it is safe to work in a physical office environment. You also get to collaborate with some of the best software engineering talent in the world and a cross-functional team that includes designers, frontend programmers and product managers. We also offer you the opportunity to create products that have a deep material impact on the world.

If you are excited about the job description and see yourself excelling in this role, hit the APPLY FOR THIS JOB button at the end of this page. Our Talent Acquisition team will get in touch with you."
Workday Reporting Specialist,"Bengaluru, Karnataka",Rolls-Royce,None,Organic,"Job Description
Rolls-Royce is a world-leading provider of power systems and services, for use on land, at sea and in the air. We're proud to have a strong presence and an 80-year heritage in India and are excited about our growing future in Bengaluru. Through innovative solutions and diverse, globally renowned products, we've been focused on the growth of the aerospace sector in India. Powering more than 50% of Wide Body Aircraft to and from India, we are poised to become an engineering hub in the region and are committed to growing our local footprint for high-end technology.
As a Workday Reporting Specialist, you will be the member of the Global People Analytics Team, reporting to the People Analytics Team Leader. You will operate globally working with stakeholders inside the HR function and in the wider business community. You will be responsible for the development, implementation and maintenance of Workday custom reports, dashboards, scorecards, metrics and Prism analytics. You will be a confident communicator who can help stakeholders understand report configuration use. You will be expected to keep up to date with the Workday solution so that future enhancements can be introduced to Rolls-Royce reports as appropriate. You will be expected to be a subject matter expert on Workday reporting, calculated fields, dashboards and metrics with knowledge of Workday security, worksheets, Prism and augmented/ people analytics.
Key Accountabilities
Development and maintenance of Workday reports, dashboards and Prism analytics.
Working with key stakeholders to determine reports and dashboard requirements.
Producing high-quality and customer friendly Workday dashboards and visualizations
Support moving customers to self-service deliver model
Reviewing reporting suite to maximize system performance
Qualifications & Experience
Bachelors Or Masters (Computers Science / IT Preferred) with 5-7 years’ experience working with Workday reporting and calculated fields in a medium to large organization
1-2 years’ experience of Workday Prism
Knowledge of Workday security, worksheets and integrations
Experience of working remotely in Global teams
Minimum 5 years of experience in data analysis
Excellent analytical skills
Excellent spoken and written English, Strong communication skills
Excellent knowledge of Excel
Excellent knowledge of database joins preferably (Oracle SQL Developer)
Working knowledge of Power BI
Attention to details, Eagerness to learn and grow
We offer excellent development prospects, along with a competitive salary and exceptional benefits.
Pioneer optimum performance. Join us and you’ll develop your skills and expertise to the very highest levels, working in an international environment for a company known the world over for brilliance and innovation.
Beyond Tomorrow.
We are an equal opportunities employer. We’re committed to developing a diverse workforce and an inclusive working environment. We believe that people from different backgrounds and cultures give us different perspectives. And the more perspectives we have, the more successful we’ll be. By building a culture of respect and appreciation, we give everyone who works here the opportunity to realize their full potential.
You can learn more about our global Diversity and Inclusion strategy here
At Rolls-Royce we also support requests for flexible working arrangements wherever possible.
Job Category
Human Resources
Posting Date
13 Aug 2020; 00:08"
Software Development Engineer,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"BE/B.Tech/ME/M.Tech in Computer Science or equivalent
3+ years of experience in a technical role in the industry
Computer Science fundamentals in object-oriented design, data structures, high-performance computing.
Computer Science fundamentals in algorithm design, complexity analysis, problem solving and diagnosis.
Proficiency in, at least, one modern programming language such as Java, C or C++

At Amazon Web Services (AWS), we hire the best minds in technology to innovate and build things for the benefit of our customers. That intense focus on customers is why we are one of the world’s most beloved brands – it’s part of our company DNA. And this is that rare opportunity to be part of AWS.
As a Software Developer working in AWS team, you will get firsthand experience managing a distributed service end to end. You will be surrounded by people who are extremely smart and passionate about cloud computing. Our work has an impact across many AWS customers. You will work in a fast-paced environment and do everything from determining priorities and designing features, to re-architecture as necessary, making operational improvements, automated testing, to mentoring others. The best candidates show true end-to-end ownership. We offer a playground of opportunities for builders to build and make history!

Experience in Java, Python
Experience taking projects from scoping requirements through V1 launch and V2 iterations.
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Excellent communication skills and the ability to work well in a team
Experience building and operating a large scale distributed system
Experience working in an Agile software development organization

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status"
Cloud Engineer Trainee,"Bengaluru, Karnataka",Econz IT solutions,None,Organic,"What do we expect?
Handle the day-to-day management of clients’ cloud-based solutions.
Diagnose and troubleshoot technical issues
Help customers successfully deploy and implement cloud computing solutions.
Resolve technical support tickets via telephone, chat, email and sometimes in-person.
Know their way around one or more popular operating systems such as Linux, Unix & Windows.
Understand artificial intelligence (AI), Internet of Things (IoT) & data analytics - in GCP
May possess basic programming skills.
Knowledge of G Suite Emailing systems
Proactively maintain broad knowledge around cloud engineering trends and advancements
How do we expect you to do it?
Setup & deploy cloud solutions.
Provide training to customers.
Responsible for day-to-day administration of cloud services
Mentor application teams on cloud computing best practices and technology to drive cloud adoption
Provide advice and information to customers regarding , GCP, G Suite, Chrome solutions.
Keep updated with new Google Services and general cloud offerings
Responsible for day-to-day customer care and administration of cloud services
Responsible for general health and maintenance of cloud service offerings
Do you fit in?
Formal degree ( 10+2+3 / 10+2+4 ); Preferably electronics and communication engineering/ Computer science engineering with Min Knowledge in Cloud Infrastructure.
Effective communication skills and customer handling.
Effective time management skills and presentation skills
Effective prioritizing and multitasking skills and a team player.
Full-time job may be partially remote too.

Type Of Positions:
Full-Time
Job Role:
Cloud Engineer Trainee
Job Function:
Information Technology
Seniority Level:
Executive"
Consultant - Talend ETL,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Consultant
Location: TRIL GTC
GCL :C3
Job description:
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The R&D Units IT is AZ’s global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.
We are looking for a passionate Visualization/Low-code developer who will leverage tools & technology best practices improving delivery performance & data engineering capabilities in the Data & Analytics (D&A) space.
Roles & Responsibilities:
Deliver efficient, automated visualisation and low-code solutions to support D&A activities and business questions/analytical demands
Undertake a range of project delivery activities including business analysis requirements, BI solution architecture, analytics, and software engineering and will be a key member of the agile project team
The Visualization Engineer will help identify opportunities for innovation in their delivery, leveraging technology and promoting methodology best practices externally and internally to improve delivery performance and team capabilities
Test and quality assess new D&A solutions, to ensure they are fit for release: code assurance, Unit and System Integration Testing, Data testing, release management control and support of UAT processes
Required skills:
Innovate tangible visual analytics/low-code solutions based on requirements by working closely alongside the business within an iterative delivery framework
Support solution development efforts through active contribution to visual analytics/low-code engineering effort, business analysis and testing activities
At least 5 years of experience in reporting tools like Power BI, Spotfire
Expert level skills in a range of BI technologies and applications and willingness to learn and use new technologies
Knowledge in any of the low-code platforms like PowerApps, Sales Force, OutSystems
Knowledge in any of the data science visual analytics tools, programming languages like R, R Shiny, Pyton or Python Dash
Proficient in making DAX queries and expertise in using advance level calculations on the data set
Experience of working with a range of data analytics architectures. These may include traditional warehousing, distributed computing, visualization analytics
Able to integrate Power BI reports into other applications using embedded analytics like Power BI service (SaaS), or by API automation. Also, one must be experienced in developing custom visuals for Power BI
Design and develop canvas and model-based apps using Power platform
Work with management to prioritize business and information needs
Adept at queries, report writing and presenting findings
Desired skills:
Domain knowledge (processes & data): Pharma R&D
Experience of working with NoSQL, virtualization, data streaming etc
Amazon Web Services: Connecting, loading and reading data from AWS database technologies like MySQL, Aurora, AWS Redshift
A self-starter with high levels of drive, energy and resilience
Agile/Scrum process
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Hardware Engineer (Intern) - India UHR,"Bengaluru, Karnataka",Cisco Systems,None,Organic,"Job Description – Hardware Engineer
In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!
We are Innovators
We drive innovation to propel business transformation while maintaining operational quality.
We are Accelerators
We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.
We are Transformers
As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients.
What You’ll Do
Impact the product development from the lowest levels of circuit design to large system design and see your contribution all the way through to high volume manufacturing.

Innovative Hardware Engineering positions available in:
ASIC Design and Verification
System/Board Design
Circuit Board Layout
Hardware Automation, Validation and Test
Signal Integrity
Power Design

Education Eligibility Criteria (Master):
Recent graduate or on your final year of studies toward a master's degree in Electrical Engineering, Computer Engineering, Applied Science, Material Engineering, Applied Physics, Math or Physics
Who You Are Minimum of an 8.0 GPA or higher The requirement is for 2021/22 passout only Ability to manage multiple tasks and work toward long-term goals Solid understanding of engineering fundamentals and technical problem-solving skills Experience in establishing and sustaining strong relationships with the extended team Excellent communication skills (verbal and written)
Why Cisco
At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!
Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
Application Engineer – Mathworks Products,"Bengaluru, Karnataka",CoreEl Technologies,None,Organic,"Job Summary
As a Application Engineer for the MATLAB software for various application areas, you will partner with our most innovative customers to establish MATLAB as a platform for our customers.
Knowledge of MATLAB, SIMULINK and STATEFLOW.
Developing algorithms in MATLAB and Simulink.
Integrating MATLAB and Simulink Products with Hardware like FPGA, ARM and GPU.
Deploying applications developed in MATLAB to an enterprise-wide system.
Technical Engagement and support to the Customer
Presale and Post Sale Support
You will work in a pre-sales manner with our customers to first identify and understand their technical and business challenges and then develop compelling demonstrations of solutions that help them appreciate how the adoption of MathWorks products add value towards enhancing their workflows.
Using your technical expertise as well as your excellent interpersonal, communication, and presentation skills, you will engage customers and prospects in seminars, conference calls, meetings, and through product evaluations to develop a shared vision for success.
Responsibilities
Provide technical pre-sales support and guidance to the India sales organization, prospects, and customers in the domains like Image processing, Computer Vision, statistics, data analytics, machine learning, distributed computing, handling Big Data, and application deployment by:
Preparing and delivering presentations, demonstrations, and application examples in customer meetings, seminars, and other public events
Managing product evaluations and developing adoption plans that assist customers in adopting MathWorks products
Partnering with sales representatives to help develop account and territory level selling strategies
Identify new trends and application areas and provide feedback to development and marketing teams. Collaborate with the worldwide team on developing compelling messages and demonstrations.
Advocate for the future direction of MathWorks products based on customer interactions.
Establish rapport and credibility with our customers across multiple hierarchy levels to build champion users and supporters of our solutions.
Minimum Qualifications
A bachelor’s degree and 1 years of professional work experience (or a master’s degree) is required.
Candidates must be willing to travel 25% to 50% of the time 25% in content preparation.
Additional Qualifications
Masters degree in Math, Science, or Engineering
1 years of relevant industry experience
Strong knowledge of computational analysis, mathematical modeling, statistics, and algorithm development
Strong knowledge of machine learning and deep learning algorithms and frameworks
Strong knowledge of analytics software (such as MATLAB, R, Python)
Experience with large scale data analysis using parallel and distributed processing algorithms is a plus
Experience in developing technical software in a professional environment using programming languages such as C, C++, Visual Basic, .NET, JAVA, C#, ASP, COM.
Strong verbal and written communication skills
Highly motivated toward working directly with customers
This position is based in Bangalore with travel generally throughout Karnataka and Kerala specific to various customer visits and seminars. Travel time can be expected to amount to approximately 30-40% with trips generally no longer than three days.

If you are a recent graduate, kindly send your resume to freshers@coreel.com."
Machine Learning Engineer/Data Scientist,"Pune, Maharashtra",Mindbowser Info Solutions Pvt Ltd,None,Organic,"Company Description
Mindbowser Info solutions is a digital transformation services provider working with global brands aiding on their journey to digital transformation. Mindbowser offers a suite of products and services around user experience, automation, analytics, and mobility that in turn helps businesses become more efficient and improves profitability.

Job Description
We are looking for a Machine Learning Engineer/Data Scientist to work alongside our innovative and growing data science team.The role will be based in our HQ, located in Pune.
Website: https://www.mindbowser.com/
Job description
Our Data Analysts are expected to explore data, technologies, and the application of mathematical techniques to derive data insights.
Ability to gather the domain specific knowledge of the data.
Should have good quantitative skills and the ability to tell a story using data.
Ability to build and fine tune machine learning algorithms which are first used at a proof-of-concept stage and then at a production level.
Should be able to translate prototypes into new products, and provide guidelines for large-scale implementation.
Exp: 0-6 Months

Key Requirements
Programming skills (Python preferred).
Experience of statistical techniques.
Selecting features, building and optimizing classifiers.
Processing, cleansing, and verifying the integrity of data used for analysis.
A basic understanding of the graphs, chart libraries used for data visualization.

Qualifications
BE/Btech/BCA/MCA
Graduate in any stream
Experience Range - 0-1 year

Additional Information

null"
Data Scientist,"Bengaluru, Karnataka",TALCHEMIST,None,Organic,"Data Scientist
Large Banking MNC
5 - 10 years
Bangalore
QUALIFICATION
Bachelor’s or Masters Technology Degree in Computer science or Equivalent
Job Description
The senior data scientist will get the opportunity to work in an agile software development enviornment addressing machine learning and optimization analytics problems. The senior data scientist will be part of cross diciplinary data science team working on software development projects, typically involving large, complex data sets. They will work with technical team in development and deployment and application of predictive analytics.
Key Skills Required
Demonstrated skill of data cleansing, data qualityy assesment. Use the descriptive statistics, feature extraction and predictive analytics on real datasets. Skills at data visualization and storytelling for an audience of stakeholders. Experience in working with Hadoop and spark will be added advantages."
Senior Software Engineer,"Hyderabad, Telangana",Teradata,None,Organic,"With primary development center in Hyderabad and two R&D facilities in Bangalore and Pune the Teradata R&D team in India is in excess of 500 engineers. R&D Labs at Hyderabad is the biggest R&D division outside of San Diego facility, and has teams producing world class features for the Teradata database stack working on wide variety of products and technologies including core database internals, Advanced Analytics in the database platform, cloud offerings for the database core and performance engineering.

Senior Software Engineer – EcoSystem and Languages Team

The EcoSystem and Languages Team at Teradata is currently seeking an experienced software engineer to join our team. This person will be primarily responsible for developing new features for the platform that runs advanced analytics on the server. The project is for building a platform which enables users to bring their favourite python and R packages into the language containers which are orchestrated by Kubernetes and run the advanced analytics closer to the database core.

Education and Experience Requirements

Bachelor’s/Master’s degree in Computer Science with 5+ years of programming and development experience.

Role & Responsibilities

Design, implement, review, test, deploy and maintain innovative software solutions to transform languages across the Teradata Vantage platform (a critical Teradata strategic component).
Collaborate well within a tight-knit team to produce world-class enterprise-grade software
Deliver quality Python/R/Go software solutions that meet performance, durability, cost, and security benchmarks.
Guide senior leadership to help drive business decisions via technical expertise.
Investigate and explore creative ways to address the challenges in the project
Mentor and promote software development & language analytics best practices across your team of developers.
Write high quality distributed & cloud system software.
Work in an agile, startup-like development environment, working on rapidly evolving business needs & delivering quality solutions on on-time.

In this role you will be responsible for a critical and highly-visible function within Teradata Vantage platform. You will be given the opportunity to autonomously deliver the technical direction of the service, and the feature roadmap. You will work with extraordinary talent and have the opportunity to shape the team to best execute on the product.

Requirements

5 to 7 years industry experience in designing software architecture, leading software development, and operating scalable software systems Experience with Python, Go, Java or other object oriented languages - preferably on a UNIX or Linux platform including internals or equivalent lower-level implementation Experience writing unit and system level tests using dependency injection frameworks and object mocking Distributed system design and development (or comparable technology)
Strong data structures and algorithms fundamentals
Strong analytical abilities involving complex software in a parallel processing environment
Experience in group software development and routine use of version control tools required, specifically Git.
Ability to work with a Product Owner, Senior Developers, Feature Testers in Agile framework

Preferred skills

Experience with python or R based open-source analytics packages is a big plus
Experience with Kubernetes, docker containers and experience programming languages such as Go
Understanding of RDBMS concepts & SQL

Scope

Individual Contributor
Works with product Owner, Architects, scrum team and reports to Engineering Manager
Generating Design Documents, Software development, Unit/Integration testing, bug fixing"
Data Scientist II,"Hyderabad, Telangana",Novartis,None,Organic,"20+ brands catering to 50+ disease areas! The team of Novartis specialists within Insights & Analytics are on a data and digital transformation journey, leveraging analytics to generate actionable insights for Novartis medicines impacting more than 500 million patients worldwide. The team is poised to enable easier, faster and reliable decisions for Novartis divisions across the globe.

Understand complex and critical business problems from Country/Regional/Global business functions, formulate integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact on ROI Through strong subject matter expertise and role modelling skills, guide the Business Analytics team in Hyderabad to enable delivery of analytical insights to the commercial stakeholders worldwide. Coach and mentor aspirant SMEs in Business Analytics team at Hyderabad in line with Novartis people development requirements and Novartis Values and Behaviours. No direct team management.

Provide solutions for a variety of business applications including but not limited to: Customer Segmentation & Targeting, Event Prediction, Propensity Modelling, Churn Modelling, Customer Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, Price Optimization. Develop automation for repeatedly refreshing analysis and generating insights. Collaborates with globally dispersed internal stakeholders and cross-functional teams to solve critical business problems, drive operational efficiencies, and deliver successfully on high visibility strategic initiatives. Understands commercial data sources including sales, contracting, promotions, social media, patient claims and Real World Evidence. Makes right choices from a breadth of tools, data sources and analytical techniques to answer a wide range of critical business questions. Articulates solutions/recommendations to business users. Presents analytical content concisely and effectively to non-technical audiences and influences non-analytical business leaders to drive major strategic decisions basis analytical inputs. Project manages critical initiatives: plans proactively, anticipates and actively manages change, sets stakeholder expectations as required, identifies operational risks and independently drives issues to resolution, balances multiple priorities and minimizes surprise escalations. Works closely with MES Function Head, Business Analytics Group Head and Regional Account Directors to shape strategy and build capability (including hiring and training) for advanced analytics delivery. Works with other teams (Forecasting, Sales Force Effectiveness, Pricing and Access etc.) at PLS Hyderabad to leverage cross-functional learnings and synergies. Ensures exemplary communication with all stakeholders including internal PLS associates and senior business leaders across Novartis. Acts as an evangelist and catalyst for innovation in BI & Analytics . Grooms Subject Matter Experts, and mentors associates for higher responsibilities. Identifies learning needs for analyst teams and plans for training implementation in alignment with training manager to expand NGSC capabilities. Identifies key skill requirements for the Business Analytics team and facilitates design and content creation for knowledge repositories and training material
Quality of insights generated and solutions provided, with quantified business impact / ROI .Effective communication with PLS and Country/Regional/Global stakeholders .Executes agreed targets for self .Define and execute development plans for potential Subject Matter Experts . Find creative ways to build team capabilities and play a direct role in driving a culture of innovation. Values and Behaviours: in line with leadership standards of Novartis

Minimum requirements
Graduate or Post-graduate or Ph.D. in any quantitative discipline, e.g. Statistics, Applied Mathematics, Econometrics, Computer Science, Engineering, Operations Research. MBA preferred English
8+ years of hands-on experience in analytics. Experience with a leading pharma or service provider highly desirable
Extensive experience in Statistical and Machine Learning techniques like Regression (Linear/Logit/Gamma), Clustering (K-Means/Modes/Hier), Decision Trees, Text Mining and Natural Language Processing, Stochastic models, Bayesian Models, Markov Chains, Monte Carlo Simulations, Non-linear Time Series, Dynamic Programming and Optimization techniques,Design of Experiments, Neural Networks, Statistical Inference,Collaborative Filtering, Feature Engineering, etc.
Extensive experience in working with large-scale datasets (in bigdata architecture, data lake, data mart, data warehouse). Demonstrateduse of analytical packages and query languages such as SAS, R, SQL,SPSS, Matlab, Alteryx
Experience in Big Data platforms like Hadoop eco-system (i.e. Hive, Pig, Sqoop, Mahout), other large scale computing systems (e.g. COSMOS,MapReduce) or modern coding languages

799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.
Division
NBS
Business Unit
PLS NBS
Country
India
Work Location
Hyderabad, AP
Company/Legal Entity
Nov Hltcr Shared Services Ind
Functional Area
BD&L & Strategic Planning
Job Type
Full Time
Employment Type
Regular
Shift Work
No"
Software Engineer - Java (Insights),"Bengaluru, Karnataka",Truecaller,None,Organic,"Hey, Truecaller is calling you from Bangalore, India! Ready to pick up?
Truecaller was born in 2009, Stockholm, Sweden, with the mission to provide more safe and efficient communication to everyone's daily life. Today, Truecaller is loved by 180 million daily active users around the world, popular in South Asia, Middle East, Africa! We are the go-to app for Caller ID, spam blocking, messaging, and payments.
We at Insights team The Insights Team is responsible for all the Smart-SMS features (Smart Notifications, InfoCards in conversations, Important tab etc) that you see in the Truecaller app and is fully based out of the Bangalore office.
As a Java Developer in the team, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
What we expect from you:
4 + Years of experience into core java
Strong understanding of core java 8, threading, generics, garbage collection, serialization etc
Strong OOPs, data structure, algorithm knowledge
Strong understanding and hands on experience of some dependency injection framework and writing testable code
hands on experience on build/deploy tools/configuration such as maven, jenkins, etc
Prior experience in resolving performance issues and should know how to go about optimizing APIs via code, configuration, caching or whatever method suitable
Aptitude/experience of analyzing and debugging complex production issues using tools such as splunk, dynatrace and sometimes UNIX commands
Ability & willingness to learn technologies at pace and adapt easily
A bachelor's degree in computer science. If the candidate has strong technical skills and/or great reasoning ability paired with decent coding ability, this will not be a barrier
What will you work on?
This position is for a java developer within the Insights Team.The team owns a patented fully offline text parser which enables all these features. The parse is written in Java and is maintained as a separate project and included within the app. It is tuned for a very small memory footprint and parsing speed compared to other parsers.If you get selected, your main focus would be to continue the work we have done in the parser, improve it in terms of efficiency and throughput and implement new features.
It would be great if you also have:
Since we are working with text parsing, it would be awesome if the candidate has
Experience in compiler design (Undergrad knowledge is good enough)
NLP knowhow and a basic understanding of how text parsers work.
Knowledge of Graph based data structures/algorithms
Some experience with stream processing paradigms
Working experience in Kotlin
More about Truecaller
Truecaller is a Swedish company founded in 2009 in Stockholm, Sweden by Nami Zarringhalam and Alan Mamedi. The app began when our co-founders were just students who wanted to create a service that would easily identify incoming calls from unknown numbers. We have our strongest presence in South Asia, Middle East, Africa, and HQ in Sweden. We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.
Life at Truecaller - Behind the code: instagram.com/truecaller/ https://www.linkedin.com/company/truecaller/
How To Apply
You can also apply with the help of link given
https://boards.greenhouse.io/truecaller/jobs/2247266
This position is based in Bangalore, India. Please contact Talent@truecaller.com if you have any questions.
What we offer:
International teams - 25+ nationalities work together!
Learning & sharing environment
Exciting company parties & team activities – Football Team, Geek lunch, Lab Days!
Flexible working hours
Start the day with delicious breakfast
Stay refreshed: juices, tea, coffee and soft drinks
Gym reimbursement.
Competitive salary
Medical, Accident,Term life insurances
Truecaller is an equal opportunity employer and value diversity company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status."
-Developer R programming and ShinyProfessional 2 Information...,"Bengaluru, Karnataka",DXC,None,Organic,"Job Description:
Description
Developer is expected to demonstrate expert competencies in Design and Building shiny web apps using R programming on Azure cloud. The developer should have good technical documentation skill and working knowledge in Agile projects.
In this role the successful candidate will work in an energetic, fast-pace and extremely professional environment to understand customers’ requirements of Enterprise Azure Cloud and find solutions to their business problems.
Qualifications
Bachelor’s in computer science engineering (or equivalent) and having statistics knowledge
5 plus years of IT experience with key focus on Business Intelligence and Analytics on Azure
Good analytical and problem-solving skills
Fluent in Data warehousing concepts
Must be knowledgeable in software development lifecycles/methodologies i.e. Agile & DevOps
Has strong presentation and collaboration skills and can communicate all aspects of the job requirements, including the creation of formal documentation
Strong problem solving, time management and organizational skills
Desired Skills:
Excellent R programing Skills and shiny web app development
Good in simulations, data analyses and data visualizations with the R package
Experience in Azure cloud
Exposure to databases such as SQL Server/SQL DWH
Assist in designing and development of technical architecture, requirements and statistical models
Good in manipulating and analyzing complex, high-volume, high-dimensional data from varying sources
Good to have Python scripting skill
Knowledge in Azure Machine learning"
Medical Affairs Specialist,"Bengaluru, Karnataka",Siemens AG,None,Organic,"Business Unit / Segments
Laboratory Diagnostics (LD)
(Products: Chemistry, Immunochemistry, Automation, Informatics, Hematology, Hemostasis and Specialty Products)

Specific Responsibilities
Primarily responsible for contributing to the timely completion of various health risk assessments and clinical use related evaluations of LD products.
Reports directly to Siemens LD Medical Affairs

Key Job Attributes
A. Within specific job description:
1. Works independently or as part of a larger team in the execution of assigned projects.
2. Maintains accurate documentation and files related to all activities and tasks.
3. Interacts directly within cross-functional teams and builds productive cross-functional working relationships for the completion of assigned tasks.
4. Critically reviews analytical and clinical performance data and reports and provides assessment of clinical/medical impact and/or risk.

B. Critical Problem Thinking:
1. Applies a strong clinical laboratory background to assess the application of medical laboratory test results (e.g. biomarkers) in clinical practice.
2. Translates and integrates the latest clinical guidance and guidelines for the use of laboratory biomarkers in the care of patients, including assessment of the impact of laboratory results on diagnosis, monitoring and treatment.
3. Demonstrates understanding of intended clinical use of complex in vitro diagnostic laboratory medical devices.
4. Displays an expert level of critical thinking in applying principles of clinical laboratory medicine, including analytical laboratory practice (e.g. assay validation, quality control) and regulations, to patient care applications.
5. Proactive attitude with logical, data driven approach to problem solving.
6. Performs special assignments and provides technical and clinical advice in area of expertise.

C. Education (Description is US-based; equivalent for India required):
M.D., Ph.D. or M.D./Ph.D. in related areas with practical experience in clinical pathology preferred. Equivalent combination of relevant education and experience, such as Master’s in medical technology, laboratory science, chemical, physical, or biological science AND a minimum of 3 years of medical laboratory experience in clinical consultancy and technical and regulatory oversight, as outlined above, may be substituted as appropriate. Board certification and ongoing accreditation by nationally and internationally known professional clinical and academic bodies such as ABCC, NRCC, CACB, RCP, ABP preferred.

D. Experience:
1. Typically 3 to 5 years of successful experience in related field.

Organization: Siemens Healthineers
Company: Siemens Healthcare Private Limited
Experience Level: Experienced Professional
Job Type: Full-time"
Cloud Engineer for CVML (Computer Vision and Machine Learnin...,"Bengaluru, Karnataka",Ittiam,None,Organic,"Profile: The prospective candidate would be part of the Cognitive Media Technologies team at Ittiam that works in the areas of visual and data analytics addressing markets such as retail, surveillance, automotive, and Industrial IOT.
Required Experience: 2 to 4 years
Job Description: Selected candidate will join an innovative team of engineers focusing on development, maintenance and support of the IoT based service on Cloud. Our current IoT systems serving the Retail markets are deployed across the globe. The candidate is expected to have working knowledge of Cloud Application Development Processes, Configuration Management, Test Planning and Execution.
Responsibility: This person will be responsible for:
Design and development of scalable web services in Cloud (Public / Private)
Design and development of data processing pipeline
Full stack development of features for production deployment
Interface with other internal teams to align on requirements and drive the release
Educational Qualification: Masters or Bachelor’s Degree in Computer Science/Electronics and Communication
Technical Skills:
Experience in Java and Python programming for server-side applications
Experience in building RESTful web services
Experience in any of RDBMS, preferably Postgres
Working knowledge on Docker and Kubernetes
Experience in JavaScript programming is an added advantage
Working knowledge on Google Cloud Platform is an added advantage
Working knowledge on open source components like Kafka, ELK stack is an added advantage
Location: Bengaluru, Karnataka

If you have an unending passion for technology, the drive to learn and excel, and great team spirit, drop in your resume at talent@ittiam.com"
A++ Data Scientists @ Pune – High Impact!,"Pune, Maharashtra",CareerXperts,None,Organic,"You will join a world famous Profitable Product Startup!
You Will :
Retrieve, prepare, and process a rich data variety of data sources such as social media, news, internal/external documents, emails, financial data, and operational data
Analyze and model structured data and implement algorithms to support analysis using advanced statistical and mathematical methods from statistics, machine learning, data mining, econometrics, and operations research
Perform Statistical Natural Language Processing to mine unstructured data, using methods such as document clustering, topic analysis, named entity recognition, document classification, and sentiment analysis
Utilize a diverse array of technologies and tools as needed, to deliver insights, such as R, SAS, Python, Spark, Hadoop, Qlikview, and Tableau
Translate advanced business analytics problems into technical approaches that yield actionable recommendations
Perform exploratory data analysis, generate and test working hypotheses, and uncover interesting trends and relationships.
Experience
2 to 4 years
Qualification
Master’s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, with five years of relevant experience and strong knowledge in at least one of the following fields: statistics, data mining, machine learning, statistics, operations research, econometrics, natural language processing, and/or information retrieval; PhD preferred.
Deep experience in extracting, cleaning, preparing, and modelling data; command-line scripting, data structures, and algorithms; and working in a Linux environment
Proficiency in analysis packages (e.g. R, SAS, Matlab) and programming languages (e.g. Python, Ruby, Java, Scala).
Write to Deepa.m@careerxperts.com to get connected!
Job Location
Pune"
Data Engineer,"Bengaluru, Karnataka",Nabler,None,Organic,"As a Data Engineer, you will work on cutting edge, petabyte scale Hadoop eco-system to ingest raw data and transform it, in to a usable and consumable information for various operational and advanced analytics purpose.

You will …

Build, test & maintain enterprise data lake and data pipelines.
Work with analytics partners to deploy scalable data pipelines for analytical needs.
Adher to the plan and quality needs of data solutions to various business problems.
Explore and establish new technologies, tools and new ways of solving problems.
Adapt to competing demands and step outside comfort zone.

You should have:
Engineering degree in Computer Science or related technical field, or equivalent practical experience.
2 to 4 years of Big Data experience with 3+ years of experience in building data processing applications using Hadoop, Spark and NoSQL DB and Hadoop streaming.
Expertise in one or more programming languages like Java, Scala or Python and in unix scripting.
Expertise in using query languages such as SQL, Hive, Sqoop and SparkSQL.
Expertise in storage and process optimization techniques in Hadoop and Spark.
Experience in using tools like Jenkins for CI, Git for version Control and
Exposure to Google Cloud (GCP) data components such as Cloud Data Flow, Cloud Data Proc, BigQuery and BigTable is preferred.
Strong problem-solving, communication and articulation skill.
E-commerce experience preferred."
Principal Data Scientist,India,CereSight,None,Organic,"Location:: Anywhere in India (remote)
Key skills:: Machine Learning Algorithms
Desired Candidate Profile::
We are looking for AI engineers who are as passionate as we are about artificial intelligence, advancing science, and inventing the next generation of intelligent machines.
We are hiring for candidates with 4+ years hands on development in experience in ML/AI.
Knowledge in a broad range of machine learning areas, including: Deep learning, including novel architectures with attention and memory, supervised learning, semi-supervised and unsupervised learning, including generative models, Reinforcement learning, Meta-learning, Multi-task learning, transfer learning, few-shot learning, continual/lifelong learning, Interpretability, fairness, accountability of machine learning models, Brain-inspired machine learning algorithms, Optimization for AI/ML, Bayesian learning, graphical models, and causal models. Familiarity with Big Data ML toolkits, such as Tensorflow, Spark ML, or H2O
You will work on the most cutting-edge, exciting projects that have immediate use in the industry. Your creativity and innovative problem solving will be essential to the success of our team and the company.
Reach out to us if you have solved real-life problems at scale utilizing message queueing (Apache Kafka, MS EventHub, or equivalent) and streaming event processing technologies (Apache Storm, Apache Spark, or equivalent), applied machine learning and AI algorithms to very large datasets at scale.
Education:: - Bachelors/ Masters / Phd
We think the knowledge acquired by earning a doctorate or master’s degree in Computer Science with AI as a specialization would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time
Company Profile: This is the right place for you, if want to work in
A Data Science and Big Data technology start-up.
A place where you would want to create value for yourself, and our customers
An environment that supports your personal growth
Culture that believes the greater priorities in life are family, health and integrity
Group of the best in class professionals who are excited about the work they do
Contact::
Sangeetha: sangpraman@gmail.com, +919655998843"
Senior Data Scientist,Karnataka,PowerSchool Group LLC,None,Organic,"Overview:
PowerSchool’s mission “Powering Brighter Futures” enables students to realize their potential, provide the best opportunities in life, and help students succeed. Built upon the foundation of 20+ years of K12 data, PowerSchool has been actively engaged in building machine learning models that are solving some of the most critical challenges that are impeding student and teacher success. We use data science to personalize learning, improve student engagement, help hire, develop, and retain top teachers that can make the learning experience enriching.
Job Overview
We are looking for a Data Scientist that will analyze, model and build data science based K12 products that will personalize learning, improve student engagement, help hire, develop, and retain top teachers and enrich the learning experience. The ideal candidate will be adept at using large data sets and using models to test the effectiveness of different solutions. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
Responsibilities:
Responsibilities for Data Scientist
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to drive business outcomes.
Develop and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications for Data Scientist
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Qualifications:
Job Description:

We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience using web services: AzureML, Redshift, S3, Spark etc. or equivalent
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.
EEO Commitment:
PowerSchool is committed to a diverse and inclusive workplace. PowerSchool is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Our inclusive culture empowers PowerSchoolers to deliver the best results for our customers. We not only celebrate the diversity of our workforce, we celebrate the diverse ways we work. If you have a disability and need an accommodation regarding our recruiting process, please let us know by emailing TA@powerschool.com."
Machine Learning Scientist (8 -10 yrs),"Chennai, Tamil Nadu","Agilysys, Inc.",None,Organic,"About Company

At Agilysys, Inc. we are proud of our 3,000+ customers including some of the world’s most recognizable resort, casino and cruise line brands. We specialize in market-leading point-of-sale, property management, inventory and procurement, and mobile and wireless solutions that are designed to streamline operations, improve efficiency and enhance the guest experience. We serve casinos, resorts, hotels, food service venues, stadiums, cruise lines, grocery stores, convenience stores, general and specialty retail businesses and partners. With extensive operations, throughout North America, and additional sales and support offices in Singapore and Hong Kong, as well as software development in India, we are growing. For more information, visit: www.agilysys.com.
Machine Learning Scientist
We are looking for Senior Applied Scientists who has deep passion for building machine-learning solutions and can help us take our products to the next level.
In this role, you will
Be responsible for developing, training, inferencing, evaluating, and deploying machine learning algorithms and/or models.
Design and perform experiments to continually refine and enhance our deep learning technology solutions.
Work closely with software engineers on detailed requirements, technical designs and solutions.
Provide technical leadership and research new machine learning approaches to drive innovation.
Help drive adoption of Machine Learning across the company.
Qualifications
Master’s degree in Data Science, Analytics or Computer Science with Machine Learning specialization or related discipline. A PhD is preferred.
5+ years hands-on experience in building Machine Learning solutions.
3+ years’ experience with data structures, algorithm design, problem solving and complex analysis.
Experience with implementing deep learning platforms such as TensorFlow, Keras, and Darknet
Experience with implementing deep learning models such as Inception, Faster-RCNN, SSD, YOLO3.
Strong coding knowledge, experience with Azure or AWS machine learning pipelines.
Excellent understanding of convolution neural networks and other machine vision algorithms and methodologies.
Experience working effectively with science, data processing, and software engineering teams.
Excellent oral and written communication skills, with the ability to effectively communicate complex technical concepts and solutions.
Proven hands on experience working with large data sets and training models.
Ability to extract the practical implementation information from academic papers.
Interest in working on embedded systems.
Proven track record of executing complex projects.
Preferred:
Experience in deploying machine learning models on the edge"
Sr. Node.js Developer,Remote,Lotus Interworks Inc,None,Organic,"About Company
Lotus Interworks Inc is an advanced technology company with leadership team form Massachusetts Institute of Technology (MIT), Stanford University, and Harvard University. Our product Simplia is re-inventing Online Local Services Marketplaces, with deep technology and strong leadership and strategy in place.
Leadership Team: Chairman: Ray Stata Founder of Analog Devices (ADI NASDAQ), President & CEO: B Gopinath. He started as a scientist at Mathematics research center of AT&T bell laboratories. He holds several fundamental patents in communications and computer technologies. Advisor: Alain Hanover, Senior Partner Elite Engineers Fund, at Alumni Venture Group (AVG recognized by PitchBook as the most active VC firm in the world in 2018). Advisor: Bill Kerrigan, Bills career includes more than 30yrs of distinguished accomplishments, Including roles as President & CEO of Abine, Radialpoint, and as EVP of McAfee's Worldwide Consumer Business.
Responsibilities and Duties
Architect, develop and maintain high performing & scalable cloud hosted microservices using Node.js frameworks which are highly responsive to requests from front-end.
Extensively engage in iterative development model right from requirement analysis, estimation, development, testing & production support.
Dedicated to deliver high-quality web & mobile server-side solutions on time.
Conduct code reviews to ensure code meets industry accepted standards. Additionally, ensuring that application is not vulnerable to web security threats.
Break down development work into manageable and measurable pieces of work.
Technically guide peer members in the team as needed.
Qualifications
Extensive working experience in Node.js and MySQL.
Innovative and an excellent problem solver.
Good team player who proactively works in achieving team & company goals.
Quick learner and capable of mastering new skills efficiently.
Should possess excellent communication & interpersonal skills and be able to prepare technical PPT's outlining module architecture/standards, conduct demos and document repeatable tasks to facilitate knowledge transfer amongst team members & to relevant stakeholders.
Create unit, integration & automated tests for any developed module/server-side application logic.
Organize, prioritize, and handle multiple tasks/projects simultaneously.
Educational qualifications - BS/MS degree in Computer Science, Engineering, MCA or any similar relevant field.
Skills
Required skills : -
Extensive hands-on Node.js development experience.
Expertise in object-oriented JavaScript.
Deep understanding of design principles behind building high performing & scalable web applications.
Basic understanding of front-end technologies such as HTML, CSS & frameworks preferably vue.js.
Sound knowledge in database design, creating & fine-tuning complex queries preferably using MySQL.
Design and develop elegant rest web services that conforms to rest standards.
Nice to have skills : -
Experience with cloud provider preferably Amazon.
Knowledge on code versioning tools preferably GIT.
Knowledge on CI/CD pipeline development preferably using Jenkins.
Experience in third party systems integration.
Experience
Proven 5 - 6 years experience developing server-side applications using Node.js.
Shift Model
Candidates should be available only for 4 mandatory hours for the scheduled shift in US timings (Open for Night Shifts), In this case Salary will be based on the productive hours spend by the employees.
Work Environment Needs
A proper and quiet work place with all necessary infrastructure is mandatory (Laptop, Headset, Desk, Chair & Power Back up)
Bandwidth Needs
Candidates should have a primary broadband connection with minimum of 30Mbps and a secondary connection which will serve as a back up, company will reimburse the amount incurred towards the broadband installation & monthly data charges borne by the employees, based on the submission of Invoice/receipt to accounts department for both primary & secondary connection.
Company Perks
Night Shift allowance as per company policy
Job Types: Full-time, Part-time, Contract
Experience:
total work: 6 years (Preferred)
developing server-side applications using Node.js: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Shifts:
Night (Required)
Work Remotely:
Yes"
Data Science AI Ops Lead,"Chennai, Tamil Nadu",AstraZeneca,None,Organic,"Job Title: Data Science AI Ops Lead
Career Level: E1
Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Role
We are looking for an AI Ops Lead to join our Data Science & AI team in Chennai. The ideal candidate will have industry experience working in a range of different cloud environments where they devised and deployed large-scale production infrastructure and platforms for data science. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery.
The successful candidate will be part of building a new, close-knit team of deeply technical experts and together have the chance to create tools that will advance the standard of healthcare, improving the lives of millions of patients across the globe. This platform will support major AI initiatives such as clinical trial data analysis, knowledge graphs, imaging & omics for our therapy areas. You will also have responsibility to help provide the frameworks for data scientists to develop scalable machine learning and predictive models with our growing data science community, in a safe and robust manner.
As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, machine learning, and data to enable the productivity of AstraZeneca. You will help envision, build, deploy and develop our next generation of data engines and tools at scale. You will be bridging the gap between science and engineering and functioning with deep expertise in both worlds.
Key Accountabilities
Own the development roadmap to build and operationalise our data science environment, platforms and tooling.
Support any external opportunities, through close partnership and engagement such as Benevolent.AI collaboration.
Deployment of systems, applications and tooling for data science on cloud environments.
Understanding of the necessary guardrails required for different use cases and data sensitivities.
Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
Provide the necessary infrastructure and platform to support the deployment and monitoring of ML solutions in production Optimizing solutions for performance and scalability.
Liaise with the Data Engineering team to ensure that the platform and the solutions deployment therein benefit from an optimised and scalable data flow between source systems and analytical models
Implementing custom machine learning code and developing benchmarking capabilities to monitor drift of any analyses over time.
Understanding of the latest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI and Domino. Experience working on regulatory data would be helpful but not essential.
Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
Being an active member of the Data Science team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure.
Appreciation of how to optimise predictive models, run in production and monitor. Experience running a service team will be beneficial.
Testing and assessing the quality of new tools.
Line management responsibilities as well as team recruitment, training provision and coaching

Candidate Knowledge, Skills and Experience
BSc in Computer Science or related quantitative field or MSc/Ph.D degree in Computer Science or related quantitative field.
More than 2 years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
Experience managing an enterprise platform and service, handling new customer demand and feature requests.
Strong software coding skills, with proficiency in Python and Scala preferred.
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential. Certification in appropriate areas will be viewed favourably.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.
Experience provisioning computational resources in a variety of environments.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Experience with automation strategies e.g. CI/CD, gitops.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Creative, collaborative, & product focused.
Ability to just get things done.
Other
The role will have line reports and task management responsibilities within project or services may occur.
Department – Data & Analytics, S&EUIT
Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.
Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Data Visualisation, Knowledge Management, Data Science, Data Analysis and Information Governance.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Python Developer for (Antivirus Products),India,Pitambari Products,None,Organic,"PYTHON DEVELOPER FOR (ANTIVIRUS PRODUCTS)
DEPARTMENT : IT
B.Sc in IT / Computer Science / BCA / MCA / B. Tech (IT) candidates should apply for this position. Any Security certification
Implement efficient functionality using Django, Visual studio and web technologies
Translate high level ideas into usable interfaces
Responsible for designing algorithms and implementation including loading from disparate data, sets, preprocessing using Hive
Continuously review and identify security improvement opportunities in existing processes, services, and workflows, to ensure security product is robust against current and future security threats.
Research and formulate define security solutions which meet internal and external requirements, including industry standards
Working on content based and collaborative recommendation engine
Developing AI Solutions in the security domain using convolutional neural networks (CNN) and a combination of deep neural networks such as CNN & RNN
Expertise in popular Python framework like Django Flask or Pyramid Python
Hardcore Developer along with C++, Java Knowledge
Integrate user facing elements into applications
Implement security and data protection solutions
Expertise in programming of deep learning/AI skills using Python, Tensorflow and deep learning frameworks like Keras, Pytorch
Job Location : Headoffice, Thane"
"Software Engineer, Backend (India)","Bengaluru, Karnataka",Carousell,None,Organic,"Carousell is one of the world's largest and fastest growing mobile classifieds apps with a mission to inspire every person in the world to start selling and buying to make more possible for one another.
Since our launch in Aug 2012, we've expanded into 7 countries, 19 major cities with over 250 million listings. As a team of passionate individuals working together to solve meaningful problems, there is so much more for you to discover in a career with Carousell.
Meet the team that handcrafts various parts of the mobile applications, website and backend systems in order to deliver the best user experience. Here at Carousell, our engineering team works on a myriad of problem domains. You get to work on building the simplest buying and selling experience on our mobile applications, dive deep into our database systems that powers the business, or even work on tools to empower the rest of the teams in Carousell. Every month, we organize an engineering day with different topics, ranging from product hackdays to a Swift workshop by the engineering team members to keep our minds sharp.
Ensuring that the user experience stays simple is complicated - and we take pride in our work to keep things that way.
We are now looking for Backend Engineers to join our Engineering Team based in India.
You will:
Design and build scalable APIs for the Carousell marketplace platform.
Write clean, testable code with unit tests.
Work with infrastructure team on deploying, scaling and performance optimization.
Participate in code reviews to maintain a high-quality code culture.
Build revenue impacting products including advertisements and visibility.
You have:
Degree in Computer Science, Software Engineering or other equivalent degrees/experience
Experience in either Go, Python, Django/Flask, RESTful APIs
Ability to write clean, maintainable and performant code making use of appropriate design principles and patterns.
Excellent knowledge of RDBMS such as PostgreSQL and technologies such as Redis, Cassandra, Kafka, Lucene / Elasticsearch / Solr.
Strong experience in optimizing the performance of backend systems and scaling infrastructure components.
Experience in building large, scalable distributed systems with good understanding of microservices architecture and associated principles.
Experience with TDD/BDD and agile methodologies
Good to have:
Experience with online advertisement technology.
Knowledge of managing data consistency in distributed systems.
Experience working with asynchronous systems."
Machine Learning Science Leader,India,CareerXperts,None,Organic,"Passionate about Big Data, Machine Learning and Predictive Software? Interested in leading new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
We are looking for a dynamic Machine Learning science leader to found and head the Data Science function in Bengaluru. As Head of Data Sciences, you will lead a high performing team of scientists and engineers in the development of innovative and rigorous Machine Learning techniques that advance Machine Learning technology for advertising and convert to high impact solutions for the business.
Major responsibilities:
Recruit, coach, and manage a team of scientists and data science engineers, lead cutting-edge research projects, and influence the technical direction of the Ads business.
Innovate and leverage machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Formulate and test hypotheses, extract signals from peta-byte scale, unstructured data sets, and ensure that our display advertising business delivers the highest standards of performance
Collaborate with distributed cross-functional teams on common goals.
Experience
6 + years , Start-up / Entrepreneurial experience preferred.
Qualification
MSc or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field. (PhD preferred).
4+ years of industrial experience in machine learning and predictive modeling, including 2+ years experience in leading junior team members and guiding them on machine learning and data modeling applications.
Proficient in Java, C/C++, or Python (or similar scripting language).
Proficient in R, Matlab, or another statistical software.
Strong communication and data presentation skills.
Preferred Qualifications:
7+ years of industrial experience in predictive modeling and analysis, predictive software development.
Experience handling gigabyte and terabyte size datasets.
Experience working with advertising, retail or e-commerce data.
Experience working with distributed systems and grid computing.
Experience working with distributed teams.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences."
"Software Engineer, Networking","Bengaluru, Karnataka",Google,None,Organic,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.
Minimum qualifications:
Bachelor's degree in Computer Science, or related technical field, or equivalent practical experience.
5 years of relevant work experience.
Experience designing and implementing distributed software systems (e.g., Java, C++, or Python).

Preferred qualifications:
PhD degree in Computer Science.
Experience with Linux networking stack. ( TCP/IP , NAT, IPtables , policy routing)
Familiarity with Enterprise or Datacenter Network architecture
Familiarity with Datacenter network switches (Eg Cisco Nexus 9000, Arista 7500 series)
Familiarity with routing protocols (BGP, IS-IS)
Familiarity with Network Virtualization , Data center bridging , VXLAN
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
The Google VMware Engine enables customers running on-premises VMware workloads to seamlessly migrate to Google Cloud without having to re-architect or refactor their applications. Leverage the value of your existing VMware investments while maintaining operational continuity and avoiding data center management, hardware refreshes, and procurement cycles.
Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
Responsibilities
Build our networking platforms, systems and infrastructure using your strong background in networked and distributed systems.
Design, develop, test, deploy, maintain, and enhance networking software solutions.
Manage individual projects priorities, deadlines and deliverables.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Software Engineer III - News Distribution,"Hyderabad, Telangana",FactSet Research Systems,None,Organic,"The News Distribution team is responsible for designing and maintaining the various APIs, services, and databases needed to support searching and alerting on document-based data across all FactSet applications and workflows. We work closely with Product Developments and other engineering teams to determine the requirements and implement solutions that are both scalable and maintainable.
Highly Desired Skills:
2 – 5 years of industry experience
Industry experience in C++
Experience with C++, Python, Java
Familiarity with OOP concepts
Experience working in a Linux environment
Experience with Linux debugging and profiling tools such as GDB
Experience with service-oriented architectures
A strong interest in distributed systems and in developing highly performant software
Strong communication skills, with both technical and non-technical people
Independent and proactive
Required Skills:
B.Tech or M.Tech in Computer Science or equivalent
Comprehensive understanding of programming principles
Comfortable navigating a large codebase
Experience with Relational or NoSQL databases
Good communication and problem-solving skills
Desire to work in a collaborative team environment
Comfortable working in a real-time, 24/7 production environment"
Software Development Engineer III (Backend),"Bengaluru, Karnataka","Zendrive, Inc.",None,Organic,"“Perfection is achieved not when there is nothing more to add, but rather when there is nothing more to take away.” – Antoine de Saint-Exupery

While there may be no such thing as a perfect world, we are working towards making it a safer place to drive by building products that support the evolution of transportation. We are writing code that processes terabytes of data in real time collected through smartphone applications that speak to millions of vehicles. Imagine the best-in-class infrastructure that makes it possible to analyse and monetize this data.

If you have 5+ years of programming experience with Java / Python, and are passionate about achieving perfection in coding, you may be what Zendrive needs for its back-end team.

What we need you to do:

Understand and analyse project requirements and translate it into specifications and programming deliverables
Work closely with analysts, designers and clients to enhance existing applications and build new ones
Test and debug the backend infrastructure in controlled situations
Maintain systems and update as per requirement

What you need to have:

BE/BTech or MTech / Dual degree in Computer Science from a Tier-1 institute
Strong understanding of data structures, algorithms and their application
Hands-on experience of coding in Python and Java among other programming languages
Good understanding of building scalable systems which are easy to operate and cost effective

What we offer you:
Apart from a competitive salary, we offer you the option of working from a location of your choice until we determine that it is safe to work in a physical office environment. You also get to collaborate with some of the best software engineering talent in the world and a cross-functional team that includes designers, frontend programmers and product managers. We also offer you the opportunity to create products that have a deep material impact on the world.

If you are excited about the job description and see yourself excelling in this role, hit the APPLY FOR THIS JOB button at the end of this page. Our Talent Acquisition team will get in touch with you."
Data Management Executive,"Chennai, Tamil Nadu",Marudhar Tanchem Pvt Ltd,"₹18,000 - ₹25,000 a month",Organic,"Proven experience as Data Management.
Excellent understanding of data administration and management functions (collection, analysis, distribution etc.)
Familiarity with modern database and information system technologies
Proficient in MS Excel ( Knowledge in Macros will be advantage)
Knowledge in Google Sheet will be of higher advantage
An analytical mindset with problem-solving skills
Excellent communication and collaboration skills
BSc/BA in Maths or computer science or relevant field
Job Type: Full-time
Salary: ₹18,000.00 - ₹25,000.00 per month
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
No"
Python Developer,"Madhapur, Hyderabad, Telangana",FinAcPlus,None,Organic,"We provide virtual business process and software services to various types of overseas clients and this position is to be part of the team which provides support to USA client from e-commerce Industry

RESPONSIBILITIES
To Work on developing projects using Python
Able to work on fast paced, short term projects
Able to switch directions quickly and ask for clarifications where necessary
Able to use object oriented design and test driven development techniques
Have a good understanding on ETL and able to compile data from various sources
Experience in API development is a Plus
Experience with AWS or other cloud technologies is a Plus
QUALIFICATIONS and experience
A range of 2 to 4+ years of experience in Python Development
Demonstrate the ability to work for new projects and automation projects
Strong knowledge of Python library and SQL server related implementation.
Excellent oral and written communication skills, including presentations to senior management
Bachelor’s Degree in Computer science and other equivalent qualifications.

QUALITIES
Strong commitment to support overseas client with utmost care.
Excellent communication skills to interact with customers and business partners of the client.
Good team player with greater level of integrity
Maintains Strict confidentiality of Client’s Data, Technology and information
Self-Motivated and Tough task master.
Quick learner and continuous learner of new technologies.
Location: Madhapur, Hi-Tech City, Hyderabad
Timings: IST 2-30pm to 11-30pm
salary : Best In Industry
Send Application TO: hr@finacplus.com"
Machine Learning Engineer - Global AI Platform Company,"Gurgaon, Haryana",Michael Page,None,Organic,"Apply
share this job
Email Job
Save Job
Get to be a part of the growth of the Intelligence Systems team from ground up
Opportunity to drive Innovation powered by Data Science, AI and ML
About Our Client
Our client provides a platform for building bespoke software using AI and a library of building blocks to democratise software development; making it faster, more accessible and less expensive for everyone.
Job Description
The key responsibilities of Machine Learning Engineer would be to:
Build, maintain and manage data pipelines that support the modelling initiatives of data scientists
Work closely with data scientists and engineering teams to productionise machine learning models
Automate machine learning workflows
Work with wider product teams to make the right data available for model building and analysis
Implement the analytical libraries, programming languages, and frameworks in production
Engineer to scale in the cloud using methodologies such as service-oriented architectures, containerised applications and lambdas
The Successful Applicant
As a successful candidate for Machine Learning Engineer role, you should have:
Higher university degree (MSc or PhD) in Computer Science, Engineering, Mathematics, Physics etc
Hands on expertise in programming language: Python & Scala
Sound fundamental knowledge of data querying and manipulation using SQL
Practical experience in ML in research and development or academic projects
Ability to communicate with diverse stakeholders
Software engineering experience (CI/CD, Docker, Kubernetes)
Experience engineering at scale using production level architecture
What's on Offer
As a Machine Learning Engineer, an opportunity to be a part of the Intelligent Systems team based in Gurgaon and work closely and collaborate with global product and engineering teams across three locations London, New Delhi and Los Angeles."
Senior/ Software Engineer - Data Engineering,"Bengaluru, Karnataka",zeotap,None,Organic,"Zeotap is a Customer Intelligence Platform (CIP) that helps companies better understand their customers and predict behaviors, to invest in more meaningful experiences. We enable brands to build on a nucleus of first-party data to win new customers and grow their loyal base. Our independent but seamlessly integrated modules include customer data unification, identity resolution, enrichment, analytics/modeling (including in data clean rooms), and activation to 100+ partners in the marketing ecosystem.

Recognized by Gartner as a ""Cool Vendor"" (2020) and by AdExchanger as the “Best Data-Enabling Technology” (2019), our platform meets the highest enterprise data privacy and security standards, including GDPR, ISO 27001 and CSA STAR. We serve the world's top brands, agencies and publishers across a dozen countries in Europe, North and Latin America, and APAC. Zeotap is also the founding member of ID+, a universal marketing ID initiative.

Responsibilities
You design, develop and implement products and modules considering aspects of performance, scalability and fault tolerance
You explore and operationalize new scalable technology in zeotap
You handle escalations and customer issues from time to time
You behave as a consultant to internal stakeholders and help design a creative solution for our customers
You are able to work on diverse technologies in Bigdata and Event Processing.
You are able to adapt and use emerging technology
You take complete responsibility for the feature/module
You need to mentor junior developers
You adhere to zeotap’s company, privacy and information security policies and procedures
You complete all the awareness trainings assigned on time

Requirements
4+ years of experience in building and deploying high scale solutions
Must have very good problem-solving skills and clear fundamentals of DS and algorithms
Expert coding skills in Java or Scala
Expert coding skills in Go or Python is a huge plus
Apache Spark or other Bigdata stack experience is a mandatory
High level and low-level design skills.
Deep understanding of any OLTP, OLAP, NoSQL or Graph databases is a huge plus.
Deep knowledge of distributed systems and design is a huge plus
Hands-on with Streaming technologies like Kafka, Flink, Samza etc is a huge plus
Good knowledge of scalable technologies involving Bigdata technologies
Bachelor or Master’s degree in information systems, computer science or other related fields is preferred

What we offer
Become part of a friendly, diverse team that values trustworthiness, agility, and a pioneer spirit
Join the company founded by successful entrepreneurs with a distinguished track record
Make an impact: at zeotap, your voice is heard, your opinion matters, your ideas change things
Work with cutting edge technologies and on-demand equipment
Your health is important to us: we offer a great health insurance (for you and your family)
Enjoy great work atmosphere, an awesome office, regular team events and much more
Get free lunches in the office, snacks and drinks in the evening, and other tax free benefits
We are family-friendly, respect your work-life balance and offer flexible office hours
Zeotap welcomes all – we are equal employment opportunity & affirmative action employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.
Interested in joining us?
We look forward to hearing from you!"
Job Opening for Kubernetes Developer(C++)-Pune (Baner)!,"Pune, Maharashtra",Talent Corner Hr Services Private Limited,"₹15,00,000 - ₹30,00,000 a year",Organic,"Here is the Job Description:


Role: Kubernetes Developer(C++)-Pune (Baner)!


We are open to hiring candidates PAN India but will have to relocate to Pune once the current state of affairs(Covid-19) recuperate.


Pre-requisite: Candidate must have a high end personal laptop, High speed broadband connectivity and stable power supply for work from home


Experience: 5-10 years

Education: Any Graduate/B.E/B.Tech/MCA/M.Tech

Location: Pune(Baner)

Work Remotely: Due to COVID-19(Interim)

Working Days: Monday to Friday(5 days working)




Roles and Responsibilities:


Requirement for Kubernetes Developer:


Graduate or higher in computer science degree

Really needs to be C++ hands-on, with coding in C++ for two or more years.

At least two recent big projects (4+ months) in the virtualization/cloud area (not just usage of technology for the product but project itself for it).

Good in Data Structures/Algorithms.

Knowledge of these is a big plus:

Design patterns

Kubernetes

One or more clouds (like any cloud certification etc. is also a big plus)



Ready to join ASAP (lesser the notice period, better it is)

Excited to work in a startup environment

5.00-15.00 Years"
Junior Data Analyst,"Gurgaon, Haryana",GroundTruth,None,Organic,"Role: Junior Data Analyst
Location: Gurgaon, India
GroundTruth is the leading global location platform that leverages data and insights to drive business performance. Using its proprietary Blueprints technology, GroundTruth is able to learn about mobile users and reach them at the right place and right time, ultimately helping companies make smarter marketing decisions, increase sales, and grow their businesses. Since its foundation in 2009, GroundTruth has launched several innovative products and won numerous awards, including Inc. 5000’s Fast Growing Private Companies and Deloitte's Fast 500 Technology companies. Today, we're proud to employ over 400 employees across three continents and serve millions of marketers across 21 countries. Learn more: www.groundtruth.com

This will be an exciting and challenging role that will enable you to work with very large data sets, expose you to cutting edge analysis techniques, work with the latest components in cloud architecture and gain experience in the usage of location data to drive businesses. As an early member you will have significant opportunities for growth within the organization. A successful applicant will be passionate about technology and developing a deep understanding of human behavior in the real world. They would also have excellent communication skills, be able to synthesize and present complex information and be a fast learner.
You will:
Learn about location-driven marketing and how companies are using location signals to drive their business
Work closely with marketing, growth strategy and sales teams based out of our offices in USA, Germany
Develop re-usable tools and templates to quickly create data driven narratives
Gather requirements, design analyses, identify data sources and define measurement metrics to present insights and recommendations for ready consumption
Be responsible for managing your work pipeline and creating re-usable analysis and documentation
You have:
BA/BSc/B.E./BTech degree in Computer Science, Statistics, Mathematics, Economics, Physics or related fields from Tier 1/Tier 2 colleges
6 months - 2 years of experience in working with data and conducting statistical and/or numerical analysis
Strong understanding of how data can be stored and accessed in different structures
Experience with writing computer programs to solve problems
Strong understanding of data operations such as sub-setting, sorting, merging, aggregating and CRUD operations
Ability to write SQL code and familiarity with R/Python, Linux shell commands
Be willing and able to quickly learn about new businesses, database technologies and analysis techniques
Ability to tell a good story and support it with numbers and visuals
Strong oral and written communication
How you can impress us:
Experience working with large datasets
Experience with AWS analytics infrastructure (Redshift, S3, Athena, Boto3)
Experience building analytics applications leveraging R, Python, Tableau, Looker or other • Experience in geo-spatial analysis with POSTGIS, QGIS
We operate in a fast paced, dynamic environment where everyone on the team is committed to the success and growth of GroundTruth. Our culture is highly entrepreneurial and our success comes from our employees who voice their opinions and ideas to facilitate growth to our bottom line. We reward hard work, support career development, offer comprehensive benefits, and foster a fun and friendly work environment.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status"
Data Analytics Specialist - Microsoft Azure,"Mumbai, Maharashtra",Lloyds Register,None,Organic,"Date: 20-Jul-2020
Location: Mumbai, IN
Company: Lloyds Register
Job ID:31135
Location:Mumbai : India Management Office (LR_L000156)
Position Category:Information Technology
Department:IN710032 : Group IS Mumbai (IN710032)
Position Type:Employee Regular
Role Purpose:

We are seeking an experienced Microsoft Azure Analytics Developer to work with key business stakeholders to identify and deliver BI reports. We are building a Data Analytics Platform using Azure technologies – Azure Data Lake, Azure Data Warehouse / Synapse, Power BI etc. This platform will ingest, transform, prepare and train data from disparate source systems including SAP, Oracle, Salesforce.com etc.
We are looking for an individual with strong skills in Power BI, Azure Analysis Services and Azure Data Warehouse / Synapse. The Azure Analytics Specialist will be responsible for role-based and data-level security of reports including managing platform access for external data exchange with customers and regulatory bodies.
The Azure Analytics Specialist will develop reports for users, during which time he / she will gain understanding of the business and existing data structures and processes, expanding their skills as required with the platforms used by the company. The individual will work collaboratively with business stakeholders in developing new and refining existing data models / reports / processes.

Key Responsibilities:

Build and enhance existing data models in Analysis Services, Azure Datawarehouse / Synapse to meet reporting requirements
Design and build reports and dashboards and assist in development of complex ad hoc queries and analyses in Power BI
Design and build reports role-based and data-level security models for both internal and external clients
Manage security-based data exchanges with external clients and regulatory bodies
Own the release management process and deployments to all environments
Support user community on Power BI technology and functionality
Work with infrastructure team and Microsoft to ensure system reliability
Conduct activities in line with internal procedures, legislation and industry standards.
To pursue Continuous Professional Development and maintain a high degree of discipline knowledge and awareness.
To mentor/coach other specialist employees to achieve effective specialist knowledge transfer and application.
Ensures documentation/data/information and tasks relevant to the section are planned, evaluated and processed in accordance with local business requirements and agreed deadlines.
Review & analyse data to provide management information/statistics, including the identification and reporting of process failures, to support the overall delivery of processes.

Technical / Professional Qualifications / Requirements:

Sound knowledge and experience of building Power BI based reports and dashboards
Good understanding of data warehouse principles and data modelling for reporting
Strong experience of SQL, Power Query, DAX, MDX and other query processing languages
Data Science experience using Python, Scala, R would be desirable
Experience in Machine Learning and Artificial Intelligence for Predictive Analytics would be an advantage

The Lloyd's Register Group comprises charities and non-charitable companies, with the latter supporting the charities in their main goal of enhancing the safety of life and property, at sea, on land and in the air - for the benefit of the public and the environment. (Group entities)


Job Segment: Database, ERP, Oracle, SAP, SQL, Technology"
Data Science Online Trainer,India,Prognoz,None,Organic,"Job Id : PTPL/HR/8
Anywhere in India
1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics."
Google Certified Professional Data Engineer (BigQuery),"Bengaluru, Karnataka",SPX FLOW,None,Organic,"This position will be part of Celeros Flow Technology. Celeros Flow Technology is a divestiture company of SPX Flow and this role will be based at Bangalore location. The India registered company for Celeros is Flow P&E India Private Limited. Spun out of the SPX Flow, the company fully concentrates on serving key market sectors where its solutions will have maximum traction. These are - Oil & Gas, Power, Chemical Processing, Water Treatment and Marine. Our product line consists of Pumps, Valves, Filters, Closures etc. To know more about our company please visit https://www.celerosft.com/en-us
Google Certified Professional Data Engineer
Google Certified Professional Data Engineer will work as a part of Celeros BI & Analytics team and will be responsible for designing, developing, and deploying modern data warehouse solutions in Google BigQuery platform. This person should have prior experience of extracting data from multiple source systems including SAP, AS/400 and other legacy ERP systems including flat files. Experience and knowledge of SAP systems and data sources is critical for this role. This person will support data feeds to Power BI and Looker reporting platforms. This position will be based at our Bangalore office and will be part of our global IT team.
Key Responsibilities
Design, develop and deploy modern data warehouse solutions in Google BigQuery platform.
Gather and document business requirements and translate it into technical design documents .
Map and extract data from SAP and other legacy ERP as source systems.
Create technical documentation, e.g. data flow diagrams, end user guide and technical operations guides.
Monitor data load jobs and perform root cause analysis of production issues.
Lead the efforts in building end to end streaming and batch data analytics pipelines. From data ingestion, processing, storage, analysis, machine-learning to visualization. Understand big-data principles and best practices. Deliver projects in data analytics, machine learning and AI.
Design architectures, publish reference code and establish data structure design based on business requirements. Should be pretty hands on.
Perform code reviews, ensure code quality and encourage a culture of excellence.
Required Skills:
Mandatory Certification: Google Certified Professional Data Engineer
5+ years of strong technology experience in the field of Big Data, Data Analytics, Data Science or Machine Learning.
Strong analytical skills.
At least one full implementation project experience with SAP as the source system and BigQuery as the target data warehouse.
Ability to support integration between Power BI & Looker with BigQuery data warehouse.
Experience with building modern data warehouse solutions in Big Query.
Experience with SAP and other legacy ERP as source systems would be an additional advantage.
Experience of working with Power BI , Looker, Data Studio or similar reporting platform.
Familiarity with standard source repositories (GIT, BitBucket)
Experience and solid knowledge in Agile (Scrum) Methodologies
Experience with managing a customer relationship with a US/UK based customer.
Desired Skills:
Working Knowledge of BI & visualization tools like Google Data Studio, Qlik Sense, Micro-strategy etc
Knowledge of cloud platforms like Google Cloud Platform, AWS, Azure
Familiarity with standard source repositories (GIT, BitBucket)
Hands-on experience in building Machine Learning and Deep Learning Models with Python, numpy, scipy, scikit-learn, pandas, Tensorflow, Keras, PyTorch etc.
Big Data experience - should have experience in building end to end data analytics pipelines with products like Apache Beam, Kafka, Spark etc.
Should understand and be able to command architecture design for Machine Learning systems.
Knowledge of implementing IoT and predictive analytics.
Membership of recognized professional accounting body
Required Education
B.E/ B.Tech in CS or MCA / Masters in Business Systems Analysis from recognized universities and institutes in India .
Excellent Communication skills in English Language."
Artificial Intelligence (AI) Internship,"Bengaluru, Karnataka",Kero Labs,"₹5,000 - ₹10,000 a month",Organic,"About the company:
Kero started as an initiative to bring artificial intelligence to machines. We are an artificial general intelligence based robotics company in India. We aim to automate repetitive tasks and processes in various industries thereby enhancing the performance and speed of machines, maintaining consistent quality of products and creating smart automated systems. We use machine learning and deep learning algorithms to train machines which can learn and perform intelligently.
About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data preparation 2. Working on language modeling and GAN network modelling 3. Training deep learning models and deploying them
Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 8th Aug'20 and 12th Sep'20
are available for duration of 3 months
have already graduated or are currently in any year of study
are from Bangalore and neighboring cities
Females willing to start/restart their career may also apply
Number of internships/jobs available: 5
Categories: Artificial Intelligence (AI),Computer Science,Engineering"
Business Intelligence Database Developer,"Chennai, Tamil Nadu",Rexon-Proserv,None,Organic,"Job Description
Description
The Business Intelligence Database Developer is responsible for implementing and constructing BI solutions which will fulfill or improve the company’s various data and information needs. The BI Database Developer will perform as member of the Development Team supporting organization-wide tactical and strategic analytics, dashboards, scorecards, reporting, and decision support activities. The BI Database Developer will work with team members to create clean, well-structured, and scalable database schemas, stored procedures, ETL processes, operational and executive dashboards, and other database structures that support organizational data and reporting initiatives. This role works closely with business users to collect requirements and formulate customized business intelligence solutions.
Required
Associate’s Degree in Computer Science or related discipline
or
1 year relevant experience
Good communication skills
Preferred
SQL Server, ETL (SSIS) and reporting (SSRS)
Experience with data warehouse design
Experience in managing complex ETL processes
Some experience in .NET development (C#, asp.net, mvc)

Education
Associate’s Degree in Computer Science or related discipline
Doctorate: Doctorate Not Required"
Software Engineer,"Mumbai, Maharashtra",Morningstar,None,Organic,"The Software Engineer focus would be to work with multiple cross functional teams and the QA team to deliver high quality software in the given time. As a Software Engineer, you would need to be involved in the Design level discussions and decisions. You would also need to work with the Global teams and hence needs to be good and crisp in communication. Should know how to work in an Agile way and if needed take additional responsibilities to deliver the software.
Responsibilities:
Be able to understand the design and develop new Features and Services using Python and AWS
Maintaining the existing services and APIs
Drive design decisions of code
Lead research and provide findings in a measurable manner
Actively participate in the Agile process and work with the team on project delivery
Collaborate with different teams in Morningstar when required and understand their requirements to help onboard them on to Data Lake
Practice and maintain high standards of development and quality checks
Preform periodic code reviews and mentoring of junior associates
Requirements:
A Bachelor’s degree in Computer Science or equivalent qualifications
2-4 years of experience working as a software developer with Python as the primary programming language, in a Unix environment
Solid understanding of object-oriented programming and design
Knowledge on AWS Services like API Gateway, Lambda, Dynamo DB, Elastic Search, S3 and Glue is desired
Exposure with building REST APIs using Python and framework such as Flask, Django
Should be able to write unit and integration test cases using pytest
Should understand CI/CD process and tools like Jenkins, CloudFormation, Terraform
Knowledge on Spark, PySpark, Hive, Pandas will be advantageous
AWS Certification (Solutions Architect or Developer) is a big Plus
Hands on experience on Apache Airflow is a big plus
Should have good analytical skills, also should have learning attitude
Should understand design concepts and have proven experience in designing software
Excellent verbal and written communications skills
A high degree of self-motivation and the ability to adapt quickly to new tasks.
Morningstar is an equal opportunity employer.
I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity"
LOS CTH Conversion Hiring - Technical Analyst 3-Support,"Bengaluru, Karnataka",Oracle,None,Organic,"LOS CTH Conversion Hiring - Technical Analyst 3-Support-20000979

Preferred Qualifications

Oracle Advanced Customer Services / Oracle Functional services has been at the helm in Development and Support projects since its inception. It has pioneered the suppleness of 24X7 production support and solution development processes and has stood as a testimony for others to follow the trail of success. This division manages several Cloud technologies, ebusiness and Siebel applications across Supply Chain, Finance, iProcurement, Advanced Supply Chain Planning, Demantra, Oracle Incentive Compensation, Fusion Middleware, Oracle Identify Management, PeopleSoft/Transportation management and Database support

Primary -
1) Experience in technology around Cloud / Oracle Application ERP R12 that contains Finance /SCM /ERP Cloud/SCM Cloud /HCM Cloud/ Business Intelligence/EPM/FMW/IDM/PeopleSoft/OTM/Database
2) Resource should be able to independently provide Techno-functional support on
3) Resource should be self-driven and should be able to investigate, analyze issues.
4) Excellent communication skills. Able to communicate very well functionally in highly escalated situations. Able to produce audience appropriate communication with executives, support personnel
5) Requirement is to work in rotational shifts including Night Shifts.
6) Any additional knowledge on other modules will be added advantage.
7) Resource should be able to write & execute SQL statements and provide solution for enhancements/new developments
8) Well-developed troubleshooting skills, ability to analyze details and synthesize ""big picture"", frequently working with incomplete or ambiguous data. Creative use of industry standard tools to aid in the diagnostic process.
9) Resource should be able to write & execute SQL statements and provide solution for enhancements/new developments

General Requirements:
1) Great team player with leadership skill and Can-Do attitude
2) This position requires strong analytical and problem solving skills with demonstrated initiative and flexibility to meet deadlines and end user expectations.
3) Should have good communication skills including written and verbal
4) Ability to work with diverse teams
5) This is a client-facing role & the candidate will have regular interactions with various client managers and business end-users.

Good logical and reasoning skills. Willingness to work in a 24X7 production support environment and shifts with a clear cut understanding of production support processes and tools like Incident Management, Ticketing Systems, Service Level Agreements, Escalation process to name a few. Candidates must have good communication skills and be willing to learn and work on emerging technologies.
Detailed Description and Job Requirements
As a member of the Support organization, your focus is to deliver post-sales support and solutions to the Oracle customer base while serving as an advocate for customer needs. This involves resolving post-sales non-technical customer inquiries via phone and electronic means, as well as, technical questions regarding the use of and troubleshooting for our Electronic Support Services. A primary point of contact for customers, you are responsible for facilitating customer relationships with Support and providing advice and assistance to internal Oracle employees on diverse customer situations and escalated issues.

As a Sr. Support Engineer, you will be the technical interface to customers, Original Equipment Manufacturers (OEMs) and Value-Added Resellers (VARs) for resolution of problems related to the installation, recommended maintenance and use of Oracle products. Have an understanding of all Oracle products in their competencies and in-depth knowledge of several products and/or platforms. Also, you should be highly experienced in multiple platforms and be able to complete assigned duties with minimal direction from management. In this position, you will routinely act independently while researching and developing solutions to customer issues.

Job duties are varied and complex utilizing independent judgment. May have project lead role. 4 years experience with Core products or five years experience with Applications products and have a technical degree i.e., BS Computer Science/Management Information Systems/Science/ Engineering/Math/Physics/Chemistry with a 3.0 GPA OR (for Applications) proven professional/ technical experience, i.e., demonstrating an understanding of Applications at a functional and technical level (preferably Oracle)"
Sr Business Systems Analyst,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
"" RESPONSIBILITIES:
Help define technical direction of CDR and influence support of technological innovation within all sub-departments
Drive continuous improvement related to CDR technologies and associated business processes, working to enhance speed and quality of business outputs, while reducing cost.
Work with functional area stakeholders to assess and prioritize system and business needs related to technology and process optimization.
Work with and manage vendors, consultants and other external partners to effectively leverage new data sources and/or business tools that contribute to optimization of internal and external data flows.
Provide oversight and support to business during requirements definition, systems and process design, data migration, data cleansing and user-acceptance testing activities.
Drive the communication to and education of users on business tools and the functional impact to workflows and processes, including oversight and development of training content, formal business guidelines and reference material.
Evaluate business technologies and their underlying processes to ensure quality and consistency related to performance, usability, user best practices and issue resolution
Ensure a data infrastructure that supports efficient and effective collection, monitoring, ownership and measurement
Ensure data flow is streamlined and centralized to minimize data redundancy, inaccuracy and incompleteness
Remain at the forefront of industry-specific systems and technologies and have full understanding of their application to clinical research and clinical trial management
Assist with project meetings, communicate with the team, internal/external partners and senior management
Establish close partnerships with stakeholders to perform hands-on planning, conduct business requirement sessions, interviews with business, workshops with the business to understand business need, document business requirements related to data strategy, data quality, applications, application interfaces, documentation and maintenance of business requirements, including work flow analysis and process engineering
Assist development teams in grooming and clarifying requirements to develop processes that help optimize business performance, support internal controls and performance KPIs
Creates, manages source-to-target data maps, data profiles, data lineage, data dictionary, data design, data flow, business rules, metadata, data quality, SDLC documentation. Defines and documents data standardizations to be performed, data enrichment operations, data validations, data security requirements, and data exception handling processes.
Participate in design review sessions and exercises around enterprise analytics standards and documentation, including reporting, testing methodology, and data validation
Work with vendors to validate and refine technical specifications against business requirements
REQUIRED KNOWLEDGE, SKILLS AND ABILITIES:
Experience in the Healthcare Industry with Life Science / Contract Research Organization (CRO) experience a strong plus.
Specific experience in CRO related solutions including CTMS, ODM, CDISC / SDTM, eDC, Safety, Lab systems is a strong plus
Experience working in a regulated Healthcare environment and a solid grasp of CFR Part 11.
Proven experience working with big data and technologies like Hadoop, Spark, Oozie, Hive, Hue ..etc.
Extensive interpersonal skills, an ability to lead multifunctional teams, and to manage staff and mentor and develop junior staff.
Demonstrated planning and organizational skills including project management
Able to prioritize various responsibilities and timelines and to adapt quickly to changing circumstances.
3-5+ years relevant work experience.
Excellent verbal and written communication skills

DESIRED ADDITIONAL SKILLS AND ABILITIES:
Experience with rule based expert systems and machine learning algorithms
Experience developing distributed, data-intensive software.
Previously worked in agile environments
Experience with AWS infrastructure like S3, Redshift, EC2, etc.
Experience with NoSQL databases like MongoDB
Experience building core services/frameworks
Experience with micro services architecture
Experience with near real-time, data streaming data flows, and solutions a strong plus.
Product development experience preferred.
Experience working with Agile methodologies, Scrum preferred.""
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
40908 Systems Opns Engineer 1,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
""Job Description
Job Title: Systems Opns Engineer 1
Reports To: SOC Team Lead
Department: Service Operations Centre
Location: Bangalore
SUMMARY
IQVIA as the world’s largest provider of biopharmaceutical development services and commercial outsourcing services, we’ve spent more than 35+years changing millions of lives for the better – all over the world. Work doesn’t get much better than that. You can be among the more than 30,000 employees around the world making a meaningful difference.
We’re looking for a Shift Lead for IT Service Operations Centre (SOC). Service Operations Center team is mandated to ensure the availability of the internal IT infrastructure and provide the highest level of client satisfaction. The shift lead ensures that standards and processes are followed to provide effective, efficient services and meet customer and business requirements. The hands-on Shift Lead is primarily responsible for managing Mail box management, Ticket analysis, participate on all escalation calls and shift handovers/turnovers.
This role involves working within a 24/7/365 Service Operations Center team supporting English Language based in Bangalore.
Principal Accountabilities
Owns the SOC mailbox with accuracy and quality in responding and monitoring the mailbox in timely manner
Work and report the ISO activities assigned by Team Leads
Identify Operations and process issues and communicate to team leads, does validation until issue is closed. Identify, analyse events / alerts and report the findings to TL
Performs daily and manual checks, swift in acting by quick collaboration and consultation with TL
Make sure all trackers (attendance, breach, comp off) are accurate and updated within 2 hours of shift resumption
Participate in P4 Incident mgmt. bridge
Uses video wall and identifies the potential issues before impact on business operations
Conducts 1:1 session with SOC staff and strives to reduce defects
Monitor the various Applications, dashboards and Service Management queues to perform checks/ escalate issues/ report failures
Email daily reports (BMS) to Incident management team by 5pm everyday
Complete all the assigned activities and responsibilities on time and reports to TL
Complete all the assigned activities assigned by management on time
KB publish, retire, flag and modify as per the defined process and report status to TL’s
Drive the SOC BAU and operations adherence to CIO SOC guidelines and Operations manual, report the issues and discrepancies to SOC Ops lead DL
Contribute for work plan project
Prepare shift handovers along with TL’s
Maintain high quality standards for the shift
Maintain expected levels of KPIs and SLAs within shift
Always strive to create a non-political and non-conflicting work environment, report issues and gaps to TL

KNOWLEDGE & EXPERIENCE
Organizes, directs and monitors daily activities of the team to ensure optimal effectiveness.
Assign the task list to engineers to ensure service is appropriately resourced and staff working hours are fairly distributed across the team.
Participate weekly performance calls and produce analyzed ticket dump.
Manage escalations to relevant resources, ensuring the Service Delivery managers are aware of any major risks, issues or outages
Ability to encourage, motivate and provide recognition
Must be energetic, pro-active, positive and able to make decisions within management guidelines.
Proven team player with experience of working with colleagues spread across multiple global locations and dealing with time zone constraints.
Excellent knowledge of Microsoft business applications; Windows OS, Office, Exchange, Excel
Ability to manage many critical tasks and projects whilst keeping an eye on the business priorities and getting issues resolved effectively and expediently.
ITIL v3 foundation level Certification
Relevant 2 - 4 years of Operational experience & 5 - 10 years of overall experience""
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Platform Engineering Lead - AI/ML,"Bengaluru, Karnataka",Standard Chartered,None,Organic,"Job: Technology
Primary Location: ASEAN & South Asia-India-Bangalore
Schedule: Full-time
Employee Status: Permanent
Posting Date: 01/Jun/2020
Unposting Date: Ongoing
About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.


To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.


We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.


Scope of Role
Position will be key to delivering a strategic programme called Client Analytics Platform (CAP) where we are building an AI and smart intelligence platform for a cloud-powered future. This will be a reliable, safe and secure advanced intelligence platform leveraging machine learning, analytics, and insights powered by artificial intelligence
This project has extremely senior visibility in the Bank and aims to deliver Delivers Relevant, Contextual Content to frontline staff, with content drawn from multiple internal & external sources. The platform will provide AI-Driven Client Insights, Opportunity Generation and Predictive Recommendations and connect front line staff with Strategic & Timely information to improve Client Outcomes.
The Role Responsibilities


In the role of artificial intelligence/machine learning platform engineering lead, you will join and lead our ML/AI platform team focusing on designing, implementing, and maintaining scalable features and services to support end-to-end ML/AI pipelines on CAP. You will work closely with the users, systems designers, and the developers. You will engage with engineering and operations teams to lead and develop machine learning solutions for a variety of tasks and projects using a multitude of tools and techniques. You will also be trusted advisor for best practice machine learning development. You will collaborate with the ML/AI algorithms team and other engineering teams to bring industry-leading machine learning solutions to the Banks RMs and Sales staff.

Responsibilities will include:
Lead the platform development teams to integrate ML tools/solutions to a high-performance production solution model
Architecting and developing machine learning solutions to productionise AI/ML models
Be comfortable with AI, ML, Big Data, Data Analytics and modelling
Be comfortable delivering cloud solutions with a micro services architecture
Be able to deliver integration with internal and external sources of data
Coordinating internal resources and vendors for the flawless execution of projects
Ensuring the project is delivered on-time, within scope and within budget
Report and escalate to management as needed
Perform risk management to minimize project risks
Our Ideal Candidate


Preferred Candidate Profile:

Ideal candidate must have proven credentials of delivering in world class engineering teams with the experience of creating a working machine learning-powered platform from the ground up. Candidate will define the end-to-end vision of our machine learning strategy as it relates to testing and product development, you will contribute innovative ideas and ingenious implementations to the team, and be capable of planning out scalable, maintainable data pipelines, services, and products. You will be interfacing with data scientists, engineering consumers, industry specialists, and business stakeholders through various areas of the Banks ecosystem. You must be a confident self-starter with ability to collaborate and devise end-to-end solutions. Relevant industry certifications are an added plus.

Must Have Core Competencies:
Great educational background, in the fields of computer science or engineering
Entrepreneurial minded, strong analytical problem-solving skills, and an aptitude for learning systems quickly.
Minimum five years of solid hands-on experience applying machine learning techniques to build models integrated into applications
Additional experience with data visualization, data analytics, and data mining
Strong software development skills with proficiency in Python
Experience with relational and non-relational databases; Postgres, Cassandra, MondoDB, etc
Experience with Big Data Technologies such as Kafka, Spark, or ElasticSearch
Experience in using distributed, highly available, low latency systems for analytics or data processing
5+ years in data structures, algorithms, highly concurrent programming, analysis of algorithm complexity
Experienced use of machine learning and statistical-analysis libraries, such as GraphLab Create, scikit-learn, scipy, NetworkX, Spacy and NLTK
High level of autonomy and influence to unblock delivery of results (evaluate and solve difficult problems involving various teams ranging from data instrumentation to analytics tool development)
A strong desire to establish standards of “Best Practice”
Ability to explain and present analyses machine learning concepts to a broad business and technical audience
Maintains professional and technical knowledge by attending workshops; reviewing intranet/external publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional working groups
Experience in delivering projects in agile model
Solid organizational skills including attention to detail and multi-tasking skills
Contributes to team effort by accomplishing related results as needed
Maintains quality service by establishing and enforcing organization standards.
Provides periodic status reports to project working groups
Proven experience dealing with Risk & control related actions and artefacts to supporting internal audit
Highly Desired Additional Competencies:
Experience with architecture and design of RESTful based systems.
Development experience with cloud platforms such as Microsoft Azure or AWS
Experience with container technologies such as Docker, Singularity and Kubernetes
Design and implement scalable cloud-based web applications for PaaS, IaaS or SaaS
Experience in cloud development principles and patterns, particularly loosely coupled architectures and micro-services
Strong working knowledge of ML algorithms including decision trees, probability networks, association rules, clustering, regression, and neural networks
Experience with deep learning frameworks, such as mxnet, Torch, Caffe, and TensorFlow
Apply now to join the Bank for those with big career ambitions.


To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working."
ML Engineer/Statistician/Data Scientist – Pre-IPO Unicorn,"Bengaluru, Karnataka",CareerXperts,None,Organic,"As a Data Scientist / ML specialist you will focus on building next-generation platform services to identify right business problems that will be more effectively solved with Machine Learning techniques
Then you will apply your algorithmic/statistical skills, analytical skills, knowledge of ML techniques and distributed systems to solve the problem in the simplest possible way.
Experience
3 to 12 years
Qualification
A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
A strong grounding in Data structures and algorithms, Database concepts
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Prior experience in building and deploying ML systems and familiarity with Machine learning algorithms
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.
Responsibilities
Collaborate with product and business teams to understand all aspects of the problem
Deliver scalable, low latency, and high-performance ML solutions for different
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Drive solutions and implementation leveraging different open source libraries and distributed systems
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.
We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.
Write to deepa.m@careerxperts.com to set up this adventure! #HighBarOfEntry
Job Location
Bengaluru"
Data Engineer,"Bengaluru, Karnataka",Menorah Personnel Management India Private,None,Organic,"Keyskills :
Data structures.
Job Description :
Requirements:
Responsible for the design and development of medium to highly complex systems.Skills include system design and analysis as well as business skills.
Works with data and project managers to understand systems and consults with customers to understand needs.
Developments and implements new systems, corrects software errors in existing systems, and works to improve performance through hardware upgrades.
Manages computer systems in a business environment and responsible for resolving technical issues.Knowledgeable in programming, data structures, computer systems, and software engineering.
Bachelor's degree in computer science, software engineering, or other related field.
Ability to manage multiple assignments.Superior written and oral communication skills. 6-10+ years of experience.
Posted On : 2019-12-28 10:03:17"
Data Scientist,"Pune, Maharashtra",Pivotchain Solution Technologies,None,Organic,"Requirements
BS/MS degree in Computer science, Maths
You are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, Hive
Experienced with data visualisation tools, such as Tableau, D3.js, GGplot, etc
Past experience with Deep Learning/NLP would be an advantage (although not necessary)
Good Communication Skills
Team Player
What We Expect.?
You take pride in your knowledge of design patterns, algorithms and data structures
You are comfortable processing, cleansing, and verifying the integrity of data used for analysis
You understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etc
You understand feature selection, model performance metrics, building and optimizing machine learning models
You are good at doing ad-hoc analysis and presenting results in a clear manner
You are good at creating automated anomaly detection systems and constant performance tracking
You can code comfortably in R & Python (NumPy, sklearn, xgboost)"
Backend Engineer,"Gurgaon, Haryana",KlearNow,None,Organic,"KlearExpress is headquartered in Santa Clara, CA. At KlearExpress, we are in the midst of an exciting period of explosive growth. Join us as we continue to scale internationally, expand our partnerships and introduce the world's first ground-breaking, on-demand, real-time customs broker platform that connects Importers, Brokers and Transporters, providing full transparency of the logistics process! You will work with the most talented developers, sales team, and thought leaders simplifying the trillion dollar industryof global logistics. We think globally, consistently stand outside the box and see our team as family. Responsibilities :

Excellent knowledge and experience on a backend language, like Java, Scala, Go, Python, etc.
Experience in handling ambiguous business requirements with excellent prioritization, time management abilities, and a focus on execution
Excellent knowledge of Computer Science fundamentals, with strong competencies in data structures, algorithms, software design and coding
Strong designing and building distributed backend systems handling high volumes of traffic
Passion to solve complex problems and make continuous improvements
BS/MS in Computer Science or equivalent with 3+ years minimum industrial working experience.

We’re looking for dynamic people to join our team of superstars who are as excited as we are to disrupt the global logistics industry. We have compelling job opportunities available right now at our Santa Clara, CA headquarters as well as our office in Gurgaon, India."
Data Analyst,"Mumbai, Maharashtra",Augmenter Consulting,None,Organic,"We are looking for dynamic, energetic and result oriented business / data analyst to be a part of team and work closely and/ or independently on specific projects. You will be an independent operator and will need to deliver the set priorities in timely and most diligent manner. Your analysis will form the basis for making appropriate recommendations to customers to help them achieve the set objectives.
The successful candidate will convert data into information, information into insight and insight into business decision for the assigned project / client.
Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analyst will develop analysis and reporting capabilities. They will also monitor performance and quality control plans for identifies improvement opportunity.
The key goal of the position is to own components of the consulting / implementation projects and drive the maximization of value preposition for the client organization.
Key responsibilities:
Define and carry out the analysis of the data and information to prepare actionable insights.
Build a robust understanding of the customer business focused towards opportunities to improve customers business performance for the assigned areas.
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiencies and quality
Acquire data from primary or secondary data source and maintain them for suitable actionable usage.
Identify, analyze and interpret trends or patterns in complex data sets.
Filter and “clean” data for review reports and key performance indicators, specific to the project or work areas.
Work with company’s management team to prioritize business and information needs.
Locate, define, seek alignment and implement process improvement opportunities.
Requirements:
Proven working experience as a business data analyst.
Technical expertise regarding data models, database design, data mining and segmentation analysis.
Strong knowledge and experience with reporting packages.
Knowledge of statistics and experience using statistical tools and packages for analyzing data.
Proficient level expertise in MS Excel & Power Point.
Strong analytics skills with ability to collect, organize, analyze and disseminate significant amount of information with attention to details and accuracy.
Adept at queries, report writing and presenting finding.
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.
Qualification and experience:
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.
Minimum 2 to 5 years of relevant experience.
Proven track record.
Compensation: in line with the market and commensurate with the relevant experience."
Vice President - Technology,"Hyderabad, Telangana",Insurance Information Bureau of India,"₹25,00,000 - ₹30,00,000 a year",Organic,"Responsibilities of the Job:
We are an organisation of Data Repository. We handle huge data and provide services to the stake holders through web services and applications. It is totally Technology driven.
The candidate should be responsible for taking care of the overall IT operations, Project Controls, Review of IT Architecture in line with the business requirements.
He should manage the IT infrastructure through Vendors such as Managed Service Providers, monitoring and managing the Vendors for applications development/ maintenance etc.
Ensure all services and applications available round the clock.
Reviewing and entering into the SLAs with vendors.Taking care of the IT Security concerns.
He will be responsible for the overall Technology requirements of the Bureau and will be reporting to CEO.
Experience and Skills required :
He should have more than 12 years experience, out of which at least 3 years should have been as Head - Technology.
Should be a First class Bachelors/Post Graduation with Computer Science/ Applications.
He should have exposure with technologies like Linux, Windows Server, JAVA/J2EE, .Net, My SQL, No SQL databases and ETL tools.
He should have exposure in Server administration, Net working, Configurations, Connectivity and client set up activities etc.
He should have experience in Application support/maintenance and management.
He should have significant development and delivery experience in leading large projects.
He should have hands on coding experience in popular languages and in web stacks.
Experience of implementing robust IT Security, security protocols and policy implementation.
Proficient in vendor identification and management.
Experience of managing relationship with preferred partners for IT delivery and operational support.
He should have excellent Communication and interpersonal Skills.
Job Type: Full-time
Salary: ₹2,500,000.00 - ₹3,000,000.00 per year
Experience:
work: 10 years (Required)
Head of Technology : 3 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
No
Speak with the employer
+91 9866020663"
Data Engineer II,"Hyderabad, Telangana",Dun & Bradstreet,None,Organic,"Why We Work at Dun & Bradstreet
We are at a transformational moment in our company journey - and we’re so excited about it. Each day, we are finding new ways to strengthen our award-winning culture, and to accelerate creativity, innovation and growth. Our purpose is to help customers improve business performance with Dun & Bradstreet’s Data Cloud and Live Business Identity, and we’re wildly passionate and committed to this purpose. So, if you’re looking to make an immediate impact at a company that welcomes bold and diverse thinking, come join us!
Team Overview: Dun & Bradstreet is looking for a Senior Engineer to join our Govt Data Science/Engineering team. You will be part of a group responsible for implementing, maintaining and supporting multiple client’s data environments in AWS through custom API’s. The Role: As a Sr. Data Engineer/Developer in the Data Engineering team you will join a team of brilliant, friendly and energetic solutions architects, developers, QA engineers and project managers who strive to deliver best of breed custom solutions to our customers. Are you someone that can thrive in a high energy, high growth, fast paced environment? Then you might be just who we are looking for. Key Responsibilities: • Responsible for real-time aggregation of large amounts of data from various sources that includes streaming and batch data into a data lake. • Define data integration flows (ETL, ELT, stream processing, events/event processors, etc.) • Work alongside development team to build data management platforms using Amazon Redshift, Amazon Elastic Map Reduce (EMR), Amazon Athena, AWS Glue, AWS Lake Formation, Data pipeline, Glue and other related services. • Designing, implementing and supporting a platform that can provide ad-hoc access to large datasets • Collaborate with solution architects, business, QA and projects manages • Data pipelines/Data Ingestion/ Data Engineering • API Development including POC’s • Data Analysis • Application support/ bug fixes / QA Key Requirements: • Bachelor’s degree in computer science, information systems, or other related field or equivalent work experience. • 3-5 years of high-tech industry and/or IT work experience in Big Data project hands on development and solution engineering roles • Experience with data bases, including relational and non-relational. • Strong Experience with AWS Big data processing tools • Strong experience with scripting / programming languages such as: JavaScript, Java/Scala, .NET, PHP, Python and Node.JS). • Good to have DevOps experience with CI/CD pipelines, Configuration Management tools, Scripting • Must have exposure to search tools implementations(Elastic Search stack or similar) • Nice to have Cloudera, Hadoop development and admin experience • Good understanding of Windows, Unix/Linux operating systems and networking. • Collaborate with developers and operations teams to build and deploy custom solutions in AWS. • Good understanding of micro-services, web-based applications and REST APIs. • Prior experience managing production cloud infrastructure at scale (AWS) • Strong organization skills with high attention to detail. • Able to work independently with minimal supervision. • Excellent communication skills – written, verbal, presentation and interpersonal. • Willing to learn new skills and implement new technologies. • Must have the ability to be on call.
Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.

We are committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with Dun & Bradstreet and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to TalentAcquisitionTeam@dnb.com. Determination on requests for reasonable accommodation are made on a case-by-case basis.
Please note that all Dun & Bradstreet job postings can be found at https://dnb.wd1.myworkdayjobs.com/Careers and all communication from Dun & Bradstreet will come from an email address ending in @dnb.com."
Lead Product Architect,"Madhapur, Hyderabad, Telangana",Signant Health,None,Organic,"Role Overview:
Signant Health innovates at the leading-edge of clinical research data, one exceptional service at a time. From the advanced technology of our eCOA electronic Clinical Outcomes Assessments flexible platform, to the efficiency of our scalable and configurable Randomization and Trial Supply Management (RTSM) Clinical IRT solution, to our science-focused Rater Training and Quality Assurance programs, Signant does it faster, better and with an eye on the future of our industry.

If you’re looking for a growing company with delighted customers, a dedication to superb products designed with the patient in mind, and a management team that allows you to make your mark on how the company evolves, we want to hear from you.

We are:
A company that offers a unique suite of solutions, with a unique perspective on clinical research development
Focused on bringing together best-in-class science, technology and service to drive superior clinical outcome results for our clients and for their patients
At the leading-edge of clinical research data, one exceptional service at a time
Experienced and have implemented over 250 studies in more than 80 countries
A company that takes great care to maintain our culture and ensure that each new team member enhances that culture
You are:
Ready to work in an inspiring team environment with an open communication culture
Creative and innovative
A detail-oriented problem solver who delights in adding value to products and their roadmap
Eager to stay abreast of emerging new software technologies, frameworks, and libraries, and identify where these could improve existing or new projects
Able to design, develop, and maintain front-end systems and back-end systems
Providing technical input to project-related decisions
Ready to use unit testing, integration testing, code coverage, and other tools to ensure correctness of software.
Drawn to Development because you like contributing to solid, well-made products
Eager to use your skills in a company with products that helps people
Key Accountabilities/Decision Making & Influence:
We are seeking an exceptional candidate to lead and produce software for our team.

This role will require an experienced Lead Product Architect ready to play a key part in our software development efforts, interfacing directly with the engineering, product testing and product management teams to ensure superb-quality development and deployments of software enhancements. As a Lead Product Architect, you will learn our innovative software suite from the inside out. You will grow both technically and increase your product knowledge. At a medium sized company, you will see the impact of your work daily as part of our rapid release schedule.

We pride ourselves on the quality of our systems and our ability to evolve products to anticipate client needs. As a Product Architect, you’ll combine organizational skills, familiarity with software development, and a keen detail orientation to help ensure we settle for nothing less than the highest standards.

As a Lead Product Architect you will be contributing to team and software development needs:
Develop architectural solutions for databases, user interfaces, services, etc
Decide on the platforms and coding standards to be used in project development
Evaluate existing software solutions to identify areas for improvement
Oversee architectural approaches from conception to installation
Evaluate and recommend tools, technologies and processes to ensure the highest quality product
Collaborate with peers and other team members to produce modernized software solutions
Communicate successfully all concepts and guidelines to development teams
Provide technical guidance and coaching to developers
Work with a vertical area of one or more products
Help drive the successful completion of development projects.
Create technical design documentation.
Takes active participation in technical training and mentoring for team members and cross functional teams
Knowledge, Skills & Attributes:
Required Skills/Experience
Ten+ years’ experience professionally developing software.
Proven experience as software architect
Experience with some or all of the following technologies:
Microsoft SQL Server or other relational databases including stored procedures, views and triggers
Microsoft Visual Studio, C#, ASP.NET, .NET Core
Node.js, JavaScript, AJAX, CSS, XML, XSLT
Web page design, Angular, React
Object Relational Mapping (OR/M), MVC, MEF, Unity Framework
Team Foundation Server, BitBucket, Git, Subversion or other source control product
Knowledge of the various services and capabilities of cloud computing platforms (AWS/Azure/GCP)
Understanding of cloud computing design and security principles
An understanding of CI/CD processes and tools like Jenkins or Bamboo is desirable
Knowledge of Docker containers and related orchestration technologies is desirable
Cloud Certifications a plus
Has analytical and conceptual skills, with a curious mind for troubleshooting and building software.
Detail-orientation with the ability to understand how each aspect interacts with the big picture.
An understanding of software development life cycle (SDLC) and programming fundamentals.
Oral and written communication skills and an ability to work with technical and non-technical staff.
A single-minded focus on deadlines and deliverables.
Understanding of Agile methodologies
Fluency in English, both written and verbal.
B.Tech/M.Tech in any engineering preferably Computer science or MCA"
Machine Learning Engineer,"Bengaluru, Karnataka",Kimberly-Clark,None,Organic,"Job Description
SU M M A R Y OF ROLE:
The IT Digital Supply Chain Data & Analytics team is organized around world-class data, advanced data science and automation to drive business value for the K-C organization. We are a group of curious people and critical thinkers focused on solving the problems of the day and opportunities of the future through applied intelligence and data science. As part of this team, the Machine Learning Engineer is responsible for integrating business, information, and technology architecture to create artificial intelligence and machine learning solutions for supply chain and manufacturing capabilities. This role is viewed as a solution innovator and expert in complex analytical and digital platform environments, encompassing both business process understanding and technical expertise.
Scope/Categories:
Role will report to a Manager in the IT Digital Supply Chain organization. Role wi ll not have any direct reports.
Key Interfaces: Data Scientists, Business Customers , Functional Engineers , Solution Enginee rs, Enterprise Data Management teams , Analytics Designers , Project Manager .
External Interfaces: Consultants , Vendors , Managed Services Providers (onshore/offshore) . Travel may include approximately 15% of work time.
Key Accountabilities :
Drive a rigorous approach leveraging data science including a rtificial i ntelligence and m achine l earning to solve problems in the context of growing Kimberly Clark brands, increasing sales, and enabling operational excellence.
Partner with Data Scientists to design and develop innovative, machine learning solutions for important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with in their area of expertise. Provide technical consulting on complex projects.
Collaborate with functional and solution engineers to develop data and model pipelines including understanding lineage and granularity of data required to perform data science and helping prepare, profile, and cleanse data needed for data science.
Assist in embedding machine learning AI outputs into key business applications including analytical and transactional solutions.
Scale up existing data science solutions (deploy to additional regions, apply to additional areas/attributes)
Support the iterative data science implementation cycle by assisting with research, design, experimentation, development, deployment, monitoring, and maintenance as required.
Communicate complex processes to business leaders – explain outputs of machine learning in business language
Produce project outcomes and isolate issues with models through continuous improvement
Research and implement best practices to enhance existing machine learning infrastructure. Contribute to new and existing data science architecture patterns.
Analyze large and complex data sets to derive valuable insights
Document solutions in appropriate service management applications and collaborate with Solution Engineers, Enterprise Architecture, and Analytics Designers to make sure that the data science solution fits within enterprise context.
Coordinate engagements with vendors as they relate to evaluation, design and delivery of business capabilities. Contribut e to the evaluation and selection of software products.
Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of K - C to deliver the end - to - end machine learning solutions.
Influences and moves the K-C culture to one that values and uses cross-business and functional data and analytics to power business performance.
Key Qualifications and Experiences :
Bachelor's degree required, Master’s degree preferred. Relevant fields include computer science/engineering, statistic s , mathematics, artificial intelligence, or operations research.
Three or more years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, Neural Networks, Random Forest, etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi , MySQL, etc.) Proficiency in SQL and Python is important.
Understanding of data structures, data modeling and software architecture . E xperience d esigning and i mplementing d ata s cience s olution s on Azure is helpful.
Familiarity with machine learning frameworks and libraries
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Experience with data integration methods and tools including ETL and virtualization.
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in retail/manufacturing environment is preferred. Basic functional knowledge in key CPG Supply Chain Area capabilities ( Planning, Procurement, Manufacturing, Logistics, Safety & Sustainability, Quality , etc.) is a big plus.
Experience collaborating with data scientists, solution architects, and engineers to identify, design, and implement highly complex, end-to-end solutions.
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Ability to operate in a digital workplace utilizing modern technologies to connect, collaborate, communicate and cooperate across a global organization and across organizational boundaries.
Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.
Ability to communicate strategies and processes around machine learning and data architecture to cross functional groups and senior levels.
Thought leader with strong connection to industry and technology user groups and networks. Keeps abreast of leading trends in digital, cloud, artificial intelligence, machine learning, block chain, virtual reality, augmented reality and combinations of technology that matter in AI & ML .
High level of communication is required. Must be self-motivated, self-disciplined and have strong time management skills. Embraces learning agility to keep abreast of new technologies and strategies.
Possesses strong leadership skills and exhibits creative thinking to be able to design inventive solutions which solve business challenges. Cultivates networking opportunities within the organization .
Kimberly-Clark and its well-known global brands are an indispensable part of life for people in more than 150 countries. Every day, 1.3 billion people - nearly a quarter of the world's population - trust K-C brands and the solutions they provide to enhance their health, hygiene, and well-being. With brands such as Kleenex, Scott, Huggies, Pull-Ups, Kotex, and Depend, Kimberly-Clark holds No.1 or No. 2 share positions in more than 80 countries. With a 135-year history of innovation, we believe in recruiting the best people and putting them in the right jobs so that they can do their best work. If fresh thinking and a passion to win inspire you, come Unleash Your Power at Kimberly-Clark.

Kimberly-Clark is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender identity or any other characteristic protected by law.

The statements above are intended to describe the general nature and level of work performed by employees assigned to this classification. Statements are not intended to be construed as an exhaustive list of all duties, responsibilities and skills required for this position.
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship. This position is subject to drug and alcohol testing, including pre-employment testing .
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time"
Machine Learning Engineer,"Bengaluru, Karnataka",UPL ltd,None,Organic,"About us

nurture.farm aspires to bring technology, digitization and best scientific practices to all farmers, big and small. We believe in bringing the best talent together, to create a team passionate for transforming the farming ecosystem. Our software engineers develop technologies that strengthen the hands of millions of farmers, making farming more profitable and sustainable. Our products need to handle information at a massive scale. We are looking for engineers who bring expertise in distributed and scalable computing, easy-to-use consumer products, UI design and mobile, machine learning, data science, networking, storage, security and much more. We’re a team that values versatility, self-motivated drive and a passion to create an impact on millions of farmers.

We’re looking for ..

builders and tinkerers, who derive pleasure from creating something from scratch,
dreamers, who are passionate about creating something that touches millions of people, and transforms lives,
sculptors, who take pride in simplicity of design, and have the keenest eye for detail when it comes to quality,
learners, who look forward to continuing to grow everyday.

If that’s you, we should chat.

Machine Learning Engineer

Minimum qualifications

BTech Computer Science, or similar field of study, or equivalent practical experience.
Software development experience in one or more general purpose programming languages.
Experience working with the following: Machine Learning Frameworks (Tensorflow, PyTorch, etc), Data Science toolkits
Conversant with Model Training, Feature Engineering, setting up training pipelines as well as bringing models into production
Familiarity with real time streaming, distributed computing
Working proficiency and communication skills in verbal and written English.

Preferred qualifications

Master’s degree, further education or experience in AI/ML, computer science or other technical related field.
Understanding of agriTech domain and application of technology in farming
Interest and ability to learn other coding languages as needed.

Responsibilities

Understand the agriculture and agtech domain and come up with concrete problem definitions based on observations from the field.
Design AI solutions to help farming, working with GIS and Remote Sensing data, and combining it with ground truth collected from the farms.
Design, develop, test, deploy, maintain and improve ML models.
Manage individual project priorities, deadlines and deliverables.
Enthusiastic to take on problems across the full-stack."
Lead - Data Management,"Pune, Maharashtra",BNY Mellon,None,Organic,"Lead - Database Management>> Analyzes application requirements and develops conceptual, logical & first-cut physical database designs (data models). Creates associated data model documentation such as entity and attribute definitions and formats. Analyzes and designs data models, logical databases, and relational database definitions in the data modeling tool using both forward and backward engineering techniques. Provides data element naming consistent with standards and conventions and ensures that data dictionaries are maintained across multiple database environments. Consults with database administration and client areas in resolving questions during the translation to a physical database design. Uses in-depth knowledge of existing database environments to make recommendations for opportunities to share data and/or reduce data redundancies. Contributes to the achievement of related teams' objectives.
Qualifications
Bachelor's degree in computer science or a related discipline, or equivalent work experience required. 4-6 years of experience in design and administration of physical relational databases or systems analysis required, experience in the securities or financial services industry is a plus.


BNY Mellon is an Equal Employment Opportunity Employer.
Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.

Primary Location: India-Maharashtra-Pune
Job: Information Technology
Internal Jobcode: 60525
Organization: Architecture And Data-HR16450
Requisition Number: 2007410"
"Senior Analyst - Operations Analytics - Bangalore, India","Bengaluru, Karnataka",MPOWER Financing,None,Organic,"THE COMPANY
MPOWER enables students from around the world to financially access higher education at top U.S. and Canadian universities. Our global team is composed of ex-management consultants, financial services and technology professionals, and other experts in their respective fields. As a FinTech startup backed by Venture Capital and Private Equity firms, we move extremely fast and leverage the latest technologies, global best practices, and analytics to tackle one of the biggest challenges in financial inclusion. We work hard, have fun, and believe greatly in our cause. For us, this mission is personal.
As a member of our team, you'll be challenged to think creatively in an environment where ideation and implementation happen very quickly. We value feedback and emphasize personal and professional development by providing the resources you need to further your skills and grow with the company. MPOWER is committed to cultivating your strengths and curiosity and helping you make an immediate impact.
THIS IS A FULL-TIME POSITION, BASED IN BANGALORE, INDIA AND REPORTING TO THE CUSTOMER RELATIONS LEADERSHIP
THE ROLE
You'll be supporting the analytics and reporting for MPOWER's Customer Relations team. Your primary focus will be to design, develop, analyze and report insights and trends specific to the operations of Customer Relations and translate complex data into actionable information. Your responsibilities will include but not limited to:
Developing analytic models for the purpose of supporting data-driven decision making.
Developing reports to support forecasting, statistical analysis, predictive analytics leading to quick decision making
Interpreting business requirements and translating them into analytical objectives
Exploring data structures and processes to ensure analytical quality control.
Performing root cause analysis on business problems and providing recommendations in a timely manner.
Automating key reports and drive information sharing across the team.
Collaborating with the Engineering teams on implementing continuous data quality best practices.
THE QUALIFICATIONS
Bachelor's degree, or higher in Analytics, Engineering, Statistics, Management Science, Applied Mathematics, Economics, or related field
3-7 years of experience in modeling or analytics, preferably in the financial services industry
Working knowledge of SQL and advanced excel would be highly preferred
Demonstrated use of: Salesforce, R, SAS, Tableau, Einstein Analytics, Python, and/or Data Studio
Experience in developing analytics for call center operations, servicing and/or collections operations will be quite valuable
Demonstrated knowledge of some or all of the following: multivariate regression, time series (forecasting), pattern identification, segmentation, logistic regression, decision trees, optimization, Monte Carlo or discrete-event simulation, unstructured data analysis, and predictive or prescriptive modeling techniques
Proficient in creating dashboards and custom reports with knowledge of visual techniques for data analysis and presentation
Ability to work independently and proactively
Outstanding written and verbal communication skills
A passion for financial inclusion and access to higher education is a must!
In addition, you should be comfortable working in a start-up environment, meaning a small agile team, fast-evolving roles and responsibilities, variable workload and tight deadlines, a high degree of autonomy, and 80-20 everything."
Vice President of Data Science,"Indore, Madhya Pradesh",TaskUs,None,Organic,"So what does a Vice President of Data Science really do? Think of yourself as the one who will be charged with driving a coordinated team of experts in delivering holistic and integrated workforce services and data strategy solutions for the Southeast Asia region, focused on Business Intelligence, Sales Solutioning, and Workforce Operations Consultation. We are searching for the best of the best, since we are a ridiculously good company, so we need your full concentration as we take you through our requirements for this crucial role.
Imagine yourself going to work with one thing on your mind: You must be able to direct the company's staffing goals and strategies to support productive and profitable business operations. You will be responsible for leadership, direction and management of data strategy - to ensure our data collection and analysis solutions are coordinated and integrated to provide actionable insights to Workforce, Technology and Operations partners. As you tackle your new tasks for the day, you know that it will lead to one thing: You will develop a vision and strategy as it relates to expanding our data driven culture.
You will shape our data strategy and communicate a roadmap to stakeholders; act as the chief advocate of data efforts across multiple leadership teams; you will build and implement business transformation through direct engagement and relationship building with your stakeholders; and you will build an analytics and reporting competency that derives insights and operational decisions from complex data sets.
Crucial to your role is the ability to build, lead and develop a motivated data and analytics core team - driving top talent at the interface of data analytics, technology and business; and working directly and collaboratively with current and potential partners. You must be able to work closely with senior leadership to identify opportunities to accelerate business transformation and drive outcomes; collaborate with technology teams on evolving our data strategy; and ensure transformed services meet or exceed senior leadership expectations, while achieving business objectives.
As Vice President of Data Science, you must be able to manage your budget; oversee long term solution architecture; assess, engage, and apply new and emerging technology; and manage vendors to provide best service at the lowest cost.
Lastly, you must be able to communicate and present on data related matters to top-level executives as well as to our clients.
So, do you have what it takes to be the Vice President of Data Science at TaskUs?
Requirements:
What is it we’re looking for? Well since this is a Vice President role, we need someone with at least 3-5 years in an executive role, with demonstrated experience as a top performer in Data Science and/or Analytics.
What else? We need someone with a Bachelor's degree in mathematics, business, statistics, economics, computer science or related fields. If you possess a Master’s Degree in relevant studies, then you’re someone we want to speak to!
As for technical know-how, we’re looking for someone who demonstrates previous exposure in Operations and Workforce; a thought leader and innovator in the development of new tools, methodologies and problem solving approaches; we want someone with a deep understanding and demonstrated ability to adapt to complex business environments and situations; must have a broad understanding of latest Data Science, Analytics and Technology trends and their impact on business
strategies; possesses the ability to articulate, persuade and communicate actionable insights; and extensive experience defining, motivating and driving change at the executive level and across multi-functional teams.
In addition, you will assess the data needs and delivery strategy for operations and support groups; and have a demonstrated understanding of statistics, structured and unstructured data analysis, predictive modeling techniques and data visualization. You must have the flexibility to work across various time zones, and travel anywhere across the globe as you take on some tough challenges."
Senior Data Scientist- AI,"Bengaluru, Karnataka",Lymbyc Solutions,None,Organic,"Description:
Background:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.
By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.
Description:
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.
Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.
Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner
Skills Required:
Must have minimum of 5-7 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc"
Full Stack Developer,"Chennai, Tamil Nadu",Cache digital,"₹12,000 - ₹30,000 a month",Organic,"Job Description
The Full Stack Web Developer (FSD) will be responsible for designing and developing a web-based biomechanics analysis platform tailored specifically for the company’s markerless motion capture and video data. The aim of this project is to develop a web-based platform, accessed through the company’s website, to aid front office personnel, coaching staff, and players in the analysis, visualization, and reporting of KinaTrax’s data. Additionally, the FSD will support future web development initiatives of the company.
Essential Job Responsibilities
The FSD performs the major functions listed below. The position may require additional duties/responsibilities that may not be outlined below, and specific functions are subject to change.
Designing and developing a web-based biomechanical analysis platform tailored specifically for use with the company’s markerless motion capture and video data.
Developing front end website architectures.
Designing user interactions on web pages.
Developing back end website applications.
Creating servers and databases for functionality.
Ensuring cross-platform optimization for mobile devices.
Ensuring responsiveness of applications.
Working alongside biomechanists and data scientists for core functionality.
Working alongside graphic designers for web design features.
Designing and developing APIs.
Troubleshooting, debugging, and upgrading software.
Designing and developing security and data protection measures.
Seeing through a project from conception to finished product.
Meeting both technical and consumer needs.
Writing technical documentation.
Staying abreast of developments in web technology.
Supporting the company’s future web development initiatives.
Designing and developing unit tests.
Participating in code reviews.
Qualifications & Requirements
The following qualifications are the minimum requirements necessary to successfully perform this role. However, any equivalent combination of experience, education and training, which provides the necessary knowledge, skills and abilities, would be acceptable, subject to any legal and/or regulatory requirements.
Degree in Computer Engineering, Computer Science or equivalent disciplines.
Proficiency with fundamental front-end languages such as HTML, CSS and JavaScript.
Proficiency with Angular JS and familiarity with other JavaScript frameworks such as React.
Proficiency with ASP.NET Core and familiarity with other server-side languages such as Python, Ruby, Java, and PHP.
Proficiency with MySQL and familiarity with other database technologies such as MSSQL, Oracle and MongoDB.
Proficiency with Microsoft Visual Studio.
Proficiency with web servers, such as IIS and Apache, and UI/UX design.
Experience in software engineering practices, including but not limited to software design and implementation, unit testing, code reviews, continuous integration, source control, and coding standards compliance.
Experience with Git is preferred.
Experience interfacing with both internal team members and external customers as part of a solution-based service process.
Experience troubleshooting and responding to customer concerns.
Proven record of being reliable and accountable for all aspects of their job.
Excellent analytical, interpersonal and communication skills with the ability to communicate complex technical issues in an easy to understand manner.
Ability to work in a fast-paced, self-directed, entrepreneurial environment.
Resourceful, with the ability to work independently.
Strong time management skills.
Ability to adapt to changing circumstances.
Decision-making, problem resolution and creative thinking skills.
Attention to detail.
Ability to multi-task activities with shifting priorities. Able to work productively in a pressurized environment.
Ethical and trustworthy.
Working Conditions
Extended periods of computer usage.
Occasional travel to meet with clients.
Relocation
None required. Remote work.
Job Type: Full-time
Salary: ₹12,000.00 - ₹30,000.00 per month
Experience:
Web Development: 3 years (Preferred)
SEO: 1 year (Preferred)
PHP: 1 year (Preferred)
Angular / Node JS: 1 year (Preferred)
Education:
Bachelor's (Preferred)"
Hiring Data Science with Machine Learning and GCP,India,Vodafone,None,Organic,"Company Profile

Vodafone Intelligent Solutions (_VOIS) is a strategic arm of Vodafone Group Plc, for which it creates value by enhancing quality and efficiency of a number of processes in the IT/ ITeS domain. Established in 2006, _VOIS has evolved into a global, multi-functional organization that currently has centres across India, Egypt, Romania and Hungary with over 23,000 professionals.

In 2009, _VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 12,000 employees, _VOIS India supports global markets and group functions of Vodafone, and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Enterprise), Finance Operations, Supply Chain Operations and HR Shared Services.

Current Opening

We are hiring Data Science professionals with Machine Learning (GCP). If your profile is shortlisted for one of our open roles, the concerned recruiter will reach out to you.

Best of luck"
"Lead, Data Management","Bengaluru, Karnataka",Covance,None,Organic,"Job Overview:
Covance’s Global Specimen Solutions (GSS) business provides specialty services in the holistic specimen tracking space. GSS improves translational science in the drug discovery process through industry best practices and a uniquely powerful pipeline data management analytics solution. GSS reduces the time, cost and risk of specimen based research, while building robust, healthy data pipelines that optimize research opportunities.

Job Summary

Data Manager responsibilities include engaging the client team during startup and working with the client’s vendors to obtain data required to meet the key objectives. They will document data transfer agreements with vendors and create transfer specifications utilized to support coding and data mapping for the agreed transfers. Interacts with the internal Project Managers to coordinate and fulfill requests related to protocol-specific data management requests.

A. Responsibilities/Duties

Individual Contributor

C. Essential Job Duties:
Collaborate with clients and vendors to finalize Data Transfer Agreements (DTA)
Provide recommendations and alternatives to optimize data quality.
Perform analysis of test transfers to determine create coding specifications including any data translation/mapping needs
Define data mapping required to successfully import data.
Convey implications of data transfer inadequacies to the client.
Create standard data transfer format(s) in compliance with client requests while adhering to internal processes.
Act as a data liaison between Data Management and all other GSS departments.
Support data discrepancy investigation and resolution including root cause analysis and, if internal in nature, identification of corrective and preventative actions
Oversees the integrity and maintenance of client data
Participates in client-related meetings
Assist in the creation and distribution of reports on clinical study data for assigned clients/studies.
Collaborate with Project Management proactively and reactively regarding study questions.
Escalate potential risks or issues to appropriate management or team members
Performs other tasks as required
Education/Qualifications:
BS/BA four-year degree or equivalent education, or 4 years Data Management and/or Clinical Trials experience. Experience:
Strong organizational, planning and critical-thinking skills.
Well-polished, inclusive, and engaging communication skills (written and verbal).
Strong negotiation skills to facilitate, guide, influence, and produce a unified approach within a global, cross-functional environment.
Ability to handle multiple tasks in a timely and professional manner under demanding conditions.
Ability to use standard Microsoft suite of software products.
Conversant with databases and database terminology.
Strong technical aptitude.
Data Management and/or Clinical Trials experience."
Data Scientist – 2 Positions,"Aundh, Pune, Maharashtra",TeamPlus Staffing Solution Pvt Ltd,None,Organic,"Gender : Male/Female
Industry : IT – Software
Job Role & Responsibilities:
2-4 years of experience in the field of Data Science / Machine Learning.
Should have built and deployed models at scale.
In-depth knowledge of Time Series Modelling, LSTMs, Regression techniques, Decision
trees. Classification algorithms like Neural Nets, SVMs. Clustering algorithms like KNNs,
Expectation Maximising algorithms, Fuzzy models – FCM.
Experience writing SQL queries and handling large amounts of data.
Experience bringing models in production.
Experience with AWS Athena, AWS Sagemaker, and other AWS services like EC2, S3, Lambda
(or other equivalent services from another Cloud platform)
Good written and oral communication skills.
Skills:
Knowledge of Data Engineering
Good to have knowledge of deep learning algorithms like RNNs, CNNs etc.
Good to have knowledge of TensorFlow, PyTorch, PySpark, MXNET etc
Joining : At the earliest"
Applications Devl Spec 2,"Bengaluru, Karnataka",IQVIA,None,Organic,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
Primary role will be to part of the integration team, responsible for development, unit testing and delivery of high-quality modules/software/patches with first time right philosophy. The ideal candidate should be well versed in creating solutions for large projects/products.
Key responsibilities -
Quick learning on the key skills required.
Good team player but independent enough to work as an individual contributor.
Should technically sound enough to handle end-to-end project activity independently.
Quick ramp up on the existing product/process and develop solution at a faster speed.
Take responsibility to identify stories from epics.
Take responsibility to write unit test case and execute them.
To participate in reviews of input docs like functional specification.
To identify HW/SW/tools required and, if required, setting environment.
Proactively look for automation and tuning opportunities and drive them.
Keeping all stakeholder appraised about all the important technical issues, progress and status.
To participate in a regular internal progress follow-up of the project with leads and other managers and provide honest and clear updates.
To participate in audits.
Confident and good communicator.
Technical Skills Required:
Qualification – B.Tech, MCA, B. Sc. (Comp. Sc. Or IT)
Essential -
Should have sound knowledge of Mulesoft, Anypoint Studio and REST APIs.
Strong in at least one programming language – Java or Python preferred.
Strong knowledge and hands-on at least one RDBMS (Oracle preferred).
Desirable -
Prior work experience on Pharma industry or Pharma datasets.
Experience on integration tools other than Mulesoft.
Working knowledge on SFDC or SAP.
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning."
Software Engineer - Equity Derivatives,"Bengaluru, Karnataka",Goldman Sachs,None,Organic,"MORE ABOUT THIS JOB:
GLOBAL MARKETS
Our core value is building strong relationships with our institutional clients, which include corporations, financial service providers, and fund managers. We help them buy and sell financial products on exchanges around the world, raise funding, and manage risk. This is a dynamic, entrepreneurial team with a passion for the markets, with individuals who thrive in fast-paced, changing environments and are energized by a bustling trading floor.
Your Impact:
The Equity Derivatives Engineering team is a front-office business facing team responsible for development of critical applications and infrastructure for the Equity Derivatives business. We work closely with trading, quants, structuring, ops and other teams in a dynamic and fast-paced environment. The team is involved in the full project lifecycle (analysis, design, development, release, support) across a wide variety of projects including new business initiatives, automation, efficiency, analytics and controls.

RESPONSIBILITIES AND QUALIFICATIONS:
Responsibilities

This is an exciting opportunity to join an expanding team leveraging technology to transform the way we conduct derivatives business and to deliver the most complex transactions for our clients. The role will be suited to a strong technologist with a keen interest in business workflows, derivative products and financial markets.
The successful candidate will need to:
Develop an in-depth understanding of Equity Derivatives front office business, flows and systems, with particular focus on Exotics, Fund Products and Structured Transactions
Form strong partnerships with trading, operations, quants, and other engineering teams
Drive commercially impactful engineering projects to deliver key desk initiatives
Strive for continuous improvement in the effectiveness and stability of the front office stack
Maintain a strong risk and control mindset to mitigate operational & technology risks
Become proficient in Goldman Sachs’ proprietary database and scripting language (SecDB and Slang) and other languages as necessary
Basic Qualifications
Bachelor’s or Master’s degree in Computer Science, Computer Engineering or related field
Strong technical, analytical and problem-solving skills
Strong programming skills in at least one OO/scripting language (e.g. Java, Python, C++)
Experience working with databases and datasets (modelling, querying)
Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
Excellent verbal/written communication skills and ability to work across teams
Ability to work in a fast paced environment whilst maintaining strong attention to detail
Highly motivated with a strong sense of ownership and desire for impact
Preferred Qualifications
Previous experience in a business-facing, front office engineering role in the finance industry
Knowledge of equities markets and experience with derivatives products such as options, swaps or exotics
ABOUT GOLDMAN SACHS:
ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity"
Senior Data Scientist,"Bengaluru, Karnataka",Noodle.ai,None,Organic,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.
Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning
Manipulate and prepare large, heterogeneous data sets to support advanced analytics
Iteratively conceptualize, design and build data-driven analytical models
Develop processes and tools to monitor and analyze model performance and data accuracy
Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.
Productionalizing machine learning code and interfacing with industry standardmsoftware systems
Understand and manipulate unstructured data from different platforms.
Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value
Qualifications:
Required:

Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems
Good to have:
4+years of experience applying advanced AI techniques to real-world problems
Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)
Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)
Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, etc...)
Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).
Demonstrable familiarity with code and programming concepts.
Knowledge of Spark and/or Hadoop
Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning
Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau
Strong problem solving skills with an emphasis on product development
Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style
Passion for learning and a desire to grow"
Sr Data Monitoring Coordinator,"Bengaluru, Karnataka",Covance,None,Organic,"Job Overview:
Covance’s Global Specimen Solutions (GSS) business provides specialty services in the holistic specimen tracking space. GSS improves translational science in the drug discovery process through industry best practices and a uniquely powerful pipeline data management analytics solution. GSS reduces the time, cost and risk of specimen based research, while building robust, healthy data pipelines that optimize research opportunities.

Job Summary

Performs monitoring of production data feeds including, but not limited to, examining the following File delivery schedule met. Data feed executed to completion correctly. Number of record errors, by category, is within acceptable tolerance by error type. Number of record errors not categorized.
Triages unacceptable errors for resolution. If error matches known error type, with known standard resolution, implement known resolution. Manually re-execute data load for data feeds that have had standard resolutions applied. For unknown errors, investigate to point of understanding resolution, or as far as possible. Escalate findings to Data Monitor Lead. Develop new standard monitoring scripts for unknown errors and develop standard resolutions instructions. Maintains and utilizes a strong knowledge of SOPS and validation work procedures/standards in relation to the System Development Life Cycle.

Essential Job Duties

Function specific
Demonstrate the ability to multi-task and manage data monitor across multiple vendors and client instances. Plan and establish timelines to meet or exceed business expectations for data feed monitoring schedules. Allocate time for investigation and resolution implementation. Strong troubleshooting and analytical skills for identification of errors and resolution steps. Utilize strong working knowledge of SOPs, validation standards, and work procedures to suggest potential improvements and to provide training and guidance to all staff.
Customer Facing
There are no customer facing job functions in this position. Support management of metrics. Assist with investigating or resolving issues of quality as directed.
Staff and Financial Management Understand implications of activities to project budgets.
Process Improvement Suggest process improvements where issues are seen. Support Six Sigma process improvement teams.
Training / SOPs Reviews training materials for staff. Mentor and support other GSS employees in their understanding and adoption of data feed configuration and date point mapping development. Active member of SOP review teams as assigned.
Other Lead or assist with special projects as designated. Perform other duties as assigned by management.

Education/Qualifications:
Minimum Required: BS/BA degree preferably in the sciences or related field, or two (2) years in a data analysis and/or profiling . Experience:
Experience Minimum 6 months to 2 years data informatics and analysis experience or equivalent work experience in a regulated (FDA, EPA, etc.) environment. Strong attention to detail. Strong analytical skills, preferably in a GCP environment. Experience with 21 CFR Part 11 in a pharmaceutical, biotechnology, CRO or related industry. Problem Solving/Logic Skills. Working knowledge of SQL preferred. Experience with data profiling an advantage ¨ Strong communication and interpersonal skills. Working knowledge of SQL and RDMS structures and relationships ¨ Strong MS/Office skills in particular with Excel and Word. Understanding of database query tools, such as DBForge or Navicat, preferred ."
Application Engineer - TM1/Planning Analytics,"Bengaluru, Karnataka",ADCI - Karnataka,None,Organic,"· 5+ years of relevant IBM Cognos TM1/Planning Analytics experience including system configuration, model building and developing reports or dashboards with TM1 · Relevant corporate finance experience exhibiting knowledge of financial planning, budgeting and forecasting functions and related processes · Bachelor's degree in Finance, Accounting, Engineering, Mathematics or other technical discipline
Since early 2006, Amazon Web Services (AWS) has provided companies of all sizes with an infrastructure platform in the cloud. Cloud computing is the kind of major shift in information technology that only comes around once a decade. If you want to be part of history, this is your opportunity. AWS is a high-growth, fast-moving group within Amazon with a start-up mentality where new and diverse challenges arise every day, but a group that operates with the full backing of one of the world’s most successful web companies.

AWS Business Systems seeks an Application Engineer with expertise in the areas of technical design, development, and operational excellence. Solutions must strike the right balance between precision and speed, providing ever more scalable and granular data models and reporting, without sacrificing accuracy or agility. This position requires a high level of technical expertise within IBM Cognos TM1/Planning Analytics.

On the AWS Business Systems team, you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class support is critical to customer success. To support this quickly growing business, you must be highly analytical and possess a strong passion for analytics and accountability, setting high standards, and razor-sharp accuracy. We take working hard, having fun, and making history seriously – you should too!

AWS needs individuals that bring the Corporate Finance experience AND the entrepreneurial aptitude to accelerate decision making and management of the business. Also needed is the intellectual capacity to produce innovative ideas/analysis and the willingness to do the heavy lifting to implement those decisions.

Responsibilities:
Collaborate with business users, development teams, and operation engineering teams to tackle business requirements and deliver against high operational standards of system availability and reliability
Dive deep to resolve problems at their root, looking for failure patterns and suggesting fixes
Prepare runbooks, methods of procedures, tutorials, training videos on best practices for the team
Build monitoring dashboards and creation of critical alarms for the system
Build and enhance software to extend system, application, or tool functionality to improve business processes and meet end user needs while working within the overall system architecture
Diagnose and resolve operational issues, perform detailed root cause analysis, respond to suggestions for enhancements, and create detailed recommendations for solutions to problems that impact code owned by another group
Identify process improvement opportunities to drive innovation
Rotational on-call availability for critical systems support

· Demonstrated history of problem solving, financial acumen, and business collaborating skills · Ability to work independently and self-motivate in a fast-paced and rapidly changing environment · Deal well with ambiguous/undefined problems; ability to think abstractly · Excellent written and verbal communication skills with a customer focused, professional demeanor · Strong scripting skills, e.g., Powershell, Python, Bash, Ruby, Perl, etc. · Familiarity with other IBM software products, including Command Center, SPSS · Experience with design & delivery of formal training curriculum and programs · Proficiency with Microsoft Project, Visio, and SharePoint · Project management, scoping, reporting, and scheduling experience a plus · Master’s degree in Computer Science, Engineering, Math, Finance, Statistics, or a related discipline

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status."
Senior Data Scientist - Credit risk,"Bengaluru, Karnataka",Scienaptic Systems,None,Organic,"Scienaptic is the world's leading AI powered Credit Underwriting platform company. Designed by seasoned Chief Risk Officers, its platform is creating industry leading business impact in terms of lifts such as higher approvals (15-40%) and lower credit losses (10-25%) with all the regulatory explainability. Last year alone, we have helped financial institutions evaluate 45 Million consumers and offer credit to over 15 Million. Scienaptic’s clients include Fortune 100 banks, community banks and Fintechs.
The Data Scientist role will enable you to be at the forefront of latest cutting-edge technology and create a significant and visible business impact for Scienaptic. You will be working with some of the best-in-class Coders, AI/ML Scientist and Business Analytics Consultants in an environment which will encourage you to contribute widely to functional and technological aspects without worrying about conventional job silos.
Responsibilities and Duties
Design, build, test and deploy ML models at scale
Experience with modern machine learning techniques including Ensemble Methods, Deep learning
Write production ready code and deploy real time ML models ; expose ML outputs through APIs
Analyse website and apps effectiveness and recommend changes to content, navigation and design
Hypothesis Testing and Design of experiments to analyse and monitor results
Experience in building digital enquiry generation models, product recommendations on website, marketing response models, social media analytics.
Engineer features to improve decision algorithms
Partner with data/ML engineers and vendor partners for input data pipes development and ML models automation
Skills and competencies
Masters in Computer Science, Mathematical / ML related disciplines with 6+ years of experience into core ML
Solid understanding of probability / statistics / data science / ML along with Python + SQL proficiency
Test of hypotheses and analysis of ML models and optimizing models for accuracy
Experience with Spark or other distributed computing systems for large scale training and prediction of ML models
End to end system design: data analysis, feature engineering, technique selection, implementation, debugging, and maintenance in production
Experience with unstructured data and text mining skillset is a plus
Send your CVs to febina@scienaptic.com"
Deep Learning Engineer,"Bengaluru, Karnataka",Radius AI,"₹30,00,000 a year",Organic,"About Us:
RadiusAI is an early-stage startup that is helping brick & mortar retailers provide a level of experience that surpasses online experiences through AI and video analytics.
About You:
You are driven and passionate about data and making a difference. You are looking to join a promising early-stage startup to have a deep impact. You understand code quality and can take initiatives to improve it. You are always curious, and you are humble about what you already know.
About the Job:
You will work with state-of-the-art technologies at the interface between our engineering and data science teams. You will be responsible for mapping images from a surveillance camera system to a 3D representation, processing and conditioning images for machine learning and developing context and scene understanding algorithms.
Requirements
Masters or PhD preferably in STEM field
Experience with distributed computing
Experience with solving real world problems using bayesian models and statistics
Experience with open source development
Doesn't believe that knowledge has boundaries"
Analyst,"Bengaluru, Karnataka","JPMorgan Chase Bank, N.A.",None,Organic,"Finance Operations is focused on the implementation of production tools and processing activities, including any adjustments, reconciliations, and data validations.
Job responsibilities:
Production support for the Essbase and UNIX environments (such as Daily Exports, Building Rules files, Calculation Scripts, security, scheduled job maintenance, general close/trouble shooting and performing quality control steps to ensure the accuracy of data).
Partner across finance to develop and optimize data mining and analytics for financial trends and initiatives
Aggregate and mine new and existing data sources to make them available for reporting and analytics
Develop clear and concise reports that identify strategic information and provide recommendations for performance improvement
Lead MIS initiatives/ impacts and results discussions
Work within the existing data infrastructure to enhance the data available in our repository and optimize ongoing processes
Partner with finance and MIS teams to ensure the consistency and accuracy of data and reporting
Partner with the business to provide analytical and reporting support throughout the month
Support in month end close cycle and quarterly close process
Support testing and UAT activities for various application. Defect finding and reporting
Flexible across time zones and adapt to business needs and requirements
Must be detail oriented, creative, innovative, and enjoy a fast paced challenging environment. Must enjoy working as a member of a team and possess the ability to work independently.
Experience in relational database platforms such as SQL, Programming Skills like Shell Scripts, Perl, Python is a required plus. Aptitude to learn new technologies is a must.
Partner with Technology and various project teams designing new processes for implementation
Work in an Agile work stream while meeting program goals and deadlines
Support the operations team through the continuous on-boarding of strategic deliverables
Engage with line of business, operations, and project partners to gather process improvements
Manage relations, communicating and presenting to various levels of stakeholders
Solve for operational deficiencies by developing systemic or operational solutions
Develop knowledge of the architecture and technical aspects of the infrastructure
Escalate issues as needed to the appropriate team(s) and management

Qualifications:
Bachelor's degree in Computer Science or related major (i.e. Computer Science, Information Systems etc.,) plus 3 year of experience or 5 years of relevant work experience will be required.
The following will be heavily relied upon but may vary depending upon experience:
Minimum 5+ years of relevant Essbase work experience
Minimum 2+ years of experience in UNIX Environment
Minimum 2+ years of experience in Automation Tools like Control-M
Strong financial/business analytical skills
Ability to work independently and efficiently.
Proven background with systems support and direct contact with users to resolve issues with financial business application
Project Management exposure
Strong verbal and written communication skills, with the ability to present information at varying levels of detail, depending on the audience, in a concise manner
Enthusiastic, self-motivated, effective under pressure
Able to develop, clearly present, and draw conclusions"
QA Engineer API/Backend Systems (NOT a Permanent F/T positio...,"Bengaluru, Karnataka",Applause,"₹4,50,000 - ₹8,00,000 a year",Organic,"IMPORTANT: This is NOT a Permanent F/T position
Are you an experienced QA Tester interested in working with Applause as we engage a global client in the Banking & Financial Services sector for a multi-year project?
We’re looking for interested QA Engineers/Testers/Analysts who bring a solid depth of experience in software QA manual testing of midrange, backend systems, along with a technical background in testing of APIs and data validations/verifications. As this is a highly data-intensive role, strong attention to detail is a must!
If you’ve gotten this far and are still interested in this type of opportunity, review the terms, responsibilities and qualifications below to see if this a great fit, and then… Apply!
-------------------------------------------------------------------------------------------------------
*NOTE: This response survey must be filled out for consideration: https://bit.ly/3jhhWUC
**NOTE: If your rate requirement exceeds the indicated range below, do NOT apply
-------------------------------------------------------------------------------------------------------
Prerequisites (REQUIREMENTS to take part in the interview: selection process):
*Complete response survey noted above
Attend video conference screening and technical rounds
Consent to background checks and associated screens
Terms:
Duration - 12 months (open-ended with multi-year expectations)
Work type - Freelance (potentially contract)
Location - Remote but must be India-based
**Rate - 4 to 8 lakh rupees maximum annual depending on experience, skills
Work hours - 8:00 AM to 6:00 PM IST OR 3:00 PM to 12:00 AM IST shift
Capacity - Up to 40 hours per week
Day-to-day Responsibilities:
API testing using SoapUI, Postman, REST Assured
SQL queries against rDBMS for data validations/verifications
Perform manual functional test case driven and exploratory testing
Develop and revise test plan and test case documentation
Document, report and escalate priority defects; retest status for patched bugs
Attend related Scrum stand-ups and team meetings
Must-have Qualifications & Experience:
B.S. degree in Computer Science, Engineering or related field
2 to 5 years experience in a formal software role such as QA Engineer, Analyst, Tester
2+ years of API testing using SoapUI, Postman, REST Assured
1+ years SQL experience writing and running queries against relational databases
1+ years of UNIX/Linux experience
Software QA testing methodology knowledge
Experience with Waterfall / Agile development methodologies
Good English communication skills, both spoken and written
Self-starter who can take initiative, work with minimal supervision and begin projects independently
Attend related Scrum stand-ups and team meetings
Preferred:
Core Java, J2EE technology experience
Banking, Financial Services or Insurance domain experience
Job Types: Full-time, Contract
Pay: ₹450,000.00 - ₹800,000.00 per year
Experience:
API testing: 2 years (Required)
Software QA: 2 years (Required)
SQL query: 2 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Yes"
